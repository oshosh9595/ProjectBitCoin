{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] 과거 주가 정보 수집\n",
    "- [ ] 시계열 예측을 위한 데이터셋 형식 구성\n",
    "- [ ] 회귀 모델을 사용해 미래 주가 예측\n",
    "- [ ] LSTM 예측\n",
    "- [ ] LSTM 성능 향상\n",
    "- [ ] Tensorboard에 성능 시각화\n",
    "\n",
    "> 함수들은 tools.py 안에 정리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 균일한 노이즈가 추가된 코사인파\n",
    "import numpy as np\n",
    "\n",
    "def fetch_cosine_values(seq_len, frequency=0.1, noise=0.1):\n",
    "    np.random.seed(101) # 실험 복제\n",
    "    x = np.arange(0.0, seq_len, 1.0)\n",
    "    return np.cos(2 * np.pi * frequency * x) + np.random.uniform(low=noise, high=noise, size=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1         0.90901699  0.40901699 -0.20901699 -0.70901699 -0.9\n",
      " -0.70901699 -0.20901699  0.40901699  0.90901699]\n"
     ]
    }
   ],
   "source": [
    "# 코사인파 출력\n",
    "print(fetch_cosine_value(10, frequancy=0.1)) # 10개의 점, 0.1 크기의 잡음(∴주기 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2897179740.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    curl \"https://quandl.com/api/v3/datasets/WIKI/FB/data.csv\"\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Quandl API 활용하기\n",
    "curl \"https://quandl.com/api/v3/datasets/WIKI/FB/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quandl API로 종목 데이터 가져오기\n",
    "import os\n",
    "import pickle\n",
    "import quandl\n",
    "\n",
    "# string to datetime format\n",
    "def date_obj_to_str(date_obj):\n",
    "    return date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "# path에 pickle 저장\n",
    "def save_pickle(something, path):\n",
    "    if not os.path.exists(os.path.dirname(path)):\n",
    "        os.makedirs(os.path.dirname(path))\n",
    "    with open(path, 'wb') as fh:\n",
    "        pickle.dump(something, fh, pickle.DEFAULT_PROTOCOL)\n",
    "\n",
    "# load pickle, return object\n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as fh:\n",
    "      return pickle.load(fh)\n",
    "\n",
    "def fetch_stock_price(symbol,\n",
    "                      from_date,\n",
    "                      to_date,\n",
    "                      cache_path=\"./tmp/prices/\"):\n",
    "    assert(from_date <= to_date)\n",
    "    filename = \"{}_{}_{}.pk\".format(symbol, str(from_date), str(to_date))\n",
    "    price_filepath = os.path.join(cache_path, filename)\n",
    "    try:\n",
    "        prices = load_pickle(price_filepath)\n",
    "        print(\"loaded from\", price_filepath)\n",
    "    except IOError:\n",
    "        historic = quandl.get(\"WIKI/\" + symbol,\n",
    "                              start_date = date_obj_to_str(from_date),\n",
    "                              end_date = date_obj_to_str(to_date))\n",
    "        prices = historic[\"Adj. Close\"].tolist()\n",
    "        save_pickle(prices, price_filepath)\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(fetch_stock_price(\"MSFT\",\n",
    "                        datetime.date(2021, 1, 1),\n",
    "                        datetime.date(2022, 1, 31)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 포맷 구성\n",
    "- 특징 개수에 변화를 주는 대신 관측값의 크기를 고정시켜 미리 정의되지 않은 시계열 데이터의 추적 기간 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_dataset(values, temporal_features):\n",
    "    feat_splits = [values[i:i + temporal_features] for i in range(len(values) - temporal_features)]\n",
    "    feats = np.vstack(feat_splits)\n",
    "    labels = np.array(values[temporal_features:])\n",
    "    return feats, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시계열 데이터와 특징 크기가 주어지면, 시계열 데이터를 훑어 내려가는 슬라이딩 윈도우를 생성하고 특징과 레이블(반복할 때마다 슬라이딩 윈도우 끝에 따라오는 값)을 만든다. 마지막으로 모든 관측값은 레이블과 함께 세로로 연결된다.\n",
    "- 결과는 정해진 개수의 열을 갖는 관측값과 레이블 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw cosine graph\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tools import fetch_cosine_values, fetch_stock_price, format_dataset\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "cos_values = fetch_cosine_values(20, frequency=0.1)\n",
    "seaborn.lineplot(x=range(len(cos_values)), y=cos_values)\n",
    "plt.xlabel(\"Days since start of the experiment\")\n",
    "plt.ylabel(\"Value of the cosine function\")\n",
    "plt.title(\"Cosine time series over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코사인 그래프를 ML 알고리즘에서 받아들일 수 있는 형식으로 바꿔서 5개의 열을 갖는 관측 행렬을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch_cos_X.shape= (15, 5)\n",
      "minibatch_cos_y.shape= (15,)\n"
     ]
    }
   ],
   "source": [
    "features_size = 5\n",
    "minibatch_cos_X, minibatch_cos_y = format_dataset(cos_values, features_size)\n",
    "print(\"minibatch_cos_X.shape=\", minibatch_cos_X.shape)\n",
    "print(\"minibatch_cos_y.shape=\", minibatch_cos_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 관측: X=[ 1.1   0.91  0.41 -0.21 -0.71] y=-0.9\n",
      "1 관측: X=[ 0.91  0.41 -0.21 -0.71 -0.9 ] y=-0.7090169943749475\n",
      "2 관측: X=[ 0.41 -0.21 -0.71 -0.9  -0.71] y=-0.20901699437494756\n",
      "3 관측: X=[-0.21 -0.71 -0.9  -0.71 -0.21] y=0.4090169943749472\n",
      "4 관측: X=[-0.71 -0.9  -0.71 -0.21  0.41] y=0.9090169943749473\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samples_to_plot = 5\n",
    "f, axarr = plt.subplots(samples_to_plot, sharex=True)\n",
    "for i in range(samples_to_plot):\n",
    "    feats = minibatch_cos_X[i, :]\n",
    "    label = minibatch_cos_y[i]\n",
    "    print(\"{} 관측: X={} y={}\".format(i, feats, label))\n",
    "    plt.subplot(samples_to_plot, 1, i+1)\n",
    "    axarr[i].plot(range(i, features_size + i), feats, '--o')\n",
    "    axarr[i].plot([features_size + i], label, 'rx')\n",
    "    axarr[i].set_ylim([-1.1, 1.1])\n",
    "plt.xlabel(\"Days since start of the experiment\")\n",
    "axarr[2].set_ylabel(\"Value of the cosine function\")\n",
    "axarr[0].set_title(\"Visualization of some observations: Features (blue) and Labels (red)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 시계열이 관측 벡터가 되고 각 벡터의 크기는 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 주가 그래프 확인\n",
    "symbols = [\"MSFT\", \"KO\", \"AAL\", \"MMM\", \"AXP\", \"GE\", \"GM\", \"JPM\", \"UPS\"]\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "for sym in symbols:\n",
    "    prices = fetch_stock_price(sym, datetime.date(2015, 1, 1), datetime.date(2022, 12, 31))\n",
    "    ax.plot(range(len(prices)), prices, label=sym)\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "plt.xlabel(\"Trading days since 2015-1-1\")\n",
    "plt.ylabel(\"Stock price [$]\")\n",
    "plt.title(\"Prices of some US Stock in trading days of 2015 and 2022\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 모델을 이용한 미래 주가 예측\n",
    "> 문제를 회귀 문제로 다루게 되면 알고리즘은 각 특징이 독립적이라고 간주해야 한다. 그러나 여기서 시계열 데이터는 슬라이딩 윈도우로 서로 상관되어 있다. 어쨋든 각 특징이 독립적이라고 가정하고 회귀모델을 사용한 예측을 실행해 본 후, 시간적 상관관계를 활용해 성능을 향상시켜본다.\n",
    "- MSE, MAE 출력\n",
    "- 성능확인(훈련, 테스트, 예측)\n",
    "- 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\works\\time-series-da\\venv\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1/20000 - Train Loss: 4018.3635 - Test Loss: 5951.1675 - MSE: 5951.1670 - MAE: 76.8886\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2/20000 - Train Loss: 3836.3154 - Test Loss: 5671.4746 - MSE: 5671.4746 - MAE: 75.0478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3/20000 - Train Loss: 3658.7034 - Test Loss: 5398.8599 - MSE: 5398.8599 - MAE: 73.2090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4/20000 - Train Loss: 3485.5984 - Test Loss: 5133.4282 - MSE: 5133.4287 - MAE: 71.3731\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5/20000 - Train Loss: 3317.0596 - Test Loss: 4875.2695 - MSE: 4875.2690 - MAE: 69.5411\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6/20000 - Train Loss: 3153.1433 - Test Loss: 4624.4678 - MSE: 4624.4678 - MAE: 67.7138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7/20000 - Train Loss: 2993.8965 - Test Loss: 4381.0938 - MSE: 4381.0942 - MAE: 65.8923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8/20000 - Train Loss: 2839.3618 - Test Loss: 4145.2090 - MSE: 4145.2095 - MAE: 64.0773\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 9/20000 - Train Loss: 2689.5740 - Test Loss: 3916.8623 - MSE: 3916.8618 - MAE: 62.2700\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10/20000 - Train Loss: 2544.5591 - Test Loss: 3696.0903 - MSE: 3696.0898 - MAE: 60.4713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11/20000 - Train Loss: 2404.3372 - Test Loss: 3482.9182 - MSE: 3482.9182 - MAE: 58.6822\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12/20000 - Train Loss: 2268.9202 - Test Loss: 3277.3594 - MSE: 3277.3599 - MAE: 56.9037\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13/20000 - Train Loss: 2138.3113 - Test Loss: 3079.4128 - MSE: 3079.4128 - MAE: 55.1369\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14/20000 - Train Loss: 2012.5054 - Test Loss: 2889.0635 - MSE: 2889.0632 - MAE: 53.3828\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 15/20000 - Train Loss: 1891.4902 - Test Loss: 2706.2864 - MSE: 2706.2861 - MAE: 51.6424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 16/20000 - Train Loss: 1775.2451 - Test Loss: 2531.0415 - MSE: 2531.0415 - MAE: 49.9168\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 17/20000 - Train Loss: 1663.7397 - Test Loss: 2363.2744 - MSE: 2363.2742 - MAE: 48.2069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 18/20000 - Train Loss: 1556.9376 - Test Loss: 2202.9194 - MSE: 2202.9199 - MAE: 46.5139\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 19/20000 - Train Loss: 1454.7927 - Test Loss: 2049.8984 - MSE: 2049.8984 - MAE: 44.8387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 20/20000 - Train Loss: 1357.2520 - Test Loss: 1904.1193 - MSE: 1904.1193 - MAE: 43.1824\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 21/20000 - Train Loss: 1264.2528 - Test Loss: 1765.4763 - MSE: 1765.4762 - MAE: 41.5459\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 22/20000 - Train Loss: 1175.7271 - Test Loss: 1633.8547 - MSE: 1633.8547 - MAE: 39.9303\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 23/20000 - Train Loss: 1091.5981 - Test Loss: 1509.1263 - MSE: 1509.1263 - MAE: 38.3365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 24/20000 - Train Loss: 1011.7833 - Test Loss: 1391.1528 - MSE: 1391.1530 - MAE: 36.7655\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 25/20000 - Train Loss: 936.1925 - Test Loss: 1279.7845 - MSE: 1279.7847 - MAE: 35.2181\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 26/20000 - Train Loss: 864.7293 - Test Loss: 1174.8621 - MSE: 1174.8622 - MAE: 33.6954\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 27/20000 - Train Loss: 797.2921 - Test Loss: 1076.2178 - MSE: 1076.2178 - MAE: 32.1981\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 28/20000 - Train Loss: 733.7725 - Test Loss: 983.6738 - MSE: 983.6736 - MAE: 30.7272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 29/20000 - Train Loss: 674.0591 - Test Loss: 897.0460 - MSE: 897.0461 - MAE: 29.2833\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 30/20000 - Train Loss: 618.0339 - Test Loss: 816.1419 - MSE: 816.1419 - MAE: 27.8674\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 31/20000 - Train Loss: 565.5765 - Test Loss: 740.7643 - MSE: 740.7643 - MAE: 26.4802\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 32/20000 - Train Loss: 516.5617 - Test Loss: 670.7095 - MSE: 670.7096 - MAE: 25.1222\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 33/20000 - Train Loss: 470.8620 - Test Loss: 605.7693 - MSE: 605.7693 - MAE: 23.7943\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 34/20000 - Train Loss: 428.3480 - Test Loss: 545.7326 - MSE: 545.7326 - MAE: 22.4970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 35/20000 - Train Loss: 388.8871 - Test Loss: 490.3854 - MSE: 490.3853 - MAE: 21.2309\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 36/20000 - Train Loss: 352.3462 - Test Loss: 439.5107 - MSE: 439.5107 - MAE: 19.9965\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 37/20000 - Train Loss: 318.5909 - Test Loss: 392.8916 - MSE: 392.8917 - MAE: 18.7943\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 38/20000 - Train Loss: 287.4872 - Test Loss: 350.3109 - MSE: 350.3108 - MAE: 17.6246\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 39/20000 - Train Loss: 258.9010 - Test Loss: 311.5523 - MSE: 311.5523 - MAE: 16.4879\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 40/20000 - Train Loss: 232.6982 - Test Loss: 276.4001 - MSE: 276.4000 - MAE: 15.3845\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 41/20000 - Train Loss: 208.7470 - Test Loss: 244.6413 - MSE: 244.6412 - MAE: 14.3145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 42/20000 - Train Loss: 186.9165 - Test Loss: 216.0660 - MSE: 216.0660 - MAE: 13.2783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 43/20000 - Train Loss: 167.0787 - Test Loss: 190.4684 - MSE: 190.4684 - MAE: 12.2853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 44/20000 - Train Loss: 149.1075 - Test Loss: 167.6471 - MSE: 167.6471 - MAE: 11.3704\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 45/20000 - Train Loss: 132.8798 - Test Loss: 147.4047 - MSE: 147.4047 - MAE: 10.5252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 46/20000 - Train Loss: 118.2764 - Test Loss: 129.5508 - MSE: 129.5508 - MAE: 9.7239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 47/20000 - Train Loss: 105.1808 - Test Loss: 113.9001 - MSE: 113.9001 - MAE: 8.9527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 48/20000 - Train Loss: 93.4812 - Test Loss: 100.2743 - MSE: 100.2743 - MAE: 8.2819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 49/20000 - Train Loss: 83.0695 - Test Loss: 88.5023 - MSE: 88.5023 - MAE: 7.7374\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 50/20000 - Train Loss: 73.8424 - Test Loss: 78.4201 - MSE: 78.4201 - MAE: 7.2883\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 51/20000 - Train Loss: 65.7005 - Test Loss: 69.8709 - MSE: 69.8709 - MAE: 6.9128\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 52/20000 - Train Loss: 58.5499 - Test Loss: 62.7066 - MSE: 62.7066 - MAE: 6.5541\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 53/20000 - Train Loss: 52.3007 - Test Loss: 56.7862 - MSE: 56.7862 - MAE: 6.2591\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 54/20000 - Train Loss: 46.8687 - Test Loss: 51.9775 - MSE: 51.9775 - MAE: 6.0611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 55/20000 - Train Loss: 42.1740 - Test Loss: 48.1560 - MSE: 48.1560 - MAE: 5.9252\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 56/20000 - Train Loss: 38.1419 - Test Loss: 45.2056 - MSE: 45.2056 - MAE: 5.8157\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 57/20000 - Train Loss: 34.7025 - Test Loss: 43.0180 - MSE: 43.0180 - MAE: 5.7203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 58/20000 - Train Loss: 31.7908 - Test Loss: 41.4929 - MSE: 41.4929 - MAE: 5.6506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 59/20000 - Train Loss: 29.3466 - Test Loss: 40.5382 - MSE: 40.5382 - MAE: 5.5848\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 60/20000 - Train Loss: 27.3140 - Test Loss: 40.0689 - MSE: 40.0689 - MAE: 5.5228\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 61/20000 - Train Loss: 25.6421 - Test Loss: 40.0076 - MSE: 40.0076 - MAE: 5.4646\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 62/20000 - Train Loss: 24.2840 - Test Loss: 40.2840 - MSE: 40.2840 - MAE: 5.4330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 63/20000 - Train Loss: 23.1970 - Test Loss: 40.8348 - MSE: 40.8348 - MAE: 5.4229\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 64/20000 - Train Loss: 22.3426 - Test Loss: 41.6029 - MSE: 41.6029 - MAE: 5.4386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 65/20000 - Train Loss: 21.6860 - Test Loss: 42.5378 - MSE: 42.5378 - MAE: 5.4829\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 66/20000 - Train Loss: 21.1960 - Test Loss: 43.5946 - MSE: 43.5946 - MAE: 5.5239\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 67/20000 - Train Loss: 20.8447 - Test Loss: 44.7338 - MSE: 44.7338 - MAE: 5.5725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 68/20000 - Train Loss: 20.6076 - Test Loss: 45.9213 - MSE: 45.9213 - MAE: 5.6211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 69/20000 - Train Loss: 20.4629 - Test Loss: 47.1277 - MSE: 47.1277 - MAE: 5.6770\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 70/20000 - Train Loss: 20.3917 - Test Loss: 48.3280 - MSE: 48.3280 - MAE: 5.7298\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 71/20000 - Train Loss: 20.3776 - Test Loss: 49.5012 - MSE: 49.5012 - MAE: 5.7777\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 72/20000 - Train Loss: 20.4065 - Test Loss: 50.6300 - MSE: 50.6300 - MAE: 5.8215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 73/20000 - Train Loss: 20.4663 - Test Loss: 51.7006 - MSE: 51.7006 - MAE: 5.8693\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 74/20000 - Train Loss: 20.5471 - Test Loss: 52.7022 - MSE: 52.7022 - MAE: 5.9173\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 75/20000 - Train Loss: 20.6405 - Test Loss: 53.6264 - MSE: 53.6264 - MAE: 5.9624\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 76/20000 - Train Loss: 20.7395 - Test Loss: 54.4676 - MSE: 54.4676 - MAE: 6.0021\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 77/20000 - Train Loss: 20.8388 - Test Loss: 55.2220 - MSE: 55.2220 - MAE: 6.0368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 78/20000 - Train Loss: 20.9340 - Test Loss: 55.8879 - MSE: 55.8879 - MAE: 6.0666\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 79/20000 - Train Loss: 21.0219 - Test Loss: 56.4651 - MSE: 56.4651 - MAE: 6.0920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 80/20000 - Train Loss: 21.1001 - Test Loss: 56.9544 - MSE: 56.9544 - MAE: 6.1132\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 81/20000 - Train Loss: 21.1671 - Test Loss: 57.3583 - MSE: 57.3583 - MAE: 6.1304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 82/20000 - Train Loss: 21.2220 - Test Loss: 57.6798 - MSE: 57.6798 - MAE: 6.1440\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 83/20000 - Train Loss: 21.2643 - Test Loss: 57.9227 - MSE: 57.9227 - MAE: 6.1542\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 84/20000 - Train Loss: 21.2941 - Test Loss: 58.0917 - MSE: 58.0917 - MAE: 6.1612\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 85/20000 - Train Loss: 21.3118 - Test Loss: 58.1913 - MSE: 58.1913 - MAE: 6.1654\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 86/20000 - Train Loss: 21.3181 - Test Loss: 58.2271 - MSE: 58.2271 - MAE: 6.1668\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 87/20000 - Train Loss: 21.3139 - Test Loss: 58.2042 - MSE: 58.2042 - MAE: 6.1659\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 88/20000 - Train Loss: 21.3001 - Test Loss: 58.1280 - MSE: 58.1280 - MAE: 6.1627\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 89/20000 - Train Loss: 21.2779 - Test Loss: 58.0039 - MSE: 58.0039 - MAE: 6.1575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 90/20000 - Train Loss: 21.2485 - Test Loss: 57.8375 - MSE: 57.8375 - MAE: 6.1506\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 91/20000 - Train Loss: 21.2129 - Test Loss: 57.6339 - MSE: 57.6339 - MAE: 6.1420\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 92/20000 - Train Loss: 21.1724 - Test Loss: 57.3980 - MSE: 57.3980 - MAE: 6.1320\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 93/20000 - Train Loss: 21.1281 - Test Loss: 57.1348 - MSE: 57.1348 - MAE: 6.1208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 94/20000 - Train Loss: 21.0810 - Test Loss: 56.8486 - MSE: 56.8486 - MAE: 6.1085\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 95/20000 - Train Loss: 21.0321 - Test Loss: 56.5438 - MSE: 56.5438 - MAE: 6.0953\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 96/20000 - Train Loss: 20.9822 - Test Loss: 56.2244 - MSE: 56.2244 - MAE: 6.0814\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 97/20000 - Train Loss: 20.9322 - Test Loss: 55.8941 - MSE: 55.8941 - MAE: 6.0668\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 98/20000 - Train Loss: 20.8827 - Test Loss: 55.5561 - MSE: 55.5561 - MAE: 6.0517\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 99/20000 - Train Loss: 20.8344 - Test Loss: 55.2136 - MSE: 55.2136 - MAE: 6.0362\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 100/20000 - Train Loss: 20.7877 - Test Loss: 54.8693 - MSE: 54.8693 - MAE: 6.0205\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 101/20000 - Train Loss: 20.7430 - Test Loss: 54.5256 - MSE: 54.5256 - MAE: 6.0047\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 102/20000 - Train Loss: 20.7007 - Test Loss: 54.1848 - MSE: 54.1848 - MAE: 5.9888\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 103/20000 - Train Loss: 20.6610 - Test Loss: 53.8488 - MSE: 53.8488 - MAE: 5.9729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 104/20000 - Train Loss: 20.6241 - Test Loss: 53.5191 - MSE: 53.5191 - MAE: 5.9571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 105/20000 - Train Loss: 20.5900 - Test Loss: 53.1973 - MSE: 53.1973 - MAE: 5.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 106/20000 - Train Loss: 20.5588 - Test Loss: 52.8846 - MSE: 52.8846 - MAE: 5.9262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 107/20000 - Train Loss: 20.5306 - Test Loss: 52.5820 - MSE: 52.5820 - MAE: 5.9112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 108/20000 - Train Loss: 20.5051 - Test Loss: 52.2902 - MSE: 52.2902 - MAE: 5.8966\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 109/20000 - Train Loss: 20.4825 - Test Loss: 52.0100 - MSE: 52.0100 - MAE: 5.8825\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 110/20000 - Train Loss: 20.4625 - Test Loss: 51.7419 - MSE: 51.7419 - MAE: 5.8709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 111/20000 - Train Loss: 20.4449 - Test Loss: 51.4861 - MSE: 51.4861 - MAE: 5.8596\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 112/20000 - Train Loss: 20.4297 - Test Loss: 51.2431 - MSE: 51.2431 - MAE: 5.8489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 113/20000 - Train Loss: 20.4166 - Test Loss: 51.0128 - MSE: 51.0128 - MAE: 5.8386\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 114/20000 - Train Loss: 20.4056 - Test Loss: 50.7955 - MSE: 50.7955 - MAE: 5.8287\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 115/20000 - Train Loss: 20.3963 - Test Loss: 50.5908 - MSE: 50.5908 - MAE: 5.8194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 116/20000 - Train Loss: 20.3885 - Test Loss: 50.3988 - MSE: 50.3988 - MAE: 5.8119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 117/20000 - Train Loss: 20.3823 - Test Loss: 50.2193 - MSE: 50.2193 - MAE: 5.8051\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 118/20000 - Train Loss: 20.3772 - Test Loss: 50.0520 - MSE: 50.0520 - MAE: 5.7987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 119/20000 - Train Loss: 20.3733 - Test Loss: 49.8967 - MSE: 49.8967 - MAE: 5.7927\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 120/20000 - Train Loss: 20.3702 - Test Loss: 49.7530 - MSE: 49.7530 - MAE: 5.7871\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 121/20000 - Train Loss: 20.3680 - Test Loss: 49.6206 - MSE: 49.6206 - MAE: 5.7819\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 122/20000 - Train Loss: 20.3664 - Test Loss: 49.4991 - MSE: 49.4991 - MAE: 5.7771\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 123/20000 - Train Loss: 20.3653 - Test Loss: 49.3883 - MSE: 49.3883 - MAE: 5.7727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 124/20000 - Train Loss: 20.3647 - Test Loss: 49.2874 - MSE: 49.2874 - MAE: 5.7686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 125/20000 - Train Loss: 20.3644 - Test Loss: 49.1962 - MSE: 49.1962 - MAE: 5.7650\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 126/20000 - Train Loss: 20.3643 - Test Loss: 49.1143 - MSE: 49.1143 - MAE: 5.7617\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 127/20000 - Train Loss: 20.3644 - Test Loss: 49.0411 - MSE: 49.0411 - MAE: 5.7587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 128/20000 - Train Loss: 20.3646 - Test Loss: 48.9763 - MSE: 48.9763 - MAE: 5.7560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 129/20000 - Train Loss: 20.3648 - Test Loss: 48.9195 - MSE: 48.9195 - MAE: 5.7537\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 130/20000 - Train Loss: 20.3651 - Test Loss: 48.8701 - MSE: 48.8700 - MAE: 5.7517\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 131/20000 - Train Loss: 20.3654 - Test Loss: 48.8277 - MSE: 48.8277 - MAE: 5.7499\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 132/20000 - Train Loss: 20.3656 - Test Loss: 48.7920 - MSE: 48.7920 - MAE: 5.7485\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 133/20000 - Train Loss: 20.3658 - Test Loss: 48.7625 - MSE: 48.7625 - MAE: 5.7472\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 134/20000 - Train Loss: 20.3659 - Test Loss: 48.7387 - MSE: 48.7387 - MAE: 5.7462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 135/20000 - Train Loss: 20.3660 - Test Loss: 48.7204 - MSE: 48.7204 - MAE: 5.7455\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 136/20000 - Train Loss: 20.3659 - Test Loss: 48.7070 - MSE: 48.7070 - MAE: 5.7449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 137/20000 - Train Loss: 20.3658 - Test Loss: 48.6981 - MSE: 48.6981 - MAE: 5.7445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 138/20000 - Train Loss: 20.3656 - Test Loss: 48.6935 - MSE: 48.6935 - MAE: 5.7443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 139/20000 - Train Loss: 20.3653 - Test Loss: 48.6926 - MSE: 48.6926 - MAE: 5.7443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 140/20000 - Train Loss: 20.3650 - Test Loss: 48.6953 - MSE: 48.6953 - MAE: 5.7444\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 141/20000 - Train Loss: 20.3646 - Test Loss: 48.7011 - MSE: 48.7011 - MAE: 5.7446\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 142/20000 - Train Loss: 20.3642 - Test Loss: 48.7098 - MSE: 48.7098 - MAE: 5.7449\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 143/20000 - Train Loss: 20.3637 - Test Loss: 48.7209 - MSE: 48.7209 - MAE: 5.7454\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 144/20000 - Train Loss: 20.3632 - Test Loss: 48.7341 - MSE: 48.7341 - MAE: 5.7459\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 145/20000 - Train Loss: 20.3627 - Test Loss: 48.7493 - MSE: 48.7493 - MAE: 5.7465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 146/20000 - Train Loss: 20.3621 - Test Loss: 48.7661 - MSE: 48.7661 - MAE: 5.7472\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 147/20000 - Train Loss: 20.3615 - Test Loss: 48.7843 - MSE: 48.7843 - MAE: 5.7479\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 148/20000 - Train Loss: 20.3610 - Test Loss: 48.8035 - MSE: 48.8035 - MAE: 5.7487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 149/20000 - Train Loss: 20.3604 - Test Loss: 48.8237 - MSE: 48.8237 - MAE: 5.7495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 150/20000 - Train Loss: 20.3598 - Test Loss: 48.8445 - MSE: 48.8445 - MAE: 5.7504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 151/20000 - Train Loss: 20.3593 - Test Loss: 48.8657 - MSE: 48.8657 - MAE: 5.7512\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 152/20000 - Train Loss: 20.3588 - Test Loss: 48.8873 - MSE: 48.8873 - MAE: 5.7521\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 153/20000 - Train Loss: 20.3582 - Test Loss: 48.9089 - MSE: 48.9089 - MAE: 5.7530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 154/20000 - Train Loss: 20.3577 - Test Loss: 48.9305 - MSE: 48.9305 - MAE: 5.7538\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 155/20000 - Train Loss: 20.3573 - Test Loss: 48.9519 - MSE: 48.9519 - MAE: 5.7547\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 156/20000 - Train Loss: 20.3568 - Test Loss: 48.9729 - MSE: 48.9729 - MAE: 5.7555\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 157/20000 - Train Loss: 20.3563 - Test Loss: 48.9936 - MSE: 48.9936 - MAE: 5.7564\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 158/20000 - Train Loss: 20.3559 - Test Loss: 49.0136 - MSE: 49.0136 - MAE: 5.7572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 159/20000 - Train Loss: 20.3555 - Test Loss: 49.0330 - MSE: 49.0330 - MAE: 5.7579\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 160/20000 - Train Loss: 20.3551 - Test Loss: 49.0517 - MSE: 49.0517 - MAE: 5.7587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 161/20000 - Train Loss: 20.3547 - Test Loss: 49.0696 - MSE: 49.0696 - MAE: 5.7594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 162/20000 - Train Loss: 20.3544 - Test Loss: 49.0866 - MSE: 49.0866 - MAE: 5.7601\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 163/20000 - Train Loss: 20.3540 - Test Loss: 49.1027 - MSE: 49.1027 - MAE: 5.7607\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 164/20000 - Train Loss: 20.3537 - Test Loss: 49.1180 - MSE: 49.1180 - MAE: 5.7613\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 165/20000 - Train Loss: 20.3533 - Test Loss: 49.1322 - MSE: 49.1322 - MAE: 5.7619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 166/20000 - Train Loss: 20.3530 - Test Loss: 49.1455 - MSE: 49.1455 - MAE: 5.7624\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 167/20000 - Train Loss: 20.3527 - Test Loss: 49.1578 - MSE: 49.1578 - MAE: 5.7629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 168/20000 - Train Loss: 20.3524 - Test Loss: 49.1691 - MSE: 49.1691 - MAE: 5.7633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 169/20000 - Train Loss: 20.3521 - Test Loss: 49.1794 - MSE: 49.1794 - MAE: 5.7637\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 170/20000 - Train Loss: 20.3518 - Test Loss: 49.1888 - MSE: 49.1888 - MAE: 5.7641\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 171/20000 - Train Loss: 20.3515 - Test Loss: 49.1972 - MSE: 49.1972 - MAE: 5.7644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 172/20000 - Train Loss: 20.3512 - Test Loss: 49.2047 - MSE: 49.2047 - MAE: 5.7647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 173/20000 - Train Loss: 20.3509 - Test Loss: 49.2112 - MSE: 49.2112 - MAE: 5.7649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 174/20000 - Train Loss: 20.3506 - Test Loss: 49.2169 - MSE: 49.2169 - MAE: 5.7651\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 175/20000 - Train Loss: 20.3503 - Test Loss: 49.2218 - MSE: 49.2218 - MAE: 5.7653\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 176/20000 - Train Loss: 20.3500 - Test Loss: 49.2259 - MSE: 49.2259 - MAE: 5.7655\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 177/20000 - Train Loss: 20.3497 - Test Loss: 49.2292 - MSE: 49.2292 - MAE: 5.7656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 178/20000 - Train Loss: 20.3494 - Test Loss: 49.2318 - MSE: 49.2318 - MAE: 5.7657\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 179/20000 - Train Loss: 20.3490 - Test Loss: 49.2337 - MSE: 49.2337 - MAE: 5.7657\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 180/20000 - Train Loss: 20.3488 - Test Loss: 49.2350 - MSE: 49.2350 - MAE: 5.7658\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 181/20000 - Train Loss: 20.3484 - Test Loss: 49.2356 - MSE: 49.2356 - MAE: 5.7658\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 182/20000 - Train Loss: 20.3481 - Test Loss: 49.2359 - MSE: 49.2359 - MAE: 5.7658\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 183/20000 - Train Loss: 20.3478 - Test Loss: 49.2355 - MSE: 49.2355 - MAE: 5.7657\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 184/20000 - Train Loss: 20.3475 - Test Loss: 49.2348 - MSE: 49.2348 - MAE: 5.7657\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 185/20000 - Train Loss: 20.3472 - Test Loss: 49.2336 - MSE: 49.2336 - MAE: 5.7656\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 186/20000 - Train Loss: 20.3469 - Test Loss: 49.2320 - MSE: 49.2320 - MAE: 5.7655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 187/20000 - Train Loss: 20.3465 - Test Loss: 49.2300 - MSE: 49.2300 - MAE: 5.7655\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 188/20000 - Train Loss: 20.3462 - Test Loss: 49.2279 - MSE: 49.2279 - MAE: 5.7654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 189/20000 - Train Loss: 20.3459 - Test Loss: 49.2255 - MSE: 49.2255 - MAE: 5.7652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 190/20000 - Train Loss: 20.3456 - Test Loss: 49.2228 - MSE: 49.2228 - MAE: 5.7651\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 191/20000 - Train Loss: 20.3452 - Test Loss: 49.2200 - MSE: 49.2200 - MAE: 5.7650\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 192/20000 - Train Loss: 20.3449 - Test Loss: 49.2170 - MSE: 49.2170 - MAE: 5.7649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 193/20000 - Train Loss: 20.3446 - Test Loss: 49.2140 - MSE: 49.2140 - MAE: 5.7647\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 194/20000 - Train Loss: 20.3443 - Test Loss: 49.2109 - MSE: 49.2109 - MAE: 5.7646\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 195/20000 - Train Loss: 20.3439 - Test Loss: 49.2077 - MSE: 49.2077 - MAE: 5.7644\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 196/20000 - Train Loss: 20.3436 - Test Loss: 49.2045 - MSE: 49.2045 - MAE: 5.7643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 197/20000 - Train Loss: 20.3433 - Test Loss: 49.2012 - MSE: 49.2012 - MAE: 5.7641\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 198/20000 - Train Loss: 20.3430 - Test Loss: 49.1980 - MSE: 49.1980 - MAE: 5.7640\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 199/20000 - Train Loss: 20.3426 - Test Loss: 49.1948 - MSE: 49.1948 - MAE: 5.7638\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 200/20000 - Train Loss: 20.3423 - Test Loss: 49.1917 - MSE: 49.1917 - MAE: 5.7637\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 201/20000 - Train Loss: 20.3420 - Test Loss: 49.1886 - MSE: 49.1886 - MAE: 5.7636\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 202/20000 - Train Loss: 20.3416 - Test Loss: 49.1856 - MSE: 49.1856 - MAE: 5.7634\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 203/20000 - Train Loss: 20.3413 - Test Loss: 49.1827 - MSE: 49.1827 - MAE: 5.7633\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 204/20000 - Train Loss: 20.3410 - Test Loss: 49.1798 - MSE: 49.1798 - MAE: 5.7632\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 205/20000 - Train Loss: 20.3406 - Test Loss: 49.1771 - MSE: 49.1771 - MAE: 5.7630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 206/20000 - Train Loss: 20.3403 - Test Loss: 49.1745 - MSE: 49.1745 - MAE: 5.7629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 207/20000 - Train Loss: 20.3400 - Test Loss: 49.1719 - MSE: 49.1719 - MAE: 5.7628\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 208/20000 - Train Loss: 20.3396 - Test Loss: 49.1695 - MSE: 49.1695 - MAE: 5.7627\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 209/20000 - Train Loss: 20.3393 - Test Loss: 49.1672 - MSE: 49.1672 - MAE: 5.7626\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 210/20000 - Train Loss: 20.3390 - Test Loss: 49.1651 - MSE: 49.1651 - MAE: 5.7625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 211/20000 - Train Loss: 20.3386 - Test Loss: 49.1630 - MSE: 49.1630 - MAE: 5.7624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 212/20000 - Train Loss: 20.3383 - Test Loss: 49.1611 - MSE: 49.1611 - MAE: 5.7623\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 213/20000 - Train Loss: 20.3379 - Test Loss: 49.1593 - MSE: 49.1593 - MAE: 5.7622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 214/20000 - Train Loss: 20.3376 - Test Loss: 49.1576 - MSE: 49.1576 - MAE: 5.7621\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 215/20000 - Train Loss: 20.3372 - Test Loss: 49.1560 - MSE: 49.1560 - MAE: 5.7620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 216/20000 - Train Loss: 20.3369 - Test Loss: 49.1546 - MSE: 49.1546 - MAE: 5.7620\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 217/20000 - Train Loss: 20.3365 - Test Loss: 49.1532 - MSE: 49.1532 - MAE: 5.7619\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 218/20000 - Train Loss: 20.3362 - Test Loss: 49.1519 - MSE: 49.1519 - MAE: 5.7618\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 219/20000 - Train Loss: 20.3359 - Test Loss: 49.1507 - MSE: 49.1507 - MAE: 5.7618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 220/20000 - Train Loss: 20.3355 - Test Loss: 49.1496 - MSE: 49.1496 - MAE: 5.7617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 221/20000 - Train Loss: 20.3352 - Test Loss: 49.1486 - MSE: 49.1486 - MAE: 5.7616\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 222/20000 - Train Loss: 20.3348 - Test Loss: 49.1477 - MSE: 49.1477 - MAE: 5.7616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 223/20000 - Train Loss: 20.3345 - Test Loss: 49.1468 - MSE: 49.1468 - MAE: 5.7615\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 224/20000 - Train Loss: 20.3341 - Test Loss: 49.1461 - MSE: 49.1461 - MAE: 5.7615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 225/20000 - Train Loss: 20.3338 - Test Loss: 49.1453 - MSE: 49.1453 - MAE: 5.7614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 226/20000 - Train Loss: 20.3334 - Test Loss: 49.1446 - MSE: 49.1446 - MAE: 5.7614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 227/20000 - Train Loss: 20.3331 - Test Loss: 49.1440 - MSE: 49.1440 - MAE: 5.7613\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 228/20000 - Train Loss: 20.3327 - Test Loss: 49.1434 - MSE: 49.1434 - MAE: 5.7613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 229/20000 - Train Loss: 20.3324 - Test Loss: 49.1428 - MSE: 49.1428 - MAE: 5.7613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 230/20000 - Train Loss: 20.3320 - Test Loss: 49.1422 - MSE: 49.1422 - MAE: 5.7612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 231/20000 - Train Loss: 20.3316 - Test Loss: 49.1418 - MSE: 49.1418 - MAE: 5.7612\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 232/20000 - Train Loss: 20.3313 - Test Loss: 49.1413 - MSE: 49.1413 - MAE: 5.7612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 233/20000 - Train Loss: 20.3309 - Test Loss: 49.1407 - MSE: 49.1407 - MAE: 5.7611\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 234/20000 - Train Loss: 20.3306 - Test Loss: 49.1403 - MSE: 49.1403 - MAE: 5.7611\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 235/20000 - Train Loss: 20.3302 - Test Loss: 49.1398 - MSE: 49.1398 - MAE: 5.7610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 236/20000 - Train Loss: 20.3298 - Test Loss: 49.1393 - MSE: 49.1393 - MAE: 5.7610\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 237/20000 - Train Loss: 20.3295 - Test Loss: 49.1388 - MSE: 49.1388 - MAE: 5.7610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 238/20000 - Train Loss: 20.3291 - Test Loss: 49.1383 - MSE: 49.1383 - MAE: 5.7609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 239/20000 - Train Loss: 20.3287 - Test Loss: 49.1379 - MSE: 49.1379 - MAE: 5.7609\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 240/20000 - Train Loss: 20.3284 - Test Loss: 49.1374 - MSE: 49.1374 - MAE: 5.7609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 241/20000 - Train Loss: 20.3280 - Test Loss: 49.1369 - MSE: 49.1369 - MAE: 5.7608\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 242/20000 - Train Loss: 20.3277 - Test Loss: 49.1364 - MSE: 49.1364 - MAE: 5.7608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 243/20000 - Train Loss: 20.3273 - Test Loss: 49.1359 - MSE: 49.1359 - MAE: 5.7607\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 244/20000 - Train Loss: 20.3269 - Test Loss: 49.1353 - MSE: 49.1353 - MAE: 5.7607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 245/20000 - Train Loss: 20.3265 - Test Loss: 49.1347 - MSE: 49.1347 - MAE: 5.7607\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 246/20000 - Train Loss: 20.3262 - Test Loss: 49.1342 - MSE: 49.1342 - MAE: 5.7606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 247/20000 - Train Loss: 20.3258 - Test Loss: 49.1336 - MSE: 49.1336 - MAE: 5.7606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 248/20000 - Train Loss: 20.3254 - Test Loss: 49.1330 - MSE: 49.1330 - MAE: 5.7605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 249/20000 - Train Loss: 20.3251 - Test Loss: 49.1323 - MSE: 49.1323 - MAE: 5.7605\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 250/20000 - Train Loss: 20.3247 - Test Loss: 49.1317 - MSE: 49.1317 - MAE: 5.7604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 251/20000 - Train Loss: 20.3243 - Test Loss: 49.1311 - MSE: 49.1311 - MAE: 5.7604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 252/20000 - Train Loss: 20.3239 - Test Loss: 49.1304 - MSE: 49.1304 - MAE: 5.7604\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 253/20000 - Train Loss: 20.3236 - Test Loss: 49.1297 - MSE: 49.1297 - MAE: 5.7603\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 254/20000 - Train Loss: 20.3232 - Test Loss: 49.1290 - MSE: 49.1290 - MAE: 5.7603\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 255/20000 - Train Loss: 20.3228 - Test Loss: 49.1282 - MSE: 49.1282 - MAE: 5.7602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 256/20000 - Train Loss: 20.3224 - Test Loss: 49.1275 - MSE: 49.1275 - MAE: 5.7602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 257/20000 - Train Loss: 20.3221 - Test Loss: 49.1267 - MSE: 49.1267 - MAE: 5.7601\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 258/20000 - Train Loss: 20.3217 - Test Loss: 49.1259 - MSE: 49.1259 - MAE: 5.7601\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 259/20000 - Train Loss: 20.3213 - Test Loss: 49.1252 - MSE: 49.1252 - MAE: 5.7600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 260/20000 - Train Loss: 20.3209 - Test Loss: 49.1243 - MSE: 49.1243 - MAE: 5.7600\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 261/20000 - Train Loss: 20.3206 - Test Loss: 49.1235 - MSE: 49.1235 - MAE: 5.7599\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 262/20000 - Train Loss: 20.3202 - Test Loss: 49.1226 - MSE: 49.1226 - MAE: 5.7599\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 263/20000 - Train Loss: 20.3198 - Test Loss: 49.1217 - MSE: 49.1217 - MAE: 5.7598\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 264/20000 - Train Loss: 20.3194 - Test Loss: 49.1210 - MSE: 49.1209 - MAE: 5.7598\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 265/20000 - Train Loss: 20.3190 - Test Loss: 49.1200 - MSE: 49.1200 - MAE: 5.7597\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 266/20000 - Train Loss: 20.3186 - Test Loss: 49.1192 - MSE: 49.1192 - MAE: 5.7596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 267/20000 - Train Loss: 20.3182 - Test Loss: 49.1183 - MSE: 49.1183 - MAE: 5.7596\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 268/20000 - Train Loss: 20.3179 - Test Loss: 49.1174 - MSE: 49.1174 - MAE: 5.7595\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 269/20000 - Train Loss: 20.3175 - Test Loss: 49.1165 - MSE: 49.1165 - MAE: 5.7595\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 270/20000 - Train Loss: 20.3171 - Test Loss: 49.1156 - MSE: 49.1156 - MAE: 5.7594\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 271/20000 - Train Loss: 20.3167 - Test Loss: 49.1147 - MSE: 49.1147 - MAE: 5.7594\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 272/20000 - Train Loss: 20.3163 - Test Loss: 49.1138 - MSE: 49.1138 - MAE: 5.7593\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 273/20000 - Train Loss: 20.3159 - Test Loss: 49.1129 - MSE: 49.1129 - MAE: 5.7593\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 274/20000 - Train Loss: 20.3155 - Test Loss: 49.1119 - MSE: 49.1119 - MAE: 5.7592\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 275/20000 - Train Loss: 20.3151 - Test Loss: 49.1110 - MSE: 49.1110 - MAE: 5.7591\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 276/20000 - Train Loss: 20.3147 - Test Loss: 49.1101 - MSE: 49.1101 - MAE: 5.7591\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 277/20000 - Train Loss: 20.3143 - Test Loss: 49.1091 - MSE: 49.1091 - MAE: 5.7590\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 278/20000 - Train Loss: 20.3139 - Test Loss: 49.1081 - MSE: 49.1081 - MAE: 5.7590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 279/20000 - Train Loss: 20.3135 - Test Loss: 49.1073 - MSE: 49.1073 - MAE: 5.7589\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 280/20000 - Train Loss: 20.3131 - Test Loss: 49.1063 - MSE: 49.1063 - MAE: 5.7589\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 281/20000 - Train Loss: 20.3127 - Test Loss: 49.1054 - MSE: 49.1054 - MAE: 5.7588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 282/20000 - Train Loss: 20.3123 - Test Loss: 49.1045 - MSE: 49.1045 - MAE: 5.7588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 283/20000 - Train Loss: 20.3119 - Test Loss: 49.1036 - MSE: 49.1037 - MAE: 5.7587\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 284/20000 - Train Loss: 20.3115 - Test Loss: 49.1027 - MSE: 49.1027 - MAE: 5.7586\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 285/20000 - Train Loss: 20.3111 - Test Loss: 49.1018 - MSE: 49.1018 - MAE: 5.7586\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 286/20000 - Train Loss: 20.3107 - Test Loss: 49.1009 - MSE: 49.1009 - MAE: 5.7585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 287/20000 - Train Loss: 20.3103 - Test Loss: 49.0999 - MSE: 49.0999 - MAE: 5.7585\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 288/20000 - Train Loss: 20.3099 - Test Loss: 49.0990 - MSE: 49.0990 - MAE: 5.7584\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 289/20000 - Train Loss: 20.3095 - Test Loss: 49.0981 - MSE: 49.0981 - MAE: 5.7584\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 290/20000 - Train Loss: 20.3091 - Test Loss: 49.0972 - MSE: 49.0972 - MAE: 5.7583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 291/20000 - Train Loss: 20.3087 - Test Loss: 49.0963 - MSE: 49.0963 - MAE: 5.7582\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 292/20000 - Train Loss: 20.3083 - Test Loss: 49.0954 - MSE: 49.0954 - MAE: 5.7582\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 293/20000 - Train Loss: 20.3079 - Test Loss: 49.0944 - MSE: 49.0945 - MAE: 5.7581\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 294/20000 - Train Loss: 20.3075 - Test Loss: 49.0936 - MSE: 49.0936 - MAE: 5.7581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 295/20000 - Train Loss: 20.3071 - Test Loss: 49.0927 - MSE: 49.0927 - MAE: 5.7580\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 296/20000 - Train Loss: 20.3067 - Test Loss: 49.0918 - MSE: 49.0918 - MAE: 5.7580\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 297/20000 - Train Loss: 20.3063 - Test Loss: 49.0909 - MSE: 49.0909 - MAE: 5.7579\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 298/20000 - Train Loss: 20.3058 - Test Loss: 49.0900 - MSE: 49.0900 - MAE: 5.7579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 299/20000 - Train Loss: 20.3054 - Test Loss: 49.0891 - MSE: 49.0891 - MAE: 5.7578\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 300/20000 - Train Loss: 20.3050 - Test Loss: 49.0882 - MSE: 49.0882 - MAE: 5.7577\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 301/20000 - Train Loss: 20.3046 - Test Loss: 49.0872 - MSE: 49.0872 - MAE: 5.7577\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 302/20000 - Train Loss: 20.3042 - Test Loss: 49.0864 - MSE: 49.0864 - MAE: 5.7576\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 303/20000 - Train Loss: 20.3038 - Test Loss: 49.0854 - MSE: 49.0854 - MAE: 5.7576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 304/20000 - Train Loss: 20.3034 - Test Loss: 49.0846 - MSE: 49.0846 - MAE: 5.7575\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 305/20000 - Train Loss: 20.3029 - Test Loss: 49.0836 - MSE: 49.0836 - MAE: 5.7575\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 306/20000 - Train Loss: 20.3025 - Test Loss: 49.0827 - MSE: 49.0827 - MAE: 5.7574\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 307/20000 - Train Loss: 20.3021 - Test Loss: 49.0818 - MSE: 49.0818 - MAE: 5.7573\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 308/20000 - Train Loss: 20.3017 - Test Loss: 49.0809 - MSE: 49.0809 - MAE: 5.7573\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 309/20000 - Train Loss: 20.3013 - Test Loss: 49.0800 - MSE: 49.0800 - MAE: 5.7572\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 310/20000 - Train Loss: 20.3008 - Test Loss: 49.0791 - MSE: 49.0790 - MAE: 5.7572\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 311/20000 - Train Loss: 20.3004 - Test Loss: 49.0781 - MSE: 49.0781 - MAE: 5.7571\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 312/20000 - Train Loss: 20.3000 - Test Loss: 49.0772 - MSE: 49.0772 - MAE: 5.7571\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 313/20000 - Train Loss: 20.2996 - Test Loss: 49.0762 - MSE: 49.0762 - MAE: 5.7570\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 314/20000 - Train Loss: 20.2992 - Test Loss: 49.0754 - MSE: 49.0754 - MAE: 5.7569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 315/20000 - Train Loss: 20.2987 - Test Loss: 49.0744 - MSE: 49.0744 - MAE: 5.7569\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 316/20000 - Train Loss: 20.2983 - Test Loss: 49.0735 - MSE: 49.0735 - MAE: 5.7568\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 317/20000 - Train Loss: 20.2979 - Test Loss: 49.0726 - MSE: 49.0726 - MAE: 5.7568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 318/20000 - Train Loss: 20.2974 - Test Loss: 49.0717 - MSE: 49.0717 - MAE: 5.7567\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 319/20000 - Train Loss: 20.2970 - Test Loss: 49.0707 - MSE: 49.0707 - MAE: 5.7566\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 320/20000 - Train Loss: 20.2966 - Test Loss: 49.0697 - MSE: 49.0697 - MAE: 5.7566\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 321/20000 - Train Loss: 20.2962 - Test Loss: 49.0688 - MSE: 49.0688 - MAE: 5.7565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 322/20000 - Train Loss: 20.2957 - Test Loss: 49.0678 - MSE: 49.0678 - MAE: 5.7565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 323/20000 - Train Loss: 20.2953 - Test Loss: 49.0669 - MSE: 49.0669 - MAE: 5.7564\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 324/20000 - Train Loss: 20.2949 - Test Loss: 49.0660 - MSE: 49.0660 - MAE: 5.7563\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 325/20000 - Train Loss: 20.2944 - Test Loss: 49.0650 - MSE: 49.0650 - MAE: 5.7563\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 326/20000 - Train Loss: 20.2940 - Test Loss: 49.0641 - MSE: 49.0641 - MAE: 5.7562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 327/20000 - Train Loss: 20.2936 - Test Loss: 49.0630 - MSE: 49.0630 - MAE: 5.7562\n",
      "2/2 [==============================] - 0s 976us/step\n",
      "Epoch 328/20000 - Train Loss: 20.2931 - Test Loss: 49.0620 - MSE: 49.0620 - MAE: 5.7561\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 329/20000 - Train Loss: 20.2927 - Test Loss: 49.0611 - MSE: 49.0611 - MAE: 5.7560\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 330/20000 - Train Loss: 20.2923 - Test Loss: 49.0601 - MSE: 49.0601 - MAE: 5.7560\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 331/20000 - Train Loss: 20.2918 - Test Loss: 49.0592 - MSE: 49.0592 - MAE: 5.7559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 332/20000 - Train Loss: 20.2914 - Test Loss: 49.0582 - MSE: 49.0582 - MAE: 5.7559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 333/20000 - Train Loss: 20.2909 - Test Loss: 49.0572 - MSE: 49.0572 - MAE: 5.7558\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 334/20000 - Train Loss: 20.2905 - Test Loss: 49.0562 - MSE: 49.0562 - MAE: 5.7557\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 335/20000 - Train Loss: 20.2901 - Test Loss: 49.0552 - MSE: 49.0552 - MAE: 5.7557\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 336/20000 - Train Loss: 20.2896 - Test Loss: 49.0543 - MSE: 49.0543 - MAE: 5.7556\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 337/20000 - Train Loss: 20.2892 - Test Loss: 49.0533 - MSE: 49.0533 - MAE: 5.7556\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 338/20000 - Train Loss: 20.2887 - Test Loss: 49.0523 - MSE: 49.0523 - MAE: 5.7555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 339/20000 - Train Loss: 20.2883 - Test Loss: 49.0514 - MSE: 49.0514 - MAE: 5.7554\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 340/20000 - Train Loss: 20.2879 - Test Loss: 49.0504 - MSE: 49.0504 - MAE: 5.7554\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 341/20000 - Train Loss: 20.2874 - Test Loss: 49.0494 - MSE: 49.0494 - MAE: 5.7553\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 342/20000 - Train Loss: 20.2870 - Test Loss: 49.0484 - MSE: 49.0484 - MAE: 5.7553\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 343/20000 - Train Loss: 20.2865 - Test Loss: 49.0474 - MSE: 49.0474 - MAE: 5.7552\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 344/20000 - Train Loss: 20.2861 - Test Loss: 49.0464 - MSE: 49.0464 - MAE: 5.7551\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 345/20000 - Train Loss: 20.2856 - Test Loss: 49.0454 - MSE: 49.0455 - MAE: 5.7551\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 346/20000 - Train Loss: 20.2852 - Test Loss: 49.0444 - MSE: 49.0444 - MAE: 5.7550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 347/20000 - Train Loss: 20.2847 - Test Loss: 49.0435 - MSE: 49.0435 - MAE: 5.7550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 348/20000 - Train Loss: 20.2843 - Test Loss: 49.0425 - MSE: 49.0425 - MAE: 5.7549\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 349/20000 - Train Loss: 20.2838 - Test Loss: 49.0415 - MSE: 49.0415 - MAE: 5.7548\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 350/20000 - Train Loss: 20.2834 - Test Loss: 49.0405 - MSE: 49.0405 - MAE: 5.7548\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 351/20000 - Train Loss: 20.2829 - Test Loss: 49.0394 - MSE: 49.0395 - MAE: 5.7547\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 352/20000 - Train Loss: 20.2825 - Test Loss: 49.0384 - MSE: 49.0384 - MAE: 5.7546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 353/20000 - Train Loss: 20.2820 - Test Loss: 49.0375 - MSE: 49.0375 - MAE: 5.7546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 354/20000 - Train Loss: 20.2816 - Test Loss: 49.0365 - MSE: 49.0365 - MAE: 5.7545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 355/20000 - Train Loss: 20.2811 - Test Loss: 49.0354 - MSE: 49.0354 - MAE: 5.7545\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 356/20000 - Train Loss: 20.2806 - Test Loss: 49.0345 - MSE: 49.0345 - MAE: 5.7544\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 357/20000 - Train Loss: 20.2802 - Test Loss: 49.0335 - MSE: 49.0335 - MAE: 5.7543\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 358/20000 - Train Loss: 20.2797 - Test Loss: 49.0325 - MSE: 49.0325 - MAE: 5.7543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 359/20000 - Train Loss: 20.2793 - Test Loss: 49.0315 - MSE: 49.0315 - MAE: 5.7542\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 360/20000 - Train Loss: 20.2788 - Test Loss: 49.0305 - MSE: 49.0305 - MAE: 5.7541\n",
      "2/2 [==============================] - 0s 965us/step\n",
      "Epoch 361/20000 - Train Loss: 20.2783 - Test Loss: 49.0294 - MSE: 49.0294 - MAE: 5.7541\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 362/20000 - Train Loss: 20.2779 - Test Loss: 49.0284 - MSE: 49.0284 - MAE: 5.7540\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 363/20000 - Train Loss: 20.2774 - Test Loss: 49.0274 - MSE: 49.0274 - MAE: 5.7539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 364/20000 - Train Loss: 20.2770 - Test Loss: 49.0264 - MSE: 49.0264 - MAE: 5.7539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 365/20000 - Train Loss: 20.2765 - Test Loss: 49.0254 - MSE: 49.0254 - MAE: 5.7538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 366/20000 - Train Loss: 20.2760 - Test Loss: 49.0244 - MSE: 49.0244 - MAE: 5.7538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 367/20000 - Train Loss: 20.2756 - Test Loss: 49.0234 - MSE: 49.0234 - MAE: 5.7537\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 368/20000 - Train Loss: 20.2751 - Test Loss: 49.0223 - MSE: 49.0223 - MAE: 5.7536\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 369/20000 - Train Loss: 20.2746 - Test Loss: 49.0213 - MSE: 49.0213 - MAE: 5.7536\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 370/20000 - Train Loss: 20.2742 - Test Loss: 49.0203 - MSE: 49.0203 - MAE: 5.7535\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 371/20000 - Train Loss: 20.2737 - Test Loss: 49.0192 - MSE: 49.0192 - MAE: 5.7534\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 372/20000 - Train Loss: 20.2732 - Test Loss: 49.0182 - MSE: 49.0182 - MAE: 5.7534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 373/20000 - Train Loss: 20.2728 - Test Loss: 49.0171 - MSE: 49.0171 - MAE: 5.7533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 374/20000 - Train Loss: 20.2723 - Test Loss: 49.0160 - MSE: 49.0160 - MAE: 5.7532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 375/20000 - Train Loss: 20.2718 - Test Loss: 49.0150 - MSE: 49.0150 - MAE: 5.7532\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 376/20000 - Train Loss: 20.2714 - Test Loss: 49.0140 - MSE: 49.0140 - MAE: 5.7531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 377/20000 - Train Loss: 20.2709 - Test Loss: 49.0129 - MSE: 49.0129 - MAE: 5.7530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 378/20000 - Train Loss: 20.2704 - Test Loss: 49.0119 - MSE: 49.0119 - MAE: 5.7530\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 379/20000 - Train Loss: 20.2699 - Test Loss: 49.0108 - MSE: 49.0108 - MAE: 5.7529\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 380/20000 - Train Loss: 20.2695 - Test Loss: 49.0098 - MSE: 49.0098 - MAE: 5.7529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 381/20000 - Train Loss: 20.2690 - Test Loss: 49.0087 - MSE: 49.0087 - MAE: 5.7528\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 382/20000 - Train Loss: 20.2685 - Test Loss: 49.0077 - MSE: 49.0077 - MAE: 5.7527\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 383/20000 - Train Loss: 20.2680 - Test Loss: 49.0066 - MSE: 49.0066 - MAE: 5.7527\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 384/20000 - Train Loss: 20.2676 - Test Loss: 49.0056 - MSE: 49.0056 - MAE: 5.7526\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 385/20000 - Train Loss: 20.2671 - Test Loss: 49.0045 - MSE: 49.0045 - MAE: 5.7525\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 386/20000 - Train Loss: 20.2666 - Test Loss: 49.0034 - MSE: 49.0034 - MAE: 5.7525\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 387/20000 - Train Loss: 20.2661 - Test Loss: 49.0024 - MSE: 49.0024 - MAE: 5.7524\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 388/20000 - Train Loss: 20.2656 - Test Loss: 49.0013 - MSE: 49.0013 - MAE: 5.7523\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 389/20000 - Train Loss: 20.2652 - Test Loss: 49.0002 - MSE: 49.0002 - MAE: 5.7523\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 390/20000 - Train Loss: 20.2647 - Test Loss: 48.9992 - MSE: 48.9992 - MAE: 5.7522\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 391/20000 - Train Loss: 20.2642 - Test Loss: 48.9982 - MSE: 48.9982 - MAE: 5.7521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 392/20000 - Train Loss: 20.2637 - Test Loss: 48.9971 - MSE: 48.9971 - MAE: 5.7521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 393/20000 - Train Loss: 20.2632 - Test Loss: 48.9960 - MSE: 48.9960 - MAE: 5.7520\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 394/20000 - Train Loss: 20.2627 - Test Loss: 48.9950 - MSE: 48.9950 - MAE: 5.7519\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 395/20000 - Train Loss: 20.2623 - Test Loss: 48.9939 - MSE: 48.9939 - MAE: 5.7519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 396/20000 - Train Loss: 20.2618 - Test Loss: 48.9928 - MSE: 48.9928 - MAE: 5.7518\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 397/20000 - Train Loss: 20.2613 - Test Loss: 48.9917 - MSE: 48.9917 - MAE: 5.7517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 398/20000 - Train Loss: 20.2608 - Test Loss: 48.9906 - MSE: 48.9906 - MAE: 5.7517\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 399/20000 - Train Loss: 20.2603 - Test Loss: 48.9896 - MSE: 48.9896 - MAE: 5.7516\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 400/20000 - Train Loss: 20.2598 - Test Loss: 48.9886 - MSE: 48.9886 - MAE: 5.7515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 401/20000 - Train Loss: 20.2593 - Test Loss: 48.9875 - MSE: 48.9875 - MAE: 5.7515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 402/20000 - Train Loss: 20.2589 - Test Loss: 48.9864 - MSE: 48.9864 - MAE: 5.7514\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch 403/20000 - Train Loss: 20.2584 - Test Loss: 48.9853 - MSE: 48.9853 - MAE: 5.7513\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 404/20000 - Train Loss: 20.2579 - Test Loss: 48.9842 - MSE: 48.9842 - MAE: 5.7513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 405/20000 - Train Loss: 20.2574 - Test Loss: 48.9831 - MSE: 48.9831 - MAE: 5.7512\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 406/20000 - Train Loss: 20.2569 - Test Loss: 48.9820 - MSE: 48.9820 - MAE: 5.7511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 407/20000 - Train Loss: 20.2564 - Test Loss: 48.9810 - MSE: 48.9809 - MAE: 5.7511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 408/20000 - Train Loss: 20.2559 - Test Loss: 48.9799 - MSE: 48.9799 - MAE: 5.7510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 409/20000 - Train Loss: 20.2554 - Test Loss: 48.9788 - MSE: 48.9788 - MAE: 5.7509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 410/20000 - Train Loss: 20.2549 - Test Loss: 48.9777 - MSE: 48.9777 - MAE: 5.7509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 411/20000 - Train Loss: 20.2544 - Test Loss: 48.9766 - MSE: 48.9766 - MAE: 5.7508\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 412/20000 - Train Loss: 20.2539 - Test Loss: 48.9755 - MSE: 48.9755 - MAE: 5.7507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 413/20000 - Train Loss: 20.2534 - Test Loss: 48.9745 - MSE: 48.9745 - MAE: 5.7506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 414/20000 - Train Loss: 20.2529 - Test Loss: 48.9733 - MSE: 48.9733 - MAE: 5.7506\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 415/20000 - Train Loss: 20.2524 - Test Loss: 48.9722 - MSE: 48.9722 - MAE: 5.7505\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 416/20000 - Train Loss: 20.2519 - Test Loss: 48.9711 - MSE: 48.9711 - MAE: 5.7504\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 417/20000 - Train Loss: 20.2514 - Test Loss: 48.9701 - MSE: 48.9701 - MAE: 5.7504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 418/20000 - Train Loss: 20.2509 - Test Loss: 48.9689 - MSE: 48.9689 - MAE: 5.7503\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 419/20000 - Train Loss: 20.2504 - Test Loss: 48.9678 - MSE: 48.9678 - MAE: 5.7502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 420/20000 - Train Loss: 20.2499 - Test Loss: 48.9666 - MSE: 48.9666 - MAE: 5.7502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 421/20000 - Train Loss: 20.2494 - Test Loss: 48.9655 - MSE: 48.9655 - MAE: 5.7501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 422/20000 - Train Loss: 20.2489 - Test Loss: 48.9644 - MSE: 48.9644 - MAE: 5.7500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 423/20000 - Train Loss: 20.2484 - Test Loss: 48.9633 - MSE: 48.9633 - MAE: 5.7500\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 424/20000 - Train Loss: 20.2479 - Test Loss: 48.9622 - MSE: 48.9622 - MAE: 5.7499\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 425/20000 - Train Loss: 20.2474 - Test Loss: 48.9611 - MSE: 48.9611 - MAE: 5.7498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 426/20000 - Train Loss: 20.2469 - Test Loss: 48.9600 - MSE: 48.9600 - MAE: 5.7497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 427/20000 - Train Loss: 20.2463 - Test Loss: 48.9588 - MSE: 48.9588 - MAE: 5.7497\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 428/20000 - Train Loss: 20.2459 - Test Loss: 48.9576 - MSE: 48.9576 - MAE: 5.7496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 429/20000 - Train Loss: 20.2453 - Test Loss: 48.9564 - MSE: 48.9565 - MAE: 5.7495\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 430/20000 - Train Loss: 20.2448 - Test Loss: 48.9553 - MSE: 48.9553 - MAE: 5.7495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 431/20000 - Train Loss: 20.2443 - Test Loss: 48.9542 - MSE: 48.9542 - MAE: 5.7494\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 432/20000 - Train Loss: 20.2438 - Test Loss: 48.9531 - MSE: 48.9531 - MAE: 5.7493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 433/20000 - Train Loss: 20.2433 - Test Loss: 48.9520 - MSE: 48.9520 - MAE: 5.7493\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 434/20000 - Train Loss: 20.2428 - Test Loss: 48.9509 - MSE: 48.9509 - MAE: 5.7492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 435/20000 - Train Loss: 20.2423 - Test Loss: 48.9497 - MSE: 48.9497 - MAE: 5.7491\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 436/20000 - Train Loss: 20.2418 - Test Loss: 48.9486 - MSE: 48.9486 - MAE: 5.7490\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 437/20000 - Train Loss: 20.2412 - Test Loss: 48.9474 - MSE: 48.9474 - MAE: 5.7490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 438/20000 - Train Loss: 20.2407 - Test Loss: 48.9463 - MSE: 48.9463 - MAE: 5.7489\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 439/20000 - Train Loss: 20.2402 - Test Loss: 48.9451 - MSE: 48.9451 - MAE: 5.7488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 440/20000 - Train Loss: 20.2397 - Test Loss: 48.9440 - MSE: 48.9440 - MAE: 5.7488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 441/20000 - Train Loss: 20.2392 - Test Loss: 48.9428 - MSE: 48.9428 - MAE: 5.7487\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 442/20000 - Train Loss: 20.2386 - Test Loss: 48.9417 - MSE: 48.9417 - MAE: 5.7486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 443/20000 - Train Loss: 20.2381 - Test Loss: 48.9406 - MSE: 48.9406 - MAE: 5.7485\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 444/20000 - Train Loss: 20.2376 - Test Loss: 48.9395 - MSE: 48.9395 - MAE: 5.7485\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 445/20000 - Train Loss: 20.2371 - Test Loss: 48.9384 - MSE: 48.9384 - MAE: 5.7484\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 446/20000 - Train Loss: 20.2366 - Test Loss: 48.9372 - MSE: 48.9372 - MAE: 5.7483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 447/20000 - Train Loss: 20.2360 - Test Loss: 48.9360 - MSE: 48.9360 - MAE: 5.7483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 448/20000 - Train Loss: 20.2355 - Test Loss: 48.9349 - MSE: 48.9349 - MAE: 5.7482\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 449/20000 - Train Loss: 20.2350 - Test Loss: 48.9337 - MSE: 48.9337 - MAE: 5.7481\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 450/20000 - Train Loss: 20.2345 - Test Loss: 48.9325 - MSE: 48.9325 - MAE: 5.7480\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 451/20000 - Train Loss: 20.2339 - Test Loss: 48.9314 - MSE: 48.9314 - MAE: 5.7480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 452/20000 - Train Loss: 20.2334 - Test Loss: 48.9302 - MSE: 48.9302 - MAE: 5.7479\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 453/20000 - Train Loss: 20.2329 - Test Loss: 48.9291 - MSE: 48.9291 - MAE: 5.7478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 454/20000 - Train Loss: 20.2324 - Test Loss: 48.9279 - MSE: 48.9279 - MAE: 5.7477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 455/20000 - Train Loss: 20.2318 - Test Loss: 48.9268 - MSE: 48.9268 - MAE: 5.7477\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 456/20000 - Train Loss: 20.2313 - Test Loss: 48.9257 - MSE: 48.9257 - MAE: 5.7476\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 457/20000 - Train Loss: 20.2308 - Test Loss: 48.9245 - MSE: 48.9245 - MAE: 5.7475\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 458/20000 - Train Loss: 20.2302 - Test Loss: 48.9232 - MSE: 48.9232 - MAE: 5.7475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 459/20000 - Train Loss: 20.2297 - Test Loss: 48.9221 - MSE: 48.9221 - MAE: 5.7474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 460/20000 - Train Loss: 20.2292 - Test Loss: 48.9209 - MSE: 48.9209 - MAE: 5.7473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 461/20000 - Train Loss: 20.2286 - Test Loss: 48.9197 - MSE: 48.9197 - MAE: 5.7472\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 462/20000 - Train Loss: 20.2281 - Test Loss: 48.9185 - MSE: 48.9185 - MAE: 5.7472\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 463/20000 - Train Loss: 20.2276 - Test Loss: 48.9174 - MSE: 48.9174 - MAE: 5.7471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 464/20000 - Train Loss: 20.2270 - Test Loss: 48.9162 - MSE: 48.9162 - MAE: 5.7470\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 465/20000 - Train Loss: 20.2265 - Test Loss: 48.9150 - MSE: 48.9150 - MAE: 5.7469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 466/20000 - Train Loss: 20.2260 - Test Loss: 48.9139 - MSE: 48.9139 - MAE: 5.7469\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 467/20000 - Train Loss: 20.2254 - Test Loss: 48.9128 - MSE: 48.9128 - MAE: 5.7468\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 468/20000 - Train Loss: 20.2249 - Test Loss: 48.9116 - MSE: 48.9115 - MAE: 5.7467\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 469/20000 - Train Loss: 20.2244 - Test Loss: 48.9103 - MSE: 48.9103 - MAE: 5.7466\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 470/20000 - Train Loss: 20.2238 - Test Loss: 48.9091 - MSE: 48.9092 - MAE: 5.7466\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 471/20000 - Train Loss: 20.2233 - Test Loss: 48.9080 - MSE: 48.9080 - MAE: 5.7465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 472/20000 - Train Loss: 20.2227 - Test Loss: 48.9068 - MSE: 48.9068 - MAE: 5.7464\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 473/20000 - Train Loss: 20.2222 - Test Loss: 48.9056 - MSE: 48.9056 - MAE: 5.7464\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 474/20000 - Train Loss: 20.2217 - Test Loss: 48.9043 - MSE: 48.9043 - MAE: 5.7463\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 475/20000 - Train Loss: 20.2211 - Test Loss: 48.9031 - MSE: 48.9031 - MAE: 5.7462\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 476/20000 - Train Loss: 20.2206 - Test Loss: 48.9019 - MSE: 48.9019 - MAE: 5.7461\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 477/20000 - Train Loss: 20.2200 - Test Loss: 48.9007 - MSE: 48.9007 - MAE: 5.7460\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 478/20000 - Train Loss: 20.2195 - Test Loss: 48.8996 - MSE: 48.8996 - MAE: 5.7460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 479/20000 - Train Loss: 20.2189 - Test Loss: 48.8983 - MSE: 48.8983 - MAE: 5.7459\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 480/20000 - Train Loss: 20.2184 - Test Loss: 48.8971 - MSE: 48.8971 - MAE: 5.7458\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 481/20000 - Train Loss: 20.2179 - Test Loss: 48.8959 - MSE: 48.8959 - MAE: 5.7457\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 482/20000 - Train Loss: 20.2173 - Test Loss: 48.8947 - MSE: 48.8947 - MAE: 5.7457\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 483/20000 - Train Loss: 20.2168 - Test Loss: 48.8934 - MSE: 48.8934 - MAE: 5.7456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 484/20000 - Train Loss: 20.2162 - Test Loss: 48.8921 - MSE: 48.8921 - MAE: 5.7455\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 485/20000 - Train Loss: 20.2157 - Test Loss: 48.8909 - MSE: 48.8909 - MAE: 5.7454\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 486/20000 - Train Loss: 20.2151 - Test Loss: 48.8897 - MSE: 48.8897 - MAE: 5.7454\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 487/20000 - Train Loss: 20.2146 - Test Loss: 48.8886 - MSE: 48.8886 - MAE: 5.7453\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 488/20000 - Train Loss: 20.2140 - Test Loss: 48.8873 - MSE: 48.8873 - MAE: 5.7452\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 489/20000 - Train Loss: 20.2135 - Test Loss: 48.8862 - MSE: 48.8862 - MAE: 5.7451\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 490/20000 - Train Loss: 20.2129 - Test Loss: 48.8849 - MSE: 48.8849 - MAE: 5.7451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 491/20000 - Train Loss: 20.2123 - Test Loss: 48.8837 - MSE: 48.8837 - MAE: 5.7450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 492/20000 - Train Loss: 20.2118 - Test Loss: 48.8825 - MSE: 48.8825 - MAE: 5.7449\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 493/20000 - Train Loss: 20.2112 - Test Loss: 48.8813 - MSE: 48.8813 - MAE: 5.7448\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 494/20000 - Train Loss: 20.2107 - Test Loss: 48.8800 - MSE: 48.8800 - MAE: 5.7448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 495/20000 - Train Loss: 20.2101 - Test Loss: 48.8788 - MSE: 48.8788 - MAE: 5.7447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 496/20000 - Train Loss: 20.2096 - Test Loss: 48.8776 - MSE: 48.8776 - MAE: 5.7446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 497/20000 - Train Loss: 20.2090 - Test Loss: 48.8763 - MSE: 48.8763 - MAE: 5.7445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 498/20000 - Train Loss: 20.2084 - Test Loss: 48.8752 - MSE: 48.8752 - MAE: 5.7445\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 499/20000 - Train Loss: 20.2079 - Test Loss: 48.8739 - MSE: 48.8739 - MAE: 5.7444\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 500/20000 - Train Loss: 20.2073 - Test Loss: 48.8727 - MSE: 48.8727 - MAE: 5.7443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 501/20000 - Train Loss: 20.2068 - Test Loss: 48.8714 - MSE: 48.8714 - MAE: 5.7442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 502/20000 - Train Loss: 20.2062 - Test Loss: 48.8702 - MSE: 48.8702 - MAE: 5.7441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 503/20000 - Train Loss: 20.2057 - Test Loss: 48.8689 - MSE: 48.8689 - MAE: 5.7441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 504/20000 - Train Loss: 20.2051 - Test Loss: 48.8677 - MSE: 48.8677 - MAE: 5.7440\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 505/20000 - Train Loss: 20.2045 - Test Loss: 48.8665 - MSE: 48.8665 - MAE: 5.7439\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 506/20000 - Train Loss: 20.2040 - Test Loss: 48.8652 - MSE: 48.8652 - MAE: 5.7438\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 507/20000 - Train Loss: 20.2034 - Test Loss: 48.8640 - MSE: 48.8640 - MAE: 5.7438\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 508/20000 - Train Loss: 20.2028 - Test Loss: 48.8628 - MSE: 48.8628 - MAE: 5.7437\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 509/20000 - Train Loss: 20.2023 - Test Loss: 48.8615 - MSE: 48.8615 - MAE: 5.7436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 510/20000 - Train Loss: 20.2017 - Test Loss: 48.8603 - MSE: 48.8603 - MAE: 5.7435\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 511/20000 - Train Loss: 20.2011 - Test Loss: 48.8590 - MSE: 48.8590 - MAE: 5.7434\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 512/20000 - Train Loss: 20.2006 - Test Loss: 48.8577 - MSE: 48.8577 - MAE: 5.7434\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 513/20000 - Train Loss: 20.2000 - Test Loss: 48.8565 - MSE: 48.8565 - MAE: 5.7433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 514/20000 - Train Loss: 20.1994 - Test Loss: 48.8553 - MSE: 48.8553 - MAE: 5.7432\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 515/20000 - Train Loss: 20.1989 - Test Loss: 48.8540 - MSE: 48.8540 - MAE: 5.7431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 516/20000 - Train Loss: 20.1983 - Test Loss: 48.8528 - MSE: 48.8528 - MAE: 5.7431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 517/20000 - Train Loss: 20.1977 - Test Loss: 48.8515 - MSE: 48.8515 - MAE: 5.7430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 518/20000 - Train Loss: 20.1971 - Test Loss: 48.8502 - MSE: 48.8502 - MAE: 5.7429\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 519/20000 - Train Loss: 20.1966 - Test Loss: 48.8489 - MSE: 48.8489 - MAE: 5.7428\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 520/20000 - Train Loss: 20.1960 - Test Loss: 48.8477 - MSE: 48.8477 - MAE: 5.7427\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 521/20000 - Train Loss: 20.1954 - Test Loss: 48.8464 - MSE: 48.8464 - MAE: 5.7427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 522/20000 - Train Loss: 20.1949 - Test Loss: 48.8452 - MSE: 48.8452 - MAE: 5.7426\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 523/20000 - Train Loss: 20.1943 - Test Loss: 48.8439 - MSE: 48.8439 - MAE: 5.7425\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 524/20000 - Train Loss: 20.1937 - Test Loss: 48.8427 - MSE: 48.8427 - MAE: 5.7424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 525/20000 - Train Loss: 20.1931 - Test Loss: 48.8414 - MSE: 48.8414 - MAE: 5.7423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 526/20000 - Train Loss: 20.1925 - Test Loss: 48.8400 - MSE: 48.8400 - MAE: 5.7423\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 527/20000 - Train Loss: 20.1920 - Test Loss: 48.8388 - MSE: 48.8388 - MAE: 5.7422\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 528/20000 - Train Loss: 20.1914 - Test Loss: 48.8375 - MSE: 48.8375 - MAE: 5.7421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 529/20000 - Train Loss: 20.1908 - Test Loss: 48.8361 - MSE: 48.8361 - MAE: 5.7420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 530/20000 - Train Loss: 20.1902 - Test Loss: 48.8348 - MSE: 48.8348 - MAE: 5.7419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 531/20000 - Train Loss: 20.1896 - Test Loss: 48.8336 - MSE: 48.8336 - MAE: 5.7419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 532/20000 - Train Loss: 20.1891 - Test Loss: 48.8323 - MSE: 48.8323 - MAE: 5.7418\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 533/20000 - Train Loss: 20.1885 - Test Loss: 48.8310 - MSE: 48.8310 - MAE: 5.7417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 534/20000 - Train Loss: 20.1879 - Test Loss: 48.8297 - MSE: 48.8297 - MAE: 5.7416\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 535/20000 - Train Loss: 20.1873 - Test Loss: 48.8284 - MSE: 48.8284 - MAE: 5.7415\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 536/20000 - Train Loss: 20.1867 - Test Loss: 48.8271 - MSE: 48.8271 - MAE: 5.7415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 537/20000 - Train Loss: 20.1861 - Test Loss: 48.8258 - MSE: 48.8258 - MAE: 5.7414\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 538/20000 - Train Loss: 20.1856 - Test Loss: 48.8245 - MSE: 48.8245 - MAE: 5.7413\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 539/20000 - Train Loss: 20.1850 - Test Loss: 48.8232 - MSE: 48.8232 - MAE: 5.7412\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 540/20000 - Train Loss: 20.1844 - Test Loss: 48.8219 - MSE: 48.8219 - MAE: 5.7411\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 541/20000 - Train Loss: 20.1838 - Test Loss: 48.8205 - MSE: 48.8205 - MAE: 5.7410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 542/20000 - Train Loss: 20.1832 - Test Loss: 48.8193 - MSE: 48.8193 - MAE: 5.7410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 543/20000 - Train Loss: 20.1826 - Test Loss: 48.8180 - MSE: 48.8180 - MAE: 5.7409\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 544/20000 - Train Loss: 20.1820 - Test Loss: 48.8167 - MSE: 48.8167 - MAE: 5.7408\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 545/20000 - Train Loss: 20.1814 - Test Loss: 48.8155 - MSE: 48.8155 - MAE: 5.7407\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 546/20000 - Train Loss: 20.1808 - Test Loss: 48.8141 - MSE: 48.8141 - MAE: 5.7406\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 547/20000 - Train Loss: 20.1802 - Test Loss: 48.8128 - MSE: 48.8129 - MAE: 5.7406\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 548/20000 - Train Loss: 20.1797 - Test Loss: 48.8115 - MSE: 48.8115 - MAE: 5.7405\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 549/20000 - Train Loss: 20.1791 - Test Loss: 48.8102 - MSE: 48.8102 - MAE: 5.7404\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 550/20000 - Train Loss: 20.1785 - Test Loss: 48.8088 - MSE: 48.8088 - MAE: 5.7403\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 551/20000 - Train Loss: 20.1779 - Test Loss: 48.8075 - MSE: 48.8075 - MAE: 5.7402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 552/20000 - Train Loss: 20.1773 - Test Loss: 48.8062 - MSE: 48.8062 - MAE: 5.7402\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 553/20000 - Train Loss: 20.1767 - Test Loss: 48.8050 - MSE: 48.8050 - MAE: 5.7401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 554/20000 - Train Loss: 20.1761 - Test Loss: 48.8037 - MSE: 48.8037 - MAE: 5.7400\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 555/20000 - Train Loss: 20.1755 - Test Loss: 48.8024 - MSE: 48.8024 - MAE: 5.7399\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 556/20000 - Train Loss: 20.1749 - Test Loss: 48.8010 - MSE: 48.8011 - MAE: 5.7398\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 557/20000 - Train Loss: 20.1743 - Test Loss: 48.7998 - MSE: 48.7998 - MAE: 5.7397\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 558/20000 - Train Loss: 20.1737 - Test Loss: 48.7984 - MSE: 48.7984 - MAE: 5.7397\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 559/20000 - Train Loss: 20.1731 - Test Loss: 48.7971 - MSE: 48.7971 - MAE: 5.7396\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 560/20000 - Train Loss: 20.1725 - Test Loss: 48.7957 - MSE: 48.7957 - MAE: 5.7395\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 561/20000 - Train Loss: 20.1719 - Test Loss: 48.7944 - MSE: 48.7944 - MAE: 5.7394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 562/20000 - Train Loss: 20.1713 - Test Loss: 48.7931 - MSE: 48.7931 - MAE: 5.7393\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 563/20000 - Train Loss: 20.1707 - Test Loss: 48.7918 - MSE: 48.7918 - MAE: 5.7392\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 564/20000 - Train Loss: 20.1701 - Test Loss: 48.7905 - MSE: 48.7905 - MAE: 5.7392\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 565/20000 - Train Loss: 20.1695 - Test Loss: 48.7891 - MSE: 48.7891 - MAE: 5.7391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 566/20000 - Train Loss: 20.1689 - Test Loss: 48.7878 - MSE: 48.7878 - MAE: 5.7390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 567/20000 - Train Loss: 20.1683 - Test Loss: 48.7865 - MSE: 48.7865 - MAE: 5.7389\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 568/20000 - Train Loss: 20.1677 - Test Loss: 48.7851 - MSE: 48.7852 - MAE: 5.7388\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 569/20000 - Train Loss: 20.1670 - Test Loss: 48.7838 - MSE: 48.7838 - MAE: 5.7387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 570/20000 - Train Loss: 20.1664 - Test Loss: 48.7825 - MSE: 48.7825 - MAE: 5.7387\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 571/20000 - Train Loss: 20.1658 - Test Loss: 48.7811 - MSE: 48.7811 - MAE: 5.7386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 572/20000 - Train Loss: 20.1652 - Test Loss: 48.7798 - MSE: 48.7798 - MAE: 5.7385\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 573/20000 - Train Loss: 20.1646 - Test Loss: 48.7784 - MSE: 48.7784 - MAE: 5.7384\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 574/20000 - Train Loss: 20.1640 - Test Loss: 48.7771 - MSE: 48.7771 - MAE: 5.7383\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 575/20000 - Train Loss: 20.1634 - Test Loss: 48.7757 - MSE: 48.7757 - MAE: 5.7382\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 576/20000 - Train Loss: 20.1628 - Test Loss: 48.7744 - MSE: 48.7744 - MAE: 5.7382\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 577/20000 - Train Loss: 20.1622 - Test Loss: 48.7731 - MSE: 48.7731 - MAE: 5.7381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 578/20000 - Train Loss: 20.1615 - Test Loss: 48.7716 - MSE: 48.7716 - MAE: 5.7380\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 579/20000 - Train Loss: 20.1609 - Test Loss: 48.7703 - MSE: 48.7703 - MAE: 5.7379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 580/20000 - Train Loss: 20.1603 - Test Loss: 48.7690 - MSE: 48.7690 - MAE: 5.7378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 581/20000 - Train Loss: 20.1597 - Test Loss: 48.7676 - MSE: 48.7676 - MAE: 5.7377\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 582/20000 - Train Loss: 20.1591 - Test Loss: 48.7662 - MSE: 48.7662 - MAE: 5.7376\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 583/20000 - Train Loss: 20.1585 - Test Loss: 48.7648 - MSE: 48.7648 - MAE: 5.7376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 584/20000 - Train Loss: 20.1579 - Test Loss: 48.7634 - MSE: 48.7634 - MAE: 5.7375\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 585/20000 - Train Loss: 20.1572 - Test Loss: 48.7620 - MSE: 48.7620 - MAE: 5.7374\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 586/20000 - Train Loss: 20.1566 - Test Loss: 48.7607 - MSE: 48.7607 - MAE: 5.7373\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 587/20000 - Train Loss: 20.1560 - Test Loss: 48.7593 - MSE: 48.7593 - MAE: 5.7372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 588/20000 - Train Loss: 20.1554 - Test Loss: 48.7579 - MSE: 48.7579 - MAE: 5.7371\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 589/20000 - Train Loss: 20.1548 - Test Loss: 48.7566 - MSE: 48.7566 - MAE: 5.7370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 590/20000 - Train Loss: 20.1541 - Test Loss: 48.7552 - MSE: 48.7552 - MAE: 5.7370\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 591/20000 - Train Loss: 20.1535 - Test Loss: 48.7538 - MSE: 48.7538 - MAE: 5.7369\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 592/20000 - Train Loss: 20.1529 - Test Loss: 48.7524 - MSE: 48.7524 - MAE: 5.7368\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 593/20000 - Train Loss: 20.1523 - Test Loss: 48.7511 - MSE: 48.7511 - MAE: 5.7367\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 594/20000 - Train Loss: 20.1516 - Test Loss: 48.7497 - MSE: 48.7497 - MAE: 5.7366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 595/20000 - Train Loss: 20.1510 - Test Loss: 48.7483 - MSE: 48.7483 - MAE: 5.7365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 596/20000 - Train Loss: 20.1504 - Test Loss: 48.7469 - MSE: 48.7469 - MAE: 5.7364\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 597/20000 - Train Loss: 20.1498 - Test Loss: 48.7455 - MSE: 48.7455 - MAE: 5.7364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 598/20000 - Train Loss: 20.1491 - Test Loss: 48.7441 - MSE: 48.7441 - MAE: 5.7363\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 599/20000 - Train Loss: 20.1485 - Test Loss: 48.7428 - MSE: 48.7428 - MAE: 5.7362\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 600/20000 - Train Loss: 20.1479 - Test Loss: 48.7414 - MSE: 48.7414 - MAE: 5.7361\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 601/20000 - Train Loss: 20.1473 - Test Loss: 48.7400 - MSE: 48.7400 - MAE: 5.7360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 602/20000 - Train Loss: 20.1466 - Test Loss: 48.7386 - MSE: 48.7386 - MAE: 5.7359\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 603/20000 - Train Loss: 20.1460 - Test Loss: 48.7372 - MSE: 48.7372 - MAE: 5.7358\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 604/20000 - Train Loss: 20.1454 - Test Loss: 48.7359 - MSE: 48.7359 - MAE: 5.7358\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 605/20000 - Train Loss: 20.1447 - Test Loss: 48.7345 - MSE: 48.7345 - MAE: 5.7357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 606/20000 - Train Loss: 20.1441 - Test Loss: 48.7331 - MSE: 48.7331 - MAE: 5.7356\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 607/20000 - Train Loss: 20.1435 - Test Loss: 48.7317 - MSE: 48.7317 - MAE: 5.7355\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 608/20000 - Train Loss: 20.1428 - Test Loss: 48.7303 - MSE: 48.7303 - MAE: 5.7354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 609/20000 - Train Loss: 20.1422 - Test Loss: 48.7289 - MSE: 48.7289 - MAE: 5.7353\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 610/20000 - Train Loss: 20.1416 - Test Loss: 48.7275 - MSE: 48.7275 - MAE: 5.7352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 611/20000 - Train Loss: 20.1409 - Test Loss: 48.7261 - MSE: 48.7261 - MAE: 5.7351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 612/20000 - Train Loss: 20.1403 - Test Loss: 48.7247 - MSE: 48.7247 - MAE: 5.7351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 613/20000 - Train Loss: 20.1397 - Test Loss: 48.7233 - MSE: 48.7233 - MAE: 5.7350\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 614/20000 - Train Loss: 20.1390 - Test Loss: 48.7219 - MSE: 48.7219 - MAE: 5.7349\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 615/20000 - Train Loss: 20.1384 - Test Loss: 48.7205 - MSE: 48.7205 - MAE: 5.7348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 616/20000 - Train Loss: 20.1377 - Test Loss: 48.7191 - MSE: 48.7191 - MAE: 5.7347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 617/20000 - Train Loss: 20.1371 - Test Loss: 48.7177 - MSE: 48.7177 - MAE: 5.7346\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 618/20000 - Train Loss: 20.1365 - Test Loss: 48.7163 - MSE: 48.7163 - MAE: 5.7345\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 619/20000 - Train Loss: 20.1358 - Test Loss: 48.7149 - MSE: 48.7149 - MAE: 5.7344\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 620/20000 - Train Loss: 20.1352 - Test Loss: 48.7134 - MSE: 48.7134 - MAE: 5.7343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 621/20000 - Train Loss: 20.1345 - Test Loss: 48.7121 - MSE: 48.7121 - MAE: 5.7343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 622/20000 - Train Loss: 20.1339 - Test Loss: 48.7106 - MSE: 48.7106 - MAE: 5.7342\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 623/20000 - Train Loss: 20.1332 - Test Loss: 48.7092 - MSE: 48.7092 - MAE: 5.7341\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 624/20000 - Train Loss: 20.1326 - Test Loss: 48.7078 - MSE: 48.7078 - MAE: 5.7340\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 625/20000 - Train Loss: 20.1320 - Test Loss: 48.7063 - MSE: 48.7063 - MAE: 5.7339\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch 626/20000 - Train Loss: 20.1313 - Test Loss: 48.7050 - MSE: 48.7050 - MAE: 5.7338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 627/20000 - Train Loss: 20.1307 - Test Loss: 48.7036 - MSE: 48.7036 - MAE: 5.7337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 628/20000 - Train Loss: 20.1300 - Test Loss: 48.7021 - MSE: 48.7021 - MAE: 5.7336\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 629/20000 - Train Loss: 20.1294 - Test Loss: 48.7007 - MSE: 48.7007 - MAE: 5.7335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 630/20000 - Train Loss: 20.1287 - Test Loss: 48.6992 - MSE: 48.6992 - MAE: 5.7335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 631/20000 - Train Loss: 20.1281 - Test Loss: 48.6978 - MSE: 48.6978 - MAE: 5.7334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 632/20000 - Train Loss: 20.1274 - Test Loss: 48.6964 - MSE: 48.6964 - MAE: 5.7333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 633/20000 - Train Loss: 20.1268 - Test Loss: 48.6949 - MSE: 48.6949 - MAE: 5.7332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 634/20000 - Train Loss: 20.1261 - Test Loss: 48.6934 - MSE: 48.6934 - MAE: 5.7331\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 635/20000 - Train Loss: 20.1255 - Test Loss: 48.6919 - MSE: 48.6919 - MAE: 5.7330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 636/20000 - Train Loss: 20.1248 - Test Loss: 48.6905 - MSE: 48.6905 - MAE: 5.7329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 637/20000 - Train Loss: 20.1242 - Test Loss: 48.6890 - MSE: 48.6890 - MAE: 5.7328\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 638/20000 - Train Loss: 20.1235 - Test Loss: 48.6876 - MSE: 48.6876 - MAE: 5.7327\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 639/20000 - Train Loss: 20.1229 - Test Loss: 48.6862 - MSE: 48.6862 - MAE: 5.7326\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 640/20000 - Train Loss: 20.1222 - Test Loss: 48.6847 - MSE: 48.6847 - MAE: 5.7326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 641/20000 - Train Loss: 20.1215 - Test Loss: 48.6832 - MSE: 48.6832 - MAE: 5.7325\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 642/20000 - Train Loss: 20.1209 - Test Loss: 48.6818 - MSE: 48.6818 - MAE: 5.7324\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 643/20000 - Train Loss: 20.1202 - Test Loss: 48.6803 - MSE: 48.6803 - MAE: 5.7323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 644/20000 - Train Loss: 20.1196 - Test Loss: 48.6789 - MSE: 48.6789 - MAE: 5.7322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 645/20000 - Train Loss: 20.1189 - Test Loss: 48.6774 - MSE: 48.6774 - MAE: 5.7321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 646/20000 - Train Loss: 20.1183 - Test Loss: 48.6760 - MSE: 48.6760 - MAE: 5.7320\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 647/20000 - Train Loss: 20.1176 - Test Loss: 48.6746 - MSE: 48.6746 - MAE: 5.7319\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 648/20000 - Train Loss: 20.1169 - Test Loss: 48.6731 - MSE: 48.6731 - MAE: 5.7318\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 649/20000 - Train Loss: 20.1163 - Test Loss: 48.6716 - MSE: 48.6716 - MAE: 5.7317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 650/20000 - Train Loss: 20.1156 - Test Loss: 48.6702 - MSE: 48.6702 - MAE: 5.7316\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 651/20000 - Train Loss: 20.1149 - Test Loss: 48.6687 - MSE: 48.6687 - MAE: 5.7315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 652/20000 - Train Loss: 20.1143 - Test Loss: 48.6673 - MSE: 48.6673 - MAE: 5.7315\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 653/20000 - Train Loss: 20.1136 - Test Loss: 48.6658 - MSE: 48.6658 - MAE: 5.7314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 654/20000 - Train Loss: 20.1130 - Test Loss: 48.6643 - MSE: 48.6643 - MAE: 5.7313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 655/20000 - Train Loss: 20.1123 - Test Loss: 48.6628 - MSE: 48.6628 - MAE: 5.7312\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 656/20000 - Train Loss: 20.1116 - Test Loss: 48.6614 - MSE: 48.6614 - MAE: 5.7311\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 657/20000 - Train Loss: 20.1110 - Test Loss: 48.6599 - MSE: 48.6599 - MAE: 5.7310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 658/20000 - Train Loss: 20.1103 - Test Loss: 48.6585 - MSE: 48.6585 - MAE: 5.7309\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 659/20000 - Train Loss: 20.1096 - Test Loss: 48.6570 - MSE: 48.6570 - MAE: 5.7308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 660/20000 - Train Loss: 20.1090 - Test Loss: 48.6555 - MSE: 48.6555 - MAE: 5.7307\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 661/20000 - Train Loss: 20.1083 - Test Loss: 48.6541 - MSE: 48.6541 - MAE: 5.7306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 662/20000 - Train Loss: 20.1076 - Test Loss: 48.6526 - MSE: 48.6526 - MAE: 5.7305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 663/20000 - Train Loss: 20.1070 - Test Loss: 48.6511 - MSE: 48.6511 - MAE: 5.7304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 664/20000 - Train Loss: 20.1063 - Test Loss: 48.6497 - MSE: 48.6497 - MAE: 5.7304\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 665/20000 - Train Loss: 20.1056 - Test Loss: 48.6482 - MSE: 48.6483 - MAE: 5.7303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 666/20000 - Train Loss: 20.1049 - Test Loss: 48.6467 - MSE: 48.6467 - MAE: 5.7302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 667/20000 - Train Loss: 20.1043 - Test Loss: 48.6453 - MSE: 48.6453 - MAE: 5.7301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 668/20000 - Train Loss: 20.1036 - Test Loss: 48.6437 - MSE: 48.6437 - MAE: 5.7300\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 669/20000 - Train Loss: 20.1029 - Test Loss: 48.6422 - MSE: 48.6422 - MAE: 5.7299\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 670/20000 - Train Loss: 20.1022 - Test Loss: 48.6408 - MSE: 48.6408 - MAE: 5.7298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 671/20000 - Train Loss: 20.1016 - Test Loss: 48.6393 - MSE: 48.6393 - MAE: 5.7297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 672/20000 - Train Loss: 20.1009 - Test Loss: 48.6379 - MSE: 48.6379 - MAE: 5.7296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 673/20000 - Train Loss: 20.1002 - Test Loss: 48.6363 - MSE: 48.6363 - MAE: 5.7295\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 674/20000 - Train Loss: 20.0995 - Test Loss: 48.6349 - MSE: 48.6349 - MAE: 5.7294\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 675/20000 - Train Loss: 20.0988 - Test Loss: 48.6334 - MSE: 48.6334 - MAE: 5.7293\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 676/20000 - Train Loss: 20.0982 - Test Loss: 48.6318 - MSE: 48.6318 - MAE: 5.7292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 677/20000 - Train Loss: 20.0975 - Test Loss: 48.6304 - MSE: 48.6304 - MAE: 5.7291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 678/20000 - Train Loss: 20.0968 - Test Loss: 48.6288 - MSE: 48.6288 - MAE: 5.7290\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 679/20000 - Train Loss: 20.0961 - Test Loss: 48.6273 - MSE: 48.6273 - MAE: 5.7290\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 680/20000 - Train Loss: 20.0955 - Test Loss: 48.6258 - MSE: 48.6258 - MAE: 5.7289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 681/20000 - Train Loss: 20.0948 - Test Loss: 48.6243 - MSE: 48.6242 - MAE: 5.7288\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 682/20000 - Train Loss: 20.0941 - Test Loss: 48.6228 - MSE: 48.6228 - MAE: 5.7287\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 683/20000 - Train Loss: 20.0934 - Test Loss: 48.6213 - MSE: 48.6213 - MAE: 5.7286\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 684/20000 - Train Loss: 20.0927 - Test Loss: 48.6198 - MSE: 48.6198 - MAE: 5.7285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 685/20000 - Train Loss: 20.0920 - Test Loss: 48.6182 - MSE: 48.6182 - MAE: 5.7284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 686/20000 - Train Loss: 20.0913 - Test Loss: 48.6167 - MSE: 48.6167 - MAE: 5.7283\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 687/20000 - Train Loss: 20.0907 - Test Loss: 48.6152 - MSE: 48.6152 - MAE: 5.7282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 688/20000 - Train Loss: 20.0900 - Test Loss: 48.6136 - MSE: 48.6136 - MAE: 5.7281\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 689/20000 - Train Loss: 20.0893 - Test Loss: 48.6121 - MSE: 48.6121 - MAE: 5.7280\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 690/20000 - Train Loss: 20.0886 - Test Loss: 48.6105 - MSE: 48.6105 - MAE: 5.7279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 691/20000 - Train Loss: 20.0879 - Test Loss: 48.6090 - MSE: 48.6090 - MAE: 5.7278\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 692/20000 - Train Loss: 20.0872 - Test Loss: 48.6074 - MSE: 48.6074 - MAE: 5.7277\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 693/20000 - Train Loss: 20.0865 - Test Loss: 48.6059 - MSE: 48.6059 - MAE: 5.7276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 694/20000 - Train Loss: 20.0858 - Test Loss: 48.6044 - MSE: 48.6044 - MAE: 5.7275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 695/20000 - Train Loss: 20.0851 - Test Loss: 48.6029 - MSE: 48.6029 - MAE: 5.7274\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 696/20000 - Train Loss: 20.0844 - Test Loss: 48.6014 - MSE: 48.6014 - MAE: 5.7273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 697/20000 - Train Loss: 20.0837 - Test Loss: 48.5999 - MSE: 48.5999 - MAE: 5.7272\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 698/20000 - Train Loss: 20.0831 - Test Loss: 48.5983 - MSE: 48.5983 - MAE: 5.7271\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 699/20000 - Train Loss: 20.0824 - Test Loss: 48.5968 - MSE: 48.5968 - MAE: 5.7270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 700/20000 - Train Loss: 20.0817 - Test Loss: 48.5953 - MSE: 48.5953 - MAE: 5.7269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 701/20000 - Train Loss: 20.0810 - Test Loss: 48.5937 - MSE: 48.5937 - MAE: 5.7269\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 702/20000 - Train Loss: 20.0803 - Test Loss: 48.5922 - MSE: 48.5922 - MAE: 5.7268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 703/20000 - Train Loss: 20.0796 - Test Loss: 48.5907 - MSE: 48.5907 - MAE: 5.7267\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 704/20000 - Train Loss: 20.0789 - Test Loss: 48.5891 - MSE: 48.5891 - MAE: 5.7266\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 705/20000 - Train Loss: 20.0782 - Test Loss: 48.5876 - MSE: 48.5876 - MAE: 5.7265\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 706/20000 - Train Loss: 20.0775 - Test Loss: 48.5860 - MSE: 48.5860 - MAE: 5.7264\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 707/20000 - Train Loss: 20.0768 - Test Loss: 48.5845 - MSE: 48.5845 - MAE: 5.7263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 708/20000 - Train Loss: 20.0761 - Test Loss: 48.5829 - MSE: 48.5829 - MAE: 5.7262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 709/20000 - Train Loss: 20.0754 - Test Loss: 48.5814 - MSE: 48.5814 - MAE: 5.7261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 710/20000 - Train Loss: 20.0747 - Test Loss: 48.5799 - MSE: 48.5799 - MAE: 5.7260\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 711/20000 - Train Loss: 20.0740 - Test Loss: 48.5784 - MSE: 48.5784 - MAE: 5.7259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 712/20000 - Train Loss: 20.0733 - Test Loss: 48.5768 - MSE: 48.5768 - MAE: 5.7258\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 713/20000 - Train Loss: 20.0726 - Test Loss: 48.5753 - MSE: 48.5753 - MAE: 5.7257\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 714/20000 - Train Loss: 20.0719 - Test Loss: 48.5737 - MSE: 48.5737 - MAE: 5.7256\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 715/20000 - Train Loss: 20.0712 - Test Loss: 48.5722 - MSE: 48.5722 - MAE: 5.7255\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 716/20000 - Train Loss: 20.0705 - Test Loss: 48.5706 - MSE: 48.5706 - MAE: 5.7254\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 717/20000 - Train Loss: 20.0697 - Test Loss: 48.5690 - MSE: 48.5690 - MAE: 5.7253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 718/20000 - Train Loss: 20.0690 - Test Loss: 48.5675 - MSE: 48.5675 - MAE: 5.7252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 719/20000 - Train Loss: 20.0683 - Test Loss: 48.5659 - MSE: 48.5659 - MAE: 5.7251\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 720/20000 - Train Loss: 20.0676 - Test Loss: 48.5644 - MSE: 48.5644 - MAE: 5.7250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 721/20000 - Train Loss: 20.0669 - Test Loss: 48.5629 - MSE: 48.5629 - MAE: 5.7249\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 722/20000 - Train Loss: 20.0662 - Test Loss: 48.5613 - MSE: 48.5613 - MAE: 5.7248\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 723/20000 - Train Loss: 20.0655 - Test Loss: 48.5597 - MSE: 48.5597 - MAE: 5.7247\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 724/20000 - Train Loss: 20.0648 - Test Loss: 48.5581 - MSE: 48.5581 - MAE: 5.7246\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 725/20000 - Train Loss: 20.0641 - Test Loss: 48.5565 - MSE: 48.5565 - MAE: 5.7245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 726/20000 - Train Loss: 20.0634 - Test Loss: 48.5549 - MSE: 48.5549 - MAE: 5.7244\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 727/20000 - Train Loss: 20.0627 - Test Loss: 48.5533 - MSE: 48.5533 - MAE: 5.7243\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 728/20000 - Train Loss: 20.0619 - Test Loss: 48.5517 - MSE: 48.5517 - MAE: 5.7242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 729/20000 - Train Loss: 20.0612 - Test Loss: 48.5502 - MSE: 48.5502 - MAE: 5.7241\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 730/20000 - Train Loss: 20.0605 - Test Loss: 48.5487 - MSE: 48.5487 - MAE: 5.7240\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 731/20000 - Train Loss: 20.0598 - Test Loss: 48.5472 - MSE: 48.5472 - MAE: 5.7239\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 732/20000 - Train Loss: 20.0591 - Test Loss: 48.5456 - MSE: 48.5456 - MAE: 5.7238\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 733/20000 - Train Loss: 20.0584 - Test Loss: 48.5440 - MSE: 48.5440 - MAE: 5.7237\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 734/20000 - Train Loss: 20.0576 - Test Loss: 48.5424 - MSE: 48.5424 - MAE: 5.7236\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 735/20000 - Train Loss: 20.0569 - Test Loss: 48.5408 - MSE: 48.5408 - MAE: 5.7235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 736/20000 - Train Loss: 20.0562 - Test Loss: 48.5392 - MSE: 48.5392 - MAE: 5.7234\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 737/20000 - Train Loss: 20.0555 - Test Loss: 48.5376 - MSE: 48.5376 - MAE: 5.7233\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 738/20000 - Train Loss: 20.0548 - Test Loss: 48.5359 - MSE: 48.5359 - MAE: 5.7232\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 739/20000 - Train Loss: 20.0540 - Test Loss: 48.5343 - MSE: 48.5343 - MAE: 5.7231\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 740/20000 - Train Loss: 20.0533 - Test Loss: 48.5328 - MSE: 48.5328 - MAE: 5.7230\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 741/20000 - Train Loss: 20.0526 - Test Loss: 48.5312 - MSE: 48.5312 - MAE: 5.7229\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 742/20000 - Train Loss: 20.0519 - Test Loss: 48.5296 - MSE: 48.5296 - MAE: 5.7228\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 743/20000 - Train Loss: 20.0511 - Test Loss: 48.5280 - MSE: 48.5280 - MAE: 5.7227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 744/20000 - Train Loss: 20.0504 - Test Loss: 48.5264 - MSE: 48.5264 - MAE: 5.7226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 745/20000 - Train Loss: 20.0497 - Test Loss: 48.5248 - MSE: 48.5248 - MAE: 5.7225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 746/20000 - Train Loss: 20.0490 - Test Loss: 48.5231 - MSE: 48.5231 - MAE: 5.7224\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 747/20000 - Train Loss: 20.0482 - Test Loss: 48.5215 - MSE: 48.5215 - MAE: 5.7223\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 748/20000 - Train Loss: 20.0475 - Test Loss: 48.5200 - MSE: 48.5200 - MAE: 5.7222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 749/20000 - Train Loss: 20.0468 - Test Loss: 48.5183 - MSE: 48.5183 - MAE: 5.7221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 750/20000 - Train Loss: 20.0461 - Test Loss: 48.5167 - MSE: 48.5167 - MAE: 5.7220\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 751/20000 - Train Loss: 20.0453 - Test Loss: 48.5151 - MSE: 48.5151 - MAE: 5.7219\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 752/20000 - Train Loss: 20.0446 - Test Loss: 48.5134 - MSE: 48.5134 - MAE: 5.7218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 753/20000 - Train Loss: 20.0439 - Test Loss: 48.5118 - MSE: 48.5118 - MAE: 5.7217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 754/20000 - Train Loss: 20.0431 - Test Loss: 48.5102 - MSE: 48.5102 - MAE: 5.7216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 755/20000 - Train Loss: 20.0424 - Test Loss: 48.5087 - MSE: 48.5087 - MAE: 5.7215\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 756/20000 - Train Loss: 20.0417 - Test Loss: 48.5070 - MSE: 48.5070 - MAE: 5.7214\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 757/20000 - Train Loss: 20.0410 - Test Loss: 48.5054 - MSE: 48.5054 - MAE: 5.7213\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 758/20000 - Train Loss: 20.0402 - Test Loss: 48.5038 - MSE: 48.5038 - MAE: 5.7212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 759/20000 - Train Loss: 20.0395 - Test Loss: 48.5022 - MSE: 48.5022 - MAE: 5.7211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 760/20000 - Train Loss: 20.0387 - Test Loss: 48.5006 - MSE: 48.5006 - MAE: 5.7210\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 761/20000 - Train Loss: 20.0380 - Test Loss: 48.4989 - MSE: 48.4989 - MAE: 5.7209\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 762/20000 - Train Loss: 20.0373 - Test Loss: 48.4973 - MSE: 48.4973 - MAE: 5.7208\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 763/20000 - Train Loss: 20.0365 - Test Loss: 48.4957 - MSE: 48.4957 - MAE: 5.7207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 764/20000 - Train Loss: 20.0358 - Test Loss: 48.4941 - MSE: 48.4941 - MAE: 5.7206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 765/20000 - Train Loss: 20.0351 - Test Loss: 48.4925 - MSE: 48.4925 - MAE: 5.7205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 766/20000 - Train Loss: 20.0343 - Test Loss: 48.4909 - MSE: 48.4909 - MAE: 5.7204\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 767/20000 - Train Loss: 20.0336 - Test Loss: 48.4893 - MSE: 48.4893 - MAE: 5.7203\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 768/20000 - Train Loss: 20.0328 - Test Loss: 48.4877 - MSE: 48.4877 - MAE: 5.7202\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 769/20000 - Train Loss: 20.0321 - Test Loss: 48.4860 - MSE: 48.4860 - MAE: 5.7201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 770/20000 - Train Loss: 20.0314 - Test Loss: 48.4844 - MSE: 48.4844 - MAE: 5.7200\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 771/20000 - Train Loss: 20.0306 - Test Loss: 48.4827 - MSE: 48.4827 - MAE: 5.7199\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 772/20000 - Train Loss: 20.0299 - Test Loss: 48.4810 - MSE: 48.4810 - MAE: 5.7198\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 773/20000 - Train Loss: 20.0291 - Test Loss: 48.4795 - MSE: 48.4795 - MAE: 5.7197\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 774/20000 - Train Loss: 20.0284 - Test Loss: 48.4778 - MSE: 48.4778 - MAE: 5.7196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 775/20000 - Train Loss: 20.0276 - Test Loss: 48.4762 - MSE: 48.4762 - MAE: 5.7195\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 776/20000 - Train Loss: 20.0269 - Test Loss: 48.4745 - MSE: 48.4745 - MAE: 5.7194\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 777/20000 - Train Loss: 20.0262 - Test Loss: 48.4729 - MSE: 48.4729 - MAE: 5.7193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 778/20000 - Train Loss: 20.0254 - Test Loss: 48.4713 - MSE: 48.4713 - MAE: 5.7192\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 779/20000 - Train Loss: 20.0247 - Test Loss: 48.4696 - MSE: 48.4696 - MAE: 5.7191\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 780/20000 - Train Loss: 20.0239 - Test Loss: 48.4679 - MSE: 48.4679 - MAE: 5.7190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 781/20000 - Train Loss: 20.0232 - Test Loss: 48.4662 - MSE: 48.4662 - MAE: 5.7189\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 782/20000 - Train Loss: 20.0224 - Test Loss: 48.4646 - MSE: 48.4646 - MAE: 5.7188\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 783/20000 - Train Loss: 20.0217 - Test Loss: 48.4629 - MSE: 48.4629 - MAE: 5.7186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 784/20000 - Train Loss: 20.0209 - Test Loss: 48.4613 - MSE: 48.4613 - MAE: 5.7185\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 785/20000 - Train Loss: 20.0202 - Test Loss: 48.4596 - MSE: 48.4596 - MAE: 5.7184\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 786/20000 - Train Loss: 20.0194 - Test Loss: 48.4579 - MSE: 48.4579 - MAE: 5.7183\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 787/20000 - Train Loss: 20.0187 - Test Loss: 48.4564 - MSE: 48.4564 - MAE: 5.7182\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 788/20000 - Train Loss: 20.0179 - Test Loss: 48.4547 - MSE: 48.4547 - MAE: 5.7181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 789/20000 - Train Loss: 20.0171 - Test Loss: 48.4530 - MSE: 48.4530 - MAE: 5.7180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 790/20000 - Train Loss: 20.0164 - Test Loss: 48.4513 - MSE: 48.4513 - MAE: 5.7179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 791/20000 - Train Loss: 20.0156 - Test Loss: 48.4497 - MSE: 48.4497 - MAE: 5.7178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 792/20000 - Train Loss: 20.0149 - Test Loss: 48.4480 - MSE: 48.4480 - MAE: 5.7177\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 793/20000 - Train Loss: 20.0141 - Test Loss: 48.4463 - MSE: 48.4463 - MAE: 5.7176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 794/20000 - Train Loss: 20.0134 - Test Loss: 48.4446 - MSE: 48.4446 - MAE: 5.7175\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 795/20000 - Train Loss: 20.0126 - Test Loss: 48.4429 - MSE: 48.4429 - MAE: 5.7174\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 796/20000 - Train Loss: 20.0118 - Test Loss: 48.4412 - MSE: 48.4412 - MAE: 5.7173\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 797/20000 - Train Loss: 20.0111 - Test Loss: 48.4395 - MSE: 48.4395 - MAE: 5.7172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 798/20000 - Train Loss: 20.0103 - Test Loss: 48.4379 - MSE: 48.4379 - MAE: 5.7171\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 799/20000 - Train Loss: 20.0096 - Test Loss: 48.4362 - MSE: 48.4362 - MAE: 5.7170\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 800/20000 - Train Loss: 20.0088 - Test Loss: 48.4345 - MSE: 48.4345 - MAE: 5.7169\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 801/20000 - Train Loss: 20.0080 - Test Loss: 48.4328 - MSE: 48.4328 - MAE: 5.7168\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 802/20000 - Train Loss: 20.0073 - Test Loss: 48.4311 - MSE: 48.4311 - MAE: 5.7167\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 803/20000 - Train Loss: 20.0065 - Test Loss: 48.4294 - MSE: 48.4294 - MAE: 5.7165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 804/20000 - Train Loss: 20.0057 - Test Loss: 48.4278 - MSE: 48.4278 - MAE: 5.7164\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 805/20000 - Train Loss: 20.0050 - Test Loss: 48.4261 - MSE: 48.4261 - MAE: 5.7163\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 806/20000 - Train Loss: 20.0042 - Test Loss: 48.4244 - MSE: 48.4244 - MAE: 5.7162\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 807/20000 - Train Loss: 20.0035 - Test Loss: 48.4227 - MSE: 48.4227 - MAE: 5.7161\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 808/20000 - Train Loss: 20.0027 - Test Loss: 48.4210 - MSE: 48.4210 - MAE: 5.7160\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 809/20000 - Train Loss: 20.0019 - Test Loss: 48.4193 - MSE: 48.4193 - MAE: 5.7159\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 810/20000 - Train Loss: 20.0012 - Test Loss: 48.4176 - MSE: 48.4176 - MAE: 5.7158\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 811/20000 - Train Loss: 20.0004 - Test Loss: 48.4159 - MSE: 48.4159 - MAE: 5.7157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 812/20000 - Train Loss: 19.9996 - Test Loss: 48.4143 - MSE: 48.4143 - MAE: 5.7156\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 813/20000 - Train Loss: 19.9988 - Test Loss: 48.4126 - MSE: 48.4125 - MAE: 5.7155\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 814/20000 - Train Loss: 19.9981 - Test Loss: 48.4108 - MSE: 48.4108 - MAE: 5.7154\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 815/20000 - Train Loss: 19.9973 - Test Loss: 48.4092 - MSE: 48.4092 - MAE: 5.7153\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 816/20000 - Train Loss: 19.9965 - Test Loss: 48.4075 - MSE: 48.4075 - MAE: 5.7152\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 817/20000 - Train Loss: 19.9958 - Test Loss: 48.4057 - MSE: 48.4057 - MAE: 5.7151\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 818/20000 - Train Loss: 19.9950 - Test Loss: 48.4041 - MSE: 48.4041 - MAE: 5.7150\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 819/20000 - Train Loss: 19.9942 - Test Loss: 48.4023 - MSE: 48.4023 - MAE: 5.7148\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 820/20000 - Train Loss: 19.9934 - Test Loss: 48.4006 - MSE: 48.4006 - MAE: 5.7147\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 821/20000 - Train Loss: 19.9927 - Test Loss: 48.3989 - MSE: 48.3989 - MAE: 5.7146\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 822/20000 - Train Loss: 19.9919 - Test Loss: 48.3972 - MSE: 48.3972 - MAE: 5.7145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 823/20000 - Train Loss: 19.9911 - Test Loss: 48.3955 - MSE: 48.3955 - MAE: 5.7144\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 824/20000 - Train Loss: 19.9903 - Test Loss: 48.3938 - MSE: 48.3938 - MAE: 5.7143\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 825/20000 - Train Loss: 19.9895 - Test Loss: 48.3921 - MSE: 48.3921 - MAE: 5.7142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 826/20000 - Train Loss: 19.9888 - Test Loss: 48.3905 - MSE: 48.3905 - MAE: 5.7141\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 827/20000 - Train Loss: 19.9880 - Test Loss: 48.3888 - MSE: 48.3888 - MAE: 5.7140\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 828/20000 - Train Loss: 19.9872 - Test Loss: 48.3870 - MSE: 48.3870 - MAE: 5.7139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 829/20000 - Train Loss: 19.9864 - Test Loss: 48.3853 - MSE: 48.3853 - MAE: 5.7138\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 830/20000 - Train Loss: 19.9857 - Test Loss: 48.3835 - MSE: 48.3835 - MAE: 5.7137\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 831/20000 - Train Loss: 19.9849 - Test Loss: 48.3818 - MSE: 48.3818 - MAE: 5.7136\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 832/20000 - Train Loss: 19.9841 - Test Loss: 48.3801 - MSE: 48.3801 - MAE: 5.7134\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 833/20000 - Train Loss: 19.9833 - Test Loss: 48.3783 - MSE: 48.3783 - MAE: 5.7133\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 834/20000 - Train Loss: 19.9825 - Test Loss: 48.3766 - MSE: 48.3766 - MAE: 5.7132\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 835/20000 - Train Loss: 19.9817 - Test Loss: 48.3749 - MSE: 48.3749 - MAE: 5.7131\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 836/20000 - Train Loss: 19.9809 - Test Loss: 48.3731 - MSE: 48.3731 - MAE: 5.7130\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 837/20000 - Train Loss: 19.9802 - Test Loss: 48.3714 - MSE: 48.3714 - MAE: 5.7129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 838/20000 - Train Loss: 19.9794 - Test Loss: 48.3697 - MSE: 48.3697 - MAE: 5.7128\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 839/20000 - Train Loss: 19.9786 - Test Loss: 48.3679 - MSE: 48.3679 - MAE: 5.7127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 840/20000 - Train Loss: 19.9778 - Test Loss: 48.3662 - MSE: 48.3662 - MAE: 5.7126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 841/20000 - Train Loss: 19.9770 - Test Loss: 48.3644 - MSE: 48.3644 - MAE: 5.7125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 842/20000 - Train Loss: 19.9762 - Test Loss: 48.3627 - MSE: 48.3627 - MAE: 5.7124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 843/20000 - Train Loss: 19.9754 - Test Loss: 48.3610 - MSE: 48.3610 - MAE: 5.7122\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 844/20000 - Train Loss: 19.9746 - Test Loss: 48.3592 - MSE: 48.3592 - MAE: 5.7121\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 845/20000 - Train Loss: 19.9739 - Test Loss: 48.3575 - MSE: 48.3575 - MAE: 5.7120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 846/20000 - Train Loss: 19.9731 - Test Loss: 48.3557 - MSE: 48.3557 - MAE: 5.7119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 847/20000 - Train Loss: 19.9723 - Test Loss: 48.3539 - MSE: 48.3539 - MAE: 5.7118\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 848/20000 - Train Loss: 19.9715 - Test Loss: 48.3521 - MSE: 48.3521 - MAE: 5.7117\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 849/20000 - Train Loss: 19.9707 - Test Loss: 48.3504 - MSE: 48.3504 - MAE: 5.7116\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 850/20000 - Train Loss: 19.9699 - Test Loss: 48.3487 - MSE: 48.3487 - MAE: 5.7115\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 851/20000 - Train Loss: 19.9691 - Test Loss: 48.3469 - MSE: 48.3469 - MAE: 5.7114\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 852/20000 - Train Loss: 19.9683 - Test Loss: 48.3452 - MSE: 48.3452 - MAE: 5.7113\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 853/20000 - Train Loss: 19.9675 - Test Loss: 48.3434 - MSE: 48.3434 - MAE: 5.7111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 854/20000 - Train Loss: 19.9667 - Test Loss: 48.3416 - MSE: 48.3416 - MAE: 5.7110\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 855/20000 - Train Loss: 19.9659 - Test Loss: 48.3398 - MSE: 48.3398 - MAE: 5.7109\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 856/20000 - Train Loss: 19.9651 - Test Loss: 48.3381 - MSE: 48.3381 - MAE: 5.7108\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 857/20000 - Train Loss: 19.9643 - Test Loss: 48.3363 - MSE: 48.3363 - MAE: 5.7107\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 858/20000 - Train Loss: 19.9635 - Test Loss: 48.3345 - MSE: 48.3345 - MAE: 5.7106\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 859/20000 - Train Loss: 19.9627 - Test Loss: 48.3328 - MSE: 48.3328 - MAE: 5.7105\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 860/20000 - Train Loss: 19.9619 - Test Loss: 48.3310 - MSE: 48.3310 - MAE: 5.7104\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 861/20000 - Train Loss: 19.9611 - Test Loss: 48.3292 - MSE: 48.3292 - MAE: 5.7103\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 862/20000 - Train Loss: 19.9603 - Test Loss: 48.3276 - MSE: 48.3276 - MAE: 5.7101\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 863/20000 - Train Loss: 19.9595 - Test Loss: 48.3257 - MSE: 48.3257 - MAE: 5.7100\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 864/20000 - Train Loss: 19.9587 - Test Loss: 48.3240 - MSE: 48.3239 - MAE: 5.7099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 865/20000 - Train Loss: 19.9579 - Test Loss: 48.3222 - MSE: 48.3222 - MAE: 5.7098\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 866/20000 - Train Loss: 19.9571 - Test Loss: 48.3204 - MSE: 48.3204 - MAE: 5.7097\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 867/20000 - Train Loss: 19.9563 - Test Loss: 48.3186 - MSE: 48.3186 - MAE: 5.7096\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 868/20000 - Train Loss: 19.9555 - Test Loss: 48.3169 - MSE: 48.3169 - MAE: 5.7095\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 869/20000 - Train Loss: 19.9547 - Test Loss: 48.3151 - MSE: 48.3151 - MAE: 5.7094\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 870/20000 - Train Loss: 19.9539 - Test Loss: 48.3133 - MSE: 48.3133 - MAE: 5.7092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 871/20000 - Train Loss: 19.9530 - Test Loss: 48.3115 - MSE: 48.3115 - MAE: 5.7091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 872/20000 - Train Loss: 19.9522 - Test Loss: 48.3098 - MSE: 48.3098 - MAE: 5.7090\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 873/20000 - Train Loss: 19.9514 - Test Loss: 48.3080 - MSE: 48.3080 - MAE: 5.7089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 874/20000 - Train Loss: 19.9506 - Test Loss: 48.3063 - MSE: 48.3063 - MAE: 5.7088\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 875/20000 - Train Loss: 19.9498 - Test Loss: 48.3045 - MSE: 48.3045 - MAE: 5.7087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 876/20000 - Train Loss: 19.9490 - Test Loss: 48.3027 - MSE: 48.3027 - MAE: 5.7086\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 877/20000 - Train Loss: 19.9482 - Test Loss: 48.3009 - MSE: 48.3009 - MAE: 5.7085\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 878/20000 - Train Loss: 19.9474 - Test Loss: 48.2991 - MSE: 48.2991 - MAE: 5.7084\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 879/20000 - Train Loss: 19.9466 - Test Loss: 48.2973 - MSE: 48.2973 - MAE: 5.7082\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 880/20000 - Train Loss: 19.9458 - Test Loss: 48.2955 - MSE: 48.2955 - MAE: 5.7081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 881/20000 - Train Loss: 19.9449 - Test Loss: 48.2937 - MSE: 48.2937 - MAE: 5.7080\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 882/20000 - Train Loss: 19.9441 - Test Loss: 48.2919 - MSE: 48.2919 - MAE: 5.7079\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 883/20000 - Train Loss: 19.9433 - Test Loss: 48.2901 - MSE: 48.2901 - MAE: 5.7078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 884/20000 - Train Loss: 19.9425 - Test Loss: 48.2883 - MSE: 48.2883 - MAE: 5.7077\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 885/20000 - Train Loss: 19.9417 - Test Loss: 48.2865 - MSE: 48.2865 - MAE: 5.7076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 886/20000 - Train Loss: 19.9409 - Test Loss: 48.2847 - MSE: 48.2847 - MAE: 5.7074\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 887/20000 - Train Loss: 19.9400 - Test Loss: 48.2829 - MSE: 48.2829 - MAE: 5.7073\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 888/20000 - Train Loss: 19.9392 - Test Loss: 48.2811 - MSE: 48.2811 - MAE: 5.7072\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 889/20000 - Train Loss: 19.9384 - Test Loss: 48.2793 - MSE: 48.2793 - MAE: 5.7071\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 890/20000 - Train Loss: 19.9376 - Test Loss: 48.2775 - MSE: 48.2775 - MAE: 5.7070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 891/20000 - Train Loss: 19.9368 - Test Loss: 48.2756 - MSE: 48.2756 - MAE: 5.7069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 892/20000 - Train Loss: 19.9359 - Test Loss: 48.2738 - MSE: 48.2738 - MAE: 5.7068\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 893/20000 - Train Loss: 19.9351 - Test Loss: 48.2719 - MSE: 48.2719 - MAE: 5.7066\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 894/20000 - Train Loss: 19.9343 - Test Loss: 48.2701 - MSE: 48.2701 - MAE: 5.7065\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 895/20000 - Train Loss: 19.9335 - Test Loss: 48.2683 - MSE: 48.2683 - MAE: 5.7064\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 896/20000 - Train Loss: 19.9326 - Test Loss: 48.2665 - MSE: 48.2665 - MAE: 5.7063\n",
      "2/2 [==============================] - 0s 976us/step\n",
      "Epoch 897/20000 - Train Loss: 19.9318 - Test Loss: 48.2647 - MSE: 48.2647 - MAE: 5.7062\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 898/20000 - Train Loss: 19.9310 - Test Loss: 48.2628 - MSE: 48.2628 - MAE: 5.7061\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 899/20000 - Train Loss: 19.9302 - Test Loss: 48.2610 - MSE: 48.2610 - MAE: 5.7060\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 900/20000 - Train Loss: 19.9293 - Test Loss: 48.2591 - MSE: 48.2591 - MAE: 5.7058\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 901/20000 - Train Loss: 19.9285 - Test Loss: 48.2573 - MSE: 48.2573 - MAE: 5.7057\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 902/20000 - Train Loss: 19.9277 - Test Loss: 48.2555 - MSE: 48.2555 - MAE: 5.7056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 903/20000 - Train Loss: 19.9268 - Test Loss: 48.2537 - MSE: 48.2537 - MAE: 5.7055\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 904/20000 - Train Loss: 19.9260 - Test Loss: 48.2518 - MSE: 48.2518 - MAE: 5.7054\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 905/20000 - Train Loss: 19.9252 - Test Loss: 48.2499 - MSE: 48.2499 - MAE: 5.7053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 906/20000 - Train Loss: 19.9243 - Test Loss: 48.2481 - MSE: 48.2481 - MAE: 5.7051\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 907/20000 - Train Loss: 19.9235 - Test Loss: 48.2463 - MSE: 48.2463 - MAE: 5.7050\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 908/20000 - Train Loss: 19.9227 - Test Loss: 48.2445 - MSE: 48.2445 - MAE: 5.7049\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 909/20000 - Train Loss: 19.9219 - Test Loss: 48.2427 - MSE: 48.2427 - MAE: 5.7048\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 910/20000 - Train Loss: 19.9210 - Test Loss: 48.2409 - MSE: 48.2409 - MAE: 5.7047\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 911/20000 - Train Loss: 19.9202 - Test Loss: 48.2390 - MSE: 48.2390 - MAE: 5.7046\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 912/20000 - Train Loss: 19.9194 - Test Loss: 48.2372 - MSE: 48.2372 - MAE: 5.7045\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 913/20000 - Train Loss: 19.9185 - Test Loss: 48.2353 - MSE: 48.2353 - MAE: 5.7043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 914/20000 - Train Loss: 19.9177 - Test Loss: 48.2334 - MSE: 48.2334 - MAE: 5.7042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 915/20000 - Train Loss: 19.9168 - Test Loss: 48.2316 - MSE: 48.2316 - MAE: 5.7041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 916/20000 - Train Loss: 19.9160 - Test Loss: 48.2298 - MSE: 48.2298 - MAE: 5.7040\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 917/20000 - Train Loss: 19.9152 - Test Loss: 48.2279 - MSE: 48.2279 - MAE: 5.7039\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 918/20000 - Train Loss: 19.9143 - Test Loss: 48.2261 - MSE: 48.2261 - MAE: 5.7038\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 919/20000 - Train Loss: 19.9135 - Test Loss: 48.2243 - MSE: 48.2243 - MAE: 5.7036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 920/20000 - Train Loss: 19.9126 - Test Loss: 48.2225 - MSE: 48.2225 - MAE: 5.7035\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 921/20000 - Train Loss: 19.9118 - Test Loss: 48.2206 - MSE: 48.2206 - MAE: 5.7034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 922/20000 - Train Loss: 19.9110 - Test Loss: 48.2187 - MSE: 48.2187 - MAE: 5.7033\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 923/20000 - Train Loss: 19.9101 - Test Loss: 48.2168 - MSE: 48.2168 - MAE: 5.7032\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 924/20000 - Train Loss: 19.9093 - Test Loss: 48.2149 - MSE: 48.2149 - MAE: 5.7031\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 925/20000 - Train Loss: 19.9084 - Test Loss: 48.2131 - MSE: 48.2131 - MAE: 5.7029\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 926/20000 - Train Loss: 19.9076 - Test Loss: 48.2112 - MSE: 48.2112 - MAE: 5.7028\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 927/20000 - Train Loss: 19.9067 - Test Loss: 48.2094 - MSE: 48.2094 - MAE: 5.7027\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 928/20000 - Train Loss: 19.9059 - Test Loss: 48.2076 - MSE: 48.2076 - MAE: 5.7026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 929/20000 - Train Loss: 19.9050 - Test Loss: 48.2057 - MSE: 48.2057 - MAE: 5.7025\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 930/20000 - Train Loss: 19.9042 - Test Loss: 48.2038 - MSE: 48.2038 - MAE: 5.7024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 931/20000 - Train Loss: 19.9034 - Test Loss: 48.2019 - MSE: 48.2019 - MAE: 5.7022\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 932/20000 - Train Loss: 19.9025 - Test Loss: 48.2001 - MSE: 48.2001 - MAE: 5.7021\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 933/20000 - Train Loss: 19.9017 - Test Loss: 48.1982 - MSE: 48.1982 - MAE: 5.7020\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 934/20000 - Train Loss: 19.9008 - Test Loss: 48.1964 - MSE: 48.1964 - MAE: 5.7019\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 935/20000 - Train Loss: 19.8999 - Test Loss: 48.1945 - MSE: 48.1945 - MAE: 5.7018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 936/20000 - Train Loss: 19.8991 - Test Loss: 48.1926 - MSE: 48.1926 - MAE: 5.7016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 937/20000 - Train Loss: 19.8983 - Test Loss: 48.1907 - MSE: 48.1907 - MAE: 5.7015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 938/20000 - Train Loss: 19.8974 - Test Loss: 48.1888 - MSE: 48.1888 - MAE: 5.7014\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 939/20000 - Train Loss: 19.8965 - Test Loss: 48.1869 - MSE: 48.1869 - MAE: 5.7013\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 940/20000 - Train Loss: 19.8957 - Test Loss: 48.1850 - MSE: 48.1850 - MAE: 5.7012\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 941/20000 - Train Loss: 19.8948 - Test Loss: 48.1831 - MSE: 48.1831 - MAE: 5.7011\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 942/20000 - Train Loss: 19.8940 - Test Loss: 48.1813 - MSE: 48.1813 - MAE: 5.7009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 943/20000 - Train Loss: 19.8931 - Test Loss: 48.1795 - MSE: 48.1794 - MAE: 5.7008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 944/20000 - Train Loss: 19.8923 - Test Loss: 48.1775 - MSE: 48.1775 - MAE: 5.7007\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 945/20000 - Train Loss: 19.8914 - Test Loss: 48.1756 - MSE: 48.1756 - MAE: 5.7006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 946/20000 - Train Loss: 19.8906 - Test Loss: 48.1737 - MSE: 48.1737 - MAE: 5.7005\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 947/20000 - Train Loss: 19.8897 - Test Loss: 48.1718 - MSE: 48.1718 - MAE: 5.7003\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 948/20000 - Train Loss: 19.8888 - Test Loss: 48.1699 - MSE: 48.1699 - MAE: 5.7002\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 949/20000 - Train Loss: 19.8880 - Test Loss: 48.1680 - MSE: 48.1680 - MAE: 5.7001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 950/20000 - Train Loss: 19.8871 - Test Loss: 48.1660 - MSE: 48.1660 - MAE: 5.7000\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 951/20000 - Train Loss: 19.8863 - Test Loss: 48.1641 - MSE: 48.1641 - MAE: 5.6999\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 952/20000 - Train Loss: 19.8854 - Test Loss: 48.1622 - MSE: 48.1622 - MAE: 5.6997\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 953/20000 - Train Loss: 19.8845 - Test Loss: 48.1603 - MSE: 48.1604 - MAE: 5.6996\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 954/20000 - Train Loss: 19.8837 - Test Loss: 48.1585 - MSE: 48.1585 - MAE: 5.6995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 955/20000 - Train Loss: 19.8828 - Test Loss: 48.1565 - MSE: 48.1565 - MAE: 5.6994\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 956/20000 - Train Loss: 19.8819 - Test Loss: 48.1546 - MSE: 48.1546 - MAE: 5.6993\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 957/20000 - Train Loss: 19.8811 - Test Loss: 48.1527 - MSE: 48.1527 - MAE: 5.6991\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 958/20000 - Train Loss: 19.8802 - Test Loss: 48.1508 - MSE: 48.1508 - MAE: 5.6990\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 959/20000 - Train Loss: 19.8793 - Test Loss: 48.1488 - MSE: 48.1488 - MAE: 5.6989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 960/20000 - Train Loss: 19.8785 - Test Loss: 48.1469 - MSE: 48.1469 - MAE: 5.6988\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 961/20000 - Train Loss: 19.8776 - Test Loss: 48.1450 - MSE: 48.1450 - MAE: 5.6987\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 962/20000 - Train Loss: 19.8767 - Test Loss: 48.1431 - MSE: 48.1431 - MAE: 5.6985\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 963/20000 - Train Loss: 19.8759 - Test Loss: 48.1412 - MSE: 48.1412 - MAE: 5.6984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 964/20000 - Train Loss: 19.8750 - Test Loss: 48.1393 - MSE: 48.1393 - MAE: 5.6983\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 965/20000 - Train Loss: 19.8741 - Test Loss: 48.1374 - MSE: 48.1374 - MAE: 5.6982\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 966/20000 - Train Loss: 19.8733 - Test Loss: 48.1356 - MSE: 48.1356 - MAE: 5.6981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 967/20000 - Train Loss: 19.8724 - Test Loss: 48.1336 - MSE: 48.1336 - MAE: 5.6979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 968/20000 - Train Loss: 19.8715 - Test Loss: 48.1317 - MSE: 48.1317 - MAE: 5.6978\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 969/20000 - Train Loss: 19.8706 - Test Loss: 48.1297 - MSE: 48.1297 - MAE: 5.6977\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 970/20000 - Train Loss: 19.8698 - Test Loss: 48.1278 - MSE: 48.1278 - MAE: 5.6976\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 971/20000 - Train Loss: 19.8689 - Test Loss: 48.1258 - MSE: 48.1258 - MAE: 5.6974\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 972/20000 - Train Loss: 19.8680 - Test Loss: 48.1239 - MSE: 48.1239 - MAE: 5.6973\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 973/20000 - Train Loss: 19.8671 - Test Loss: 48.1220 - MSE: 48.1220 - MAE: 5.6972\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 974/20000 - Train Loss: 19.8663 - Test Loss: 48.1201 - MSE: 48.1201 - MAE: 5.6971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 975/20000 - Train Loss: 19.8654 - Test Loss: 48.1182 - MSE: 48.1182 - MAE: 5.6970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 976/20000 - Train Loss: 19.8645 - Test Loss: 48.1163 - MSE: 48.1163 - MAE: 5.6968\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 977/20000 - Train Loss: 19.8636 - Test Loss: 48.1144 - MSE: 48.1144 - MAE: 5.6967\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 978/20000 - Train Loss: 19.8627 - Test Loss: 48.1124 - MSE: 48.1124 - MAE: 5.6966\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 979/20000 - Train Loss: 19.8619 - Test Loss: 48.1104 - MSE: 48.1104 - MAE: 5.6965\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 980/20000 - Train Loss: 19.8610 - Test Loss: 48.1085 - MSE: 48.1085 - MAE: 5.6963\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 981/20000 - Train Loss: 19.8601 - Test Loss: 48.1066 - MSE: 48.1066 - MAE: 5.6962\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 982/20000 - Train Loss: 19.8592 - Test Loss: 48.1045 - MSE: 48.1045 - MAE: 5.6961\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 983/20000 - Train Loss: 19.8584 - Test Loss: 48.1026 - MSE: 48.1026 - MAE: 5.6960\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 984/20000 - Train Loss: 19.8575 - Test Loss: 48.1007 - MSE: 48.1007 - MAE: 5.6959\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 985/20000 - Train Loss: 19.8566 - Test Loss: 48.0987 - MSE: 48.0987 - MAE: 5.6957\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 986/20000 - Train Loss: 19.8557 - Test Loss: 48.0968 - MSE: 48.0968 - MAE: 5.6956\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 987/20000 - Train Loss: 19.8548 - Test Loss: 48.0948 - MSE: 48.0948 - MAE: 5.6955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 988/20000 - Train Loss: 19.8539 - Test Loss: 48.0928 - MSE: 48.0928 - MAE: 5.6954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 989/20000 - Train Loss: 19.8530 - Test Loss: 48.0909 - MSE: 48.0909 - MAE: 5.6952\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 990/20000 - Train Loss: 19.8522 - Test Loss: 48.0890 - MSE: 48.0890 - MAE: 5.6951\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 991/20000 - Train Loss: 19.8513 - Test Loss: 48.0870 - MSE: 48.0871 - MAE: 5.6950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 992/20000 - Train Loss: 19.8504 - Test Loss: 48.0851 - MSE: 48.0851 - MAE: 5.6949\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 993/20000 - Train Loss: 19.8495 - Test Loss: 48.0831 - MSE: 48.0831 - MAE: 5.6947\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 994/20000 - Train Loss: 19.8486 - Test Loss: 48.0812 - MSE: 48.0812 - MAE: 5.6946\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 995/20000 - Train Loss: 19.8477 - Test Loss: 48.0791 - MSE: 48.0791 - MAE: 5.6945\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 996/20000 - Train Loss: 19.8468 - Test Loss: 48.0772 - MSE: 48.0772 - MAE: 5.6944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 997/20000 - Train Loss: 19.8459 - Test Loss: 48.0753 - MSE: 48.0753 - MAE: 5.6943\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 998/20000 - Train Loss: 19.8450 - Test Loss: 48.0733 - MSE: 48.0733 - MAE: 5.6941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 999/20000 - Train Loss: 19.8441 - Test Loss: 48.0714 - MSE: 48.0714 - MAE: 5.6940\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1000/20000 - Train Loss: 19.8432 - Test Loss: 48.0694 - MSE: 48.0694 - MAE: 5.6939\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1001/20000 - Train Loss: 19.8424 - Test Loss: 48.0674 - MSE: 48.0674 - MAE: 5.6938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1002/20000 - Train Loss: 19.8415 - Test Loss: 48.0654 - MSE: 48.0654 - MAE: 5.6936\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1003/20000 - Train Loss: 19.8406 - Test Loss: 48.0635 - MSE: 48.0635 - MAE: 5.6935\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1004/20000 - Train Loss: 19.8397 - Test Loss: 48.0615 - MSE: 48.0615 - MAE: 5.6934\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1005/20000 - Train Loss: 19.8388 - Test Loss: 48.0594 - MSE: 48.0594 - MAE: 5.6933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1006/20000 - Train Loss: 19.8379 - Test Loss: 48.0574 - MSE: 48.0574 - MAE: 5.6931\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 1007/20000 - Train Loss: 19.8370 - Test Loss: 48.0554 - MSE: 48.0554 - MAE: 5.6930\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1008/20000 - Train Loss: 19.8361 - Test Loss: 48.0534 - MSE: 48.0534 - MAE: 5.6929\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 1009/20000 - Train Loss: 19.8352 - Test Loss: 48.0514 - MSE: 48.0514 - MAE: 5.6928\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1010/20000 - Train Loss: 19.8343 - Test Loss: 48.0495 - MSE: 48.0495 - MAE: 5.6926\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1011/20000 - Train Loss: 19.8334 - Test Loss: 48.0476 - MSE: 48.0476 - MAE: 5.6925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1012/20000 - Train Loss: 19.8325 - Test Loss: 48.0456 - MSE: 48.0456 - MAE: 5.6924\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1013/20000 - Train Loss: 19.8316 - Test Loss: 48.0435 - MSE: 48.0435 - MAE: 5.6923\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1014/20000 - Train Loss: 19.8307 - Test Loss: 48.0415 - MSE: 48.0415 - MAE: 5.6921\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1015/20000 - Train Loss: 19.8298 - Test Loss: 48.0395 - MSE: 48.0395 - MAE: 5.6920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1016/20000 - Train Loss: 19.8289 - Test Loss: 48.0375 - MSE: 48.0375 - MAE: 5.6919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1017/20000 - Train Loss: 19.8280 - Test Loss: 48.0355 - MSE: 48.0355 - MAE: 5.6917\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1018/20000 - Train Loss: 19.8271 - Test Loss: 48.0335 - MSE: 48.0335 - MAE: 5.6916\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1019/20000 - Train Loss: 19.8261 - Test Loss: 48.0315 - MSE: 48.0315 - MAE: 5.6915\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1020/20000 - Train Loss: 19.8252 - Test Loss: 48.0295 - MSE: 48.0295 - MAE: 5.6914\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1021/20000 - Train Loss: 19.8243 - Test Loss: 48.0276 - MSE: 48.0276 - MAE: 5.6912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1022/20000 - Train Loss: 19.8234 - Test Loss: 48.0255 - MSE: 48.0255 - MAE: 5.6911\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1023/20000 - Train Loss: 19.8225 - Test Loss: 48.0235 - MSE: 48.0235 - MAE: 5.6910\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1024/20000 - Train Loss: 19.8216 - Test Loss: 48.0216 - MSE: 48.0216 - MAE: 5.6909\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1025/20000 - Train Loss: 19.8207 - Test Loss: 48.0196 - MSE: 48.0196 - MAE: 5.6907\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1026/20000 - Train Loss: 19.8198 - Test Loss: 48.0175 - MSE: 48.0175 - MAE: 5.6906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1027/20000 - Train Loss: 19.8189 - Test Loss: 48.0155 - MSE: 48.0155 - MAE: 5.6905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1028/20000 - Train Loss: 19.8180 - Test Loss: 48.0135 - MSE: 48.0135 - MAE: 5.6904\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1029/20000 - Train Loss: 19.8170 - Test Loss: 48.0115 - MSE: 48.0115 - MAE: 5.6902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1030/20000 - Train Loss: 19.8161 - Test Loss: 48.0095 - MSE: 48.0095 - MAE: 5.6901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1031/20000 - Train Loss: 19.8152 - Test Loss: 48.0075 - MSE: 48.0075 - MAE: 5.6900\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1032/20000 - Train Loss: 19.8143 - Test Loss: 48.0055 - MSE: 48.0055 - MAE: 5.6899\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1033/20000 - Train Loss: 19.8134 - Test Loss: 48.0035 - MSE: 48.0035 - MAE: 5.6897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1034/20000 - Train Loss: 19.8125 - Test Loss: 48.0015 - MSE: 48.0015 - MAE: 5.6896\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1035/20000 - Train Loss: 19.8116 - Test Loss: 47.9995 - MSE: 47.9995 - MAE: 5.6895\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 1036/20000 - Train Loss: 19.8106 - Test Loss: 47.9975 - MSE: 47.9975 - MAE: 5.6893\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1037/20000 - Train Loss: 19.8097 - Test Loss: 47.9954 - MSE: 47.9954 - MAE: 5.6892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1038/20000 - Train Loss: 19.8088 - Test Loss: 47.9934 - MSE: 47.9934 - MAE: 5.6891\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1039/20000 - Train Loss: 19.8079 - Test Loss: 47.9914 - MSE: 47.9914 - MAE: 5.6890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1040/20000 - Train Loss: 19.8070 - Test Loss: 47.9893 - MSE: 47.9893 - MAE: 5.6888\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1041/20000 - Train Loss: 19.8060 - Test Loss: 47.9873 - MSE: 47.9873 - MAE: 5.6887\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1042/20000 - Train Loss: 19.8051 - Test Loss: 47.9853 - MSE: 47.9853 - MAE: 5.6886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1043/20000 - Train Loss: 19.8042 - Test Loss: 47.9833 - MSE: 47.9833 - MAE: 5.6884\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1044/20000 - Train Loss: 19.8033 - Test Loss: 47.9812 - MSE: 47.9812 - MAE: 5.6883\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1045/20000 - Train Loss: 19.8024 - Test Loss: 47.9792 - MSE: 47.9792 - MAE: 5.6882\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1046/20000 - Train Loss: 19.8014 - Test Loss: 47.9772 - MSE: 47.9772 - MAE: 5.6881\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1047/20000 - Train Loss: 19.8005 - Test Loss: 47.9752 - MSE: 47.9752 - MAE: 5.6879\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1048/20000 - Train Loss: 19.7996 - Test Loss: 47.9731 - MSE: 47.9731 - MAE: 5.6878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1049/20000 - Train Loss: 19.7987 - Test Loss: 47.9710 - MSE: 47.9710 - MAE: 5.6877\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1050/20000 - Train Loss: 19.7977 - Test Loss: 47.9689 - MSE: 47.9689 - MAE: 5.6875\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1051/20000 - Train Loss: 19.7968 - Test Loss: 47.9669 - MSE: 47.9669 - MAE: 5.6874\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1052/20000 - Train Loss: 19.7959 - Test Loss: 47.9648 - MSE: 47.9648 - MAE: 5.6873\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1053/20000 - Train Loss: 19.7949 - Test Loss: 47.9627 - MSE: 47.9627 - MAE: 5.6872\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1054/20000 - Train Loss: 19.7940 - Test Loss: 47.9607 - MSE: 47.9607 - MAE: 5.6870\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1055/20000 - Train Loss: 19.7931 - Test Loss: 47.9587 - MSE: 47.9587 - MAE: 5.6869\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1056/20000 - Train Loss: 19.7921 - Test Loss: 47.9566 - MSE: 47.9566 - MAE: 5.6868\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1057/20000 - Train Loss: 19.7912 - Test Loss: 47.9545 - MSE: 47.9545 - MAE: 5.6866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1058/20000 - Train Loss: 19.7903 - Test Loss: 47.9525 - MSE: 47.9525 - MAE: 5.6865\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1059/20000 - Train Loss: 19.7894 - Test Loss: 47.9504 - MSE: 47.9504 - MAE: 5.6864\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 1060/20000 - Train Loss: 19.7884 - Test Loss: 47.9483 - MSE: 47.9483 - MAE: 5.6862\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1061/20000 - Train Loss: 19.7875 - Test Loss: 47.9463 - MSE: 47.9463 - MAE: 5.6861\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1062/20000 - Train Loss: 19.7866 - Test Loss: 47.9441 - MSE: 47.9441 - MAE: 5.6860\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1063/20000 - Train Loss: 19.7856 - Test Loss: 47.9421 - MSE: 47.9421 - MAE: 5.6858\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1064/20000 - Train Loss: 19.7847 - Test Loss: 47.9400 - MSE: 47.9400 - MAE: 5.6857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1065/20000 - Train Loss: 19.7837 - Test Loss: 47.9380 - MSE: 47.9380 - MAE: 5.6856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1066/20000 - Train Loss: 19.7828 - Test Loss: 47.9359 - MSE: 47.9359 - MAE: 5.6855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1067/20000 - Train Loss: 19.7819 - Test Loss: 47.9339 - MSE: 47.9339 - MAE: 5.6853\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1068/20000 - Train Loss: 19.7809 - Test Loss: 47.9318 - MSE: 47.9318 - MAE: 5.6852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1069/20000 - Train Loss: 19.7800 - Test Loss: 47.9297 - MSE: 47.9297 - MAE: 5.6851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1070/20000 - Train Loss: 19.7790 - Test Loss: 47.9276 - MSE: 47.9276 - MAE: 5.6849\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1071/20000 - Train Loss: 19.7781 - Test Loss: 47.9256 - MSE: 47.9256 - MAE: 5.6848\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1072/20000 - Train Loss: 19.7772 - Test Loss: 47.9235 - MSE: 47.9235 - MAE: 5.6847\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1073/20000 - Train Loss: 19.7762 - Test Loss: 47.9214 - MSE: 47.9214 - MAE: 5.6845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1074/20000 - Train Loss: 19.7753 - Test Loss: 47.9194 - MSE: 47.9194 - MAE: 5.6844\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1075/20000 - Train Loss: 19.7743 - Test Loss: 47.9173 - MSE: 47.9173 - MAE: 5.6843\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1076/20000 - Train Loss: 19.7734 - Test Loss: 47.9152 - MSE: 47.9152 - MAE: 5.6842\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1077/20000 - Train Loss: 19.7725 - Test Loss: 47.9132 - MSE: 47.9132 - MAE: 5.6840\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1078/20000 - Train Loss: 19.7715 - Test Loss: 47.9111 - MSE: 47.9111 - MAE: 5.6839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1079/20000 - Train Loss: 19.7706 - Test Loss: 47.9090 - MSE: 47.9090 - MAE: 5.6838\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1080/20000 - Train Loss: 19.7696 - Test Loss: 47.9069 - MSE: 47.9069 - MAE: 5.6836\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1081/20000 - Train Loss: 19.7687 - Test Loss: 47.9048 - MSE: 47.9048 - MAE: 5.6835\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1082/20000 - Train Loss: 19.7677 - Test Loss: 47.9027 - MSE: 47.9027 - MAE: 5.6834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1083/20000 - Train Loss: 19.7668 - Test Loss: 47.9006 - MSE: 47.9006 - MAE: 5.6832\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1084/20000 - Train Loss: 19.7658 - Test Loss: 47.8986 - MSE: 47.8986 - MAE: 5.6831\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1085/20000 - Train Loss: 19.7649 - Test Loss: 47.8964 - MSE: 47.8964 - MAE: 5.6830\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1086/20000 - Train Loss: 19.7639 - Test Loss: 47.8943 - MSE: 47.8943 - MAE: 5.6828\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1087/20000 - Train Loss: 19.7630 - Test Loss: 47.8923 - MSE: 47.8923 - MAE: 5.6827\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1088/20000 - Train Loss: 19.7620 - Test Loss: 47.8902 - MSE: 47.8902 - MAE: 5.6826\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1089/20000 - Train Loss: 19.7611 - Test Loss: 47.8880 - MSE: 47.8880 - MAE: 5.6824\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1090/20000 - Train Loss: 19.7601 - Test Loss: 47.8859 - MSE: 47.8859 - MAE: 5.6823\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1091/20000 - Train Loss: 19.7591 - Test Loss: 47.8839 - MSE: 47.8839 - MAE: 5.6822\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1092/20000 - Train Loss: 19.7582 - Test Loss: 47.8818 - MSE: 47.8818 - MAE: 5.6820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1093/20000 - Train Loss: 19.7572 - Test Loss: 47.8797 - MSE: 47.8797 - MAE: 5.6819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1094/20000 - Train Loss: 19.7563 - Test Loss: 47.8776 - MSE: 47.8776 - MAE: 5.6818\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1095/20000 - Train Loss: 19.7553 - Test Loss: 47.8755 - MSE: 47.8755 - MAE: 5.6816\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1096/20000 - Train Loss: 19.7544 - Test Loss: 47.8733 - MSE: 47.8733 - MAE: 5.6815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1097/20000 - Train Loss: 19.7534 - Test Loss: 47.8712 - MSE: 47.8712 - MAE: 5.6814\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1098/20000 - Train Loss: 19.7525 - Test Loss: 47.8691 - MSE: 47.8691 - MAE: 5.6812\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1099/20000 - Train Loss: 19.7515 - Test Loss: 47.8670 - MSE: 47.8670 - MAE: 5.6811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1100/20000 - Train Loss: 19.7505 - Test Loss: 47.8649 - MSE: 47.8649 - MAE: 5.6810\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1101/20000 - Train Loss: 19.7496 - Test Loss: 47.8628 - MSE: 47.8628 - MAE: 5.6808\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1102/20000 - Train Loss: 19.7486 - Test Loss: 47.8607 - MSE: 47.8607 - MAE: 5.6807\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1103/20000 - Train Loss: 19.7476 - Test Loss: 47.8586 - MSE: 47.8586 - MAE: 5.6806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1104/20000 - Train Loss: 19.7467 - Test Loss: 47.8564 - MSE: 47.8564 - MAE: 5.6804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1105/20000 - Train Loss: 19.7457 - Test Loss: 47.8542 - MSE: 47.8542 - MAE: 5.6803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1106/20000 - Train Loss: 19.7448 - Test Loss: 47.8520 - MSE: 47.8520 - MAE: 5.6802\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1107/20000 - Train Loss: 19.7438 - Test Loss: 47.8499 - MSE: 47.8499 - MAE: 5.6800\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1108/20000 - Train Loss: 19.7428 - Test Loss: 47.8478 - MSE: 47.8478 - MAE: 5.6799\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1109/20000 - Train Loss: 19.7419 - Test Loss: 47.8456 - MSE: 47.8456 - MAE: 5.6797\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1110/20000 - Train Loss: 19.7409 - Test Loss: 47.8434 - MSE: 47.8434 - MAE: 5.6796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1111/20000 - Train Loss: 19.7399 - Test Loss: 47.8413 - MSE: 47.8413 - MAE: 5.6795\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1112/20000 - Train Loss: 19.7390 - Test Loss: 47.8392 - MSE: 47.8392 - MAE: 5.6793\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1113/20000 - Train Loss: 19.7380 - Test Loss: 47.8371 - MSE: 47.8371 - MAE: 5.6792\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1114/20000 - Train Loss: 19.7370 - Test Loss: 47.8349 - MSE: 47.8349 - MAE: 5.6791\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 1115/20000 - Train Loss: 19.7360 - Test Loss: 47.8328 - MSE: 47.8328 - MAE: 5.6789\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1116/20000 - Train Loss: 19.7351 - Test Loss: 47.8307 - MSE: 47.8307 - MAE: 5.6788\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1117/20000 - Train Loss: 19.7341 - Test Loss: 47.8285 - MSE: 47.8285 - MAE: 5.6787\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1118/20000 - Train Loss: 19.7331 - Test Loss: 47.8264 - MSE: 47.8264 - MAE: 5.6785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1119/20000 - Train Loss: 19.7322 - Test Loss: 47.8243 - MSE: 47.8243 - MAE: 5.6784\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1120/20000 - Train Loss: 19.7312 - Test Loss: 47.8221 - MSE: 47.8221 - MAE: 5.6783\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1121/20000 - Train Loss: 19.7302 - Test Loss: 47.8200 - MSE: 47.8200 - MAE: 5.6781\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1122/20000 - Train Loss: 19.7292 - Test Loss: 47.8179 - MSE: 47.8179 - MAE: 5.6780\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 1123/20000 - Train Loss: 19.7283 - Test Loss: 47.8157 - MSE: 47.8157 - MAE: 5.6779\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1124/20000 - Train Loss: 19.7273 - Test Loss: 47.8135 - MSE: 47.8135 - MAE: 5.6777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1125/20000 - Train Loss: 19.7263 - Test Loss: 47.8114 - MSE: 47.8114 - MAE: 5.6776\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1126/20000 - Train Loss: 19.7253 - Test Loss: 47.8092 - MSE: 47.8092 - MAE: 5.6774\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 1127/20000 - Train Loss: 19.7244 - Test Loss: 47.8071 - MSE: 47.8071 - MAE: 5.6773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1128/20000 - Train Loss: 19.7234 - Test Loss: 47.8050 - MSE: 47.8050 - MAE: 5.6772\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1129/20000 - Train Loss: 19.7224 - Test Loss: 47.8028 - MSE: 47.8028 - MAE: 5.6770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1130/20000 - Train Loss: 19.7214 - Test Loss: 47.8006 - MSE: 47.8006 - MAE: 5.6769\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 1131/20000 - Train Loss: 19.7204 - Test Loss: 47.7985 - MSE: 47.7985 - MAE: 5.6768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1132/20000 - Train Loss: 19.7194 - Test Loss: 47.7963 - MSE: 47.7963 - MAE: 5.6766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1133/20000 - Train Loss: 19.7185 - Test Loss: 47.7941 - MSE: 47.7941 - MAE: 5.6765\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1134/20000 - Train Loss: 19.7175 - Test Loss: 47.7920 - MSE: 47.7920 - MAE: 5.6764\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1135/20000 - Train Loss: 19.7165 - Test Loss: 47.7898 - MSE: 47.7898 - MAE: 5.6762\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1136/20000 - Train Loss: 19.7155 - Test Loss: 47.7876 - MSE: 47.7876 - MAE: 5.6761\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1137/20000 - Train Loss: 19.7145 - Test Loss: 47.7855 - MSE: 47.7855 - MAE: 5.6759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1138/20000 - Train Loss: 19.7135 - Test Loss: 47.7834 - MSE: 47.7834 - MAE: 5.6758\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1139/20000 - Train Loss: 19.7125 - Test Loss: 47.7811 - MSE: 47.7811 - MAE: 5.6757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1140/20000 - Train Loss: 19.7116 - Test Loss: 47.7790 - MSE: 47.7790 - MAE: 5.6755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1141/20000 - Train Loss: 19.7106 - Test Loss: 47.7768 - MSE: 47.7768 - MAE: 5.6754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1142/20000 - Train Loss: 19.7096 - Test Loss: 47.7746 - MSE: 47.7746 - MAE: 5.6753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1143/20000 - Train Loss: 19.7086 - Test Loss: 47.7724 - MSE: 47.7724 - MAE: 5.6751\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1144/20000 - Train Loss: 19.7076 - Test Loss: 47.7702 - MSE: 47.7702 - MAE: 5.6750\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1145/20000 - Train Loss: 19.7066 - Test Loss: 47.7680 - MSE: 47.7680 - MAE: 5.6748\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1146/20000 - Train Loss: 19.7056 - Test Loss: 47.7658 - MSE: 47.7658 - MAE: 5.6747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1147/20000 - Train Loss: 19.7046 - Test Loss: 47.7636 - MSE: 47.7636 - MAE: 5.6746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1148/20000 - Train Loss: 19.7037 - Test Loss: 47.7615 - MSE: 47.7615 - MAE: 5.6744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1149/20000 - Train Loss: 19.7027 - Test Loss: 47.7593 - MSE: 47.7593 - MAE: 5.6743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1150/20000 - Train Loss: 19.7017 - Test Loss: 47.7571 - MSE: 47.7571 - MAE: 5.6741\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 1151/20000 - Train Loss: 19.7007 - Test Loss: 47.7549 - MSE: 47.7549 - MAE: 5.6740\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1152/20000 - Train Loss: 19.6997 - Test Loss: 47.7527 - MSE: 47.7527 - MAE: 5.6739\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1153/20000 - Train Loss: 19.6987 - Test Loss: 47.7504 - MSE: 47.7504 - MAE: 5.6737\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1154/20000 - Train Loss: 19.6977 - Test Loss: 47.7482 - MSE: 47.7482 - MAE: 5.6736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1155/20000 - Train Loss: 19.6967 - Test Loss: 47.7461 - MSE: 47.7461 - MAE: 5.6734\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1156/20000 - Train Loss: 19.6957 - Test Loss: 47.7438 - MSE: 47.7438 - MAE: 5.6733\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1157/20000 - Train Loss: 19.6947 - Test Loss: 47.7416 - MSE: 47.7416 - MAE: 5.6732\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1158/20000 - Train Loss: 19.6937 - Test Loss: 47.7394 - MSE: 47.7394 - MAE: 5.6730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1159/20000 - Train Loss: 19.6927 - Test Loss: 47.7373 - MSE: 47.7373 - MAE: 5.6729\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1160/20000 - Train Loss: 19.6917 - Test Loss: 47.7350 - MSE: 47.7350 - MAE: 5.6727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1161/20000 - Train Loss: 19.6907 - Test Loss: 47.7327 - MSE: 47.7327 - MAE: 5.6726\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1162/20000 - Train Loss: 19.6897 - Test Loss: 47.7305 - MSE: 47.7305 - MAE: 5.6725\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1163/20000 - Train Loss: 19.6887 - Test Loss: 47.7283 - MSE: 47.7283 - MAE: 5.6723\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 1164/20000 - Train Loss: 19.6877 - Test Loss: 47.7261 - MSE: 47.7261 - MAE: 5.6722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1165/20000 - Train Loss: 19.6867 - Test Loss: 47.7239 - MSE: 47.7239 - MAE: 5.6720\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1166/20000 - Train Loss: 19.6857 - Test Loss: 47.7217 - MSE: 47.7217 - MAE: 5.6719\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1167/20000 - Train Loss: 19.6847 - Test Loss: 47.7195 - MSE: 47.7195 - MAE: 5.6718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1168/20000 - Train Loss: 19.6837 - Test Loss: 47.7173 - MSE: 47.7173 - MAE: 5.6716\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1169/20000 - Train Loss: 19.6827 - Test Loss: 47.7151 - MSE: 47.7151 - MAE: 5.6715\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1170/20000 - Train Loss: 19.6816 - Test Loss: 47.7128 - MSE: 47.7128 - MAE: 5.6713\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1171/20000 - Train Loss: 19.6806 - Test Loss: 47.7106 - MSE: 47.7106 - MAE: 5.6712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1172/20000 - Train Loss: 19.6796 - Test Loss: 47.7085 - MSE: 47.7085 - MAE: 5.6711\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1173/20000 - Train Loss: 19.6786 - Test Loss: 47.7062 - MSE: 47.7062 - MAE: 5.6709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1174/20000 - Train Loss: 19.6776 - Test Loss: 47.7041 - MSE: 47.7041 - MAE: 5.6708\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 1175/20000 - Train Loss: 19.6766 - Test Loss: 47.7018 - MSE: 47.7018 - MAE: 5.6706\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1176/20000 - Train Loss: 19.6756 - Test Loss: 47.6996 - MSE: 47.6996 - MAE: 5.6705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1177/20000 - Train Loss: 19.6746 - Test Loss: 47.6974 - MSE: 47.6974 - MAE: 5.6704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1178/20000 - Train Loss: 19.6736 - Test Loss: 47.6951 - MSE: 47.6951 - MAE: 5.6702\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1179/20000 - Train Loss: 19.6725 - Test Loss: 47.6929 - MSE: 47.6929 - MAE: 5.6701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1180/20000 - Train Loss: 19.6715 - Test Loss: 47.6906 - MSE: 47.6906 - MAE: 5.6699\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1181/20000 - Train Loss: 19.6705 - Test Loss: 47.6884 - MSE: 47.6884 - MAE: 5.6698\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1182/20000 - Train Loss: 19.6695 - Test Loss: 47.6862 - MSE: 47.6862 - MAE: 5.6697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1183/20000 - Train Loss: 19.6685 - Test Loss: 47.6840 - MSE: 47.6840 - MAE: 5.6695\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1184/20000 - Train Loss: 19.6675 - Test Loss: 47.6818 - MSE: 47.6818 - MAE: 5.6694\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1185/20000 - Train Loss: 19.6665 - Test Loss: 47.6795 - MSE: 47.6795 - MAE: 5.6692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1186/20000 - Train Loss: 19.6654 - Test Loss: 47.6772 - MSE: 47.6772 - MAE: 5.6691\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1187/20000 - Train Loss: 19.6644 - Test Loss: 47.6749 - MSE: 47.6749 - MAE: 5.6689\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1188/20000 - Train Loss: 19.6634 - Test Loss: 47.6727 - MSE: 47.6727 - MAE: 5.6688\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1189/20000 - Train Loss: 19.6624 - Test Loss: 47.6704 - MSE: 47.6704 - MAE: 5.6686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1190/20000 - Train Loss: 19.6614 - Test Loss: 47.6682 - MSE: 47.6682 - MAE: 5.6685\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1191/20000 - Train Loss: 19.6603 - Test Loss: 47.6660 - MSE: 47.6660 - MAE: 5.6684\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1192/20000 - Train Loss: 19.6593 - Test Loss: 47.6637 - MSE: 47.6637 - MAE: 5.6682\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1193/20000 - Train Loss: 19.6583 - Test Loss: 47.6614 - MSE: 47.6614 - MAE: 5.6681\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1194/20000 - Train Loss: 19.6573 - Test Loss: 47.6593 - MSE: 47.6592 - MAE: 5.6679\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1195/20000 - Train Loss: 19.6562 - Test Loss: 47.6570 - MSE: 47.6570 - MAE: 5.6678\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 1196/20000 - Train Loss: 19.6552 - Test Loss: 47.6547 - MSE: 47.6547 - MAE: 5.6676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1197/20000 - Train Loss: 19.6542 - Test Loss: 47.6524 - MSE: 47.6524 - MAE: 5.6675\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1198/20000 - Train Loss: 19.6532 - Test Loss: 47.6501 - MSE: 47.6501 - MAE: 5.6674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1199/20000 - Train Loss: 19.6521 - Test Loss: 47.6478 - MSE: 47.6478 - MAE: 5.6672\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1200/20000 - Train Loss: 19.6511 - Test Loss: 47.6456 - MSE: 47.6456 - MAE: 5.6671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1201/20000 - Train Loss: 19.6501 - Test Loss: 47.6434 - MSE: 47.6434 - MAE: 5.6669\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1202/20000 - Train Loss: 19.6491 - Test Loss: 47.6411 - MSE: 47.6411 - MAE: 5.6668\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1203/20000 - Train Loss: 19.6480 - Test Loss: 47.6388 - MSE: 47.6388 - MAE: 5.6666\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1204/20000 - Train Loss: 19.6470 - Test Loss: 47.6366 - MSE: 47.6366 - MAE: 5.6665\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1205/20000 - Train Loss: 19.6460 - Test Loss: 47.6343 - MSE: 47.6343 - MAE: 5.6664\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1206/20000 - Train Loss: 19.6449 - Test Loss: 47.6320 - MSE: 47.6320 - MAE: 5.6662\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1207/20000 - Train Loss: 19.6439 - Test Loss: 47.6296 - MSE: 47.6296 - MAE: 5.6661\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1208/20000 - Train Loss: 19.6429 - Test Loss: 47.6272 - MSE: 47.6272 - MAE: 5.6659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1209/20000 - Train Loss: 19.6418 - Test Loss: 47.6250 - MSE: 47.6250 - MAE: 5.6658\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 1210/20000 - Train Loss: 19.6408 - Test Loss: 47.6228 - MSE: 47.6228 - MAE: 5.6656\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1211/20000 - Train Loss: 19.6398 - Test Loss: 47.6204 - MSE: 47.6204 - MAE: 5.6655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1212/20000 - Train Loss: 19.6387 - Test Loss: 47.6182 - MSE: 47.6182 - MAE: 5.6653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1213/20000 - Train Loss: 19.6377 - Test Loss: 47.6159 - MSE: 47.6159 - MAE: 5.6652\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1214/20000 - Train Loss: 19.6367 - Test Loss: 47.6136 - MSE: 47.6136 - MAE: 5.6650\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1215/20000 - Train Loss: 19.6356 - Test Loss: 47.6114 - MSE: 47.6114 - MAE: 5.6649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1216/20000 - Train Loss: 19.6346 - Test Loss: 47.6091 - MSE: 47.6091 - MAE: 5.6648\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1217/20000 - Train Loss: 19.6335 - Test Loss: 47.6067 - MSE: 47.6067 - MAE: 5.6646\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1218/20000 - Train Loss: 19.6325 - Test Loss: 47.6045 - MSE: 47.6045 - MAE: 5.6645\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1219/20000 - Train Loss: 19.6315 - Test Loss: 47.6022 - MSE: 47.6022 - MAE: 5.6643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1220/20000 - Train Loss: 19.6304 - Test Loss: 47.5999 - MSE: 47.5999 - MAE: 5.6642\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1221/20000 - Train Loss: 19.6294 - Test Loss: 47.5977 - MSE: 47.5977 - MAE: 5.6640\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1222/20000 - Train Loss: 19.6283 - Test Loss: 47.5953 - MSE: 47.5953 - MAE: 5.6639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1223/20000 - Train Loss: 19.6273 - Test Loss: 47.5930 - MSE: 47.5930 - MAE: 5.6637\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1224/20000 - Train Loss: 19.6262 - Test Loss: 47.5907 - MSE: 47.5907 - MAE: 5.6636\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1225/20000 - Train Loss: 19.6252 - Test Loss: 47.5884 - MSE: 47.5884 - MAE: 5.6634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1226/20000 - Train Loss: 19.6242 - Test Loss: 47.5861 - MSE: 47.5861 - MAE: 5.6633\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1227/20000 - Train Loss: 19.6231 - Test Loss: 47.5839 - MSE: 47.5839 - MAE: 5.6632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1228/20000 - Train Loss: 19.6221 - Test Loss: 47.5816 - MSE: 47.5815 - MAE: 5.6630\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1229/20000 - Train Loss: 19.6210 - Test Loss: 47.5792 - MSE: 47.5792 - MAE: 5.6629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1230/20000 - Train Loss: 19.6200 - Test Loss: 47.5769 - MSE: 47.5769 - MAE: 5.6627\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1231/20000 - Train Loss: 19.6189 - Test Loss: 47.5746 - MSE: 47.5746 - MAE: 5.6626\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1232/20000 - Train Loss: 19.6179 - Test Loss: 47.5723 - MSE: 47.5723 - MAE: 5.6624\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1233/20000 - Train Loss: 19.6168 - Test Loss: 47.5699 - MSE: 47.5699 - MAE: 5.6623\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1234/20000 - Train Loss: 19.6158 - Test Loss: 47.5677 - MSE: 47.5677 - MAE: 5.6621\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1235/20000 - Train Loss: 19.6147 - Test Loss: 47.5654 - MSE: 47.5654 - MAE: 5.6620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1236/20000 - Train Loss: 19.6137 - Test Loss: 47.5630 - MSE: 47.5630 - MAE: 5.6618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1237/20000 - Train Loss: 19.6126 - Test Loss: 47.5607 - MSE: 47.5607 - MAE: 5.6617\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1238/20000 - Train Loss: 19.6116 - Test Loss: 47.5585 - MSE: 47.5585 - MAE: 5.6615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1239/20000 - Train Loss: 19.6105 - Test Loss: 47.5561 - MSE: 47.5561 - MAE: 5.6614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1240/20000 - Train Loss: 19.6095 - Test Loss: 47.5537 - MSE: 47.5537 - MAE: 5.6612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1241/20000 - Train Loss: 19.6084 - Test Loss: 47.5514 - MSE: 47.5514 - MAE: 5.6611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1242/20000 - Train Loss: 19.6073 - Test Loss: 47.5491 - MSE: 47.5491 - MAE: 5.6609\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1243/20000 - Train Loss: 19.6063 - Test Loss: 47.5468 - MSE: 47.5468 - MAE: 5.6608\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1244/20000 - Train Loss: 19.6052 - Test Loss: 47.5444 - MSE: 47.5444 - MAE: 5.6606\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1245/20000 - Train Loss: 19.6042 - Test Loss: 47.5421 - MSE: 47.5421 - MAE: 5.6605\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1246/20000 - Train Loss: 19.6031 - Test Loss: 47.5397 - MSE: 47.5397 - MAE: 5.6604\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1247/20000 - Train Loss: 19.6021 - Test Loss: 47.5375 - MSE: 47.5375 - MAE: 5.6602\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1248/20000 - Train Loss: 19.6010 - Test Loss: 47.5351 - MSE: 47.5351 - MAE: 5.6601\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1249/20000 - Train Loss: 19.5999 - Test Loss: 47.5328 - MSE: 47.5328 - MAE: 5.6599\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1250/20000 - Train Loss: 19.5989 - Test Loss: 47.5304 - MSE: 47.5304 - MAE: 5.6598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1251/20000 - Train Loss: 19.5978 - Test Loss: 47.5280 - MSE: 47.5280 - MAE: 5.6596\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1252/20000 - Train Loss: 19.5967 - Test Loss: 47.5256 - MSE: 47.5256 - MAE: 5.6595\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1253/20000 - Train Loss: 19.5957 - Test Loss: 47.5232 - MSE: 47.5232 - MAE: 5.6593\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1254/20000 - Train Loss: 19.5946 - Test Loss: 47.5209 - MSE: 47.5209 - MAE: 5.6592\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1255/20000 - Train Loss: 19.5936 - Test Loss: 47.5186 - MSE: 47.5186 - MAE: 5.6590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1256/20000 - Train Loss: 19.5925 - Test Loss: 47.5163 - MSE: 47.5163 - MAE: 5.6589\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1257/20000 - Train Loss: 19.5914 - Test Loss: 47.5139 - MSE: 47.5139 - MAE: 5.6587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1258/20000 - Train Loss: 19.5903 - Test Loss: 47.5116 - MSE: 47.5116 - MAE: 5.6586\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1259/20000 - Train Loss: 19.5893 - Test Loss: 47.5092 - MSE: 47.5092 - MAE: 5.6584\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1260/20000 - Train Loss: 19.5882 - Test Loss: 47.5069 - MSE: 47.5069 - MAE: 5.6583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1261/20000 - Train Loss: 19.5871 - Test Loss: 47.5045 - MSE: 47.5045 - MAE: 5.6581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1262/20000 - Train Loss: 19.5861 - Test Loss: 47.5021 - MSE: 47.5021 - MAE: 5.6580\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1263/20000 - Train Loss: 19.5850 - Test Loss: 47.4997 - MSE: 47.4997 - MAE: 5.6578\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1264/20000 - Train Loss: 19.5839 - Test Loss: 47.4974 - MSE: 47.4974 - MAE: 5.6577\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1265/20000 - Train Loss: 19.5829 - Test Loss: 47.4951 - MSE: 47.4951 - MAE: 5.6575\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1266/20000 - Train Loss: 19.5818 - Test Loss: 47.4927 - MSE: 47.4927 - MAE: 5.6574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1267/20000 - Train Loss: 19.5807 - Test Loss: 47.4903 - MSE: 47.4903 - MAE: 5.6572\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1268/20000 - Train Loss: 19.5796 - Test Loss: 47.4880 - MSE: 47.4880 - MAE: 5.6571\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1269/20000 - Train Loss: 19.5786 - Test Loss: 47.4856 - MSE: 47.4856 - MAE: 5.6569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1270/20000 - Train Loss: 19.5775 - Test Loss: 47.4832 - MSE: 47.4832 - MAE: 5.6568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1271/20000 - Train Loss: 19.5764 - Test Loss: 47.4809 - MSE: 47.4809 - MAE: 5.6566\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1272/20000 - Train Loss: 19.5753 - Test Loss: 47.4785 - MSE: 47.4785 - MAE: 5.6565\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1273/20000 - Train Loss: 19.5743 - Test Loss: 47.4762 - MSE: 47.4762 - MAE: 5.6563\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1274/20000 - Train Loss: 19.5732 - Test Loss: 47.4738 - MSE: 47.4738 - MAE: 5.6562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1275/20000 - Train Loss: 19.5721 - Test Loss: 47.4714 - MSE: 47.4714 - MAE: 5.6560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1276/20000 - Train Loss: 19.5710 - Test Loss: 47.4690 - MSE: 47.4690 - MAE: 5.6559\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1277/20000 - Train Loss: 19.5700 - Test Loss: 47.4666 - MSE: 47.4666 - MAE: 5.6557\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1278/20000 - Train Loss: 19.5689 - Test Loss: 47.4643 - MSE: 47.4643 - MAE: 5.6556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1279/20000 - Train Loss: 19.5678 - Test Loss: 47.4619 - MSE: 47.4619 - MAE: 5.6554\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1280/20000 - Train Loss: 19.5667 - Test Loss: 47.4595 - MSE: 47.4595 - MAE: 5.6553\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1281/20000 - Train Loss: 19.5656 - Test Loss: 47.4572 - MSE: 47.4572 - MAE: 5.6551\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1282/20000 - Train Loss: 19.5645 - Test Loss: 47.4548 - MSE: 47.4548 - MAE: 5.6550\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1283/20000 - Train Loss: 19.5635 - Test Loss: 47.4524 - MSE: 47.4524 - MAE: 5.6548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1284/20000 - Train Loss: 19.5624 - Test Loss: 47.4499 - MSE: 47.4499 - MAE: 5.6546\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1285/20000 - Train Loss: 19.5613 - Test Loss: 47.4475 - MSE: 47.4475 - MAE: 5.6545\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1286/20000 - Train Loss: 19.5602 - Test Loss: 47.4451 - MSE: 47.4451 - MAE: 5.6543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1287/20000 - Train Loss: 19.5591 - Test Loss: 47.4428 - MSE: 47.4428 - MAE: 5.6542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1288/20000 - Train Loss: 19.5580 - Test Loss: 47.4403 - MSE: 47.4403 - MAE: 5.6540\n",
      "2/2 [==============================] - 0s 965us/step\n",
      "Epoch 1289/20000 - Train Loss: 19.5569 - Test Loss: 47.4379 - MSE: 47.4379 - MAE: 5.6539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1290/20000 - Train Loss: 19.5559 - Test Loss: 47.4356 - MSE: 47.4356 - MAE: 5.6537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1291/20000 - Train Loss: 19.5548 - Test Loss: 47.4332 - MSE: 47.4332 - MAE: 5.6536\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1292/20000 - Train Loss: 19.5537 - Test Loss: 47.4308 - MSE: 47.4308 - MAE: 5.6534\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1293/20000 - Train Loss: 19.5526 - Test Loss: 47.4284 - MSE: 47.4284 - MAE: 5.6533\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1294/20000 - Train Loss: 19.5515 - Test Loss: 47.4259 - MSE: 47.4259 - MAE: 5.6531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1295/20000 - Train Loss: 19.5504 - Test Loss: 47.4235 - MSE: 47.4235 - MAE: 5.6530\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1296/20000 - Train Loss: 19.5493 - Test Loss: 47.4211 - MSE: 47.4211 - MAE: 5.6528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1297/20000 - Train Loss: 19.5482 - Test Loss: 47.4187 - MSE: 47.4187 - MAE: 5.6527\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1298/20000 - Train Loss: 19.5471 - Test Loss: 47.4162 - MSE: 47.4162 - MAE: 5.6525\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1299/20000 - Train Loss: 19.5460 - Test Loss: 47.4139 - MSE: 47.4139 - MAE: 5.6524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1300/20000 - Train Loss: 19.5449 - Test Loss: 47.4115 - MSE: 47.4115 - MAE: 5.6522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1301/20000 - Train Loss: 19.5438 - Test Loss: 47.4090 - MSE: 47.4090 - MAE: 5.6520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1302/20000 - Train Loss: 19.5427 - Test Loss: 47.4066 - MSE: 47.4066 - MAE: 5.6519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1303/20000 - Train Loss: 19.5416 - Test Loss: 47.4041 - MSE: 47.4041 - MAE: 5.6517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1304/20000 - Train Loss: 19.5405 - Test Loss: 47.4017 - MSE: 47.4017 - MAE: 5.6516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1305/20000 - Train Loss: 19.5394 - Test Loss: 47.3993 - MSE: 47.3993 - MAE: 5.6514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1306/20000 - Train Loss: 19.5383 - Test Loss: 47.3969 - MSE: 47.3969 - MAE: 5.6513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1307/20000 - Train Loss: 19.5372 - Test Loss: 47.3944 - MSE: 47.3944 - MAE: 5.6511\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1308/20000 - Train Loss: 19.5361 - Test Loss: 47.3920 - MSE: 47.3920 - MAE: 5.6510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1309/20000 - Train Loss: 19.5350 - Test Loss: 47.3895 - MSE: 47.3895 - MAE: 5.6508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1310/20000 - Train Loss: 19.5339 - Test Loss: 47.3871 - MSE: 47.3871 - MAE: 5.6506\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1311/20000 - Train Loss: 19.5328 - Test Loss: 47.3847 - MSE: 47.3847 - MAE: 5.6505\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1312/20000 - Train Loss: 19.5317 - Test Loss: 47.3823 - MSE: 47.3823 - MAE: 5.6503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1313/20000 - Train Loss: 19.5306 - Test Loss: 47.3798 - MSE: 47.3798 - MAE: 5.6502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1314/20000 - Train Loss: 19.5295 - Test Loss: 47.3774 - MSE: 47.3774 - MAE: 5.6500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1315/20000 - Train Loss: 19.5284 - Test Loss: 47.3750 - MSE: 47.3750 - MAE: 5.6499\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1316/20000 - Train Loss: 19.5273 - Test Loss: 47.3725 - MSE: 47.3725 - MAE: 5.6497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1317/20000 - Train Loss: 19.5262 - Test Loss: 47.3701 - MSE: 47.3701 - MAE: 5.6496\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 1318/20000 - Train Loss: 19.5251 - Test Loss: 47.3676 - MSE: 47.3676 - MAE: 5.6494\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1319/20000 - Train Loss: 19.5240 - Test Loss: 47.3652 - MSE: 47.3652 - MAE: 5.6493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1320/20000 - Train Loss: 19.5229 - Test Loss: 47.3627 - MSE: 47.3627 - MAE: 5.6491\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1321/20000 - Train Loss: 19.5218 - Test Loss: 47.3603 - MSE: 47.3603 - MAE: 5.6489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1322/20000 - Train Loss: 19.5206 - Test Loss: 47.3579 - MSE: 47.3579 - MAE: 5.6488\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1323/20000 - Train Loss: 19.5195 - Test Loss: 47.3555 - MSE: 47.3555 - MAE: 5.6486\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1324/20000 - Train Loss: 19.5184 - Test Loss: 47.3530 - MSE: 47.3530 - MAE: 5.6485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1325/20000 - Train Loss: 19.5173 - Test Loss: 47.3506 - MSE: 47.3506 - MAE: 5.6483\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1326/20000 - Train Loss: 19.5162 - Test Loss: 47.3481 - MSE: 47.3481 - MAE: 5.6482\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1327/20000 - Train Loss: 19.5151 - Test Loss: 47.3457 - MSE: 47.3457 - MAE: 5.6480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1328/20000 - Train Loss: 19.5140 - Test Loss: 47.3432 - MSE: 47.3432 - MAE: 5.6479\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1329/20000 - Train Loss: 19.5128 - Test Loss: 47.3407 - MSE: 47.3407 - MAE: 5.6477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1330/20000 - Train Loss: 19.5117 - Test Loss: 47.3382 - MSE: 47.3382 - MAE: 5.6475\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 1331/20000 - Train Loss: 19.5106 - Test Loss: 47.3358 - MSE: 47.3358 - MAE: 5.6474\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1332/20000 - Train Loss: 19.5095 - Test Loss: 47.3334 - MSE: 47.3334 - MAE: 5.6472\n",
      "2/2 [==============================] - 0s 985us/step\n",
      "Epoch 1333/20000 - Train Loss: 19.5084 - Test Loss: 47.3309 - MSE: 47.3309 - MAE: 5.6471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1334/20000 - Train Loss: 19.5073 - Test Loss: 47.3285 - MSE: 47.3285 - MAE: 5.6469\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1335/20000 - Train Loss: 19.5061 - Test Loss: 47.3260 - MSE: 47.3260 - MAE: 5.6468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1336/20000 - Train Loss: 19.5050 - Test Loss: 47.3235 - MSE: 47.3235 - MAE: 5.6466\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1337/20000 - Train Loss: 19.5039 - Test Loss: 47.3210 - MSE: 47.3210 - MAE: 5.6464\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1338/20000 - Train Loss: 19.5028 - Test Loss: 47.3185 - MSE: 47.3185 - MAE: 5.6463\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1339/20000 - Train Loss: 19.5016 - Test Loss: 47.3160 - MSE: 47.3160 - MAE: 5.6461\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1340/20000 - Train Loss: 19.5005 - Test Loss: 47.3135 - MSE: 47.3135 - MAE: 5.6460\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1341/20000 - Train Loss: 19.4994 - Test Loss: 47.3111 - MSE: 47.3111 - MAE: 5.6458\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1342/20000 - Train Loss: 19.4983 - Test Loss: 47.3086 - MSE: 47.3086 - MAE: 5.6456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1343/20000 - Train Loss: 19.4971 - Test Loss: 47.3061 - MSE: 47.3061 - MAE: 5.6455\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1344/20000 - Train Loss: 19.4960 - Test Loss: 47.3037 - MSE: 47.3037 - MAE: 5.6453\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1345/20000 - Train Loss: 19.4949 - Test Loss: 47.3012 - MSE: 47.3012 - MAE: 5.6452\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1346/20000 - Train Loss: 19.4938 - Test Loss: 47.2987 - MSE: 47.2987 - MAE: 5.6450\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1347/20000 - Train Loss: 19.4926 - Test Loss: 47.2961 - MSE: 47.2961 - MAE: 5.6449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1348/20000 - Train Loss: 19.4915 - Test Loss: 47.2937 - MSE: 47.2937 - MAE: 5.6447\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1349/20000 - Train Loss: 19.4904 - Test Loss: 47.2912 - MSE: 47.2912 - MAE: 5.6445\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1350/20000 - Train Loss: 19.4893 - Test Loss: 47.2887 - MSE: 47.2887 - MAE: 5.6444\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 1351/20000 - Train Loss: 19.4881 - Test Loss: 47.2862 - MSE: 47.2862 - MAE: 5.6442\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 1352/20000 - Train Loss: 19.4870 - Test Loss: 47.2837 - MSE: 47.2837 - MAE: 5.6441\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1353/20000 - Train Loss: 19.4859 - Test Loss: 47.2812 - MSE: 47.2812 - MAE: 5.6439\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1354/20000 - Train Loss: 19.4847 - Test Loss: 47.2787 - MSE: 47.2787 - MAE: 5.6437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1355/20000 - Train Loss: 19.4836 - Test Loss: 47.2762 - MSE: 47.2762 - MAE: 5.6436\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1356/20000 - Train Loss: 19.4825 - Test Loss: 47.2736 - MSE: 47.2736 - MAE: 5.6434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1357/20000 - Train Loss: 19.4813 - Test Loss: 47.2712 - MSE: 47.2712 - MAE: 5.6433\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1358/20000 - Train Loss: 19.4802 - Test Loss: 47.2687 - MSE: 47.2687 - MAE: 5.6431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1359/20000 - Train Loss: 19.4790 - Test Loss: 47.2662 - MSE: 47.2662 - MAE: 5.6429\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1360/20000 - Train Loss: 19.4779 - Test Loss: 47.2637 - MSE: 47.2637 - MAE: 5.6428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1361/20000 - Train Loss: 19.4768 - Test Loss: 47.2612 - MSE: 47.2612 - MAE: 5.6426\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1362/20000 - Train Loss: 19.4756 - Test Loss: 47.2586 - MSE: 47.2586 - MAE: 5.6425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1363/20000 - Train Loss: 19.4745 - Test Loss: 47.2561 - MSE: 47.2561 - MAE: 5.6423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1364/20000 - Train Loss: 19.4734 - Test Loss: 47.2536 - MSE: 47.2536 - MAE: 5.6421\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 1365/20000 - Train Loss: 19.4722 - Test Loss: 47.2510 - MSE: 47.2510 - MAE: 5.6420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1366/20000 - Train Loss: 19.4711 - Test Loss: 47.2486 - MSE: 47.2486 - MAE: 5.6418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1367/20000 - Train Loss: 19.4699 - Test Loss: 47.2461 - MSE: 47.2461 - MAE: 5.6417\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1368/20000 - Train Loss: 19.4688 - Test Loss: 47.2435 - MSE: 47.2435 - MAE: 5.6415\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1369/20000 - Train Loss: 19.4676 - Test Loss: 47.2411 - MSE: 47.2411 - MAE: 5.6413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1370/20000 - Train Loss: 19.4665 - Test Loss: 47.2386 - MSE: 47.2386 - MAE: 5.6412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1371/20000 - Train Loss: 19.4654 - Test Loss: 47.2360 - MSE: 47.2360 - MAE: 5.6410\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1372/20000 - Train Loss: 19.4642 - Test Loss: 47.2335 - MSE: 47.2335 - MAE: 5.6409\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1373/20000 - Train Loss: 19.4631 - Test Loss: 47.2310 - MSE: 47.2310 - MAE: 5.6407\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1374/20000 - Train Loss: 19.4619 - Test Loss: 47.2284 - MSE: 47.2284 - MAE: 5.6405\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1375/20000 - Train Loss: 19.4608 - Test Loss: 47.2259 - MSE: 47.2259 - MAE: 5.6404\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1376/20000 - Train Loss: 19.4596 - Test Loss: 47.2234 - MSE: 47.2234 - MAE: 5.6402\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1377/20000 - Train Loss: 19.4585 - Test Loss: 47.2209 - MSE: 47.2209 - MAE: 5.6401\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1378/20000 - Train Loss: 19.4573 - Test Loss: 47.2184 - MSE: 47.2184 - MAE: 5.6399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1379/20000 - Train Loss: 19.4562 - Test Loss: 47.2158 - MSE: 47.2158 - MAE: 5.6397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1380/20000 - Train Loss: 19.4550 - Test Loss: 47.2133 - MSE: 47.2133 - MAE: 5.6396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1381/20000 - Train Loss: 19.4539 - Test Loss: 47.2107 - MSE: 47.2107 - MAE: 5.6394\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 1382/20000 - Train Loss: 19.4527 - Test Loss: 47.2082 - MSE: 47.2082 - MAE: 5.6392\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 1383/20000 - Train Loss: 19.4516 - Test Loss: 47.2057 - MSE: 47.2057 - MAE: 5.6391\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1384/20000 - Train Loss: 19.4504 - Test Loss: 47.2031 - MSE: 47.2031 - MAE: 5.6389\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 1385/20000 - Train Loss: 19.4493 - Test Loss: 47.2006 - MSE: 47.2006 - MAE: 5.6388\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1386/20000 - Train Loss: 19.4481 - Test Loss: 47.1980 - MSE: 47.1980 - MAE: 5.6386\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1387/20000 - Train Loss: 19.4469 - Test Loss: 47.1955 - MSE: 47.1955 - MAE: 5.6384\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1388/20000 - Train Loss: 19.4458 - Test Loss: 47.1929 - MSE: 47.1929 - MAE: 5.6383\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1389/20000 - Train Loss: 19.4446 - Test Loss: 47.1904 - MSE: 47.1904 - MAE: 5.6381\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1390/20000 - Train Loss: 19.4435 - Test Loss: 47.1878 - MSE: 47.1878 - MAE: 5.6379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1391/20000 - Train Loss: 19.4423 - Test Loss: 47.1852 - MSE: 47.1852 - MAE: 5.6378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1392/20000 - Train Loss: 19.4412 - Test Loss: 47.1826 - MSE: 47.1826 - MAE: 5.6376\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1393/20000 - Train Loss: 19.4400 - Test Loss: 47.1801 - MSE: 47.1801 - MAE: 5.6375\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1394/20000 - Train Loss: 19.4388 - Test Loss: 47.1775 - MSE: 47.1775 - MAE: 5.6373\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1395/20000 - Train Loss: 19.4377 - Test Loss: 47.1749 - MSE: 47.1749 - MAE: 5.6371\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1396/20000 - Train Loss: 19.4365 - Test Loss: 47.1724 - MSE: 47.1724 - MAE: 5.6370\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1397/20000 - Train Loss: 19.4353 - Test Loss: 47.1698 - MSE: 47.1698 - MAE: 5.6368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1398/20000 - Train Loss: 19.4342 - Test Loss: 47.1672 - MSE: 47.1672 - MAE: 5.6366\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1399/20000 - Train Loss: 19.4330 - Test Loss: 47.1646 - MSE: 47.1646 - MAE: 5.6365\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1400/20000 - Train Loss: 19.4319 - Test Loss: 47.1621 - MSE: 47.1621 - MAE: 5.6363\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1401/20000 - Train Loss: 19.4307 - Test Loss: 47.1595 - MSE: 47.1595 - MAE: 5.6361\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1402/20000 - Train Loss: 19.4295 - Test Loss: 47.1570 - MSE: 47.1570 - MAE: 5.6360\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1403/20000 - Train Loss: 19.4284 - Test Loss: 47.1544 - MSE: 47.1544 - MAE: 5.6358\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1404/20000 - Train Loss: 19.4272 - Test Loss: 47.1518 - MSE: 47.1518 - MAE: 5.6356\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1405/20000 - Train Loss: 19.4260 - Test Loss: 47.1493 - MSE: 47.1493 - MAE: 5.6355\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1406/20000 - Train Loss: 19.4248 - Test Loss: 47.1467 - MSE: 47.1467 - MAE: 5.6353\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1407/20000 - Train Loss: 19.4237 - Test Loss: 47.1441 - MSE: 47.1441 - MAE: 5.6352\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1408/20000 - Train Loss: 19.4225 - Test Loss: 47.1416 - MSE: 47.1416 - MAE: 5.6350\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1409/20000 - Train Loss: 19.4213 - Test Loss: 47.1390 - MSE: 47.1390 - MAE: 5.6348\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1410/20000 - Train Loss: 19.4202 - Test Loss: 47.1364 - MSE: 47.1364 - MAE: 5.6347\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1411/20000 - Train Loss: 19.4190 - Test Loss: 47.1339 - MSE: 47.1339 - MAE: 5.6345\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1412/20000 - Train Loss: 19.4178 - Test Loss: 47.1313 - MSE: 47.1313 - MAE: 5.6343\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1413/20000 - Train Loss: 19.4166 - Test Loss: 47.1286 - MSE: 47.1286 - MAE: 5.6342\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1414/20000 - Train Loss: 19.4155 - Test Loss: 47.1260 - MSE: 47.1260 - MAE: 5.6340\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1415/20000 - Train Loss: 19.4143 - Test Loss: 47.1234 - MSE: 47.1234 - MAE: 5.6338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1416/20000 - Train Loss: 19.4131 - Test Loss: 47.1209 - MSE: 47.1209 - MAE: 5.6337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1417/20000 - Train Loss: 19.4119 - Test Loss: 47.1182 - MSE: 47.1182 - MAE: 5.6335\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1418/20000 - Train Loss: 19.4108 - Test Loss: 47.1157 - MSE: 47.1157 - MAE: 5.6333\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1419/20000 - Train Loss: 19.4096 - Test Loss: 47.1131 - MSE: 47.1131 - MAE: 5.6332\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1420/20000 - Train Loss: 19.4084 - Test Loss: 47.1105 - MSE: 47.1105 - MAE: 5.6330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1421/20000 - Train Loss: 19.4072 - Test Loss: 47.1079 - MSE: 47.1080 - MAE: 5.6328\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1422/20000 - Train Loss: 19.4060 - Test Loss: 47.1054 - MSE: 47.1054 - MAE: 5.6327\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1423/20000 - Train Loss: 19.4049 - Test Loss: 47.1027 - MSE: 47.1027 - MAE: 5.6325\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1424/20000 - Train Loss: 19.4037 - Test Loss: 47.1001 - MSE: 47.1001 - MAE: 5.6323\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1425/20000 - Train Loss: 19.4025 - Test Loss: 47.0975 - MSE: 47.0975 - MAE: 5.6322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1426/20000 - Train Loss: 19.4013 - Test Loss: 47.0948 - MSE: 47.0948 - MAE: 5.6320\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1427/20000 - Train Loss: 19.4001 - Test Loss: 47.0922 - MSE: 47.0922 - MAE: 5.6318\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1428/20000 - Train Loss: 19.3989 - Test Loss: 47.0897 - MSE: 47.0897 - MAE: 5.6317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1429/20000 - Train Loss: 19.3978 - Test Loss: 47.0871 - MSE: 47.0871 - MAE: 5.6315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1430/20000 - Train Loss: 19.3966 - Test Loss: 47.0844 - MSE: 47.0845 - MAE: 5.6313\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 1431/20000 - Train Loss: 19.3954 - Test Loss: 47.0818 - MSE: 47.0818 - MAE: 5.6312\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1432/20000 - Train Loss: 19.3942 - Test Loss: 47.0792 - MSE: 47.0792 - MAE: 5.6310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1433/20000 - Train Loss: 19.3930 - Test Loss: 47.0766 - MSE: 47.0766 - MAE: 5.6308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1434/20000 - Train Loss: 19.3918 - Test Loss: 47.0739 - MSE: 47.0739 - MAE: 5.6307\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1435/20000 - Train Loss: 19.3906 - Test Loss: 47.0713 - MSE: 47.0713 - MAE: 5.6305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1436/20000 - Train Loss: 19.3894 - Test Loss: 47.0687 - MSE: 47.0687 - MAE: 5.6303\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1437/20000 - Train Loss: 19.3882 - Test Loss: 47.0661 - MSE: 47.0661 - MAE: 5.6302\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1438/20000 - Train Loss: 19.3871 - Test Loss: 47.0634 - MSE: 47.0634 - MAE: 5.6300\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1439/20000 - Train Loss: 19.3859 - Test Loss: 47.0608 - MSE: 47.0608 - MAE: 5.6298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1440/20000 - Train Loss: 19.3847 - Test Loss: 47.0581 - MSE: 47.0581 - MAE: 5.6297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1441/20000 - Train Loss: 19.3835 - Test Loss: 47.0555 - MSE: 47.0555 - MAE: 5.6295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1442/20000 - Train Loss: 19.3823 - Test Loss: 47.0529 - MSE: 47.0529 - MAE: 5.6293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1443/20000 - Train Loss: 19.3811 - Test Loss: 47.0503 - MSE: 47.0503 - MAE: 5.6292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1444/20000 - Train Loss: 19.3799 - Test Loss: 47.0476 - MSE: 47.0476 - MAE: 5.6290\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1445/20000 - Train Loss: 19.3787 - Test Loss: 47.0450 - MSE: 47.0450 - MAE: 5.6288\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1446/20000 - Train Loss: 19.3775 - Test Loss: 47.0423 - MSE: 47.0423 - MAE: 5.6286\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1447/20000 - Train Loss: 19.3763 - Test Loss: 47.0396 - MSE: 47.0396 - MAE: 5.6285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1448/20000 - Train Loss: 19.3751 - Test Loss: 47.0370 - MSE: 47.0370 - MAE: 5.6283\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1449/20000 - Train Loss: 19.3739 - Test Loss: 47.0343 - MSE: 47.0343 - MAE: 5.6281\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1450/20000 - Train Loss: 19.3727 - Test Loss: 47.0317 - MSE: 47.0317 - MAE: 5.6280\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1451/20000 - Train Loss: 19.3715 - Test Loss: 47.0291 - MSE: 47.0291 - MAE: 5.6278\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1452/20000 - Train Loss: 19.3703 - Test Loss: 47.0265 - MSE: 47.0265 - MAE: 5.6276\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1453/20000 - Train Loss: 19.3691 - Test Loss: 47.0239 - MSE: 47.0239 - MAE: 5.6275\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1454/20000 - Train Loss: 19.3679 - Test Loss: 47.0213 - MSE: 47.0213 - MAE: 5.6273\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1455/20000 - Train Loss: 19.3667 - Test Loss: 47.0185 - MSE: 47.0185 - MAE: 5.6271\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1456/20000 - Train Loss: 19.3655 - Test Loss: 47.0159 - MSE: 47.0159 - MAE: 5.6270\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1457/20000 - Train Loss: 19.3643 - Test Loss: 47.0132 - MSE: 47.0132 - MAE: 5.6268\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1458/20000 - Train Loss: 19.3631 - Test Loss: 47.0105 - MSE: 47.0105 - MAE: 5.6266\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1459/20000 - Train Loss: 19.3619 - Test Loss: 47.0079 - MSE: 47.0079 - MAE: 5.6264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1460/20000 - Train Loss: 19.3607 - Test Loss: 47.0052 - MSE: 47.0052 - MAE: 5.6263\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1461/20000 - Train Loss: 19.3595 - Test Loss: 47.0026 - MSE: 47.0026 - MAE: 5.6261\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1462/20000 - Train Loss: 19.3583 - Test Loss: 47.0000 - MSE: 47.0000 - MAE: 5.6259\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1463/20000 - Train Loss: 19.3570 - Test Loss: 46.9973 - MSE: 46.9973 - MAE: 5.6258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1464/20000 - Train Loss: 19.3558 - Test Loss: 46.9947 - MSE: 46.9947 - MAE: 5.6256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1465/20000 - Train Loss: 19.3546 - Test Loss: 46.9920 - MSE: 46.9920 - MAE: 5.6254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1466/20000 - Train Loss: 19.3534 - Test Loss: 46.9893 - MSE: 46.9893 - MAE: 5.6253\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1467/20000 - Train Loss: 19.3522 - Test Loss: 46.9866 - MSE: 46.9866 - MAE: 5.6251\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1468/20000 - Train Loss: 19.3510 - Test Loss: 46.9840 - MSE: 46.9839 - MAE: 5.6249\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1469/20000 - Train Loss: 19.3498 - Test Loss: 46.9813 - MSE: 46.9813 - MAE: 5.6247\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1470/20000 - Train Loss: 19.3486 - Test Loss: 46.9786 - MSE: 46.9786 - MAE: 5.6246\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1471/20000 - Train Loss: 19.3473 - Test Loss: 46.9759 - MSE: 46.9759 - MAE: 5.6244\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1472/20000 - Train Loss: 19.3461 - Test Loss: 46.9733 - MSE: 46.9733 - MAE: 5.6242\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1473/20000 - Train Loss: 19.3449 - Test Loss: 46.9706 - MSE: 46.9706 - MAE: 5.6241\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1474/20000 - Train Loss: 19.3437 - Test Loss: 46.9679 - MSE: 46.9679 - MAE: 5.6239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1475/20000 - Train Loss: 19.3425 - Test Loss: 46.9652 - MSE: 46.9652 - MAE: 5.6237\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1476/20000 - Train Loss: 19.3413 - Test Loss: 46.9625 - MSE: 46.9625 - MAE: 5.6235\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1477/20000 - Train Loss: 19.3400 - Test Loss: 46.9598 - MSE: 46.9598 - MAE: 5.6234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1478/20000 - Train Loss: 19.3388 - Test Loss: 46.9571 - MSE: 46.9571 - MAE: 5.6232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1479/20000 - Train Loss: 19.3376 - Test Loss: 46.9544 - MSE: 46.9544 - MAE: 5.6230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1480/20000 - Train Loss: 19.3364 - Test Loss: 46.9517 - MSE: 46.9517 - MAE: 5.6228\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1481/20000 - Train Loss: 19.3351 - Test Loss: 46.9490 - MSE: 46.9490 - MAE: 5.6227\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1482/20000 - Train Loss: 19.3339 - Test Loss: 46.9463 - MSE: 46.9463 - MAE: 5.6225\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1483/20000 - Train Loss: 19.3327 - Test Loss: 46.9436 - MSE: 46.9436 - MAE: 5.6223\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1484/20000 - Train Loss: 19.3315 - Test Loss: 46.9409 - MSE: 46.9409 - MAE: 5.6222\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1485/20000 - Train Loss: 19.3303 - Test Loss: 46.9382 - MSE: 46.9382 - MAE: 5.6220\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1486/20000 - Train Loss: 19.3290 - Test Loss: 46.9355 - MSE: 46.9355 - MAE: 5.6218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1487/20000 - Train Loss: 19.3278 - Test Loss: 46.9328 - MSE: 46.9328 - MAE: 5.6216\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1488/20000 - Train Loss: 19.3266 - Test Loss: 46.9301 - MSE: 46.9301 - MAE: 5.6215\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1489/20000 - Train Loss: 19.3253 - Test Loss: 46.9274 - MSE: 46.9274 - MAE: 5.6213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1490/20000 - Train Loss: 19.3241 - Test Loss: 46.9246 - MSE: 46.9246 - MAE: 5.6211\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1491/20000 - Train Loss: 19.3229 - Test Loss: 46.9219 - MSE: 46.9219 - MAE: 5.6209\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1492/20000 - Train Loss: 19.3217 - Test Loss: 46.9192 - MSE: 46.9192 - MAE: 5.6208\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1493/20000 - Train Loss: 19.3204 - Test Loss: 46.9165 - MSE: 46.9165 - MAE: 5.6206\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1494/20000 - Train Loss: 19.3192 - Test Loss: 46.9138 - MSE: 46.9138 - MAE: 5.6204\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1495/20000 - Train Loss: 19.3180 - Test Loss: 46.9111 - MSE: 46.9111 - MAE: 5.6202\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1496/20000 - Train Loss: 19.3167 - Test Loss: 46.9084 - MSE: 46.9084 - MAE: 5.6201\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1497/20000 - Train Loss: 19.3155 - Test Loss: 46.9057 - MSE: 46.9057 - MAE: 5.6199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1498/20000 - Train Loss: 19.3143 - Test Loss: 46.9030 - MSE: 46.9030 - MAE: 5.6197\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1499/20000 - Train Loss: 19.3130 - Test Loss: 46.9003 - MSE: 46.9003 - MAE: 5.6196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1500/20000 - Train Loss: 19.3118 - Test Loss: 46.8975 - MSE: 46.8975 - MAE: 5.6194\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1501/20000 - Train Loss: 19.3106 - Test Loss: 46.8948 - MSE: 46.8948 - MAE: 5.6192\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1502/20000 - Train Loss: 19.3093 - Test Loss: 46.8921 - MSE: 46.8921 - MAE: 5.6190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1503/20000 - Train Loss: 19.3081 - Test Loss: 46.8894 - MSE: 46.8894 - MAE: 5.6189\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1504/20000 - Train Loss: 19.3069 - Test Loss: 46.8867 - MSE: 46.8867 - MAE: 5.6187\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1505/20000 - Train Loss: 19.3056 - Test Loss: 46.8840 - MSE: 46.8840 - MAE: 5.6185\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1506/20000 - Train Loss: 19.3044 - Test Loss: 46.8813 - MSE: 46.8813 - MAE: 5.6183\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1507/20000 - Train Loss: 19.3031 - Test Loss: 46.8785 - MSE: 46.8785 - MAE: 5.6182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1508/20000 - Train Loss: 19.3019 - Test Loss: 46.8757 - MSE: 46.8757 - MAE: 5.6180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1509/20000 - Train Loss: 19.3006 - Test Loss: 46.8731 - MSE: 46.8731 - MAE: 5.6178\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1510/20000 - Train Loss: 19.2994 - Test Loss: 46.8703 - MSE: 46.8703 - MAE: 5.6176\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1511/20000 - Train Loss: 19.2982 - Test Loss: 46.8676 - MSE: 46.8676 - MAE: 5.6175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1512/20000 - Train Loss: 19.2969 - Test Loss: 46.8648 - MSE: 46.8648 - MAE: 5.6173\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1513/20000 - Train Loss: 19.2957 - Test Loss: 46.8621 - MSE: 46.8621 - MAE: 5.6171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1514/20000 - Train Loss: 19.2944 - Test Loss: 46.8593 - MSE: 46.8593 - MAE: 5.6169\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 1515/20000 - Train Loss: 19.2932 - Test Loss: 46.8566 - MSE: 46.8566 - MAE: 5.6168\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 1516/20000 - Train Loss: 19.2919 - Test Loss: 46.8538 - MSE: 46.8538 - MAE: 5.6166\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1517/20000 - Train Loss: 19.2907 - Test Loss: 46.8511 - MSE: 46.8511 - MAE: 5.6164\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 1518/20000 - Train Loss: 19.2894 - Test Loss: 46.8483 - MSE: 46.8483 - MAE: 5.6162\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1519/20000 - Train Loss: 19.2882 - Test Loss: 46.8455 - MSE: 46.8455 - MAE: 5.6160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1520/20000 - Train Loss: 19.2869 - Test Loss: 46.8428 - MSE: 46.8428 - MAE: 5.6159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1521/20000 - Train Loss: 19.2857 - Test Loss: 46.8401 - MSE: 46.8401 - MAE: 5.6157\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1522/20000 - Train Loss: 19.2844 - Test Loss: 46.8373 - MSE: 46.8373 - MAE: 5.6155\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1523/20000 - Train Loss: 19.2832 - Test Loss: 46.8345 - MSE: 46.8345 - MAE: 5.6153\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1524/20000 - Train Loss: 19.2819 - Test Loss: 46.8317 - MSE: 46.8317 - MAE: 5.6152\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1525/20000 - Train Loss: 19.2807 - Test Loss: 46.8290 - MSE: 46.8290 - MAE: 5.6150\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1526/20000 - Train Loss: 19.2794 - Test Loss: 46.8262 - MSE: 46.8262 - MAE: 5.6148\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1527/20000 - Train Loss: 19.2782 - Test Loss: 46.8235 - MSE: 46.8235 - MAE: 5.6146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1528/20000 - Train Loss: 19.2769 - Test Loss: 46.8207 - MSE: 46.8207 - MAE: 5.6145\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1529/20000 - Train Loss: 19.2757 - Test Loss: 46.8179 - MSE: 46.8179 - MAE: 5.6143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1530/20000 - Train Loss: 19.2744 - Test Loss: 46.8152 - MSE: 46.8152 - MAE: 5.6141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1531/20000 - Train Loss: 19.2731 - Test Loss: 46.8124 - MSE: 46.8124 - MAE: 5.6139\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1532/20000 - Train Loss: 19.2719 - Test Loss: 46.8095 - MSE: 46.8095 - MAE: 5.6137\n",
      "2/2 [==============================] - 0s 982us/step\n",
      "Epoch 1533/20000 - Train Loss: 19.2706 - Test Loss: 46.8068 - MSE: 46.8068 - MAE: 5.6136\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1534/20000 - Train Loss: 19.2694 - Test Loss: 46.8041 - MSE: 46.8041 - MAE: 5.6134\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1535/20000 - Train Loss: 19.2681 - Test Loss: 46.8013 - MSE: 46.8013 - MAE: 5.6132\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1536/20000 - Train Loss: 19.2668 - Test Loss: 46.7985 - MSE: 46.7985 - MAE: 5.6130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1537/20000 - Train Loss: 19.2656 - Test Loss: 46.7957 - MSE: 46.7957 - MAE: 5.6128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1538/20000 - Train Loss: 19.2643 - Test Loss: 46.7930 - MSE: 46.7930 - MAE: 5.6127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1539/20000 - Train Loss: 19.2631 - Test Loss: 46.7901 - MSE: 46.7901 - MAE: 5.6125\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1540/20000 - Train Loss: 19.2618 - Test Loss: 46.7873 - MSE: 46.7873 - MAE: 5.6123\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1541/20000 - Train Loss: 19.2605 - Test Loss: 46.7846 - MSE: 46.7846 - MAE: 5.6121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1542/20000 - Train Loss: 19.2593 - Test Loss: 46.7817 - MSE: 46.7817 - MAE: 5.6120\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1543/20000 - Train Loss: 19.2580 - Test Loss: 46.7790 - MSE: 46.7790 - MAE: 5.6118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1544/20000 - Train Loss: 19.2567 - Test Loss: 46.7762 - MSE: 46.7762 - MAE: 5.6116\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1545/20000 - Train Loss: 19.2555 - Test Loss: 46.7734 - MSE: 46.7734 - MAE: 5.6114\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1546/20000 - Train Loss: 19.2542 - Test Loss: 46.7706 - MSE: 46.7706 - MAE: 5.6112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1547/20000 - Train Loss: 19.2529 - Test Loss: 46.7678 - MSE: 46.7678 - MAE: 5.6111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1548/20000 - Train Loss: 19.2517 - Test Loss: 46.7650 - MSE: 46.7650 - MAE: 5.6109\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1549/20000 - Train Loss: 19.2504 - Test Loss: 46.7623 - MSE: 46.7623 - MAE: 5.6107\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1550/20000 - Train Loss: 19.2491 - Test Loss: 46.7595 - MSE: 46.7595 - MAE: 5.6105\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1551/20000 - Train Loss: 19.2478 - Test Loss: 46.7567 - MSE: 46.7567 - MAE: 5.6103\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1552/20000 - Train Loss: 19.2466 - Test Loss: 46.7538 - MSE: 46.7538 - MAE: 5.6102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1553/20000 - Train Loss: 19.2453 - Test Loss: 46.7511 - MSE: 46.7511 - MAE: 5.6100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1554/20000 - Train Loss: 19.2440 - Test Loss: 46.7482 - MSE: 46.7482 - MAE: 5.6098\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1555/20000 - Train Loss: 19.2427 - Test Loss: 46.7455 - MSE: 46.7455 - MAE: 5.6096\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1556/20000 - Train Loss: 19.2415 - Test Loss: 46.7427 - MSE: 46.7427 - MAE: 5.6094\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1557/20000 - Train Loss: 19.2402 - Test Loss: 46.7399 - MSE: 46.7399 - MAE: 5.6093\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1558/20000 - Train Loss: 19.2389 - Test Loss: 46.7370 - MSE: 46.7370 - MAE: 5.6091\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1559/20000 - Train Loss: 19.2376 - Test Loss: 46.7342 - MSE: 46.7342 - MAE: 5.6089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1560/20000 - Train Loss: 19.2364 - Test Loss: 46.7314 - MSE: 46.7314 - MAE: 5.6087\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1561/20000 - Train Loss: 19.2351 - Test Loss: 46.7285 - MSE: 46.7285 - MAE: 5.6085\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1562/20000 - Train Loss: 19.2338 - Test Loss: 46.7257 - MSE: 46.7257 - MAE: 5.6084\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1563/20000 - Train Loss: 19.2325 - Test Loss: 46.7229 - MSE: 46.7229 - MAE: 5.6082\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1564/20000 - Train Loss: 19.2312 - Test Loss: 46.7201 - MSE: 46.7201 - MAE: 5.6080\n",
      "2/2 [==============================] - 0s 985us/step\n",
      "Epoch 1565/20000 - Train Loss: 19.2300 - Test Loss: 46.7172 - MSE: 46.7172 - MAE: 5.6078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1566/20000 - Train Loss: 19.2287 - Test Loss: 46.7144 - MSE: 46.7144 - MAE: 5.6076\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1567/20000 - Train Loss: 19.2274 - Test Loss: 46.7116 - MSE: 46.7116 - MAE: 5.6074\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1568/20000 - Train Loss: 19.2261 - Test Loss: 46.7088 - MSE: 46.7088 - MAE: 5.6073\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1569/20000 - Train Loss: 19.2248 - Test Loss: 46.7060 - MSE: 46.7060 - MAE: 5.6071\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 1570/20000 - Train Loss: 19.2235 - Test Loss: 46.7031 - MSE: 46.7031 - MAE: 5.6069\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 1571/20000 - Train Loss: 19.2223 - Test Loss: 46.7002 - MSE: 46.7002 - MAE: 5.6067\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1572/20000 - Train Loss: 19.2210 - Test Loss: 46.6974 - MSE: 46.6974 - MAE: 5.6065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1573/20000 - Train Loss: 19.2197 - Test Loss: 46.6945 - MSE: 46.6945 - MAE: 5.6064\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1574/20000 - Train Loss: 19.2184 - Test Loss: 46.6916 - MSE: 46.6916 - MAE: 5.6062\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1575/20000 - Train Loss: 19.2171 - Test Loss: 46.6888 - MSE: 46.6888 - MAE: 5.6060\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 1576/20000 - Train Loss: 19.2158 - Test Loss: 46.6860 - MSE: 46.6860 - MAE: 5.6058\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1577/20000 - Train Loss: 19.2145 - Test Loss: 46.6831 - MSE: 46.6831 - MAE: 5.6056\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1578/20000 - Train Loss: 19.2132 - Test Loss: 46.6803 - MSE: 46.6803 - MAE: 5.6054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1579/20000 - Train Loss: 19.2119 - Test Loss: 46.6775 - MSE: 46.6774 - MAE: 5.6053\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1580/20000 - Train Loss: 19.2106 - Test Loss: 46.6746 - MSE: 46.6746 - MAE: 5.6051\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1581/20000 - Train Loss: 19.2094 - Test Loss: 46.6717 - MSE: 46.6717 - MAE: 5.6049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1582/20000 - Train Loss: 19.2081 - Test Loss: 46.6689 - MSE: 46.6689 - MAE: 5.6047\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1583/20000 - Train Loss: 19.2068 - Test Loss: 46.6661 - MSE: 46.6661 - MAE: 5.6045\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1584/20000 - Train Loss: 19.2055 - Test Loss: 46.6632 - MSE: 46.6632 - MAE: 5.6043\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1585/20000 - Train Loss: 19.2042 - Test Loss: 46.6604 - MSE: 46.6604 - MAE: 5.6042\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1586/20000 - Train Loss: 19.2029 - Test Loss: 46.6576 - MSE: 46.6576 - MAE: 5.6040\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1587/20000 - Train Loss: 19.2016 - Test Loss: 46.6548 - MSE: 46.6548 - MAE: 5.6038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1588/20000 - Train Loss: 19.2003 - Test Loss: 46.6519 - MSE: 46.6519 - MAE: 5.6036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1589/20000 - Train Loss: 19.1990 - Test Loss: 46.6490 - MSE: 46.6490 - MAE: 5.6034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1590/20000 - Train Loss: 19.1977 - Test Loss: 46.6461 - MSE: 46.6461 - MAE: 5.6032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1591/20000 - Train Loss: 19.1964 - Test Loss: 46.6433 - MSE: 46.6433 - MAE: 5.6031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1592/20000 - Train Loss: 19.1951 - Test Loss: 46.6404 - MSE: 46.6404 - MAE: 5.6029\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1593/20000 - Train Loss: 19.1938 - Test Loss: 46.6375 - MSE: 46.6375 - MAE: 5.6027\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 1594/20000 - Train Loss: 19.1925 - Test Loss: 46.6346 - MSE: 46.6346 - MAE: 5.6025\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1595/20000 - Train Loss: 19.1912 - Test Loss: 46.6318 - MSE: 46.6318 - MAE: 5.6023\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1596/20000 - Train Loss: 19.1899 - Test Loss: 46.6289 - MSE: 46.6289 - MAE: 5.6021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1597/20000 - Train Loss: 19.1886 - Test Loss: 46.6261 - MSE: 46.6261 - MAE: 5.6019\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1598/20000 - Train Loss: 19.1873 - Test Loss: 46.6231 - MSE: 46.6231 - MAE: 5.6018\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1599/20000 - Train Loss: 19.1859 - Test Loss: 46.6203 - MSE: 46.6203 - MAE: 5.6016\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1600/20000 - Train Loss: 19.1846 - Test Loss: 46.6174 - MSE: 46.6174 - MAE: 5.6014\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1601/20000 - Train Loss: 19.1833 - Test Loss: 46.6145 - MSE: 46.6145 - MAE: 5.6012\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1602/20000 - Train Loss: 19.1820 - Test Loss: 46.6116 - MSE: 46.6116 - MAE: 5.6010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1603/20000 - Train Loss: 19.1807 - Test Loss: 46.6088 - MSE: 46.6088 - MAE: 5.6008\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1604/20000 - Train Loss: 19.1794 - Test Loss: 46.6059 - MSE: 46.6059 - MAE: 5.6007\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1605/20000 - Train Loss: 19.1781 - Test Loss: 46.6029 - MSE: 46.6029 - MAE: 5.6005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1606/20000 - Train Loss: 19.1768 - Test Loss: 46.6001 - MSE: 46.6001 - MAE: 5.6003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1607/20000 - Train Loss: 19.1755 - Test Loss: 46.5972 - MSE: 46.5972 - MAE: 5.6001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1608/20000 - Train Loss: 19.1742 - Test Loss: 46.5943 - MSE: 46.5943 - MAE: 5.5999\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1609/20000 - Train Loss: 19.1728 - Test Loss: 46.5914 - MSE: 46.5914 - MAE: 5.5997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1610/20000 - Train Loss: 19.1715 - Test Loss: 46.5885 - MSE: 46.5885 - MAE: 5.5995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1611/20000 - Train Loss: 19.1702 - Test Loss: 46.5856 - MSE: 46.5856 - MAE: 5.5993\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1612/20000 - Train Loss: 19.1689 - Test Loss: 46.5827 - MSE: 46.5827 - MAE: 5.5992\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1613/20000 - Train Loss: 19.1676 - Test Loss: 46.5797 - MSE: 46.5797 - MAE: 5.5990\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1614/20000 - Train Loss: 19.1663 - Test Loss: 46.5768 - MSE: 46.5768 - MAE: 5.5988\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1615/20000 - Train Loss: 19.1649 - Test Loss: 46.5740 - MSE: 46.5740 - MAE: 5.5986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1616/20000 - Train Loss: 19.1636 - Test Loss: 46.5711 - MSE: 46.5711 - MAE: 5.5984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1617/20000 - Train Loss: 19.1623 - Test Loss: 46.5682 - MSE: 46.5682 - MAE: 5.5982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1618/20000 - Train Loss: 19.1610 - Test Loss: 46.5652 - MSE: 46.5652 - MAE: 5.5980\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1619/20000 - Train Loss: 19.1597 - Test Loss: 46.5623 - MSE: 46.5623 - MAE: 5.5978\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1620/20000 - Train Loss: 19.1583 - Test Loss: 46.5593 - MSE: 46.5593 - MAE: 5.5977\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1621/20000 - Train Loss: 19.1570 - Test Loss: 46.5564 - MSE: 46.5564 - MAE: 5.5975\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1622/20000 - Train Loss: 19.1557 - Test Loss: 46.5535 - MSE: 46.5535 - MAE: 5.5973\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1623/20000 - Train Loss: 19.1544 - Test Loss: 46.5506 - MSE: 46.5506 - MAE: 5.5971\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1624/20000 - Train Loss: 19.1530 - Test Loss: 46.5477 - MSE: 46.5477 - MAE: 5.5969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1625/20000 - Train Loss: 19.1517 - Test Loss: 46.5448 - MSE: 46.5448 - MAE: 5.5967\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1626/20000 - Train Loss: 19.1504 - Test Loss: 46.5419 - MSE: 46.5419 - MAE: 5.5965\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1627/20000 - Train Loss: 19.1491 - Test Loss: 46.5391 - MSE: 46.5391 - MAE: 5.5964\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1628/20000 - Train Loss: 19.1477 - Test Loss: 46.5361 - MSE: 46.5361 - MAE: 5.5962\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1629/20000 - Train Loss: 19.1464 - Test Loss: 46.5331 - MSE: 46.5331 - MAE: 5.5960\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1630/20000 - Train Loss: 19.1451 - Test Loss: 46.5302 - MSE: 46.5302 - MAE: 5.5958\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1631/20000 - Train Loss: 19.1438 - Test Loss: 46.5273 - MSE: 46.5273 - MAE: 5.5956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1632/20000 - Train Loss: 19.1424 - Test Loss: 46.5243 - MSE: 46.5243 - MAE: 5.5954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1633/20000 - Train Loss: 19.1411 - Test Loss: 46.5214 - MSE: 46.5214 - MAE: 5.5952\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1634/20000 - Train Loss: 19.1398 - Test Loss: 46.5185 - MSE: 46.5185 - MAE: 5.5950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1635/20000 - Train Loss: 19.1384 - Test Loss: 46.5156 - MSE: 46.5156 - MAE: 5.5948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1636/20000 - Train Loss: 19.1371 - Test Loss: 46.5127 - MSE: 46.5126 - MAE: 5.5947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1637/20000 - Train Loss: 19.1358 - Test Loss: 46.5098 - MSE: 46.5098 - MAE: 5.5945\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1638/20000 - Train Loss: 19.1344 - Test Loss: 46.5068 - MSE: 46.5068 - MAE: 5.5943\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1639/20000 - Train Loss: 19.1331 - Test Loss: 46.5039 - MSE: 46.5038 - MAE: 5.5941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1640/20000 - Train Loss: 19.1318 - Test Loss: 46.5009 - MSE: 46.5009 - MAE: 5.5939\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1641/20000 - Train Loss: 19.1304 - Test Loss: 46.4980 - MSE: 46.4980 - MAE: 5.5937\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1642/20000 - Train Loss: 19.1291 - Test Loss: 46.4950 - MSE: 46.4950 - MAE: 5.5935\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 1643/20000 - Train Loss: 19.1277 - Test Loss: 46.4920 - MSE: 46.4920 - MAE: 5.5933\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1644/20000 - Train Loss: 19.1264 - Test Loss: 46.4891 - MSE: 46.4891 - MAE: 5.5931\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1645/20000 - Train Loss: 19.1251 - Test Loss: 46.4861 - MSE: 46.4861 - MAE: 5.5929\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1646/20000 - Train Loss: 19.1237 - Test Loss: 46.4832 - MSE: 46.4832 - MAE: 5.5928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1647/20000 - Train Loss: 19.1224 - Test Loss: 46.4803 - MSE: 46.4803 - MAE: 5.5926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1648/20000 - Train Loss: 19.1210 - Test Loss: 46.4773 - MSE: 46.4773 - MAE: 5.5924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1649/20000 - Train Loss: 19.1197 - Test Loss: 46.4743 - MSE: 46.4743 - MAE: 5.5922\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1650/20000 - Train Loss: 19.1184 - Test Loss: 46.4714 - MSE: 46.4714 - MAE: 5.5920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1651/20000 - Train Loss: 19.1170 - Test Loss: 46.4684 - MSE: 46.4684 - MAE: 5.5918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1652/20000 - Train Loss: 19.1157 - Test Loss: 46.4654 - MSE: 46.4654 - MAE: 5.5916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1653/20000 - Train Loss: 19.1143 - Test Loss: 46.4625 - MSE: 46.4625 - MAE: 5.5914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1654/20000 - Train Loss: 19.1130 - Test Loss: 46.4595 - MSE: 46.4595 - MAE: 5.5912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1655/20000 - Train Loss: 19.1116 - Test Loss: 46.4565 - MSE: 46.4565 - MAE: 5.5910\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1656/20000 - Train Loss: 19.1103 - Test Loss: 46.4536 - MSE: 46.4536 - MAE: 5.5908\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1657/20000 - Train Loss: 19.1089 - Test Loss: 46.4506 - MSE: 46.4506 - MAE: 5.5907\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1658/20000 - Train Loss: 19.1076 - Test Loss: 46.4476 - MSE: 46.4476 - MAE: 5.5905\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 1659/20000 - Train Loss: 19.1062 - Test Loss: 46.4446 - MSE: 46.4446 - MAE: 5.5903\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1660/20000 - Train Loss: 19.1049 - Test Loss: 46.4416 - MSE: 46.4416 - MAE: 5.5901\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1661/20000 - Train Loss: 19.1035 - Test Loss: 46.4386 - MSE: 46.4386 - MAE: 5.5899\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1662/20000 - Train Loss: 19.1022 - Test Loss: 46.4356 - MSE: 46.4356 - MAE: 5.5897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1663/20000 - Train Loss: 19.1008 - Test Loss: 46.4326 - MSE: 46.4326 - MAE: 5.5895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1664/20000 - Train Loss: 19.0995 - Test Loss: 46.4297 - MSE: 46.4297 - MAE: 5.5893\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1665/20000 - Train Loss: 19.0981 - Test Loss: 46.4267 - MSE: 46.4267 - MAE: 5.5891\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1666/20000 - Train Loss: 19.0968 - Test Loss: 46.4238 - MSE: 46.4238 - MAE: 5.5889\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1667/20000 - Train Loss: 19.0954 - Test Loss: 46.4208 - MSE: 46.4208 - MAE: 5.5887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1668/20000 - Train Loss: 19.0940 - Test Loss: 46.4178 - MSE: 46.4178 - MAE: 5.5885\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1669/20000 - Train Loss: 19.0927 - Test Loss: 46.4147 - MSE: 46.4147 - MAE: 5.5883\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1670/20000 - Train Loss: 19.0913 - Test Loss: 46.4117 - MSE: 46.4117 - MAE: 5.5881\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1671/20000 - Train Loss: 19.0900 - Test Loss: 46.4087 - MSE: 46.4087 - MAE: 5.5880\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1672/20000 - Train Loss: 19.0886 - Test Loss: 46.4058 - MSE: 46.4058 - MAE: 5.5878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1673/20000 - Train Loss: 19.0873 - Test Loss: 46.4028 - MSE: 46.4028 - MAE: 5.5876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1674/20000 - Train Loss: 19.0859 - Test Loss: 46.3998 - MSE: 46.3998 - MAE: 5.5874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1675/20000 - Train Loss: 19.0845 - Test Loss: 46.3968 - MSE: 46.3968 - MAE: 5.5872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1676/20000 - Train Loss: 19.0832 - Test Loss: 46.3938 - MSE: 46.3938 - MAE: 5.5870\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1677/20000 - Train Loss: 19.0818 - Test Loss: 46.3909 - MSE: 46.3909 - MAE: 5.5868\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 1678/20000 - Train Loss: 19.0804 - Test Loss: 46.3878 - MSE: 46.3878 - MAE: 5.5866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1679/20000 - Train Loss: 19.0791 - Test Loss: 46.3848 - MSE: 46.3848 - MAE: 5.5864\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1680/20000 - Train Loss: 19.0777 - Test Loss: 46.3818 - MSE: 46.3818 - MAE: 5.5862\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1681/20000 - Train Loss: 19.0763 - Test Loss: 46.3788 - MSE: 46.3788 - MAE: 5.5860\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1682/20000 - Train Loss: 19.0750 - Test Loss: 46.3758 - MSE: 46.3758 - MAE: 5.5858\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1683/20000 - Train Loss: 19.0736 - Test Loss: 46.3728 - MSE: 46.3728 - MAE: 5.5856\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1684/20000 - Train Loss: 19.0722 - Test Loss: 46.3698 - MSE: 46.3698 - MAE: 5.5854\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1685/20000 - Train Loss: 19.0709 - Test Loss: 46.3667 - MSE: 46.3667 - MAE: 5.5852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1686/20000 - Train Loss: 19.0695 - Test Loss: 46.3638 - MSE: 46.3638 - MAE: 5.5851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1687/20000 - Train Loss: 19.0681 - Test Loss: 46.3608 - MSE: 46.3608 - MAE: 5.5849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1688/20000 - Train Loss: 19.0668 - Test Loss: 46.3578 - MSE: 46.3578 - MAE: 5.5847\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1689/20000 - Train Loss: 19.0654 - Test Loss: 46.3547 - MSE: 46.3547 - MAE: 5.5845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1690/20000 - Train Loss: 19.0640 - Test Loss: 46.3517 - MSE: 46.3517 - MAE: 5.5843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1691/20000 - Train Loss: 19.0627 - Test Loss: 46.3486 - MSE: 46.3486 - MAE: 5.5841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1692/20000 - Train Loss: 19.0613 - Test Loss: 46.3456 - MSE: 46.3456 - MAE: 5.5839\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1693/20000 - Train Loss: 19.0599 - Test Loss: 46.3425 - MSE: 46.3425 - MAE: 5.5837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1694/20000 - Train Loss: 19.0585 - Test Loss: 46.3396 - MSE: 46.3396 - MAE: 5.5835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1695/20000 - Train Loss: 19.0571 - Test Loss: 46.3365 - MSE: 46.3365 - MAE: 5.5833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1696/20000 - Train Loss: 19.0558 - Test Loss: 46.3335 - MSE: 46.3334 - MAE: 5.5831\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 1697/20000 - Train Loss: 19.0544 - Test Loss: 46.3304 - MSE: 46.3304 - MAE: 5.5829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1698/20000 - Train Loss: 19.0530 - Test Loss: 46.3274 - MSE: 46.3274 - MAE: 5.5827\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 1699/20000 - Train Loss: 19.0516 - Test Loss: 46.3243 - MSE: 46.3243 - MAE: 5.5825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1700/20000 - Train Loss: 19.0502 - Test Loss: 46.3212 - MSE: 46.3212 - MAE: 5.5823\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1701/20000 - Train Loss: 19.0489 - Test Loss: 46.3182 - MSE: 46.3182 - MAE: 5.5821\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1702/20000 - Train Loss: 19.0475 - Test Loss: 46.3151 - MSE: 46.3151 - MAE: 5.5819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1703/20000 - Train Loss: 19.0461 - Test Loss: 46.3121 - MSE: 46.3121 - MAE: 5.5817\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1704/20000 - Train Loss: 19.0447 - Test Loss: 46.3090 - MSE: 46.3090 - MAE: 5.5815\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 1705/20000 - Train Loss: 19.0433 - Test Loss: 46.3060 - MSE: 46.3060 - MAE: 5.5813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1706/20000 - Train Loss: 19.0420 - Test Loss: 46.3030 - MSE: 46.3030 - MAE: 5.5811\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1707/20000 - Train Loss: 19.0406 - Test Loss: 46.2999 - MSE: 46.2999 - MAE: 5.5809\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1708/20000 - Train Loss: 19.0392 - Test Loss: 46.2968 - MSE: 46.2968 - MAE: 5.5807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1709/20000 - Train Loss: 19.0378 - Test Loss: 46.2938 - MSE: 46.2938 - MAE: 5.5805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1710/20000 - Train Loss: 19.0364 - Test Loss: 46.2908 - MSE: 46.2908 - MAE: 5.5803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1711/20000 - Train Loss: 19.0350 - Test Loss: 46.2877 - MSE: 46.2877 - MAE: 5.5801\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1712/20000 - Train Loss: 19.0336 - Test Loss: 46.2847 - MSE: 46.2847 - MAE: 5.5799\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1713/20000 - Train Loss: 19.0322 - Test Loss: 46.2817 - MSE: 46.2817 - MAE: 5.5797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1714/20000 - Train Loss: 19.0309 - Test Loss: 46.2786 - MSE: 46.2786 - MAE: 5.5795\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 1715/20000 - Train Loss: 19.0295 - Test Loss: 46.2756 - MSE: 46.2756 - MAE: 5.5794\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1716/20000 - Train Loss: 19.0281 - Test Loss: 46.2725 - MSE: 46.2725 - MAE: 5.5792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1717/20000 - Train Loss: 19.0267 - Test Loss: 46.2694 - MSE: 46.2694 - MAE: 5.5790\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1718/20000 - Train Loss: 19.0253 - Test Loss: 46.2663 - MSE: 46.2663 - MAE: 5.5788\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 1719/20000 - Train Loss: 19.0239 - Test Loss: 46.2633 - MSE: 46.2633 - MAE: 5.5786\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1720/20000 - Train Loss: 19.0225 - Test Loss: 46.2602 - MSE: 46.2602 - MAE: 5.5784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1721/20000 - Train Loss: 19.0211 - Test Loss: 46.2571 - MSE: 46.2571 - MAE: 5.5782\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1722/20000 - Train Loss: 19.0197 - Test Loss: 46.2541 - MSE: 46.2541 - MAE: 5.5780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1723/20000 - Train Loss: 19.0183 - Test Loss: 46.2509 - MSE: 46.2509 - MAE: 5.5778\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1724/20000 - Train Loss: 19.0169 - Test Loss: 46.2479 - MSE: 46.2479 - MAE: 5.5776\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1725/20000 - Train Loss: 19.0155 - Test Loss: 46.2448 - MSE: 46.2448 - MAE: 5.5774\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 1726/20000 - Train Loss: 19.0141 - Test Loss: 46.2418 - MSE: 46.2418 - MAE: 5.5772\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1727/20000 - Train Loss: 19.0127 - Test Loss: 46.2386 - MSE: 46.2386 - MAE: 5.5770\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1728/20000 - Train Loss: 19.0113 - Test Loss: 46.2355 - MSE: 46.2355 - MAE: 5.5768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1729/20000 - Train Loss: 19.0099 - Test Loss: 46.2324 - MSE: 46.2324 - MAE: 5.5766\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 1730/20000 - Train Loss: 19.0085 - Test Loss: 46.2294 - MSE: 46.2294 - MAE: 5.5764\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1731/20000 - Train Loss: 19.0071 - Test Loss: 46.2263 - MSE: 46.2263 - MAE: 5.5762\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1732/20000 - Train Loss: 19.0057 - Test Loss: 46.2232 - MSE: 46.2232 - MAE: 5.5760\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1733/20000 - Train Loss: 19.0043 - Test Loss: 46.2201 - MSE: 46.2201 - MAE: 5.5758\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1734/20000 - Train Loss: 19.0029 - Test Loss: 46.2170 - MSE: 46.2170 - MAE: 5.5756\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1735/20000 - Train Loss: 19.0015 - Test Loss: 46.2139 - MSE: 46.2139 - MAE: 5.5754\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1736/20000 - Train Loss: 19.0001 - Test Loss: 46.2108 - MSE: 46.2108 - MAE: 5.5752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1737/20000 - Train Loss: 18.9987 - Test Loss: 46.2077 - MSE: 46.2077 - MAE: 5.5750\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1738/20000 - Train Loss: 18.9973 - Test Loss: 46.2046 - MSE: 46.2046 - MAE: 5.5748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1739/20000 - Train Loss: 18.9958 - Test Loss: 46.2015 - MSE: 46.2015 - MAE: 5.5746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1740/20000 - Train Loss: 18.9944 - Test Loss: 46.1983 - MSE: 46.1983 - MAE: 5.5744\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1741/20000 - Train Loss: 18.9930 - Test Loss: 46.1952 - MSE: 46.1952 - MAE: 5.5742\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 1742/20000 - Train Loss: 18.9916 - Test Loss: 46.1921 - MSE: 46.1921 - MAE: 5.5740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1743/20000 - Train Loss: 18.9902 - Test Loss: 46.1890 - MSE: 46.1890 - MAE: 5.5738\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1744/20000 - Train Loss: 18.9888 - Test Loss: 46.1859 - MSE: 46.1859 - MAE: 5.5736\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1745/20000 - Train Loss: 18.9874 - Test Loss: 46.1828 - MSE: 46.1828 - MAE: 5.5734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1746/20000 - Train Loss: 18.9860 - Test Loss: 46.1797 - MSE: 46.1797 - MAE: 5.5732\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1747/20000 - Train Loss: 18.9845 - Test Loss: 46.1765 - MSE: 46.1765 - MAE: 5.5730\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1748/20000 - Train Loss: 18.9831 - Test Loss: 46.1734 - MSE: 46.1734 - MAE: 5.5727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1749/20000 - Train Loss: 18.9817 - Test Loss: 46.1703 - MSE: 46.1703 - MAE: 5.5725\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1750/20000 - Train Loss: 18.9803 - Test Loss: 46.1672 - MSE: 46.1672 - MAE: 5.5723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1751/20000 - Train Loss: 18.9789 - Test Loss: 46.1641 - MSE: 46.1641 - MAE: 5.5721\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1752/20000 - Train Loss: 18.9775 - Test Loss: 46.1610 - MSE: 46.1610 - MAE: 5.5719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1753/20000 - Train Loss: 18.9760 - Test Loss: 46.1578 - MSE: 46.1578 - MAE: 5.5717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1754/20000 - Train Loss: 18.9746 - Test Loss: 46.1547 - MSE: 46.1547 - MAE: 5.5715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1755/20000 - Train Loss: 18.9732 - Test Loss: 46.1516 - MSE: 46.1516 - MAE: 5.5713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1756/20000 - Train Loss: 18.9718 - Test Loss: 46.1485 - MSE: 46.1485 - MAE: 5.5711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1757/20000 - Train Loss: 18.9704 - Test Loss: 46.1454 - MSE: 46.1454 - MAE: 5.5709\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1758/20000 - Train Loss: 18.9689 - Test Loss: 46.1422 - MSE: 46.1422 - MAE: 5.5707\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1759/20000 - Train Loss: 18.9675 - Test Loss: 46.1391 - MSE: 46.1391 - MAE: 5.5705\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1760/20000 - Train Loss: 18.9661 - Test Loss: 46.1360 - MSE: 46.1359 - MAE: 5.5703\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1761/20000 - Train Loss: 18.9647 - Test Loss: 46.1328 - MSE: 46.1328 - MAE: 5.5701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1762/20000 - Train Loss: 18.9632 - Test Loss: 46.1297 - MSE: 46.1297 - MAE: 5.5699\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1763/20000 - Train Loss: 18.9618 - Test Loss: 46.1266 - MSE: 46.1266 - MAE: 5.5697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1764/20000 - Train Loss: 18.9604 - Test Loss: 46.1234 - MSE: 46.1234 - MAE: 5.5695\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1765/20000 - Train Loss: 18.9590 - Test Loss: 46.1203 - MSE: 46.1203 - MAE: 5.5693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1766/20000 - Train Loss: 18.9575 - Test Loss: 46.1172 - MSE: 46.1172 - MAE: 5.5691\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1767/20000 - Train Loss: 18.9561 - Test Loss: 46.1140 - MSE: 46.1140 - MAE: 5.5689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1768/20000 - Train Loss: 18.9547 - Test Loss: 46.1108 - MSE: 46.1108 - MAE: 5.5687\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1769/20000 - Train Loss: 18.9532 - Test Loss: 46.1077 - MSE: 46.1077 - MAE: 5.5685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1770/20000 - Train Loss: 18.9518 - Test Loss: 46.1044 - MSE: 46.1044 - MAE: 5.5683\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1771/20000 - Train Loss: 18.9504 - Test Loss: 46.1013 - MSE: 46.1013 - MAE: 5.5681\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1772/20000 - Train Loss: 18.9489 - Test Loss: 46.0981 - MSE: 46.0981 - MAE: 5.5679\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1773/20000 - Train Loss: 18.9475 - Test Loss: 46.0950 - MSE: 46.0950 - MAE: 5.5677\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1774/20000 - Train Loss: 18.9461 - Test Loss: 46.0919 - MSE: 46.0919 - MAE: 5.5675\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1775/20000 - Train Loss: 18.9446 - Test Loss: 46.0888 - MSE: 46.0888 - MAE: 5.5673\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1776/20000 - Train Loss: 18.9432 - Test Loss: 46.0855 - MSE: 46.0855 - MAE: 5.5671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1777/20000 - Train Loss: 18.9418 - Test Loss: 46.0823 - MSE: 46.0823 - MAE: 5.5668\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1778/20000 - Train Loss: 18.9403 - Test Loss: 46.0791 - MSE: 46.0791 - MAE: 5.5666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1779/20000 - Train Loss: 18.9389 - Test Loss: 46.0759 - MSE: 46.0759 - MAE: 5.5664\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1780/20000 - Train Loss: 18.9374 - Test Loss: 46.0727 - MSE: 46.0727 - MAE: 5.5662\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1781/20000 - Train Loss: 18.9360 - Test Loss: 46.0696 - MSE: 46.0696 - MAE: 5.5660\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1782/20000 - Train Loss: 18.9346 - Test Loss: 46.0664 - MSE: 46.0664 - MAE: 5.5658\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1783/20000 - Train Loss: 18.9331 - Test Loss: 46.0633 - MSE: 46.0633 - MAE: 5.5656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1784/20000 - Train Loss: 18.9317 - Test Loss: 46.0601 - MSE: 46.0601 - MAE: 5.5654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1785/20000 - Train Loss: 18.9302 - Test Loss: 46.0569 - MSE: 46.0569 - MAE: 5.5652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1786/20000 - Train Loss: 18.9288 - Test Loss: 46.0537 - MSE: 46.0537 - MAE: 5.5650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1787/20000 - Train Loss: 18.9273 - Test Loss: 46.0505 - MSE: 46.0505 - MAE: 5.5648\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1788/20000 - Train Loss: 18.9259 - Test Loss: 46.0474 - MSE: 46.0474 - MAE: 5.5646\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1789/20000 - Train Loss: 18.9244 - Test Loss: 46.0442 - MSE: 46.0442 - MAE: 5.5644\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1790/20000 - Train Loss: 18.9230 - Test Loss: 46.0410 - MSE: 46.0410 - MAE: 5.5642\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1791/20000 - Train Loss: 18.9216 - Test Loss: 46.0378 - MSE: 46.0378 - MAE: 5.5640\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1792/20000 - Train Loss: 18.9201 - Test Loss: 46.0347 - MSE: 46.0347 - MAE: 5.5638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1793/20000 - Train Loss: 18.9187 - Test Loss: 46.0315 - MSE: 46.0315 - MAE: 5.5636\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1794/20000 - Train Loss: 18.9172 - Test Loss: 46.0284 - MSE: 46.0284 - MAE: 5.5634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1795/20000 - Train Loss: 18.9158 - Test Loss: 46.0251 - MSE: 46.0251 - MAE: 5.5631\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1796/20000 - Train Loss: 18.9143 - Test Loss: 46.0219 - MSE: 46.0219 - MAE: 5.5629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1797/20000 - Train Loss: 18.9129 - Test Loss: 46.0187 - MSE: 46.0187 - MAE: 5.5627\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 1798/20000 - Train Loss: 18.9114 - Test Loss: 46.0155 - MSE: 46.0155 - MAE: 5.5625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1799/20000 - Train Loss: 18.9099 - Test Loss: 46.0123 - MSE: 46.0123 - MAE: 5.5623\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1800/20000 - Train Loss: 18.9085 - Test Loss: 46.0090 - MSE: 46.0091 - MAE: 5.5621\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1801/20000 - Train Loss: 18.9070 - Test Loss: 46.0059 - MSE: 46.0059 - MAE: 5.5619\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 1802/20000 - Train Loss: 18.9056 - Test Loss: 46.0027 - MSE: 46.0027 - MAE: 5.5617\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1803/20000 - Train Loss: 18.9041 - Test Loss: 45.9994 - MSE: 45.9994 - MAE: 5.5615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1804/20000 - Train Loss: 18.9027 - Test Loss: 45.9963 - MSE: 45.9963 - MAE: 5.5613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1805/20000 - Train Loss: 18.9012 - Test Loss: 45.9931 - MSE: 45.9931 - MAE: 5.5611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1806/20000 - Train Loss: 18.8998 - Test Loss: 45.9898 - MSE: 45.9898 - MAE: 5.5609\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1807/20000 - Train Loss: 18.8983 - Test Loss: 45.9866 - MSE: 45.9866 - MAE: 5.5606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1808/20000 - Train Loss: 18.8968 - Test Loss: 45.9833 - MSE: 45.9833 - MAE: 5.5604\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1809/20000 - Train Loss: 18.8954 - Test Loss: 45.9802 - MSE: 45.9802 - MAE: 5.5602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1810/20000 - Train Loss: 18.8939 - Test Loss: 45.9770 - MSE: 45.9770 - MAE: 5.5600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1811/20000 - Train Loss: 18.8924 - Test Loss: 45.9737 - MSE: 45.9737 - MAE: 5.5598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1812/20000 - Train Loss: 18.8910 - Test Loss: 45.9705 - MSE: 45.9705 - MAE: 5.5596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1813/20000 - Train Loss: 18.8895 - Test Loss: 45.9673 - MSE: 45.9673 - MAE: 5.5594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1814/20000 - Train Loss: 18.8881 - Test Loss: 45.9641 - MSE: 45.9641 - MAE: 5.5592\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1815/20000 - Train Loss: 18.8866 - Test Loss: 45.9608 - MSE: 45.9608 - MAE: 5.5590\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1816/20000 - Train Loss: 18.8851 - Test Loss: 45.9576 - MSE: 45.9576 - MAE: 5.5588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1817/20000 - Train Loss: 18.8837 - Test Loss: 45.9544 - MSE: 45.9544 - MAE: 5.5586\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1818/20000 - Train Loss: 18.8822 - Test Loss: 45.9511 - MSE: 45.9511 - MAE: 5.5583\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1819/20000 - Train Loss: 18.8807 - Test Loss: 45.9479 - MSE: 45.9479 - MAE: 5.5581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1820/20000 - Train Loss: 18.8792 - Test Loss: 45.9447 - MSE: 45.9447 - MAE: 5.5579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1821/20000 - Train Loss: 18.8778 - Test Loss: 45.9414 - MSE: 45.9414 - MAE: 5.5577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1822/20000 - Train Loss: 18.8763 - Test Loss: 45.9382 - MSE: 45.9382 - MAE: 5.5575\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1823/20000 - Train Loss: 18.8748 - Test Loss: 45.9349 - MSE: 45.9349 - MAE: 5.5573\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1824/20000 - Train Loss: 18.8734 - Test Loss: 45.9316 - MSE: 45.9316 - MAE: 5.5571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1825/20000 - Train Loss: 18.8719 - Test Loss: 45.9283 - MSE: 45.9283 - MAE: 5.5569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1826/20000 - Train Loss: 18.8704 - Test Loss: 45.9252 - MSE: 45.9252 - MAE: 5.5567\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1827/20000 - Train Loss: 18.8689 - Test Loss: 45.9220 - MSE: 45.9220 - MAE: 5.5565\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1828/20000 - Train Loss: 18.8675 - Test Loss: 45.9187 - MSE: 45.9187 - MAE: 5.5562\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1829/20000 - Train Loss: 18.8660 - Test Loss: 45.9155 - MSE: 45.9155 - MAE: 5.5560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1830/20000 - Train Loss: 18.8645 - Test Loss: 45.9123 - MSE: 45.9123 - MAE: 5.5558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1831/20000 - Train Loss: 18.8630 - Test Loss: 45.9090 - MSE: 45.9090 - MAE: 5.5556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1832/20000 - Train Loss: 18.8616 - Test Loss: 45.9058 - MSE: 45.9057 - MAE: 5.5554\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 1833/20000 - Train Loss: 18.8601 - Test Loss: 45.9024 - MSE: 45.9025 - MAE: 5.5552\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1834/20000 - Train Loss: 18.8586 - Test Loss: 45.8992 - MSE: 45.8992 - MAE: 5.5550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1835/20000 - Train Loss: 18.8571 - Test Loss: 45.8960 - MSE: 45.8960 - MAE: 5.5548\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1836/20000 - Train Loss: 18.8556 - Test Loss: 45.8927 - MSE: 45.8927 - MAE: 5.5546\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1837/20000 - Train Loss: 18.8541 - Test Loss: 45.8894 - MSE: 45.8895 - MAE: 5.5543\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1838/20000 - Train Loss: 18.8527 - Test Loss: 45.8862 - MSE: 45.8862 - MAE: 5.5541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1839/20000 - Train Loss: 18.8512 - Test Loss: 45.8829 - MSE: 45.8829 - MAE: 5.5539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1840/20000 - Train Loss: 18.8497 - Test Loss: 45.8797 - MSE: 45.8797 - MAE: 5.5537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1841/20000 - Train Loss: 18.8482 - Test Loss: 45.8764 - MSE: 45.8764 - MAE: 5.5535\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1842/20000 - Train Loss: 18.8467 - Test Loss: 45.8732 - MSE: 45.8732 - MAE: 5.5533\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1843/20000 - Train Loss: 18.8452 - Test Loss: 45.8699 - MSE: 45.8699 - MAE: 5.5531\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1844/20000 - Train Loss: 18.8438 - Test Loss: 45.8665 - MSE: 45.8665 - MAE: 5.5528\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1845/20000 - Train Loss: 18.8423 - Test Loss: 45.8632 - MSE: 45.8632 - MAE: 5.5526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1846/20000 - Train Loss: 18.8408 - Test Loss: 45.8600 - MSE: 45.8599 - MAE: 5.5524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1847/20000 - Train Loss: 18.8393 - Test Loss: 45.8567 - MSE: 45.8567 - MAE: 5.5522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1848/20000 - Train Loss: 18.8378 - Test Loss: 45.8534 - MSE: 45.8534 - MAE: 5.5520\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1849/20000 - Train Loss: 18.8363 - Test Loss: 45.8502 - MSE: 45.8502 - MAE: 5.5518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1850/20000 - Train Loss: 18.8348 - Test Loss: 45.8469 - MSE: 45.8469 - MAE: 5.5516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1851/20000 - Train Loss: 18.8333 - Test Loss: 45.8436 - MSE: 45.8436 - MAE: 5.5514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1852/20000 - Train Loss: 18.8318 - Test Loss: 45.8403 - MSE: 45.8403 - MAE: 5.5511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1853/20000 - Train Loss: 18.8303 - Test Loss: 45.8370 - MSE: 45.8370 - MAE: 5.5509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1854/20000 - Train Loss: 18.8288 - Test Loss: 45.8337 - MSE: 45.8337 - MAE: 5.5507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1855/20000 - Train Loss: 18.8273 - Test Loss: 45.8304 - MSE: 45.8304 - MAE: 5.5505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1856/20000 - Train Loss: 18.8258 - Test Loss: 45.8270 - MSE: 45.8270 - MAE: 5.5503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1857/20000 - Train Loss: 18.8243 - Test Loss: 45.8237 - MSE: 45.8237 - MAE: 5.5501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1858/20000 - Train Loss: 18.8228 - Test Loss: 45.8205 - MSE: 45.8205 - MAE: 5.5499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1859/20000 - Train Loss: 18.8213 - Test Loss: 45.8171 - MSE: 45.8171 - MAE: 5.5496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1860/20000 - Train Loss: 18.8198 - Test Loss: 45.8138 - MSE: 45.8138 - MAE: 5.5494\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 1861/20000 - Train Loss: 18.8183 - Test Loss: 45.8105 - MSE: 45.8105 - MAE: 5.5492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1862/20000 - Train Loss: 18.8168 - Test Loss: 45.8072 - MSE: 45.8072 - MAE: 5.5490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1863/20000 - Train Loss: 18.8153 - Test Loss: 45.8039 - MSE: 45.8039 - MAE: 5.5488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1864/20000 - Train Loss: 18.8138 - Test Loss: 45.8005 - MSE: 45.8005 - MAE: 5.5486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1865/20000 - Train Loss: 18.8123 - Test Loss: 45.7973 - MSE: 45.7973 - MAE: 5.5483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1866/20000 - Train Loss: 18.8108 - Test Loss: 45.7940 - MSE: 45.7940 - MAE: 5.5481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1867/20000 - Train Loss: 18.8093 - Test Loss: 45.7907 - MSE: 45.7907 - MAE: 5.5479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1868/20000 - Train Loss: 18.8078 - Test Loss: 45.7874 - MSE: 45.7874 - MAE: 5.5477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1869/20000 - Train Loss: 18.8063 - Test Loss: 45.7841 - MSE: 45.7841 - MAE: 5.5475\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1870/20000 - Train Loss: 18.8048 - Test Loss: 45.7807 - MSE: 45.7807 - MAE: 5.5473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1871/20000 - Train Loss: 18.8033 - Test Loss: 45.7774 - MSE: 45.7774 - MAE: 5.5471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1872/20000 - Train Loss: 18.8018 - Test Loss: 45.7742 - MSE: 45.7742 - MAE: 5.5468\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 1873/20000 - Train Loss: 18.8003 - Test Loss: 45.7708 - MSE: 45.7708 - MAE: 5.5466\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1874/20000 - Train Loss: 18.7988 - Test Loss: 45.7675 - MSE: 45.7675 - MAE: 5.5464\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1875/20000 - Train Loss: 18.7973 - Test Loss: 45.7642 - MSE: 45.7642 - MAE: 5.5462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1876/20000 - Train Loss: 18.7957 - Test Loss: 45.7608 - MSE: 45.7608 - MAE: 5.5460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1877/20000 - Train Loss: 18.7942 - Test Loss: 45.7575 - MSE: 45.7575 - MAE: 5.5458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1878/20000 - Train Loss: 18.7927 - Test Loss: 45.7543 - MSE: 45.7543 - MAE: 5.5455\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1879/20000 - Train Loss: 18.7912 - Test Loss: 45.7509 - MSE: 45.7509 - MAE: 5.5453\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1880/20000 - Train Loss: 18.7897 - Test Loss: 45.7475 - MSE: 45.7475 - MAE: 5.5451\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1881/20000 - Train Loss: 18.7882 - Test Loss: 45.7442 - MSE: 45.7442 - MAE: 5.5449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1882/20000 - Train Loss: 18.7867 - Test Loss: 45.7408 - MSE: 45.7408 - MAE: 5.5447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1883/20000 - Train Loss: 18.7851 - Test Loss: 45.7374 - MSE: 45.7374 - MAE: 5.5445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1884/20000 - Train Loss: 18.7836 - Test Loss: 45.7341 - MSE: 45.7341 - MAE: 5.5442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1885/20000 - Train Loss: 18.7821 - Test Loss: 45.7308 - MSE: 45.7308 - MAE: 5.5440\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1886/20000 - Train Loss: 18.7806 - Test Loss: 45.7275 - MSE: 45.7275 - MAE: 5.5438\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1887/20000 - Train Loss: 18.7791 - Test Loss: 45.7241 - MSE: 45.7241 - MAE: 5.5436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1888/20000 - Train Loss: 18.7775 - Test Loss: 45.7208 - MSE: 45.7208 - MAE: 5.5434\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1889/20000 - Train Loss: 18.7760 - Test Loss: 45.7174 - MSE: 45.7174 - MAE: 5.5431\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1890/20000 - Train Loss: 18.7745 - Test Loss: 45.7141 - MSE: 45.7141 - MAE: 5.5429\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 1891/20000 - Train Loss: 18.7730 - Test Loss: 45.7107 - MSE: 45.7107 - MAE: 5.5427\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1892/20000 - Train Loss: 18.7714 - Test Loss: 45.7073 - MSE: 45.7073 - MAE: 5.5425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1893/20000 - Train Loss: 18.7699 - Test Loss: 45.7039 - MSE: 45.7039 - MAE: 5.5423\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1894/20000 - Train Loss: 18.7684 - Test Loss: 45.7006 - MSE: 45.7006 - MAE: 5.5420\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 1895/20000 - Train Loss: 18.7669 - Test Loss: 45.6972 - MSE: 45.6972 - MAE: 5.5418\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 1896/20000 - Train Loss: 18.7653 - Test Loss: 45.6938 - MSE: 45.6938 - MAE: 5.5416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1897/20000 - Train Loss: 18.7638 - Test Loss: 45.6905 - MSE: 45.6905 - MAE: 5.5414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1898/20000 - Train Loss: 18.7623 - Test Loss: 45.6871 - MSE: 45.6871 - MAE: 5.5412\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 1899/20000 - Train Loss: 18.7608 - Test Loss: 45.6837 - MSE: 45.6837 - MAE: 5.5410\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1900/20000 - Train Loss: 18.7592 - Test Loss: 45.6804 - MSE: 45.6804 - MAE: 5.5407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1901/20000 - Train Loss: 18.7577 - Test Loss: 45.6770 - MSE: 45.6770 - MAE: 5.5405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1902/20000 - Train Loss: 18.7562 - Test Loss: 45.6737 - MSE: 45.6737 - MAE: 5.5403\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1903/20000 - Train Loss: 18.7546 - Test Loss: 45.6703 - MSE: 45.6703 - MAE: 5.5401\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1904/20000 - Train Loss: 18.7531 - Test Loss: 45.6669 - MSE: 45.6670 - MAE: 5.5399\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1905/20000 - Train Loss: 18.7516 - Test Loss: 45.6636 - MSE: 45.6636 - MAE: 5.5396\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1906/20000 - Train Loss: 18.7500 - Test Loss: 45.6602 - MSE: 45.6602 - MAE: 5.5394\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1907/20000 - Train Loss: 18.7485 - Test Loss: 45.6567 - MSE: 45.6567 - MAE: 5.5392\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1908/20000 - Train Loss: 18.7470 - Test Loss: 45.6534 - MSE: 45.6534 - MAE: 5.5390\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1909/20000 - Train Loss: 18.7454 - Test Loss: 45.6500 - MSE: 45.6500 - MAE: 5.5388\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 1910/20000 - Train Loss: 18.7439 - Test Loss: 45.6466 - MSE: 45.6466 - MAE: 5.5385\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1911/20000 - Train Loss: 18.7423 - Test Loss: 45.6432 - MSE: 45.6432 - MAE: 5.5383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1912/20000 - Train Loss: 18.7408 - Test Loss: 45.6398 - MSE: 45.6398 - MAE: 5.5381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1913/20000 - Train Loss: 18.7393 - Test Loss: 45.6364 - MSE: 45.6364 - MAE: 5.5379\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1914/20000 - Train Loss: 18.7377 - Test Loss: 45.6331 - MSE: 45.6331 - MAE: 5.5377\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1915/20000 - Train Loss: 18.7362 - Test Loss: 45.6297 - MSE: 45.6297 - MAE: 5.5374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1916/20000 - Train Loss: 18.7346 - Test Loss: 45.6263 - MSE: 45.6263 - MAE: 5.5372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1917/20000 - Train Loss: 18.7331 - Test Loss: 45.6230 - MSE: 45.6230 - MAE: 5.5370\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1918/20000 - Train Loss: 18.7316 - Test Loss: 45.6195 - MSE: 45.6195 - MAE: 5.5368\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 1919/20000 - Train Loss: 18.7300 - Test Loss: 45.6161 - MSE: 45.6161 - MAE: 5.5365\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1920/20000 - Train Loss: 18.7284 - Test Loss: 45.6127 - MSE: 45.6127 - MAE: 5.5363\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1921/20000 - Train Loss: 18.7269 - Test Loss: 45.6092 - MSE: 45.6092 - MAE: 5.5361\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1922/20000 - Train Loss: 18.7254 - Test Loss: 45.6059 - MSE: 45.6059 - MAE: 5.5359\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1923/20000 - Train Loss: 18.7238 - Test Loss: 45.6025 - MSE: 45.6024 - MAE: 5.5357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1924/20000 - Train Loss: 18.7223 - Test Loss: 45.5991 - MSE: 45.5991 - MAE: 5.5354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1925/20000 - Train Loss: 18.7207 - Test Loss: 45.5957 - MSE: 45.5957 - MAE: 5.5352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1926/20000 - Train Loss: 18.7192 - Test Loss: 45.5923 - MSE: 45.5923 - MAE: 5.5350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1927/20000 - Train Loss: 18.7176 - Test Loss: 45.5888 - MSE: 45.5888 - MAE: 5.5348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1928/20000 - Train Loss: 18.7161 - Test Loss: 45.5854 - MSE: 45.5854 - MAE: 5.5345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1929/20000 - Train Loss: 18.7145 - Test Loss: 45.5819 - MSE: 45.5819 - MAE: 5.5343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1930/20000 - Train Loss: 18.7130 - Test Loss: 45.5785 - MSE: 45.5785 - MAE: 5.5341\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1931/20000 - Train Loss: 18.7114 - Test Loss: 45.5751 - MSE: 45.5751 - MAE: 5.5339\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1932/20000 - Train Loss: 18.7099 - Test Loss: 45.5717 - MSE: 45.5717 - MAE: 5.5336\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1933/20000 - Train Loss: 18.7083 - Test Loss: 45.5683 - MSE: 45.5683 - MAE: 5.5334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1934/20000 - Train Loss: 18.7067 - Test Loss: 45.5648 - MSE: 45.5648 - MAE: 5.5332\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1935/20000 - Train Loss: 18.7052 - Test Loss: 45.5614 - MSE: 45.5614 - MAE: 5.5330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1936/20000 - Train Loss: 18.7036 - Test Loss: 45.5580 - MSE: 45.5580 - MAE: 5.5328\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 1937/20000 - Train Loss: 18.7021 - Test Loss: 45.5545 - MSE: 45.5545 - MAE: 5.5325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1938/20000 - Train Loss: 18.7005 - Test Loss: 45.5511 - MSE: 45.5511 - MAE: 5.5323\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1939/20000 - Train Loss: 18.6990 - Test Loss: 45.5477 - MSE: 45.5477 - MAE: 5.5321\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1940/20000 - Train Loss: 18.6974 - Test Loss: 45.5443 - MSE: 45.5443 - MAE: 5.5319\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1941/20000 - Train Loss: 18.6958 - Test Loss: 45.5408 - MSE: 45.5408 - MAE: 5.5316\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1942/20000 - Train Loss: 18.6943 - Test Loss: 45.5374 - MSE: 45.5374 - MAE: 5.5314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1943/20000 - Train Loss: 18.6927 - Test Loss: 45.5340 - MSE: 45.5340 - MAE: 5.5312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1944/20000 - Train Loss: 18.6911 - Test Loss: 45.5305 - MSE: 45.5305 - MAE: 5.5310\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1945/20000 - Train Loss: 18.6896 - Test Loss: 45.5270 - MSE: 45.5271 - MAE: 5.5307\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1946/20000 - Train Loss: 18.6880 - Test Loss: 45.5235 - MSE: 45.5235 - MAE: 5.5305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1947/20000 - Train Loss: 18.6864 - Test Loss: 45.5201 - MSE: 45.5201 - MAE: 5.5303\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1948/20000 - Train Loss: 18.6849 - Test Loss: 45.5167 - MSE: 45.5167 - MAE: 5.5301\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1949/20000 - Train Loss: 18.6833 - Test Loss: 45.5132 - MSE: 45.5132 - MAE: 5.5298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1950/20000 - Train Loss: 18.6817 - Test Loss: 45.5098 - MSE: 45.5098 - MAE: 5.5296\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1951/20000 - Train Loss: 18.6802 - Test Loss: 45.5064 - MSE: 45.5064 - MAE: 5.5294\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1952/20000 - Train Loss: 18.6786 - Test Loss: 45.5030 - MSE: 45.5030 - MAE: 5.5292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1953/20000 - Train Loss: 18.6770 - Test Loss: 45.4995 - MSE: 45.4995 - MAE: 5.5289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1954/20000 - Train Loss: 18.6755 - Test Loss: 45.4961 - MSE: 45.4961 - MAE: 5.5287\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 1955/20000 - Train Loss: 18.6739 - Test Loss: 45.4926 - MSE: 45.4926 - MAE: 5.5285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1956/20000 - Train Loss: 18.6723 - Test Loss: 45.4891 - MSE: 45.4891 - MAE: 5.5283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1957/20000 - Train Loss: 18.6707 - Test Loss: 45.4856 - MSE: 45.4856 - MAE: 5.5280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1958/20000 - Train Loss: 18.6692 - Test Loss: 45.4822 - MSE: 45.4822 - MAE: 5.5278\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1959/20000 - Train Loss: 18.6676 - Test Loss: 45.4787 - MSE: 45.4787 - MAE: 5.5276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1960/20000 - Train Loss: 18.6660 - Test Loss: 45.4753 - MSE: 45.4752 - MAE: 5.5273\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1961/20000 - Train Loss: 18.6644 - Test Loss: 45.4717 - MSE: 45.4717 - MAE: 5.5271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1962/20000 - Train Loss: 18.6628 - Test Loss: 45.4682 - MSE: 45.4682 - MAE: 5.5269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1963/20000 - Train Loss: 18.6613 - Test Loss: 45.4648 - MSE: 45.4648 - MAE: 5.5267\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1964/20000 - Train Loss: 18.6597 - Test Loss: 45.4613 - MSE: 45.4613 - MAE: 5.5264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1965/20000 - Train Loss: 18.6581 - Test Loss: 45.4578 - MSE: 45.4578 - MAE: 5.5262\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 1966/20000 - Train Loss: 18.6565 - Test Loss: 45.4543 - MSE: 45.4543 - MAE: 5.5260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1967/20000 - Train Loss: 18.6549 - Test Loss: 45.4508 - MSE: 45.4508 - MAE: 5.5258\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 1968/20000 - Train Loss: 18.6534 - Test Loss: 45.4473 - MSE: 45.4473 - MAE: 5.5255\n",
      "2/2 [==============================] - 0s 984us/step\n",
      "Epoch 1969/20000 - Train Loss: 18.6518 - Test Loss: 45.4439 - MSE: 45.4439 - MAE: 5.5253\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1970/20000 - Train Loss: 18.6502 - Test Loss: 45.4404 - MSE: 45.4404 - MAE: 5.5251\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 1971/20000 - Train Loss: 18.6486 - Test Loss: 45.4369 - MSE: 45.4369 - MAE: 5.5248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1972/20000 - Train Loss: 18.6470 - Test Loss: 45.4333 - MSE: 45.4333 - MAE: 5.5246\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1973/20000 - Train Loss: 18.6454 - Test Loss: 45.4299 - MSE: 45.4299 - MAE: 5.5244\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 1974/20000 - Train Loss: 18.6439 - Test Loss: 45.4264 - MSE: 45.4264 - MAE: 5.5242\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1975/20000 - Train Loss: 18.6423 - Test Loss: 45.4229 - MSE: 45.4229 - MAE: 5.5239\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 1976/20000 - Train Loss: 18.6407 - Test Loss: 45.4194 - MSE: 45.4194 - MAE: 5.5237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1977/20000 - Train Loss: 18.6391 - Test Loss: 45.4159 - MSE: 45.4159 - MAE: 5.5235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1978/20000 - Train Loss: 18.6375 - Test Loss: 45.4124 - MSE: 45.4124 - MAE: 5.5232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1979/20000 - Train Loss: 18.6359 - Test Loss: 45.4089 - MSE: 45.4089 - MAE: 5.5230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1980/20000 - Train Loss: 18.6343 - Test Loss: 45.4054 - MSE: 45.4054 - MAE: 5.5228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1981/20000 - Train Loss: 18.6327 - Test Loss: 45.4019 - MSE: 45.4019 - MAE: 5.5226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1982/20000 - Train Loss: 18.6311 - Test Loss: 45.3984 - MSE: 45.3983 - MAE: 5.5223\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 1983/20000 - Train Loss: 18.6295 - Test Loss: 45.3949 - MSE: 45.3949 - MAE: 5.5221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1984/20000 - Train Loss: 18.6279 - Test Loss: 45.3913 - MSE: 45.3913 - MAE: 5.5219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1985/20000 - Train Loss: 18.6263 - Test Loss: 45.3879 - MSE: 45.3879 - MAE: 5.5216\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 1986/20000 - Train Loss: 18.6247 - Test Loss: 45.3844 - MSE: 45.3844 - MAE: 5.5214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1987/20000 - Train Loss: 18.6231 - Test Loss: 45.3808 - MSE: 45.3808 - MAE: 5.5212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1988/20000 - Train Loss: 18.6215 - Test Loss: 45.3774 - MSE: 45.3774 - MAE: 5.5209\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1989/20000 - Train Loss: 18.6199 - Test Loss: 45.3739 - MSE: 45.3739 - MAE: 5.5207\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 1990/20000 - Train Loss: 18.6184 - Test Loss: 45.3703 - MSE: 45.3703 - MAE: 5.5205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1991/20000 - Train Loss: 18.6168 - Test Loss: 45.3668 - MSE: 45.3668 - MAE: 5.5203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1992/20000 - Train Loss: 18.6151 - Test Loss: 45.3632 - MSE: 45.3632 - MAE: 5.5200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1993/20000 - Train Loss: 18.6136 - Test Loss: 45.3597 - MSE: 45.3597 - MAE: 5.5198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1994/20000 - Train Loss: 18.6119 - Test Loss: 45.3562 - MSE: 45.3562 - MAE: 5.5196\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 1995/20000 - Train Loss: 18.6103 - Test Loss: 45.3527 - MSE: 45.3527 - MAE: 5.5193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1996/20000 - Train Loss: 18.6087 - Test Loss: 45.3492 - MSE: 45.3492 - MAE: 5.5191\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1997/20000 - Train Loss: 18.6071 - Test Loss: 45.3456 - MSE: 45.3456 - MAE: 5.5189\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 1998/20000 - Train Loss: 18.6055 - Test Loss: 45.3420 - MSE: 45.3420 - MAE: 5.5186\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 1999/20000 - Train Loss: 18.6039 - Test Loss: 45.3385 - MSE: 45.3385 - MAE: 5.5184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2000/20000 - Train Loss: 18.6023 - Test Loss: 45.3350 - MSE: 45.3350 - MAE: 5.5182\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2001/20000 - Train Loss: 18.6007 - Test Loss: 45.3314 - MSE: 45.3314 - MAE: 5.5179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2002/20000 - Train Loss: 18.5991 - Test Loss: 45.3279 - MSE: 45.3279 - MAE: 5.5177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2003/20000 - Train Loss: 18.5975 - Test Loss: 45.3244 - MSE: 45.3244 - MAE: 5.5175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2004/20000 - Train Loss: 18.5959 - Test Loss: 45.3209 - MSE: 45.3209 - MAE: 5.5172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2005/20000 - Train Loss: 18.5943 - Test Loss: 45.3173 - MSE: 45.3173 - MAE: 5.5170\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2006/20000 - Train Loss: 18.5926 - Test Loss: 45.3137 - MSE: 45.3137 - MAE: 5.5168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2007/20000 - Train Loss: 18.5910 - Test Loss: 45.3101 - MSE: 45.3101 - MAE: 5.5165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2008/20000 - Train Loss: 18.5894 - Test Loss: 45.3066 - MSE: 45.3066 - MAE: 5.5163\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2009/20000 - Train Loss: 18.5878 - Test Loss: 45.3030 - MSE: 45.3030 - MAE: 5.5161\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2010/20000 - Train Loss: 18.5862 - Test Loss: 45.2994 - MSE: 45.2994 - MAE: 5.5158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2011/20000 - Train Loss: 18.5846 - Test Loss: 45.2959 - MSE: 45.2959 - MAE: 5.5156\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2012/20000 - Train Loss: 18.5830 - Test Loss: 45.2924 - MSE: 45.2924 - MAE: 5.5154\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2013/20000 - Train Loss: 18.5813 - Test Loss: 45.2888 - MSE: 45.2888 - MAE: 5.5151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2014/20000 - Train Loss: 18.5797 - Test Loss: 45.2852 - MSE: 45.2852 - MAE: 5.5149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2015/20000 - Train Loss: 18.5781 - Test Loss: 45.2817 - MSE: 45.2817 - MAE: 5.5147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2016/20000 - Train Loss: 18.5765 - Test Loss: 45.2782 - MSE: 45.2782 - MAE: 5.5145\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 2017/20000 - Train Loss: 18.5749 - Test Loss: 45.2746 - MSE: 45.2746 - MAE: 5.5142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2018/20000 - Train Loss: 18.5732 - Test Loss: 45.2710 - MSE: 45.2710 - MAE: 5.5140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2019/20000 - Train Loss: 18.5716 - Test Loss: 45.2676 - MSE: 45.2676 - MAE: 5.5138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2020/20000 - Train Loss: 18.5700 - Test Loss: 45.2639 - MSE: 45.2639 - MAE: 5.5135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2021/20000 - Train Loss: 18.5684 - Test Loss: 45.2603 - MSE: 45.2603 - MAE: 5.5133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2022/20000 - Train Loss: 18.5667 - Test Loss: 45.2568 - MSE: 45.2568 - MAE: 5.5130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2023/20000 - Train Loss: 18.5651 - Test Loss: 45.2533 - MSE: 45.2533 - MAE: 5.5128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2024/20000 - Train Loss: 18.5635 - Test Loss: 45.2496 - MSE: 45.2496 - MAE: 5.5126\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2025/20000 - Train Loss: 18.5619 - Test Loss: 45.2460 - MSE: 45.2460 - MAE: 5.5123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2026/20000 - Train Loss: 18.5602 - Test Loss: 45.2424 - MSE: 45.2424 - MAE: 5.5121\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2027/20000 - Train Loss: 18.5586 - Test Loss: 45.2388 - MSE: 45.2388 - MAE: 5.5119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2028/20000 - Train Loss: 18.5570 - Test Loss: 45.2352 - MSE: 45.2352 - MAE: 5.5116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2029/20000 - Train Loss: 18.5554 - Test Loss: 45.2317 - MSE: 45.2317 - MAE: 5.5114\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 2030/20000 - Train Loss: 18.5537 - Test Loss: 45.2280 - MSE: 45.2280 - MAE: 5.5112\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2031/20000 - Train Loss: 18.5521 - Test Loss: 45.2245 - MSE: 45.2245 - MAE: 5.5109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2032/20000 - Train Loss: 18.5505 - Test Loss: 45.2209 - MSE: 45.2209 - MAE: 5.5107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2033/20000 - Train Loss: 18.5488 - Test Loss: 45.2173 - MSE: 45.2173 - MAE: 5.5105\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2034/20000 - Train Loss: 18.5472 - Test Loss: 45.2137 - MSE: 45.2137 - MAE: 5.5102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2035/20000 - Train Loss: 18.5456 - Test Loss: 45.2101 - MSE: 45.2101 - MAE: 5.5100\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2036/20000 - Train Loss: 18.5439 - Test Loss: 45.2064 - MSE: 45.2064 - MAE: 5.5098\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2037/20000 - Train Loss: 18.5423 - Test Loss: 45.2028 - MSE: 45.2028 - MAE: 5.5095\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2038/20000 - Train Loss: 18.5406 - Test Loss: 45.1992 - MSE: 45.1992 - MAE: 5.5093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2039/20000 - Train Loss: 18.5390 - Test Loss: 45.1956 - MSE: 45.1956 - MAE: 5.5090\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2040/20000 - Train Loss: 18.5374 - Test Loss: 45.1920 - MSE: 45.1920 - MAE: 5.5088\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2041/20000 - Train Loss: 18.5357 - Test Loss: 45.1884 - MSE: 45.1884 - MAE: 5.5086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2042/20000 - Train Loss: 18.5341 - Test Loss: 45.1848 - MSE: 45.1848 - MAE: 5.5083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2043/20000 - Train Loss: 18.5324 - Test Loss: 45.1812 - MSE: 45.1812 - MAE: 5.5081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2044/20000 - Train Loss: 18.5308 - Test Loss: 45.1775 - MSE: 45.1775 - MAE: 5.5079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2045/20000 - Train Loss: 18.5292 - Test Loss: 45.1740 - MSE: 45.1740 - MAE: 5.5076\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2046/20000 - Train Loss: 18.5275 - Test Loss: 45.1703 - MSE: 45.1703 - MAE: 5.5074\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2047/20000 - Train Loss: 18.5259 - Test Loss: 45.1667 - MSE: 45.1667 - MAE: 5.5071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2048/20000 - Train Loss: 18.5242 - Test Loss: 45.1631 - MSE: 45.1631 - MAE: 5.5069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2049/20000 - Train Loss: 18.5226 - Test Loss: 45.1595 - MSE: 45.1595 - MAE: 5.5067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2050/20000 - Train Loss: 18.5209 - Test Loss: 45.1559 - MSE: 45.1559 - MAE: 5.5064\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2051/20000 - Train Loss: 18.5193 - Test Loss: 45.1523 - MSE: 45.1523 - MAE: 5.5062\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 2052/20000 - Train Loss: 18.5176 - Test Loss: 45.1486 - MSE: 45.1486 - MAE: 5.5060\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2053/20000 - Train Loss: 18.5160 - Test Loss: 45.1450 - MSE: 45.1450 - MAE: 5.5057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2054/20000 - Train Loss: 18.5143 - Test Loss: 45.1414 - MSE: 45.1414 - MAE: 5.5055\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 2055/20000 - Train Loss: 18.5127 - Test Loss: 45.1377 - MSE: 45.1377 - MAE: 5.5052\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2056/20000 - Train Loss: 18.5110 - Test Loss: 45.1341 - MSE: 45.1341 - MAE: 5.5050\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2057/20000 - Train Loss: 18.5094 - Test Loss: 45.1305 - MSE: 45.1305 - MAE: 5.5048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2058/20000 - Train Loss: 18.5077 - Test Loss: 45.1269 - MSE: 45.1269 - MAE: 5.5045\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2059/20000 - Train Loss: 18.5061 - Test Loss: 45.1232 - MSE: 45.1232 - MAE: 5.5043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2060/20000 - Train Loss: 18.5044 - Test Loss: 45.1196 - MSE: 45.1196 - MAE: 5.5040\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 2061/20000 - Train Loss: 18.5028 - Test Loss: 45.1160 - MSE: 45.1160 - MAE: 5.5038\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 2062/20000 - Train Loss: 18.5011 - Test Loss: 45.1123 - MSE: 45.1123 - MAE: 5.5036\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2063/20000 - Train Loss: 18.4995 - Test Loss: 45.1086 - MSE: 45.1086 - MAE: 5.5033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2064/20000 - Train Loss: 18.4978 - Test Loss: 45.1050 - MSE: 45.1050 - MAE: 5.5031\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2065/20000 - Train Loss: 18.4961 - Test Loss: 45.1014 - MSE: 45.1014 - MAE: 5.5029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2066/20000 - Train Loss: 18.4945 - Test Loss: 45.0977 - MSE: 45.0977 - MAE: 5.5026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2067/20000 - Train Loss: 18.4928 - Test Loss: 45.0941 - MSE: 45.0941 - MAE: 5.5024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2068/20000 - Train Loss: 18.4912 - Test Loss: 45.0904 - MSE: 45.0904 - MAE: 5.5021\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2069/20000 - Train Loss: 18.4895 - Test Loss: 45.0868 - MSE: 45.0868 - MAE: 5.5019\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2070/20000 - Train Loss: 18.4878 - Test Loss: 45.0830 - MSE: 45.0830 - MAE: 5.5017\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2071/20000 - Train Loss: 18.4862 - Test Loss: 45.0794 - MSE: 45.0794 - MAE: 5.5014\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2072/20000 - Train Loss: 18.4845 - Test Loss: 45.0757 - MSE: 45.0757 - MAE: 5.5012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2073/20000 - Train Loss: 18.4828 - Test Loss: 45.0720 - MSE: 45.0720 - MAE: 5.5009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2074/20000 - Train Loss: 18.4812 - Test Loss: 45.0684 - MSE: 45.0684 - MAE: 5.5007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2075/20000 - Train Loss: 18.4795 - Test Loss: 45.0648 - MSE: 45.0648 - MAE: 5.5004\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2076/20000 - Train Loss: 18.4778 - Test Loss: 45.0610 - MSE: 45.0610 - MAE: 5.5002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2077/20000 - Train Loss: 18.4762 - Test Loss: 45.0574 - MSE: 45.0574 - MAE: 5.5000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2078/20000 - Train Loss: 18.4745 - Test Loss: 45.0536 - MSE: 45.0536 - MAE: 5.4997\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2079/20000 - Train Loss: 18.4728 - Test Loss: 45.0500 - MSE: 45.0500 - MAE: 5.4995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2080/20000 - Train Loss: 18.4712 - Test Loss: 45.0462 - MSE: 45.0462 - MAE: 5.4992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2081/20000 - Train Loss: 18.4695 - Test Loss: 45.0426 - MSE: 45.0426 - MAE: 5.4990\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 2082/20000 - Train Loss: 18.4678 - Test Loss: 45.0389 - MSE: 45.0389 - MAE: 5.4988\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2083/20000 - Train Loss: 18.4661 - Test Loss: 45.0353 - MSE: 45.0353 - MAE: 5.4985\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2084/20000 - Train Loss: 18.4645 - Test Loss: 45.0315 - MSE: 45.0315 - MAE: 5.4983\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2085/20000 - Train Loss: 18.4628 - Test Loss: 45.0279 - MSE: 45.0279 - MAE: 5.4980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2086/20000 - Train Loss: 18.4611 - Test Loss: 45.0243 - MSE: 45.0243 - MAE: 5.4978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2087/20000 - Train Loss: 18.4594 - Test Loss: 45.0206 - MSE: 45.0206 - MAE: 5.4975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2088/20000 - Train Loss: 18.4578 - Test Loss: 45.0169 - MSE: 45.0169 - MAE: 5.4973\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2089/20000 - Train Loss: 18.4561 - Test Loss: 45.0132 - MSE: 45.0132 - MAE: 5.4971\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2090/20000 - Train Loss: 18.4544 - Test Loss: 45.0095 - MSE: 45.0095 - MAE: 5.4968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2091/20000 - Train Loss: 18.4527 - Test Loss: 45.0058 - MSE: 45.0058 - MAE: 5.4966\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2092/20000 - Train Loss: 18.4511 - Test Loss: 45.0021 - MSE: 45.0021 - MAE: 5.4963\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2093/20000 - Train Loss: 18.4494 - Test Loss: 44.9985 - MSE: 44.9985 - MAE: 5.4961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2094/20000 - Train Loss: 18.4477 - Test Loss: 44.9948 - MSE: 44.9948 - MAE: 5.4958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2095/20000 - Train Loss: 18.4460 - Test Loss: 44.9911 - MSE: 44.9911 - MAE: 5.4956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2096/20000 - Train Loss: 18.4443 - Test Loss: 44.9874 - MSE: 44.9874 - MAE: 5.4954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2097/20000 - Train Loss: 18.4426 - Test Loss: 44.9837 - MSE: 44.9837 - MAE: 5.4951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2098/20000 - Train Loss: 18.4410 - Test Loss: 44.9800 - MSE: 44.9800 - MAE: 5.4949\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2099/20000 - Train Loss: 18.4393 - Test Loss: 44.9762 - MSE: 44.9762 - MAE: 5.4946\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2100/20000 - Train Loss: 18.4376 - Test Loss: 44.9726 - MSE: 44.9726 - MAE: 5.4944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2101/20000 - Train Loss: 18.4359 - Test Loss: 44.9688 - MSE: 44.9688 - MAE: 5.4941\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2102/20000 - Train Loss: 18.4342 - Test Loss: 44.9652 - MSE: 44.9652 - MAE: 5.4939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2103/20000 - Train Loss: 18.4325 - Test Loss: 44.9614 - MSE: 44.9614 - MAE: 5.4936\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2104/20000 - Train Loss: 18.4308 - Test Loss: 44.9576 - MSE: 44.9576 - MAE: 5.4934\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2105/20000 - Train Loss: 18.4291 - Test Loss: 44.9539 - MSE: 44.9539 - MAE: 5.4932\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2106/20000 - Train Loss: 18.4275 - Test Loss: 44.9501 - MSE: 44.9501 - MAE: 5.4929\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2107/20000 - Train Loss: 18.4258 - Test Loss: 44.9464 - MSE: 44.9464 - MAE: 5.4927\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2108/20000 - Train Loss: 18.4241 - Test Loss: 44.9427 - MSE: 44.9427 - MAE: 5.4924\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2109/20000 - Train Loss: 18.4224 - Test Loss: 44.9390 - MSE: 44.9390 - MAE: 5.4922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2110/20000 - Train Loss: 18.4207 - Test Loss: 44.9353 - MSE: 44.9353 - MAE: 5.4919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2111/20000 - Train Loss: 18.4190 - Test Loss: 44.9316 - MSE: 44.9315 - MAE: 5.4917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2112/20000 - Train Loss: 18.4173 - Test Loss: 44.9278 - MSE: 44.9278 - MAE: 5.4914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2113/20000 - Train Loss: 18.4156 - Test Loss: 44.9241 - MSE: 44.9241 - MAE: 5.4912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2114/20000 - Train Loss: 18.4139 - Test Loss: 44.9203 - MSE: 44.9203 - MAE: 5.4909\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2115/20000 - Train Loss: 18.4122 - Test Loss: 44.9166 - MSE: 44.9166 - MAE: 5.4907\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2116/20000 - Train Loss: 18.4105 - Test Loss: 44.9128 - MSE: 44.9128 - MAE: 5.4905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2117/20000 - Train Loss: 18.4088 - Test Loss: 44.9091 - MSE: 44.9091 - MAE: 5.4902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2118/20000 - Train Loss: 18.4071 - Test Loss: 44.9054 - MSE: 44.9054 - MAE: 5.4900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2119/20000 - Train Loss: 18.4054 - Test Loss: 44.9017 - MSE: 44.9017 - MAE: 5.4897\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 2120/20000 - Train Loss: 18.4037 - Test Loss: 44.8980 - MSE: 44.8980 - MAE: 5.4895\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2121/20000 - Train Loss: 18.4020 - Test Loss: 44.8942 - MSE: 44.8942 - MAE: 5.4892\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2122/20000 - Train Loss: 18.4003 - Test Loss: 44.8904 - MSE: 44.8904 - MAE: 5.4890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2123/20000 - Train Loss: 18.3986 - Test Loss: 44.8867 - MSE: 44.8867 - MAE: 5.4887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2124/20000 - Train Loss: 18.3969 - Test Loss: 44.8830 - MSE: 44.8830 - MAE: 5.4885\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2125/20000 - Train Loss: 18.3952 - Test Loss: 44.8792 - MSE: 44.8792 - MAE: 5.4882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2126/20000 - Train Loss: 18.3935 - Test Loss: 44.8755 - MSE: 44.8755 - MAE: 5.4880\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2127/20000 - Train Loss: 18.3918 - Test Loss: 44.8717 - MSE: 44.8717 - MAE: 5.4877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2128/20000 - Train Loss: 18.3900 - Test Loss: 44.8679 - MSE: 44.8679 - MAE: 5.4875\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2129/20000 - Train Loss: 18.3883 - Test Loss: 44.8642 - MSE: 44.8642 - MAE: 5.4872\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2130/20000 - Train Loss: 18.3866 - Test Loss: 44.8604 - MSE: 44.8604 - MAE: 5.4870\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2131/20000 - Train Loss: 18.3849 - Test Loss: 44.8567 - MSE: 44.8567 - MAE: 5.4867\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2132/20000 - Train Loss: 18.3832 - Test Loss: 44.8529 - MSE: 44.8529 - MAE: 5.4865\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2133/20000 - Train Loss: 18.3815 - Test Loss: 44.8491 - MSE: 44.8491 - MAE: 5.4863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2134/20000 - Train Loss: 18.3798 - Test Loss: 44.8453 - MSE: 44.8453 - MAE: 5.4860\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2135/20000 - Train Loss: 18.3781 - Test Loss: 44.8416 - MSE: 44.8416 - MAE: 5.4858\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2136/20000 - Train Loss: 18.3763 - Test Loss: 44.8378 - MSE: 44.8378 - MAE: 5.4855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2137/20000 - Train Loss: 18.3746 - Test Loss: 44.8341 - MSE: 44.8341 - MAE: 5.4853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2138/20000 - Train Loss: 18.3729 - Test Loss: 44.8302 - MSE: 44.8302 - MAE: 5.4850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2139/20000 - Train Loss: 18.3712 - Test Loss: 44.8265 - MSE: 44.8265 - MAE: 5.4848\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2140/20000 - Train Loss: 18.3695 - Test Loss: 44.8226 - MSE: 44.8226 - MAE: 5.4845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2141/20000 - Train Loss: 18.3678 - Test Loss: 44.8189 - MSE: 44.8188 - MAE: 5.4843\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2142/20000 - Train Loss: 18.3661 - Test Loss: 44.8151 - MSE: 44.8151 - MAE: 5.4840\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2143/20000 - Train Loss: 18.3643 - Test Loss: 44.8113 - MSE: 44.8113 - MAE: 5.4838\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2144/20000 - Train Loss: 18.3626 - Test Loss: 44.8075 - MSE: 44.8075 - MAE: 5.4835\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2145/20000 - Train Loss: 18.3609 - Test Loss: 44.8037 - MSE: 44.8037 - MAE: 5.4833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2146/20000 - Train Loss: 18.3592 - Test Loss: 44.7999 - MSE: 44.7999 - MAE: 5.4830\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2147/20000 - Train Loss: 18.3574 - Test Loss: 44.7961 - MSE: 44.7961 - MAE: 5.4828\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2148/20000 - Train Loss: 18.3557 - Test Loss: 44.7922 - MSE: 44.7922 - MAE: 5.4825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2149/20000 - Train Loss: 18.3540 - Test Loss: 44.7885 - MSE: 44.7885 - MAE: 5.4823\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2150/20000 - Train Loss: 18.3523 - Test Loss: 44.7846 - MSE: 44.7846 - MAE: 5.4820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2151/20000 - Train Loss: 18.3505 - Test Loss: 44.7809 - MSE: 44.7809 - MAE: 5.4818\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2152/20000 - Train Loss: 18.3488 - Test Loss: 44.7771 - MSE: 44.7771 - MAE: 5.4815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2153/20000 - Train Loss: 18.3471 - Test Loss: 44.7733 - MSE: 44.7733 - MAE: 5.4813\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2154/20000 - Train Loss: 18.3453 - Test Loss: 44.7695 - MSE: 44.7695 - MAE: 5.4810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2155/20000 - Train Loss: 18.3436 - Test Loss: 44.7657 - MSE: 44.7657 - MAE: 5.4808\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2156/20000 - Train Loss: 18.3419 - Test Loss: 44.7619 - MSE: 44.7619 - MAE: 5.4805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2157/20000 - Train Loss: 18.3402 - Test Loss: 44.7581 - MSE: 44.7581 - MAE: 5.4803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2158/20000 - Train Loss: 18.3384 - Test Loss: 44.7543 - MSE: 44.7543 - MAE: 5.4800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2159/20000 - Train Loss: 18.3367 - Test Loss: 44.7505 - MSE: 44.7505 - MAE: 5.4797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2160/20000 - Train Loss: 18.3349 - Test Loss: 44.7467 - MSE: 44.7467 - MAE: 5.4795\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2161/20000 - Train Loss: 18.3332 - Test Loss: 44.7429 - MSE: 44.7429 - MAE: 5.4792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2162/20000 - Train Loss: 18.3315 - Test Loss: 44.7391 - MSE: 44.7391 - MAE: 5.4790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2163/20000 - Train Loss: 18.3298 - Test Loss: 44.7353 - MSE: 44.7353 - MAE: 5.4787\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2164/20000 - Train Loss: 18.3280 - Test Loss: 44.7315 - MSE: 44.7315 - MAE: 5.4785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2165/20000 - Train Loss: 18.3263 - Test Loss: 44.7276 - MSE: 44.7276 - MAE: 5.4782\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 2166/20000 - Train Loss: 18.3245 - Test Loss: 44.7238 - MSE: 44.7238 - MAE: 5.4780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2167/20000 - Train Loss: 18.3228 - Test Loss: 44.7200 - MSE: 44.7200 - MAE: 5.4777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2168/20000 - Train Loss: 18.3211 - Test Loss: 44.7162 - MSE: 44.7162 - MAE: 5.4775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2169/20000 - Train Loss: 18.3193 - Test Loss: 44.7123 - MSE: 44.7123 - MAE: 5.4772\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2170/20000 - Train Loss: 18.3176 - Test Loss: 44.7085 - MSE: 44.7085 - MAE: 5.4770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2171/20000 - Train Loss: 18.3158 - Test Loss: 44.7047 - MSE: 44.7047 - MAE: 5.4767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2172/20000 - Train Loss: 18.3141 - Test Loss: 44.7009 - MSE: 44.7009 - MAE: 5.4765\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2173/20000 - Train Loss: 18.3123 - Test Loss: 44.6970 - MSE: 44.6970 - MAE: 5.4762\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2174/20000 - Train Loss: 18.3106 - Test Loss: 44.6931 - MSE: 44.6931 - MAE: 5.4760\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2175/20000 - Train Loss: 18.3089 - Test Loss: 44.6892 - MSE: 44.6892 - MAE: 5.4757\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2176/20000 - Train Loss: 18.3071 - Test Loss: 44.6853 - MSE: 44.6853 - MAE: 5.4754\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2177/20000 - Train Loss: 18.3054 - Test Loss: 44.6815 - MSE: 44.6815 - MAE: 5.4752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2178/20000 - Train Loss: 18.3036 - Test Loss: 44.6777 - MSE: 44.6777 - MAE: 5.4749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2179/20000 - Train Loss: 18.3019 - Test Loss: 44.6738 - MSE: 44.6738 - MAE: 5.4747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2180/20000 - Train Loss: 18.3001 - Test Loss: 44.6699 - MSE: 44.6700 - MAE: 5.4744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2181/20000 - Train Loss: 18.2984 - Test Loss: 44.6661 - MSE: 44.6661 - MAE: 5.4742\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2182/20000 - Train Loss: 18.2966 - Test Loss: 44.6622 - MSE: 44.6622 - MAE: 5.4739\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2183/20000 - Train Loss: 18.2948 - Test Loss: 44.6584 - MSE: 44.6584 - MAE: 5.4737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2184/20000 - Train Loss: 18.2931 - Test Loss: 44.6546 - MSE: 44.6546 - MAE: 5.4734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2185/20000 - Train Loss: 18.2913 - Test Loss: 44.6507 - MSE: 44.6507 - MAE: 5.4732\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2186/20000 - Train Loss: 18.2896 - Test Loss: 44.6469 - MSE: 44.6469 - MAE: 5.4729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2187/20000 - Train Loss: 18.2878 - Test Loss: 44.6430 - MSE: 44.6430 - MAE: 5.4726\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 2188/20000 - Train Loss: 18.2861 - Test Loss: 44.6392 - MSE: 44.6392 - MAE: 5.4724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2189/20000 - Train Loss: 18.2843 - Test Loss: 44.6353 - MSE: 44.6353 - MAE: 5.4721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2190/20000 - Train Loss: 18.2825 - Test Loss: 44.6314 - MSE: 44.6314 - MAE: 5.4719\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2191/20000 - Train Loss: 18.2808 - Test Loss: 44.6275 - MSE: 44.6275 - MAE: 5.4716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2192/20000 - Train Loss: 18.2790 - Test Loss: 44.6237 - MSE: 44.6237 - MAE: 5.4714\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2193/20000 - Train Loss: 18.2773 - Test Loss: 44.6198 - MSE: 44.6198 - MAE: 5.4711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2194/20000 - Train Loss: 18.2755 - Test Loss: 44.6160 - MSE: 44.6160 - MAE: 5.4709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2195/20000 - Train Loss: 18.2738 - Test Loss: 44.6121 - MSE: 44.6121 - MAE: 5.4706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2196/20000 - Train Loss: 18.2720 - Test Loss: 44.6082 - MSE: 44.6082 - MAE: 5.4703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2197/20000 - Train Loss: 18.2702 - Test Loss: 44.6044 - MSE: 44.6044 - MAE: 5.4701\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2198/20000 - Train Loss: 18.2685 - Test Loss: 44.6004 - MSE: 44.6004 - MAE: 5.4698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2199/20000 - Train Loss: 18.2667 - Test Loss: 44.5965 - MSE: 44.5965 - MAE: 5.4696\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2200/20000 - Train Loss: 18.2649 - Test Loss: 44.5927 - MSE: 44.5927 - MAE: 5.4693\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2201/20000 - Train Loss: 18.2632 - Test Loss: 44.5888 - MSE: 44.5888 - MAE: 5.4691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2202/20000 - Train Loss: 18.2614 - Test Loss: 44.5849 - MSE: 44.5849 - MAE: 5.4688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2203/20000 - Train Loss: 18.2596 - Test Loss: 44.5810 - MSE: 44.5810 - MAE: 5.4685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2204/20000 - Train Loss: 18.2579 - Test Loss: 44.5771 - MSE: 44.5771 - MAE: 5.4683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2205/20000 - Train Loss: 18.2561 - Test Loss: 44.5733 - MSE: 44.5733 - MAE: 5.4680\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2206/20000 - Train Loss: 18.2543 - Test Loss: 44.5694 - MSE: 44.5694 - MAE: 5.4678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2207/20000 - Train Loss: 18.2525 - Test Loss: 44.5654 - MSE: 44.5654 - MAE: 5.4675\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2208/20000 - Train Loss: 18.2508 - Test Loss: 44.5615 - MSE: 44.5615 - MAE: 5.4673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2209/20000 - Train Loss: 18.2490 - Test Loss: 44.5576 - MSE: 44.5576 - MAE: 5.4670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2210/20000 - Train Loss: 18.2472 - Test Loss: 44.5537 - MSE: 44.5537 - MAE: 5.4667\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2211/20000 - Train Loss: 18.2454 - Test Loss: 44.5497 - MSE: 44.5497 - MAE: 5.4665\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2212/20000 - Train Loss: 18.2437 - Test Loss: 44.5458 - MSE: 44.5458 - MAE: 5.4662\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 2213/20000 - Train Loss: 18.2419 - Test Loss: 44.5420 - MSE: 44.5420 - MAE: 5.4660\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2214/20000 - Train Loss: 18.2401 - Test Loss: 44.5381 - MSE: 44.5381 - MAE: 5.4657\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2215/20000 - Train Loss: 18.2383 - Test Loss: 44.5341 - MSE: 44.5341 - MAE: 5.4654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2216/20000 - Train Loss: 18.2366 - Test Loss: 44.5302 - MSE: 44.5302 - MAE: 5.4652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2217/20000 - Train Loss: 18.2348 - Test Loss: 44.5262 - MSE: 44.5262 - MAE: 5.4649\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2218/20000 - Train Loss: 18.2330 - Test Loss: 44.5223 - MSE: 44.5223 - MAE: 5.4647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2219/20000 - Train Loss: 18.2312 - Test Loss: 44.5184 - MSE: 44.5184 - MAE: 5.4644\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2220/20000 - Train Loss: 18.2294 - Test Loss: 44.5145 - MSE: 44.5145 - MAE: 5.4641\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2221/20000 - Train Loss: 18.2277 - Test Loss: 44.5106 - MSE: 44.5106 - MAE: 5.4639\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2222/20000 - Train Loss: 18.2259 - Test Loss: 44.5067 - MSE: 44.5067 - MAE: 5.4636\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2223/20000 - Train Loss: 18.2241 - Test Loss: 44.5028 - MSE: 44.5028 - MAE: 5.4634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2224/20000 - Train Loss: 18.2223 - Test Loss: 44.4989 - MSE: 44.4989 - MAE: 5.4631\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2225/20000 - Train Loss: 18.2205 - Test Loss: 44.4950 - MSE: 44.4950 - MAE: 5.4628\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2226/20000 - Train Loss: 18.2187 - Test Loss: 44.4911 - MSE: 44.4911 - MAE: 5.4626\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2227/20000 - Train Loss: 18.2169 - Test Loss: 44.4871 - MSE: 44.4871 - MAE: 5.4623\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2228/20000 - Train Loss: 18.2151 - Test Loss: 44.4832 - MSE: 44.4832 - MAE: 5.4621\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2229/20000 - Train Loss: 18.2134 - Test Loss: 44.4792 - MSE: 44.4792 - MAE: 5.4618\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2230/20000 - Train Loss: 18.2116 - Test Loss: 44.4754 - MSE: 44.4754 - MAE: 5.4615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2231/20000 - Train Loss: 18.2098 - Test Loss: 44.4714 - MSE: 44.4714 - MAE: 5.4613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2232/20000 - Train Loss: 18.2080 - Test Loss: 44.4674 - MSE: 44.4674 - MAE: 5.4610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2233/20000 - Train Loss: 18.2062 - Test Loss: 44.4635 - MSE: 44.4635 - MAE: 5.4608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2234/20000 - Train Loss: 18.2044 - Test Loss: 44.4595 - MSE: 44.4595 - MAE: 5.4605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2235/20000 - Train Loss: 18.2026 - Test Loss: 44.4556 - MSE: 44.4556 - MAE: 5.4602\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2236/20000 - Train Loss: 18.2008 - Test Loss: 44.4516 - MSE: 44.4516 - MAE: 5.4600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2237/20000 - Train Loss: 18.1990 - Test Loss: 44.4477 - MSE: 44.4477 - MAE: 5.4597\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 2238/20000 - Train Loss: 18.1972 - Test Loss: 44.4437 - MSE: 44.4437 - MAE: 5.4595\n",
      "2/2 [==============================] - 0s 982us/step\n",
      "Epoch 2239/20000 - Train Loss: 18.1954 - Test Loss: 44.4397 - MSE: 44.4397 - MAE: 5.4592\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2240/20000 - Train Loss: 18.1936 - Test Loss: 44.4358 - MSE: 44.4358 - MAE: 5.4589\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2241/20000 - Train Loss: 18.1918 - Test Loss: 44.4318 - MSE: 44.4318 - MAE: 5.4587\n",
      "2/2 [==============================] - 0s 975us/step\n",
      "Epoch 2242/20000 - Train Loss: 18.1900 - Test Loss: 44.4278 - MSE: 44.4278 - MAE: 5.4584\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2243/20000 - Train Loss: 18.1882 - Test Loss: 44.4238 - MSE: 44.4238 - MAE: 5.4581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2244/20000 - Train Loss: 18.1864 - Test Loss: 44.4199 - MSE: 44.4199 - MAE: 5.4579\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2245/20000 - Train Loss: 18.1846 - Test Loss: 44.4159 - MSE: 44.4159 - MAE: 5.4576\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2246/20000 - Train Loss: 18.1828 - Test Loss: 44.4119 - MSE: 44.4119 - MAE: 5.4573\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2247/20000 - Train Loss: 18.1810 - Test Loss: 44.4080 - MSE: 44.4080 - MAE: 5.4571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2248/20000 - Train Loss: 18.1792 - Test Loss: 44.4040 - MSE: 44.4040 - MAE: 5.4568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2249/20000 - Train Loss: 18.1774 - Test Loss: 44.4000 - MSE: 44.4000 - MAE: 5.4566\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2250/20000 - Train Loss: 18.1756 - Test Loss: 44.3961 - MSE: 44.3961 - MAE: 5.4563\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2251/20000 - Train Loss: 18.1738 - Test Loss: 44.3921 - MSE: 44.3921 - MAE: 5.4560\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 2252/20000 - Train Loss: 18.1720 - Test Loss: 44.3881 - MSE: 44.3881 - MAE: 5.4558\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2253/20000 - Train Loss: 18.1702 - Test Loss: 44.3842 - MSE: 44.3842 - MAE: 5.4555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2254/20000 - Train Loss: 18.1683 - Test Loss: 44.3802 - MSE: 44.3802 - MAE: 5.4552\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2255/20000 - Train Loss: 18.1665 - Test Loss: 44.3763 - MSE: 44.3763 - MAE: 5.4550\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2256/20000 - Train Loss: 18.1647 - Test Loss: 44.3723 - MSE: 44.3723 - MAE: 5.4547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2257/20000 - Train Loss: 18.1629 - Test Loss: 44.3683 - MSE: 44.3683 - MAE: 5.4544\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2258/20000 - Train Loss: 18.1611 - Test Loss: 44.3643 - MSE: 44.3643 - MAE: 5.4542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2259/20000 - Train Loss: 18.1593 - Test Loss: 44.3603 - MSE: 44.3603 - MAE: 5.4539\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2260/20000 - Train Loss: 18.1575 - Test Loss: 44.3563 - MSE: 44.3563 - MAE: 5.4537\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2261/20000 - Train Loss: 18.1557 - Test Loss: 44.3524 - MSE: 44.3524 - MAE: 5.4534\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2262/20000 - Train Loss: 18.1538 - Test Loss: 44.3483 - MSE: 44.3483 - MAE: 5.4531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2263/20000 - Train Loss: 18.1520 - Test Loss: 44.3443 - MSE: 44.3443 - MAE: 5.4529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2264/20000 - Train Loss: 18.1502 - Test Loss: 44.3403 - MSE: 44.3403 - MAE: 5.4526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2265/20000 - Train Loss: 18.1484 - Test Loss: 44.3363 - MSE: 44.3363 - MAE: 5.4523\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2266/20000 - Train Loss: 18.1466 - Test Loss: 44.3323 - MSE: 44.3323 - MAE: 5.4521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2267/20000 - Train Loss: 18.1447 - Test Loss: 44.3283 - MSE: 44.3283 - MAE: 5.4518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2268/20000 - Train Loss: 18.1429 - Test Loss: 44.3243 - MSE: 44.3243 - MAE: 5.4515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2269/20000 - Train Loss: 18.1411 - Test Loss: 44.3203 - MSE: 44.3203 - MAE: 5.4513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2270/20000 - Train Loss: 18.1393 - Test Loss: 44.3163 - MSE: 44.3163 - MAE: 5.4510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2271/20000 - Train Loss: 18.1374 - Test Loss: 44.3123 - MSE: 44.3123 - MAE: 5.4507\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 2272/20000 - Train Loss: 18.1356 - Test Loss: 44.3083 - MSE: 44.3083 - MAE: 5.4505\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2273/20000 - Train Loss: 18.1338 - Test Loss: 44.3042 - MSE: 44.3042 - MAE: 5.4502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2274/20000 - Train Loss: 18.1320 - Test Loss: 44.3002 - MSE: 44.3002 - MAE: 5.4499\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2275/20000 - Train Loss: 18.1301 - Test Loss: 44.2962 - MSE: 44.2962 - MAE: 5.4497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2276/20000 - Train Loss: 18.1283 - Test Loss: 44.2921 - MSE: 44.2921 - MAE: 5.4494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2277/20000 - Train Loss: 18.1265 - Test Loss: 44.2881 - MSE: 44.2881 - MAE: 5.4491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2278/20000 - Train Loss: 18.1246 - Test Loss: 44.2841 - MSE: 44.2841 - MAE: 5.4489\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2279/20000 - Train Loss: 18.1228 - Test Loss: 44.2801 - MSE: 44.2801 - MAE: 5.4486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2280/20000 - Train Loss: 18.1210 - Test Loss: 44.2761 - MSE: 44.2761 - MAE: 5.4483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2281/20000 - Train Loss: 18.1192 - Test Loss: 44.2720 - MSE: 44.2720 - MAE: 5.4481\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 2282/20000 - Train Loss: 18.1173 - Test Loss: 44.2679 - MSE: 44.2679 - MAE: 5.4478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2283/20000 - Train Loss: 18.1155 - Test Loss: 44.2640 - MSE: 44.2640 - MAE: 5.4475\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2284/20000 - Train Loss: 18.1137 - Test Loss: 44.2599 - MSE: 44.2599 - MAE: 5.4472\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2285/20000 - Train Loss: 18.1118 - Test Loss: 44.2559 - MSE: 44.2559 - MAE: 5.4470\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2286/20000 - Train Loss: 18.1100 - Test Loss: 44.2519 - MSE: 44.2519 - MAE: 5.4467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2287/20000 - Train Loss: 18.1082 - Test Loss: 44.2478 - MSE: 44.2478 - MAE: 5.4464\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2288/20000 - Train Loss: 18.1063 - Test Loss: 44.2439 - MSE: 44.2439 - MAE: 5.4462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2289/20000 - Train Loss: 18.1045 - Test Loss: 44.2398 - MSE: 44.2398 - MAE: 5.4459\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2290/20000 - Train Loss: 18.1026 - Test Loss: 44.2357 - MSE: 44.2357 - MAE: 5.4456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2291/20000 - Train Loss: 18.1008 - Test Loss: 44.2317 - MSE: 44.2317 - MAE: 5.4454\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2292/20000 - Train Loss: 18.0989 - Test Loss: 44.2277 - MSE: 44.2277 - MAE: 5.4451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2293/20000 - Train Loss: 18.0971 - Test Loss: 44.2235 - MSE: 44.2235 - MAE: 5.4448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2294/20000 - Train Loss: 18.0953 - Test Loss: 44.2195 - MSE: 44.2195 - MAE: 5.4446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2295/20000 - Train Loss: 18.0934 - Test Loss: 44.2154 - MSE: 44.2154 - MAE: 5.4443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2296/20000 - Train Loss: 18.0916 - Test Loss: 44.2114 - MSE: 44.2114 - MAE: 5.4440\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2297/20000 - Train Loss: 18.0897 - Test Loss: 44.2074 - MSE: 44.2074 - MAE: 5.4437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2298/20000 - Train Loss: 18.0879 - Test Loss: 44.2033 - MSE: 44.2033 - MAE: 5.4435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2299/20000 - Train Loss: 18.0860 - Test Loss: 44.1992 - MSE: 44.1992 - MAE: 5.4432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2300/20000 - Train Loss: 18.0842 - Test Loss: 44.1952 - MSE: 44.1952 - MAE: 5.4429\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2301/20000 - Train Loss: 18.0823 - Test Loss: 44.1911 - MSE: 44.1911 - MAE: 5.4427\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2302/20000 - Train Loss: 18.0805 - Test Loss: 44.1871 - MSE: 44.1871 - MAE: 5.4424\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2303/20000 - Train Loss: 18.0786 - Test Loss: 44.1830 - MSE: 44.1830 - MAE: 5.4421\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2304/20000 - Train Loss: 18.0768 - Test Loss: 44.1789 - MSE: 44.1789 - MAE: 5.4419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2305/20000 - Train Loss: 18.0749 - Test Loss: 44.1748 - MSE: 44.1748 - MAE: 5.4416\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2306/20000 - Train Loss: 18.0731 - Test Loss: 44.1707 - MSE: 44.1707 - MAE: 5.4413\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2307/20000 - Train Loss: 18.0712 - Test Loss: 44.1666 - MSE: 44.1666 - MAE: 5.4410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2308/20000 - Train Loss: 18.0694 - Test Loss: 44.1625 - MSE: 44.1625 - MAE: 5.4408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2309/20000 - Train Loss: 18.0675 - Test Loss: 44.1584 - MSE: 44.1584 - MAE: 5.4405\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2310/20000 - Train Loss: 18.0657 - Test Loss: 44.1544 - MSE: 44.1544 - MAE: 5.4402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2311/20000 - Train Loss: 18.0638 - Test Loss: 44.1503 - MSE: 44.1503 - MAE: 5.4400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2312/20000 - Train Loss: 18.0619 - Test Loss: 44.1462 - MSE: 44.1462 - MAE: 5.4397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2313/20000 - Train Loss: 18.0601 - Test Loss: 44.1421 - MSE: 44.1421 - MAE: 5.4394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2314/20000 - Train Loss: 18.0582 - Test Loss: 44.1380 - MSE: 44.1380 - MAE: 5.4391\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2315/20000 - Train Loss: 18.0564 - Test Loss: 44.1339 - MSE: 44.1339 - MAE: 5.4389\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2316/20000 - Train Loss: 18.0545 - Test Loss: 44.1298 - MSE: 44.1299 - MAE: 5.4386\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2317/20000 - Train Loss: 18.0526 - Test Loss: 44.1257 - MSE: 44.1257 - MAE: 5.4383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2318/20000 - Train Loss: 18.0508 - Test Loss: 44.1217 - MSE: 44.1217 - MAE: 5.4380\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2319/20000 - Train Loss: 18.0489 - Test Loss: 44.1176 - MSE: 44.1176 - MAE: 5.4378\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2320/20000 - Train Loss: 18.0471 - Test Loss: 44.1135 - MSE: 44.1135 - MAE: 5.4375\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2321/20000 - Train Loss: 18.0452 - Test Loss: 44.1095 - MSE: 44.1095 - MAE: 5.4372\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2322/20000 - Train Loss: 18.0433 - Test Loss: 44.1053 - MSE: 44.1053 - MAE: 5.4370\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 2323/20000 - Train Loss: 18.0415 - Test Loss: 44.1012 - MSE: 44.1012 - MAE: 5.4367\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2324/20000 - Train Loss: 18.0396 - Test Loss: 44.0972 - MSE: 44.0972 - MAE: 5.4364\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2325/20000 - Train Loss: 18.0377 - Test Loss: 44.0930 - MSE: 44.0930 - MAE: 5.4361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2326/20000 - Train Loss: 18.0358 - Test Loss: 44.0889 - MSE: 44.0889 - MAE: 5.4359\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2327/20000 - Train Loss: 18.0340 - Test Loss: 44.0848 - MSE: 44.0848 - MAE: 5.4356\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2328/20000 - Train Loss: 18.0321 - Test Loss: 44.0807 - MSE: 44.0807 - MAE: 5.4353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2329/20000 - Train Loss: 18.0302 - Test Loss: 44.0766 - MSE: 44.0766 - MAE: 5.4350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2330/20000 - Train Loss: 18.0284 - Test Loss: 44.0724 - MSE: 44.0724 - MAE: 5.4348\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2331/20000 - Train Loss: 18.0265 - Test Loss: 44.0683 - MSE: 44.0683 - MAE: 5.4345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2332/20000 - Train Loss: 18.0246 - Test Loss: 44.0642 - MSE: 44.0642 - MAE: 5.4342\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2333/20000 - Train Loss: 18.0227 - Test Loss: 44.0600 - MSE: 44.0600 - MAE: 5.4339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2334/20000 - Train Loss: 18.0209 - Test Loss: 44.0559 - MSE: 44.0559 - MAE: 5.4337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2335/20000 - Train Loss: 18.0190 - Test Loss: 44.0518 - MSE: 44.0518 - MAE: 5.4334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2336/20000 - Train Loss: 18.0171 - Test Loss: 44.0477 - MSE: 44.0477 - MAE: 5.4331\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2337/20000 - Train Loss: 18.0152 - Test Loss: 44.0435 - MSE: 44.0435 - MAE: 5.4328\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2338/20000 - Train Loss: 18.0133 - Test Loss: 44.0394 - MSE: 44.0394 - MAE: 5.4326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2339/20000 - Train Loss: 18.0115 - Test Loss: 44.0353 - MSE: 44.0353 - MAE: 5.4323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2340/20000 - Train Loss: 18.0096 - Test Loss: 44.0311 - MSE: 44.0311 - MAE: 5.4320\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2341/20000 - Train Loss: 18.0077 - Test Loss: 44.0269 - MSE: 44.0269 - MAE: 5.4317\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 2342/20000 - Train Loss: 18.0058 - Test Loss: 44.0228 - MSE: 44.0228 - MAE: 5.4315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2343/20000 - Train Loss: 18.0039 - Test Loss: 44.0187 - MSE: 44.0187 - MAE: 5.4312\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2344/20000 - Train Loss: 18.0021 - Test Loss: 44.0145 - MSE: 44.0145 - MAE: 5.4309\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2345/20000 - Train Loss: 18.0002 - Test Loss: 44.0104 - MSE: 44.0104 - MAE: 5.4306\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2346/20000 - Train Loss: 17.9983 - Test Loss: 44.0063 - MSE: 44.0063 - MAE: 5.4304\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2347/20000 - Train Loss: 17.9964 - Test Loss: 44.0021 - MSE: 44.0021 - MAE: 5.4301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2348/20000 - Train Loss: 17.9945 - Test Loss: 43.9980 - MSE: 43.9980 - MAE: 5.4298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2349/20000 - Train Loss: 17.9926 - Test Loss: 43.9938 - MSE: 43.9938 - MAE: 5.4295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2350/20000 - Train Loss: 17.9907 - Test Loss: 43.9896 - MSE: 43.9896 - MAE: 5.4292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2351/20000 - Train Loss: 17.9888 - Test Loss: 43.9855 - MSE: 43.9855 - MAE: 5.4290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2352/20000 - Train Loss: 17.9870 - Test Loss: 43.9814 - MSE: 43.9814 - MAE: 5.4287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2353/20000 - Train Loss: 17.9851 - Test Loss: 43.9773 - MSE: 43.9773 - MAE: 5.4284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2354/20000 - Train Loss: 17.9832 - Test Loss: 43.9731 - MSE: 43.9731 - MAE: 5.4281\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 2355/20000 - Train Loss: 17.9813 - Test Loss: 43.9689 - MSE: 43.9689 - MAE: 5.4279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2356/20000 - Train Loss: 17.9794 - Test Loss: 43.9648 - MSE: 43.9648 - MAE: 5.4276\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2357/20000 - Train Loss: 17.9775 - Test Loss: 43.9606 - MSE: 43.9606 - MAE: 5.4273\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2358/20000 - Train Loss: 17.9756 - Test Loss: 43.9564 - MSE: 43.9564 - MAE: 5.4270\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 2359/20000 - Train Loss: 17.9737 - Test Loss: 43.9523 - MSE: 43.9523 - MAE: 5.4267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2360/20000 - Train Loss: 17.9718 - Test Loss: 43.9481 - MSE: 43.9481 - MAE: 5.4265\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2361/20000 - Train Loss: 17.9699 - Test Loss: 43.9439 - MSE: 43.9439 - MAE: 5.4262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2362/20000 - Train Loss: 17.9680 - Test Loss: 43.9397 - MSE: 43.9397 - MAE: 5.4259\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 2363/20000 - Train Loss: 17.9661 - Test Loss: 43.9356 - MSE: 43.9356 - MAE: 5.4256\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2364/20000 - Train Loss: 17.9642 - Test Loss: 43.9314 - MSE: 43.9314 - MAE: 5.4253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2365/20000 - Train Loss: 17.9623 - Test Loss: 43.9272 - MSE: 43.9272 - MAE: 5.4251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2366/20000 - Train Loss: 17.9604 - Test Loss: 43.9230 - MSE: 43.9230 - MAE: 5.4248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2367/20000 - Train Loss: 17.9585 - Test Loss: 43.9188 - MSE: 43.9188 - MAE: 5.4245\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2368/20000 - Train Loss: 17.9566 - Test Loss: 43.9146 - MSE: 43.9146 - MAE: 5.4242\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 2369/20000 - Train Loss: 17.9547 - Test Loss: 43.9104 - MSE: 43.9104 - MAE: 5.4239\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2370/20000 - Train Loss: 17.9528 - Test Loss: 43.9062 - MSE: 43.9062 - MAE: 5.4237\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2371/20000 - Train Loss: 17.9509 - Test Loss: 43.9020 - MSE: 43.9020 - MAE: 5.4234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2372/20000 - Train Loss: 17.9490 - Test Loss: 43.8978 - MSE: 43.8978 - MAE: 5.4231\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2373/20000 - Train Loss: 17.9471 - Test Loss: 43.8936 - MSE: 43.8936 - MAE: 5.4228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2374/20000 - Train Loss: 17.9451 - Test Loss: 43.8894 - MSE: 43.8894 - MAE: 5.4225\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2375/20000 - Train Loss: 17.9432 - Test Loss: 43.8851 - MSE: 43.8851 - MAE: 5.4223\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2376/20000 - Train Loss: 17.9413 - Test Loss: 43.8810 - MSE: 43.8810 - MAE: 5.4220\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2377/20000 - Train Loss: 17.9394 - Test Loss: 43.8769 - MSE: 43.8769 - MAE: 5.4217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2378/20000 - Train Loss: 17.9375 - Test Loss: 43.8727 - MSE: 43.8727 - MAE: 5.4214\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2379/20000 - Train Loss: 17.9356 - Test Loss: 43.8684 - MSE: 43.8684 - MAE: 5.4211\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2380/20000 - Train Loss: 17.9337 - Test Loss: 43.8642 - MSE: 43.8642 - MAE: 5.4209\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2381/20000 - Train Loss: 17.9318 - Test Loss: 43.8600 - MSE: 43.8600 - MAE: 5.4206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2382/20000 - Train Loss: 17.9298 - Test Loss: 43.8558 - MSE: 43.8558 - MAE: 5.4203\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2383/20000 - Train Loss: 17.9279 - Test Loss: 43.8517 - MSE: 43.8517 - MAE: 5.4200\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2384/20000 - Train Loss: 17.9260 - Test Loss: 43.8474 - MSE: 43.8474 - MAE: 5.4197\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2385/20000 - Train Loss: 17.9241 - Test Loss: 43.8432 - MSE: 43.8432 - MAE: 5.4195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2386/20000 - Train Loss: 17.9222 - Test Loss: 43.8390 - MSE: 43.8390 - MAE: 5.4192\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2387/20000 - Train Loss: 17.9203 - Test Loss: 43.8348 - MSE: 43.8348 - MAE: 5.4189\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2388/20000 - Train Loss: 17.9183 - Test Loss: 43.8306 - MSE: 43.8306 - MAE: 5.4186\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 2389/20000 - Train Loss: 17.9164 - Test Loss: 43.8263 - MSE: 43.8263 - MAE: 5.4183\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2390/20000 - Train Loss: 17.9145 - Test Loss: 43.8221 - MSE: 43.8221 - MAE: 5.4180\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2391/20000 - Train Loss: 17.9126 - Test Loss: 43.8179 - MSE: 43.8179 - MAE: 5.4178\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2392/20000 - Train Loss: 17.9106 - Test Loss: 43.8137 - MSE: 43.8137 - MAE: 5.4175\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2393/20000 - Train Loss: 17.9087 - Test Loss: 43.8094 - MSE: 43.8094 - MAE: 5.4172\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2394/20000 - Train Loss: 17.9068 - Test Loss: 43.8052 - MSE: 43.8052 - MAE: 5.4169\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2395/20000 - Train Loss: 17.9049 - Test Loss: 43.8009 - MSE: 43.8009 - MAE: 5.4166\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2396/20000 - Train Loss: 17.9029 - Test Loss: 43.7967 - MSE: 43.7967 - MAE: 5.4163\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 2397/20000 - Train Loss: 17.9010 - Test Loss: 43.7924 - MSE: 43.7924 - MAE: 5.4161\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2398/20000 - Train Loss: 17.8991 - Test Loss: 43.7882 - MSE: 43.7882 - MAE: 5.4158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2399/20000 - Train Loss: 17.8971 - Test Loss: 43.7840 - MSE: 43.7840 - MAE: 5.4155\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 2400/20000 - Train Loss: 17.8952 - Test Loss: 43.7797 - MSE: 43.7797 - MAE: 5.4152\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2401/20000 - Train Loss: 17.8933 - Test Loss: 43.7754 - MSE: 43.7754 - MAE: 5.4149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2402/20000 - Train Loss: 17.8913 - Test Loss: 43.7712 - MSE: 43.7712 - MAE: 5.4146\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2403/20000 - Train Loss: 17.8894 - Test Loss: 43.7669 - MSE: 43.7669 - MAE: 5.4143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2404/20000 - Train Loss: 17.8875 - Test Loss: 43.7626 - MSE: 43.7626 - MAE: 5.4141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2405/20000 - Train Loss: 17.8856 - Test Loss: 43.7584 - MSE: 43.7584 - MAE: 5.4138\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2406/20000 - Train Loss: 17.8836 - Test Loss: 43.7542 - MSE: 43.7542 - MAE: 5.4135\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2407/20000 - Train Loss: 17.8817 - Test Loss: 43.7499 - MSE: 43.7499 - MAE: 5.4132\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2408/20000 - Train Loss: 17.8797 - Test Loss: 43.7457 - MSE: 43.7457 - MAE: 5.4129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2409/20000 - Train Loss: 17.8778 - Test Loss: 43.7414 - MSE: 43.7414 - MAE: 5.4126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2410/20000 - Train Loss: 17.8759 - Test Loss: 43.7372 - MSE: 43.7372 - MAE: 5.4124\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2411/20000 - Train Loss: 17.8739 - Test Loss: 43.7329 - MSE: 43.7329 - MAE: 5.4121\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2412/20000 - Train Loss: 17.8720 - Test Loss: 43.7286 - MSE: 43.7286 - MAE: 5.4118\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2413/20000 - Train Loss: 17.8700 - Test Loss: 43.7243 - MSE: 43.7243 - MAE: 5.4115\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2414/20000 - Train Loss: 17.8681 - Test Loss: 43.7202 - MSE: 43.7202 - MAE: 5.4112\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2415/20000 - Train Loss: 17.8661 - Test Loss: 43.7159 - MSE: 43.7159 - MAE: 5.4109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2416/20000 - Train Loss: 17.8642 - Test Loss: 43.7116 - MSE: 43.7116 - MAE: 5.4106\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2417/20000 - Train Loss: 17.8623 - Test Loss: 43.7072 - MSE: 43.7072 - MAE: 5.4104\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2418/20000 - Train Loss: 17.8603 - Test Loss: 43.7031 - MSE: 43.7031 - MAE: 5.4101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2419/20000 - Train Loss: 17.8584 - Test Loss: 43.6987 - MSE: 43.6987 - MAE: 5.4098\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2420/20000 - Train Loss: 17.8564 - Test Loss: 43.6944 - MSE: 43.6944 - MAE: 5.4095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2421/20000 - Train Loss: 17.8545 - Test Loss: 43.6902 - MSE: 43.6902 - MAE: 5.4092\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2422/20000 - Train Loss: 17.8525 - Test Loss: 43.6859 - MSE: 43.6859 - MAE: 5.4089\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2423/20000 - Train Loss: 17.8506 - Test Loss: 43.6816 - MSE: 43.6816 - MAE: 5.4086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2424/20000 - Train Loss: 17.8486 - Test Loss: 43.6773 - MSE: 43.6773 - MAE: 5.4083\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2425/20000 - Train Loss: 17.8467 - Test Loss: 43.6730 - MSE: 43.6730 - MAE: 5.4081\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2426/20000 - Train Loss: 17.8447 - Test Loss: 43.6687 - MSE: 43.6687 - MAE: 5.4078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2427/20000 - Train Loss: 17.8428 - Test Loss: 43.6644 - MSE: 43.6644 - MAE: 5.4075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2428/20000 - Train Loss: 17.8408 - Test Loss: 43.6601 - MSE: 43.6601 - MAE: 5.4072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2429/20000 - Train Loss: 17.8388 - Test Loss: 43.6558 - MSE: 43.6558 - MAE: 5.4069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2430/20000 - Train Loss: 17.8369 - Test Loss: 43.6515 - MSE: 43.6515 - MAE: 5.4066\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2431/20000 - Train Loss: 17.8349 - Test Loss: 43.6472 - MSE: 43.6472 - MAE: 5.4063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2432/20000 - Train Loss: 17.8330 - Test Loss: 43.6429 - MSE: 43.6429 - MAE: 5.4060\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2433/20000 - Train Loss: 17.8310 - Test Loss: 43.6386 - MSE: 43.6386 - MAE: 5.4057\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2434/20000 - Train Loss: 17.8291 - Test Loss: 43.6342 - MSE: 43.6342 - MAE: 5.4055\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2435/20000 - Train Loss: 17.8271 - Test Loss: 43.6299 - MSE: 43.6299 - MAE: 5.4052\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2436/20000 - Train Loss: 17.8251 - Test Loss: 43.6256 - MSE: 43.6256 - MAE: 5.4049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2437/20000 - Train Loss: 17.8232 - Test Loss: 43.6213 - MSE: 43.6213 - MAE: 5.4046\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2438/20000 - Train Loss: 17.8212 - Test Loss: 43.6171 - MSE: 43.6171 - MAE: 5.4043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2439/20000 - Train Loss: 17.8193 - Test Loss: 43.6128 - MSE: 43.6128 - MAE: 5.4040\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2440/20000 - Train Loss: 17.8173 - Test Loss: 43.6084 - MSE: 43.6084 - MAE: 5.4037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2441/20000 - Train Loss: 17.8153 - Test Loss: 43.6041 - MSE: 43.6041 - MAE: 5.4034\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2442/20000 - Train Loss: 17.8134 - Test Loss: 43.5998 - MSE: 43.5998 - MAE: 5.4031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2443/20000 - Train Loss: 17.8114 - Test Loss: 43.5955 - MSE: 43.5955 - MAE: 5.4029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2444/20000 - Train Loss: 17.8094 - Test Loss: 43.5912 - MSE: 43.5912 - MAE: 5.4026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2445/20000 - Train Loss: 17.8075 - Test Loss: 43.5868 - MSE: 43.5868 - MAE: 5.4023\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2446/20000 - Train Loss: 17.8055 - Test Loss: 43.5825 - MSE: 43.5825 - MAE: 5.4020\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2447/20000 - Train Loss: 17.8035 - Test Loss: 43.5782 - MSE: 43.5782 - MAE: 5.4017\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2448/20000 - Train Loss: 17.8015 - Test Loss: 43.5739 - MSE: 43.5739 - MAE: 5.4014\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2449/20000 - Train Loss: 17.7996 - Test Loss: 43.5696 - MSE: 43.5696 - MAE: 5.4011\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2450/20000 - Train Loss: 17.7976 - Test Loss: 43.5652 - MSE: 43.5652 - MAE: 5.4008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2451/20000 - Train Loss: 17.7956 - Test Loss: 43.5608 - MSE: 43.5608 - MAE: 5.4005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2452/20000 - Train Loss: 17.7936 - Test Loss: 43.5565 - MSE: 43.5565 - MAE: 5.4002\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2453/20000 - Train Loss: 17.7917 - Test Loss: 43.5521 - MSE: 43.5521 - MAE: 5.3999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2454/20000 - Train Loss: 17.7897 - Test Loss: 43.5478 - MSE: 43.5478 - MAE: 5.3997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2455/20000 - Train Loss: 17.7877 - Test Loss: 43.5435 - MSE: 43.5435 - MAE: 5.3994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2456/20000 - Train Loss: 17.7857 - Test Loss: 43.5392 - MSE: 43.5392 - MAE: 5.3991\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2457/20000 - Train Loss: 17.7838 - Test Loss: 43.5348 - MSE: 43.5348 - MAE: 5.3988\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2458/20000 - Train Loss: 17.7818 - Test Loss: 43.5303 - MSE: 43.5303 - MAE: 5.3985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2459/20000 - Train Loss: 17.7798 - Test Loss: 43.5260 - MSE: 43.5260 - MAE: 5.3982\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2460/20000 - Train Loss: 17.7778 - Test Loss: 43.5216 - MSE: 43.5216 - MAE: 5.3979\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2461/20000 - Train Loss: 17.7758 - Test Loss: 43.5173 - MSE: 43.5173 - MAE: 5.3976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2462/20000 - Train Loss: 17.7738 - Test Loss: 43.5129 - MSE: 43.5129 - MAE: 5.3973\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2463/20000 - Train Loss: 17.7719 - Test Loss: 43.5086 - MSE: 43.5086 - MAE: 5.3970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2464/20000 - Train Loss: 17.7699 - Test Loss: 43.5042 - MSE: 43.5042 - MAE: 5.3967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2465/20000 - Train Loss: 17.7679 - Test Loss: 43.4999 - MSE: 43.4999 - MAE: 5.3964\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2466/20000 - Train Loss: 17.7659 - Test Loss: 43.4955 - MSE: 43.4955 - MAE: 5.3961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2467/20000 - Train Loss: 17.7639 - Test Loss: 43.4911 - MSE: 43.4911 - MAE: 5.3958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2468/20000 - Train Loss: 17.7619 - Test Loss: 43.4867 - MSE: 43.4867 - MAE: 5.3955\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2469/20000 - Train Loss: 17.7600 - Test Loss: 43.4824 - MSE: 43.4824 - MAE: 5.3953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2470/20000 - Train Loss: 17.7580 - Test Loss: 43.4780 - MSE: 43.4780 - MAE: 5.3950\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2471/20000 - Train Loss: 17.7560 - Test Loss: 43.4737 - MSE: 43.4737 - MAE: 5.3947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2472/20000 - Train Loss: 17.7540 - Test Loss: 43.4693 - MSE: 43.4693 - MAE: 5.3944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2473/20000 - Train Loss: 17.7520 - Test Loss: 43.4649 - MSE: 43.4649 - MAE: 5.3941\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 2474/20000 - Train Loss: 17.7500 - Test Loss: 43.4606 - MSE: 43.4606 - MAE: 5.3938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2475/20000 - Train Loss: 17.7480 - Test Loss: 43.4562 - MSE: 43.4562 - MAE: 5.3935\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2476/20000 - Train Loss: 17.7460 - Test Loss: 43.4518 - MSE: 43.4518 - MAE: 5.3932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2477/20000 - Train Loss: 17.7440 - Test Loss: 43.4475 - MSE: 43.4474 - MAE: 5.3929\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2478/20000 - Train Loss: 17.7420 - Test Loss: 43.4431 - MSE: 43.4431 - MAE: 5.3926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2479/20000 - Train Loss: 17.7400 - Test Loss: 43.4387 - MSE: 43.4387 - MAE: 5.3923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2480/20000 - Train Loss: 17.7380 - Test Loss: 43.4343 - MSE: 43.4343 - MAE: 5.3920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2481/20000 - Train Loss: 17.7360 - Test Loss: 43.4299 - MSE: 43.4299 - MAE: 5.3917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2482/20000 - Train Loss: 17.7340 - Test Loss: 43.4255 - MSE: 43.4255 - MAE: 5.3914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2483/20000 - Train Loss: 17.7320 - Test Loss: 43.4210 - MSE: 43.4210 - MAE: 5.3911\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2484/20000 - Train Loss: 17.7300 - Test Loss: 43.4166 - MSE: 43.4166 - MAE: 5.3908\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2485/20000 - Train Loss: 17.7280 - Test Loss: 43.4122 - MSE: 43.4122 - MAE: 5.3905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2486/20000 - Train Loss: 17.7260 - Test Loss: 43.4078 - MSE: 43.4078 - MAE: 5.3902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2487/20000 - Train Loss: 17.7240 - Test Loss: 43.4034 - MSE: 43.4034 - MAE: 5.3899\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2488/20000 - Train Loss: 17.7220 - Test Loss: 43.3990 - MSE: 43.3990 - MAE: 5.3896\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2489/20000 - Train Loss: 17.7200 - Test Loss: 43.3945 - MSE: 43.3945 - MAE: 5.3893\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2490/20000 - Train Loss: 17.7180 - Test Loss: 43.3901 - MSE: 43.3901 - MAE: 5.3890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2491/20000 - Train Loss: 17.7160 - Test Loss: 43.3857 - MSE: 43.3857 - MAE: 5.3888\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2492/20000 - Train Loss: 17.7140 - Test Loss: 43.3813 - MSE: 43.3813 - MAE: 5.3885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2493/20000 - Train Loss: 17.7120 - Test Loss: 43.3769 - MSE: 43.3769 - MAE: 5.3882\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 2494/20000 - Train Loss: 17.7099 - Test Loss: 43.3725 - MSE: 43.3725 - MAE: 5.3879\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2495/20000 - Train Loss: 17.7079 - Test Loss: 43.3681 - MSE: 43.3681 - MAE: 5.3876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2496/20000 - Train Loss: 17.7059 - Test Loss: 43.3637 - MSE: 43.3637 - MAE: 5.3873\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2497/20000 - Train Loss: 17.7039 - Test Loss: 43.3593 - MSE: 43.3593 - MAE: 5.3870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2498/20000 - Train Loss: 17.7019 - Test Loss: 43.3549 - MSE: 43.3549 - MAE: 5.3867\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2499/20000 - Train Loss: 17.6999 - Test Loss: 43.3505 - MSE: 43.3505 - MAE: 5.3864\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2500/20000 - Train Loss: 17.6979 - Test Loss: 43.3460 - MSE: 43.3460 - MAE: 5.3861\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2501/20000 - Train Loss: 17.6959 - Test Loss: 43.3417 - MSE: 43.3417 - MAE: 5.3858\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2502/20000 - Train Loss: 17.6938 - Test Loss: 43.3372 - MSE: 43.3372 - MAE: 5.3855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2503/20000 - Train Loss: 17.6918 - Test Loss: 43.3328 - MSE: 43.3328 - MAE: 5.3852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2504/20000 - Train Loss: 17.6898 - Test Loss: 43.3283 - MSE: 43.3283 - MAE: 5.3849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2505/20000 - Train Loss: 17.6878 - Test Loss: 43.3239 - MSE: 43.3239 - MAE: 5.3846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2506/20000 - Train Loss: 17.6858 - Test Loss: 43.3194 - MSE: 43.3194 - MAE: 5.3843\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2507/20000 - Train Loss: 17.6837 - Test Loss: 43.3150 - MSE: 43.3150 - MAE: 5.3840\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2508/20000 - Train Loss: 17.6817 - Test Loss: 43.3106 - MSE: 43.3106 - MAE: 5.3837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2509/20000 - Train Loss: 17.6797 - Test Loss: 43.3061 - MSE: 43.3061 - MAE: 5.3834\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2510/20000 - Train Loss: 17.6777 - Test Loss: 43.3016 - MSE: 43.3016 - MAE: 5.3831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2511/20000 - Train Loss: 17.6756 - Test Loss: 43.2971 - MSE: 43.2971 - MAE: 5.3828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2512/20000 - Train Loss: 17.6736 - Test Loss: 43.2927 - MSE: 43.2927 - MAE: 5.3825\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2513/20000 - Train Loss: 17.6716 - Test Loss: 43.2882 - MSE: 43.2882 - MAE: 5.3822\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2514/20000 - Train Loss: 17.6696 - Test Loss: 43.2838 - MSE: 43.2838 - MAE: 5.3819\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2515/20000 - Train Loss: 17.6675 - Test Loss: 43.2794 - MSE: 43.2794 - MAE: 5.3816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2516/20000 - Train Loss: 17.6655 - Test Loss: 43.2749 - MSE: 43.2749 - MAE: 5.3813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2517/20000 - Train Loss: 17.6635 - Test Loss: 43.2705 - MSE: 43.2705 - MAE: 5.3810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2518/20000 - Train Loss: 17.6615 - Test Loss: 43.2659 - MSE: 43.2659 - MAE: 5.3807\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 2519/20000 - Train Loss: 17.6594 - Test Loss: 43.2615 - MSE: 43.2615 - MAE: 5.3804\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2520/20000 - Train Loss: 17.6574 - Test Loss: 43.2570 - MSE: 43.2570 - MAE: 5.3801\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2521/20000 - Train Loss: 17.6554 - Test Loss: 43.2525 - MSE: 43.2525 - MAE: 5.3798\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2522/20000 - Train Loss: 17.6533 - Test Loss: 43.2481 - MSE: 43.2481 - MAE: 5.3795\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2523/20000 - Train Loss: 17.6513 - Test Loss: 43.2437 - MSE: 43.2437 - MAE: 5.3792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2524/20000 - Train Loss: 17.6493 - Test Loss: 43.2392 - MSE: 43.2392 - MAE: 5.3789\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2525/20000 - Train Loss: 17.6472 - Test Loss: 43.2347 - MSE: 43.2347 - MAE: 5.3786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2526/20000 - Train Loss: 17.6452 - Test Loss: 43.2302 - MSE: 43.2302 - MAE: 5.3783\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2527/20000 - Train Loss: 17.6431 - Test Loss: 43.2257 - MSE: 43.2257 - MAE: 5.3780\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2528/20000 - Train Loss: 17.6411 - Test Loss: 43.2212 - MSE: 43.2212 - MAE: 5.3777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2529/20000 - Train Loss: 17.6391 - Test Loss: 43.2168 - MSE: 43.2168 - MAE: 5.3774\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2530/20000 - Train Loss: 17.6370 - Test Loss: 43.2124 - MSE: 43.2124 - MAE: 5.3771\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2531/20000 - Train Loss: 17.6350 - Test Loss: 43.2079 - MSE: 43.2079 - MAE: 5.3768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2532/20000 - Train Loss: 17.6329 - Test Loss: 43.2034 - MSE: 43.2034 - MAE: 5.3765\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2533/20000 - Train Loss: 17.6309 - Test Loss: 43.1989 - MSE: 43.1989 - MAE: 5.3762\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2534/20000 - Train Loss: 17.6289 - Test Loss: 43.1944 - MSE: 43.1944 - MAE: 5.3758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2535/20000 - Train Loss: 17.6268 - Test Loss: 43.1899 - MSE: 43.1899 - MAE: 5.3755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2536/20000 - Train Loss: 17.6248 - Test Loss: 43.1854 - MSE: 43.1854 - MAE: 5.3752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2537/20000 - Train Loss: 17.6227 - Test Loss: 43.1810 - MSE: 43.1810 - MAE: 5.3749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2538/20000 - Train Loss: 17.6207 - Test Loss: 43.1764 - MSE: 43.1764 - MAE: 5.3746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2539/20000 - Train Loss: 17.6186 - Test Loss: 43.1719 - MSE: 43.1719 - MAE: 5.3743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2540/20000 - Train Loss: 17.6166 - Test Loss: 43.1674 - MSE: 43.1674 - MAE: 5.3740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2541/20000 - Train Loss: 17.6145 - Test Loss: 43.1629 - MSE: 43.1629 - MAE: 5.3737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2542/20000 - Train Loss: 17.6125 - Test Loss: 43.1584 - MSE: 43.1584 - MAE: 5.3734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2543/20000 - Train Loss: 17.6104 - Test Loss: 43.1538 - MSE: 43.1539 - MAE: 5.3731\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2544/20000 - Train Loss: 17.6084 - Test Loss: 43.1494 - MSE: 43.1494 - MAE: 5.3728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2545/20000 - Train Loss: 17.6063 - Test Loss: 43.1448 - MSE: 43.1448 - MAE: 5.3725\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2546/20000 - Train Loss: 17.6042 - Test Loss: 43.1403 - MSE: 43.1403 - MAE: 5.3722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2547/20000 - Train Loss: 17.6022 - Test Loss: 43.1358 - MSE: 43.1358 - MAE: 5.3719\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2548/20000 - Train Loss: 17.6001 - Test Loss: 43.1313 - MSE: 43.1313 - MAE: 5.3716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2549/20000 - Train Loss: 17.5981 - Test Loss: 43.1268 - MSE: 43.1268 - MAE: 5.3713\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2550/20000 - Train Loss: 17.5960 - Test Loss: 43.1222 - MSE: 43.1222 - MAE: 5.3710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2551/20000 - Train Loss: 17.5940 - Test Loss: 43.1177 - MSE: 43.1177 - MAE: 5.3707\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2552/20000 - Train Loss: 17.5919 - Test Loss: 43.1132 - MSE: 43.1132 - MAE: 5.3704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2553/20000 - Train Loss: 17.5898 - Test Loss: 43.1087 - MSE: 43.1087 - MAE: 5.3701\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2554/20000 - Train Loss: 17.5878 - Test Loss: 43.1042 - MSE: 43.1042 - MAE: 5.3698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2555/20000 - Train Loss: 17.5857 - Test Loss: 43.0996 - MSE: 43.0996 - MAE: 5.3694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2556/20000 - Train Loss: 17.5837 - Test Loss: 43.0951 - MSE: 43.0951 - MAE: 5.3691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2557/20000 - Train Loss: 17.5816 - Test Loss: 43.0906 - MSE: 43.0906 - MAE: 5.3688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2558/20000 - Train Loss: 17.5795 - Test Loss: 43.0861 - MSE: 43.0861 - MAE: 5.3685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2559/20000 - Train Loss: 17.5775 - Test Loss: 43.0815 - MSE: 43.0815 - MAE: 5.3682\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 2560/20000 - Train Loss: 17.5754 - Test Loss: 43.0769 - MSE: 43.0769 - MAE: 5.3679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2561/20000 - Train Loss: 17.5733 - Test Loss: 43.0725 - MSE: 43.0725 - MAE: 5.3676\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 2562/20000 - Train Loss: 17.5713 - Test Loss: 43.0679 - MSE: 43.0679 - MAE: 5.3673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2563/20000 - Train Loss: 17.5692 - Test Loss: 43.0634 - MSE: 43.0634 - MAE: 5.3670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2564/20000 - Train Loss: 17.5671 - Test Loss: 43.0589 - MSE: 43.0589 - MAE: 5.3667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2565/20000 - Train Loss: 17.5651 - Test Loss: 43.0543 - MSE: 43.0543 - MAE: 5.3664\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 2566/20000 - Train Loss: 17.5630 - Test Loss: 43.0497 - MSE: 43.0497 - MAE: 5.3661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2567/20000 - Train Loss: 17.5609 - Test Loss: 43.0451 - MSE: 43.0451 - MAE: 5.3658\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2568/20000 - Train Loss: 17.5588 - Test Loss: 43.0406 - MSE: 43.0406 - MAE: 5.3654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2569/20000 - Train Loss: 17.5568 - Test Loss: 43.0360 - MSE: 43.0360 - MAE: 5.3651\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2570/20000 - Train Loss: 17.5547 - Test Loss: 43.0315 - MSE: 43.0315 - MAE: 5.3648\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2571/20000 - Train Loss: 17.5526 - Test Loss: 43.0269 - MSE: 43.0269 - MAE: 5.3645\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2572/20000 - Train Loss: 17.5505 - Test Loss: 43.0223 - MSE: 43.0223 - MAE: 5.3642\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2573/20000 - Train Loss: 17.5485 - Test Loss: 43.0177 - MSE: 43.0177 - MAE: 5.3639\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2574/20000 - Train Loss: 17.5464 - Test Loss: 43.0132 - MSE: 43.0132 - MAE: 5.3636\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2575/20000 - Train Loss: 17.5443 - Test Loss: 43.0086 - MSE: 43.0086 - MAE: 5.3633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2576/20000 - Train Loss: 17.5422 - Test Loss: 43.0040 - MSE: 43.0040 - MAE: 5.3630\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2577/20000 - Train Loss: 17.5401 - Test Loss: 42.9995 - MSE: 42.9995 - MAE: 5.3627\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2578/20000 - Train Loss: 17.5381 - Test Loss: 42.9949 - MSE: 42.9949 - MAE: 5.3624\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2579/20000 - Train Loss: 17.5360 - Test Loss: 42.9904 - MSE: 42.9904 - MAE: 5.3620\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2580/20000 - Train Loss: 17.5339 - Test Loss: 42.9858 - MSE: 42.9858 - MAE: 5.3617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2581/20000 - Train Loss: 17.5318 - Test Loss: 42.9812 - MSE: 42.9812 - MAE: 5.3614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2582/20000 - Train Loss: 17.5297 - Test Loss: 42.9766 - MSE: 42.9766 - MAE: 5.3611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2583/20000 - Train Loss: 17.5276 - Test Loss: 42.9720 - MSE: 42.9720 - MAE: 5.3608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2584/20000 - Train Loss: 17.5255 - Test Loss: 42.9674 - MSE: 42.9674 - MAE: 5.3605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2585/20000 - Train Loss: 17.5235 - Test Loss: 42.9629 - MSE: 42.9629 - MAE: 5.3602\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2586/20000 - Train Loss: 17.5214 - Test Loss: 42.9583 - MSE: 42.9583 - MAE: 5.3599\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2587/20000 - Train Loss: 17.5193 - Test Loss: 42.9537 - MSE: 42.9537 - MAE: 5.3596\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2588/20000 - Train Loss: 17.5172 - Test Loss: 42.9491 - MSE: 42.9491 - MAE: 5.3593\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2589/20000 - Train Loss: 17.5151 - Test Loss: 42.9445 - MSE: 42.9445 - MAE: 5.3589\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2590/20000 - Train Loss: 17.5130 - Test Loss: 42.9399 - MSE: 42.9399 - MAE: 5.3586\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2591/20000 - Train Loss: 17.5109 - Test Loss: 42.9353 - MSE: 42.9353 - MAE: 5.3583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2592/20000 - Train Loss: 17.5088 - Test Loss: 42.9308 - MSE: 42.9308 - MAE: 5.3580\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2593/20000 - Train Loss: 17.5067 - Test Loss: 42.9262 - MSE: 42.9262 - MAE: 5.3577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2594/20000 - Train Loss: 17.5046 - Test Loss: 42.9215 - MSE: 42.9215 - MAE: 5.3574\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2595/20000 - Train Loss: 17.5025 - Test Loss: 42.9170 - MSE: 42.9170 - MAE: 5.3571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2596/20000 - Train Loss: 17.5004 - Test Loss: 42.9123 - MSE: 42.9123 - MAE: 5.3568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2597/20000 - Train Loss: 17.4983 - Test Loss: 42.9077 - MSE: 42.9077 - MAE: 5.3564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2598/20000 - Train Loss: 17.4962 - Test Loss: 42.9032 - MSE: 42.9032 - MAE: 5.3561\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2599/20000 - Train Loss: 17.4941 - Test Loss: 42.8985 - MSE: 42.8985 - MAE: 5.3558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2600/20000 - Train Loss: 17.4920 - Test Loss: 42.8939 - MSE: 42.8939 - MAE: 5.3555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2601/20000 - Train Loss: 17.4899 - Test Loss: 42.8892 - MSE: 42.8892 - MAE: 5.3552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2602/20000 - Train Loss: 17.4878 - Test Loss: 42.8846 - MSE: 42.8846 - MAE: 5.3549\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2603/20000 - Train Loss: 17.4857 - Test Loss: 42.8799 - MSE: 42.8799 - MAE: 5.3546\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2604/20000 - Train Loss: 17.4836 - Test Loss: 42.8753 - MSE: 42.8753 - MAE: 5.3542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2605/20000 - Train Loss: 17.4815 - Test Loss: 42.8707 - MSE: 42.8707 - MAE: 5.3539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2606/20000 - Train Loss: 17.4794 - Test Loss: 42.8661 - MSE: 42.8661 - MAE: 5.3536\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2607/20000 - Train Loss: 17.4773 - Test Loss: 42.8615 - MSE: 42.8615 - MAE: 5.3533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2608/20000 - Train Loss: 17.4752 - Test Loss: 42.8568 - MSE: 42.8568 - MAE: 5.3530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2609/20000 - Train Loss: 17.4731 - Test Loss: 42.8522 - MSE: 42.8522 - MAE: 5.3527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2610/20000 - Train Loss: 17.4710 - Test Loss: 42.8476 - MSE: 42.8476 - MAE: 5.3524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2611/20000 - Train Loss: 17.4689 - Test Loss: 42.8430 - MSE: 42.8430 - MAE: 5.3521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2612/20000 - Train Loss: 17.4668 - Test Loss: 42.8383 - MSE: 42.8383 - MAE: 5.3517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2613/20000 - Train Loss: 17.4647 - Test Loss: 42.8337 - MSE: 42.8337 - MAE: 5.3514\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2614/20000 - Train Loss: 17.4625 - Test Loss: 42.8291 - MSE: 42.8291 - MAE: 5.3511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2615/20000 - Train Loss: 17.4604 - Test Loss: 42.8245 - MSE: 42.8245 - MAE: 5.3508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2616/20000 - Train Loss: 17.4583 - Test Loss: 42.8198 - MSE: 42.8198 - MAE: 5.3505\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2617/20000 - Train Loss: 17.4562 - Test Loss: 42.8151 - MSE: 42.8151 - MAE: 5.3502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2618/20000 - Train Loss: 17.4541 - Test Loss: 42.8105 - MSE: 42.8105 - MAE: 5.3499\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2619/20000 - Train Loss: 17.4520 - Test Loss: 42.8059 - MSE: 42.8059 - MAE: 5.3495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2620/20000 - Train Loss: 17.4499 - Test Loss: 42.8012 - MSE: 42.8012 - MAE: 5.3492\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2621/20000 - Train Loss: 17.4477 - Test Loss: 42.7966 - MSE: 42.7966 - MAE: 5.3489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2622/20000 - Train Loss: 17.4456 - Test Loss: 42.7920 - MSE: 42.7920 - MAE: 5.3486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2623/20000 - Train Loss: 17.4435 - Test Loss: 42.7873 - MSE: 42.7873 - MAE: 5.3483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2624/20000 - Train Loss: 17.4414 - Test Loss: 42.7826 - MSE: 42.7826 - MAE: 5.3479\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2625/20000 - Train Loss: 17.4392 - Test Loss: 42.7780 - MSE: 42.7780 - MAE: 5.3476\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2626/20000 - Train Loss: 17.4371 - Test Loss: 42.7732 - MSE: 42.7732 - MAE: 5.3473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2627/20000 - Train Loss: 17.4350 - Test Loss: 42.7686 - MSE: 42.7686 - MAE: 5.3470\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2628/20000 - Train Loss: 17.4329 - Test Loss: 42.7639 - MSE: 42.7639 - MAE: 5.3467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2629/20000 - Train Loss: 17.4307 - Test Loss: 42.7592 - MSE: 42.7592 - MAE: 5.3464\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2630/20000 - Train Loss: 17.4286 - Test Loss: 42.7545 - MSE: 42.7545 - MAE: 5.3460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2631/20000 - Train Loss: 17.4265 - Test Loss: 42.7498 - MSE: 42.7498 - MAE: 5.3457\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2632/20000 - Train Loss: 17.4244 - Test Loss: 42.7451 - MSE: 42.7451 - MAE: 5.3454\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 2633/20000 - Train Loss: 17.4222 - Test Loss: 42.7405 - MSE: 42.7405 - MAE: 5.3451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2634/20000 - Train Loss: 17.4201 - Test Loss: 42.7358 - MSE: 42.7358 - MAE: 5.3448\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2635/20000 - Train Loss: 17.4180 - Test Loss: 42.7311 - MSE: 42.7311 - MAE: 5.3445\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2636/20000 - Train Loss: 17.4158 - Test Loss: 42.7265 - MSE: 42.7265 - MAE: 5.3441\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2637/20000 - Train Loss: 17.4137 - Test Loss: 42.7218 - MSE: 42.7218 - MAE: 5.3438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2638/20000 - Train Loss: 17.4116 - Test Loss: 42.7171 - MSE: 42.7171 - MAE: 5.3435\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2639/20000 - Train Loss: 17.4094 - Test Loss: 42.7124 - MSE: 42.7124 - MAE: 5.3432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2640/20000 - Train Loss: 17.4073 - Test Loss: 42.7078 - MSE: 42.7078 - MAE: 5.3429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2641/20000 - Train Loss: 17.4052 - Test Loss: 42.7031 - MSE: 42.7031 - MAE: 5.3425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2642/20000 - Train Loss: 17.4030 - Test Loss: 42.6985 - MSE: 42.6985 - MAE: 5.3422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2643/20000 - Train Loss: 17.4009 - Test Loss: 42.6938 - MSE: 42.6938 - MAE: 5.3419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2644/20000 - Train Loss: 17.3988 - Test Loss: 42.6891 - MSE: 42.6891 - MAE: 5.3416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2645/20000 - Train Loss: 17.3966 - Test Loss: 42.6843 - MSE: 42.6843 - MAE: 5.3413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2646/20000 - Train Loss: 17.3945 - Test Loss: 42.6797 - MSE: 42.6797 - MAE: 5.3410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2647/20000 - Train Loss: 17.3923 - Test Loss: 42.6749 - MSE: 42.6749 - MAE: 5.3406\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2648/20000 - Train Loss: 17.3902 - Test Loss: 42.6702 - MSE: 42.6702 - MAE: 5.3403\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2649/20000 - Train Loss: 17.3881 - Test Loss: 42.6655 - MSE: 42.6655 - MAE: 5.3400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2650/20000 - Train Loss: 17.3859 - Test Loss: 42.6608 - MSE: 42.6608 - MAE: 5.3397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2651/20000 - Train Loss: 17.3838 - Test Loss: 42.6561 - MSE: 42.6561 - MAE: 5.3393\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2652/20000 - Train Loss: 17.3816 - Test Loss: 42.6514 - MSE: 42.6514 - MAE: 5.3390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2653/20000 - Train Loss: 17.3795 - Test Loss: 42.6466 - MSE: 42.6466 - MAE: 5.3387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2654/20000 - Train Loss: 17.3773 - Test Loss: 42.6419 - MSE: 42.6419 - MAE: 5.3384\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2655/20000 - Train Loss: 17.3752 - Test Loss: 42.6372 - MSE: 42.6372 - MAE: 5.3381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2656/20000 - Train Loss: 17.3730 - Test Loss: 42.6325 - MSE: 42.6325 - MAE: 5.3377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2657/20000 - Train Loss: 17.3709 - Test Loss: 42.6278 - MSE: 42.6278 - MAE: 5.3374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2658/20000 - Train Loss: 17.3687 - Test Loss: 42.6230 - MSE: 42.6230 - MAE: 5.3371\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2659/20000 - Train Loss: 17.3666 - Test Loss: 42.6183 - MSE: 42.6183 - MAE: 5.3368\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 2660/20000 - Train Loss: 17.3644 - Test Loss: 42.6136 - MSE: 42.6136 - MAE: 5.3365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2661/20000 - Train Loss: 17.3623 - Test Loss: 42.6088 - MSE: 42.6088 - MAE: 5.3361\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2662/20000 - Train Loss: 17.3601 - Test Loss: 42.6041 - MSE: 42.6041 - MAE: 5.3358\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2663/20000 - Train Loss: 17.3580 - Test Loss: 42.5994 - MSE: 42.5994 - MAE: 5.3355\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2664/20000 - Train Loss: 17.3558 - Test Loss: 42.5947 - MSE: 42.5947 - MAE: 5.3352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2665/20000 - Train Loss: 17.3536 - Test Loss: 42.5899 - MSE: 42.5899 - MAE: 5.3348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2666/20000 - Train Loss: 17.3515 - Test Loss: 42.5852 - MSE: 42.5852 - MAE: 5.3345\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2667/20000 - Train Loss: 17.3493 - Test Loss: 42.5804 - MSE: 42.5804 - MAE: 5.3342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2668/20000 - Train Loss: 17.3472 - Test Loss: 42.5757 - MSE: 42.5757 - MAE: 5.3339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2669/20000 - Train Loss: 17.3450 - Test Loss: 42.5710 - MSE: 42.5710 - MAE: 5.3335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2670/20000 - Train Loss: 17.3428 - Test Loss: 42.5663 - MSE: 42.5663 - MAE: 5.3332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2671/20000 - Train Loss: 17.3407 - Test Loss: 42.5615 - MSE: 42.5615 - MAE: 5.3329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2672/20000 - Train Loss: 17.3385 - Test Loss: 42.5567 - MSE: 42.5567 - MAE: 5.3326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2673/20000 - Train Loss: 17.3364 - Test Loss: 42.5520 - MSE: 42.5520 - MAE: 5.3323\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2674/20000 - Train Loss: 17.3342 - Test Loss: 42.5473 - MSE: 42.5473 - MAE: 5.3319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2675/20000 - Train Loss: 17.3320 - Test Loss: 42.5425 - MSE: 42.5425 - MAE: 5.3316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2676/20000 - Train Loss: 17.3299 - Test Loss: 42.5378 - MSE: 42.5378 - MAE: 5.3313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2677/20000 - Train Loss: 17.3277 - Test Loss: 42.5330 - MSE: 42.5330 - MAE: 5.3310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2678/20000 - Train Loss: 17.3255 - Test Loss: 42.5282 - MSE: 42.5282 - MAE: 5.3306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2679/20000 - Train Loss: 17.3234 - Test Loss: 42.5235 - MSE: 42.5235 - MAE: 5.3303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2680/20000 - Train Loss: 17.3212 - Test Loss: 42.5187 - MSE: 42.5187 - MAE: 5.3300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2681/20000 - Train Loss: 17.3190 - Test Loss: 42.5140 - MSE: 42.5140 - MAE: 5.3297\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2682/20000 - Train Loss: 17.3168 - Test Loss: 42.5091 - MSE: 42.5091 - MAE: 5.3293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2683/20000 - Train Loss: 17.3147 - Test Loss: 42.5043 - MSE: 42.5043 - MAE: 5.3290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2684/20000 - Train Loss: 17.3125 - Test Loss: 42.4995 - MSE: 42.4995 - MAE: 5.3287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2685/20000 - Train Loss: 17.3103 - Test Loss: 42.4947 - MSE: 42.4947 - MAE: 5.3283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2686/20000 - Train Loss: 17.3081 - Test Loss: 42.4900 - MSE: 42.4900 - MAE: 5.3280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2687/20000 - Train Loss: 17.3060 - Test Loss: 42.4852 - MSE: 42.4852 - MAE: 5.3277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2688/20000 - Train Loss: 17.3038 - Test Loss: 42.4805 - MSE: 42.4805 - MAE: 5.3274\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2689/20000 - Train Loss: 17.3016 - Test Loss: 42.4757 - MSE: 42.4757 - MAE: 5.3270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2690/20000 - Train Loss: 17.2994 - Test Loss: 42.4709 - MSE: 42.4709 - MAE: 5.3267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2691/20000 - Train Loss: 17.2973 - Test Loss: 42.4661 - MSE: 42.4661 - MAE: 5.3264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2692/20000 - Train Loss: 17.2951 - Test Loss: 42.4613 - MSE: 42.4613 - MAE: 5.3261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2693/20000 - Train Loss: 17.2929 - Test Loss: 42.4565 - MSE: 42.4565 - MAE: 5.3257\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2694/20000 - Train Loss: 17.2907 - Test Loss: 42.4517 - MSE: 42.4517 - MAE: 5.3254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2695/20000 - Train Loss: 17.2885 - Test Loss: 42.4470 - MSE: 42.4470 - MAE: 5.3251\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2696/20000 - Train Loss: 17.2863 - Test Loss: 42.4422 - MSE: 42.4422 - MAE: 5.3248\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2697/20000 - Train Loss: 17.2842 - Test Loss: 42.4375 - MSE: 42.4375 - MAE: 5.3244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2698/20000 - Train Loss: 17.2820 - Test Loss: 42.4327 - MSE: 42.4327 - MAE: 5.3241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2699/20000 - Train Loss: 17.2798 - Test Loss: 42.4278 - MSE: 42.4278 - MAE: 5.3238\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2700/20000 - Train Loss: 17.2776 - Test Loss: 42.4230 - MSE: 42.4230 - MAE: 5.3235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2701/20000 - Train Loss: 17.2754 - Test Loss: 42.4183 - MSE: 42.4183 - MAE: 5.3231\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2702/20000 - Train Loss: 17.2732 - Test Loss: 42.4135 - MSE: 42.4135 - MAE: 5.3228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2703/20000 - Train Loss: 17.2710 - Test Loss: 42.4086 - MSE: 42.4086 - MAE: 5.3225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2704/20000 - Train Loss: 17.2688 - Test Loss: 42.4038 - MSE: 42.4038 - MAE: 5.3221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2705/20000 - Train Loss: 17.2667 - Test Loss: 42.3989 - MSE: 42.3989 - MAE: 5.3218\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2706/20000 - Train Loss: 17.2645 - Test Loss: 42.3941 - MSE: 42.3941 - MAE: 5.3215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2707/20000 - Train Loss: 17.2623 - Test Loss: 42.3892 - MSE: 42.3892 - MAE: 5.3211\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2708/20000 - Train Loss: 17.2601 - Test Loss: 42.3845 - MSE: 42.3845 - MAE: 5.3208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2709/20000 - Train Loss: 17.2579 - Test Loss: 42.3797 - MSE: 42.3797 - MAE: 5.3205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2710/20000 - Train Loss: 17.2557 - Test Loss: 42.3748 - MSE: 42.3748 - MAE: 5.3202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2711/20000 - Train Loss: 17.2535 - Test Loss: 42.3700 - MSE: 42.3700 - MAE: 5.3198\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2712/20000 - Train Loss: 17.2513 - Test Loss: 42.3651 - MSE: 42.3651 - MAE: 5.3195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2713/20000 - Train Loss: 17.2491 - Test Loss: 42.3603 - MSE: 42.3603 - MAE: 5.3192\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2714/20000 - Train Loss: 17.2469 - Test Loss: 42.3554 - MSE: 42.3554 - MAE: 5.3188\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2715/20000 - Train Loss: 17.2447 - Test Loss: 42.3506 - MSE: 42.3506 - MAE: 5.3185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2716/20000 - Train Loss: 17.2425 - Test Loss: 42.3459 - MSE: 42.3459 - MAE: 5.3182\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2717/20000 - Train Loss: 17.2403 - Test Loss: 42.3410 - MSE: 42.3410 - MAE: 5.3178\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2718/20000 - Train Loss: 17.2381 - Test Loss: 42.3362 - MSE: 42.3362 - MAE: 5.3175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2719/20000 - Train Loss: 17.2359 - Test Loss: 42.3314 - MSE: 42.3314 - MAE: 5.3172\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2720/20000 - Train Loss: 17.2337 - Test Loss: 42.3266 - MSE: 42.3266 - MAE: 5.3169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2721/20000 - Train Loss: 17.2315 - Test Loss: 42.3218 - MSE: 42.3218 - MAE: 5.3165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2722/20000 - Train Loss: 17.2293 - Test Loss: 42.3170 - MSE: 42.3170 - MAE: 5.3162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2723/20000 - Train Loss: 17.2270 - Test Loss: 42.3121 - MSE: 42.3121 - MAE: 5.3159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2724/20000 - Train Loss: 17.2249 - Test Loss: 42.3072 - MSE: 42.3072 - MAE: 5.3155\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2725/20000 - Train Loss: 17.2226 - Test Loss: 42.3023 - MSE: 42.3023 - MAE: 5.3152\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2726/20000 - Train Loss: 17.2204 - Test Loss: 42.2975 - MSE: 42.2975 - MAE: 5.3149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2727/20000 - Train Loss: 17.2182 - Test Loss: 42.2926 - MSE: 42.2926 - MAE: 5.3145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2728/20000 - Train Loss: 17.2160 - Test Loss: 42.2877 - MSE: 42.2877 - MAE: 5.3142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2729/20000 - Train Loss: 17.2138 - Test Loss: 42.2829 - MSE: 42.2829 - MAE: 5.3139\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2730/20000 - Train Loss: 17.2116 - Test Loss: 42.2781 - MSE: 42.2781 - MAE: 5.3135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2731/20000 - Train Loss: 17.2094 - Test Loss: 42.2732 - MSE: 42.2732 - MAE: 5.3132\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2732/20000 - Train Loss: 17.2071 - Test Loss: 42.2683 - MSE: 42.2683 - MAE: 5.3129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2733/20000 - Train Loss: 17.2049 - Test Loss: 42.2634 - MSE: 42.2634 - MAE: 5.3125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2734/20000 - Train Loss: 17.2027 - Test Loss: 42.2585 - MSE: 42.2585 - MAE: 5.3122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2735/20000 - Train Loss: 17.2005 - Test Loss: 42.2537 - MSE: 42.2537 - MAE: 5.3119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2736/20000 - Train Loss: 17.1983 - Test Loss: 42.2488 - MSE: 42.2488 - MAE: 5.3115\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2737/20000 - Train Loss: 17.1961 - Test Loss: 42.2439 - MSE: 42.2439 - MAE: 5.3112\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2738/20000 - Train Loss: 17.1938 - Test Loss: 42.2391 - MSE: 42.2391 - MAE: 5.3109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2739/20000 - Train Loss: 17.1916 - Test Loss: 42.2342 - MSE: 42.2342 - MAE: 5.3105\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2740/20000 - Train Loss: 17.1894 - Test Loss: 42.2294 - MSE: 42.2294 - MAE: 5.3102\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2741/20000 - Train Loss: 17.1872 - Test Loss: 42.2245 - MSE: 42.2245 - MAE: 5.3099\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2742/20000 - Train Loss: 17.1849 - Test Loss: 42.2196 - MSE: 42.2196 - MAE: 5.3095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2743/20000 - Train Loss: 17.1827 - Test Loss: 42.2147 - MSE: 42.2147 - MAE: 5.3092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2744/20000 - Train Loss: 17.1805 - Test Loss: 42.2099 - MSE: 42.2099 - MAE: 5.3089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2745/20000 - Train Loss: 17.1783 - Test Loss: 42.2050 - MSE: 42.2050 - MAE: 5.3085\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2746/20000 - Train Loss: 17.1760 - Test Loss: 42.2001 - MSE: 42.2001 - MAE: 5.3082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2747/20000 - Train Loss: 17.1738 - Test Loss: 42.1952 - MSE: 42.1952 - MAE: 5.3079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2748/20000 - Train Loss: 17.1716 - Test Loss: 42.1903 - MSE: 42.1903 - MAE: 5.3075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2749/20000 - Train Loss: 17.1694 - Test Loss: 42.1854 - MSE: 42.1854 - MAE: 5.3072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2750/20000 - Train Loss: 17.1671 - Test Loss: 42.1805 - MSE: 42.1805 - MAE: 5.3068\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2751/20000 - Train Loss: 17.1649 - Test Loss: 42.1756 - MSE: 42.1756 - MAE: 5.3065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2752/20000 - Train Loss: 17.1627 - Test Loss: 42.1707 - MSE: 42.1707 - MAE: 5.3062\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2753/20000 - Train Loss: 17.1604 - Test Loss: 42.1658 - MSE: 42.1658 - MAE: 5.3058\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2754/20000 - Train Loss: 17.1582 - Test Loss: 42.1609 - MSE: 42.1609 - MAE: 5.3055\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2755/20000 - Train Loss: 17.1560 - Test Loss: 42.1559 - MSE: 42.1559 - MAE: 5.3052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2756/20000 - Train Loss: 17.1537 - Test Loss: 42.1511 - MSE: 42.1511 - MAE: 5.3048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2757/20000 - Train Loss: 17.1515 - Test Loss: 42.1461 - MSE: 42.1461 - MAE: 5.3045\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2758/20000 - Train Loss: 17.1492 - Test Loss: 42.1412 - MSE: 42.1412 - MAE: 5.3042\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2759/20000 - Train Loss: 17.1470 - Test Loss: 42.1363 - MSE: 42.1363 - MAE: 5.3038\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2760/20000 - Train Loss: 17.1448 - Test Loss: 42.1313 - MSE: 42.1313 - MAE: 5.3035\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2761/20000 - Train Loss: 17.1425 - Test Loss: 42.1264 - MSE: 42.1264 - MAE: 5.3031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2762/20000 - Train Loss: 17.1403 - Test Loss: 42.1215 - MSE: 42.1215 - MAE: 5.3028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2763/20000 - Train Loss: 17.1380 - Test Loss: 42.1166 - MSE: 42.1166 - MAE: 5.3025\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2764/20000 - Train Loss: 17.1358 - Test Loss: 42.1117 - MSE: 42.1117 - MAE: 5.3021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2765/20000 - Train Loss: 17.1336 - Test Loss: 42.1067 - MSE: 42.1067 - MAE: 5.3018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2766/20000 - Train Loss: 17.1313 - Test Loss: 42.1019 - MSE: 42.1019 - MAE: 5.3015\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2767/20000 - Train Loss: 17.1291 - Test Loss: 42.0970 - MSE: 42.0970 - MAE: 5.3011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2768/20000 - Train Loss: 17.1268 - Test Loss: 42.0920 - MSE: 42.0920 - MAE: 5.3008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2769/20000 - Train Loss: 17.1246 - Test Loss: 42.0871 - MSE: 42.0871 - MAE: 5.3005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2770/20000 - Train Loss: 17.1223 - Test Loss: 42.0821 - MSE: 42.0821 - MAE: 5.3001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2771/20000 - Train Loss: 17.1201 - Test Loss: 42.0772 - MSE: 42.0772 - MAE: 5.2998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2772/20000 - Train Loss: 17.1178 - Test Loss: 42.0723 - MSE: 42.0723 - MAE: 5.2995\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2773/20000 - Train Loss: 17.1156 - Test Loss: 42.0673 - MSE: 42.0673 - MAE: 5.2992\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2774/20000 - Train Loss: 17.1133 - Test Loss: 42.0624 - MSE: 42.0624 - MAE: 5.2988\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2775/20000 - Train Loss: 17.1111 - Test Loss: 42.0575 - MSE: 42.0575 - MAE: 5.2985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2776/20000 - Train Loss: 17.1088 - Test Loss: 42.0525 - MSE: 42.0525 - MAE: 5.2982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2777/20000 - Train Loss: 17.1066 - Test Loss: 42.0476 - MSE: 42.0476 - MAE: 5.2978\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2778/20000 - Train Loss: 17.1043 - Test Loss: 42.0426 - MSE: 42.0426 - MAE: 5.2975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2779/20000 - Train Loss: 17.1020 - Test Loss: 42.0377 - MSE: 42.0377 - MAE: 5.2972\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2780/20000 - Train Loss: 17.0998 - Test Loss: 42.0328 - MSE: 42.0328 - MAE: 5.2968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2781/20000 - Train Loss: 17.0975 - Test Loss: 42.0278 - MSE: 42.0278 - MAE: 5.2965\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2782/20000 - Train Loss: 17.0953 - Test Loss: 42.0228 - MSE: 42.0228 - MAE: 5.2962\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2783/20000 - Train Loss: 17.0930 - Test Loss: 42.0178 - MSE: 42.0178 - MAE: 5.2958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2784/20000 - Train Loss: 17.0907 - Test Loss: 42.0128 - MSE: 42.0128 - MAE: 5.2955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2785/20000 - Train Loss: 17.0885 - Test Loss: 42.0079 - MSE: 42.0079 - MAE: 5.2952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2786/20000 - Train Loss: 17.0862 - Test Loss: 42.0029 - MSE: 42.0029 - MAE: 5.2948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2787/20000 - Train Loss: 17.0840 - Test Loss: 41.9979 - MSE: 41.9979 - MAE: 5.2945\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2788/20000 - Train Loss: 17.0817 - Test Loss: 41.9930 - MSE: 41.9930 - MAE: 5.2942\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2789/20000 - Train Loss: 17.0794 - Test Loss: 41.9880 - MSE: 41.9880 - MAE: 5.2938\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2790/20000 - Train Loss: 17.0772 - Test Loss: 41.9830 - MSE: 41.9830 - MAE: 5.2935\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2791/20000 - Train Loss: 17.0749 - Test Loss: 41.9781 - MSE: 41.9781 - MAE: 5.2932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2792/20000 - Train Loss: 17.0726 - Test Loss: 41.9730 - MSE: 41.9730 - MAE: 5.2928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2793/20000 - Train Loss: 17.0704 - Test Loss: 41.9681 - MSE: 41.9681 - MAE: 5.2925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2794/20000 - Train Loss: 17.0681 - Test Loss: 41.9631 - MSE: 41.9631 - MAE: 5.2922\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2795/20000 - Train Loss: 17.0658 - Test Loss: 41.9581 - MSE: 41.9581 - MAE: 5.2918\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2796/20000 - Train Loss: 17.0635 - Test Loss: 41.9531 - MSE: 41.9532 - MAE: 5.2915\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 2797/20000 - Train Loss: 17.0613 - Test Loss: 41.9482 - MSE: 41.9482 - MAE: 5.2912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2798/20000 - Train Loss: 17.0590 - Test Loss: 41.9432 - MSE: 41.9432 - MAE: 5.2908\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2799/20000 - Train Loss: 17.0567 - Test Loss: 41.9382 - MSE: 41.9382 - MAE: 5.2905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2800/20000 - Train Loss: 17.0545 - Test Loss: 41.9332 - MSE: 41.9332 - MAE: 5.2902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2801/20000 - Train Loss: 17.0522 - Test Loss: 41.9282 - MSE: 41.9282 - MAE: 5.2898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2802/20000 - Train Loss: 17.0499 - Test Loss: 41.9232 - MSE: 41.9232 - MAE: 5.2895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2803/20000 - Train Loss: 17.0476 - Test Loss: 41.9183 - MSE: 41.9183 - MAE: 5.2892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2804/20000 - Train Loss: 17.0453 - Test Loss: 41.9132 - MSE: 41.9132 - MAE: 5.2888\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2805/20000 - Train Loss: 17.0431 - Test Loss: 41.9082 - MSE: 41.9082 - MAE: 5.2885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2806/20000 - Train Loss: 17.0408 - Test Loss: 41.9032 - MSE: 41.9032 - MAE: 5.2882\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2807/20000 - Train Loss: 17.0385 - Test Loss: 41.8982 - MSE: 41.8982 - MAE: 5.2878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2808/20000 - Train Loss: 17.0362 - Test Loss: 41.8932 - MSE: 41.8932 - MAE: 5.2875\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2809/20000 - Train Loss: 17.0339 - Test Loss: 41.8882 - MSE: 41.8882 - MAE: 5.2871\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2810/20000 - Train Loss: 17.0317 - Test Loss: 41.8831 - MSE: 41.8831 - MAE: 5.2868\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2811/20000 - Train Loss: 17.0294 - Test Loss: 41.8780 - MSE: 41.8780 - MAE: 5.2865\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2812/20000 - Train Loss: 17.0271 - Test Loss: 41.8731 - MSE: 41.8731 - MAE: 5.2861\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2813/20000 - Train Loss: 17.0248 - Test Loss: 41.8681 - MSE: 41.8681 - MAE: 5.2858\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2814/20000 - Train Loss: 17.0225 - Test Loss: 41.8630 - MSE: 41.8630 - MAE: 5.2855\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2815/20000 - Train Loss: 17.0202 - Test Loss: 41.8581 - MSE: 41.8581 - MAE: 5.2851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2816/20000 - Train Loss: 17.0179 - Test Loss: 41.8531 - MSE: 41.8531 - MAE: 5.2848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2817/20000 - Train Loss: 17.0156 - Test Loss: 41.8480 - MSE: 41.8480 - MAE: 5.2844\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2818/20000 - Train Loss: 17.0134 - Test Loss: 41.8430 - MSE: 41.8430 - MAE: 5.2841\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2819/20000 - Train Loss: 17.0111 - Test Loss: 41.8380 - MSE: 41.8380 - MAE: 5.2838\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2820/20000 - Train Loss: 17.0088 - Test Loss: 41.8330 - MSE: 41.8330 - MAE: 5.2834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2821/20000 - Train Loss: 17.0065 - Test Loss: 41.8279 - MSE: 41.8279 - MAE: 5.2831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2822/20000 - Train Loss: 17.0042 - Test Loss: 41.8230 - MSE: 41.8230 - MAE: 5.2828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2823/20000 - Train Loss: 17.0019 - Test Loss: 41.8179 - MSE: 41.8179 - MAE: 5.2824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2824/20000 - Train Loss: 16.9996 - Test Loss: 41.8128 - MSE: 41.8128 - MAE: 5.2821\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2825/20000 - Train Loss: 16.9973 - Test Loss: 41.8078 - MSE: 41.8078 - MAE: 5.2817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2826/20000 - Train Loss: 16.9950 - Test Loss: 41.8027 - MSE: 41.8027 - MAE: 5.2814\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2827/20000 - Train Loss: 16.9927 - Test Loss: 41.7977 - MSE: 41.7977 - MAE: 5.2811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2828/20000 - Train Loss: 16.9904 - Test Loss: 41.7926 - MSE: 41.7926 - MAE: 5.2807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2829/20000 - Train Loss: 16.9881 - Test Loss: 41.7876 - MSE: 41.7876 - MAE: 5.2804\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2830/20000 - Train Loss: 16.9858 - Test Loss: 41.7826 - MSE: 41.7826 - MAE: 5.2800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2831/20000 - Train Loss: 16.9835 - Test Loss: 41.7775 - MSE: 41.7775 - MAE: 5.2797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2832/20000 - Train Loss: 16.9812 - Test Loss: 41.7725 - MSE: 41.7725 - MAE: 5.2794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2833/20000 - Train Loss: 16.9789 - Test Loss: 41.7673 - MSE: 41.7673 - MAE: 5.2790\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2834/20000 - Train Loss: 16.9766 - Test Loss: 41.7623 - MSE: 41.7623 - MAE: 5.2787\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2835/20000 - Train Loss: 16.9743 - Test Loss: 41.7572 - MSE: 41.7572 - MAE: 5.2783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2836/20000 - Train Loss: 16.9720 - Test Loss: 41.7522 - MSE: 41.7522 - MAE: 5.2780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2837/20000 - Train Loss: 16.9697 - Test Loss: 41.7472 - MSE: 41.7472 - MAE: 5.2777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2838/20000 - Train Loss: 16.9673 - Test Loss: 41.7420 - MSE: 41.7420 - MAE: 5.2773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2839/20000 - Train Loss: 16.9650 - Test Loss: 41.7370 - MSE: 41.7370 - MAE: 5.2770\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2840/20000 - Train Loss: 16.9627 - Test Loss: 41.7319 - MSE: 41.7319 - MAE: 5.2766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2841/20000 - Train Loss: 16.9604 - Test Loss: 41.7268 - MSE: 41.7268 - MAE: 5.2763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2842/20000 - Train Loss: 16.9581 - Test Loss: 41.7218 - MSE: 41.7218 - MAE: 5.2760\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2843/20000 - Train Loss: 16.9558 - Test Loss: 41.7167 - MSE: 41.7167 - MAE: 5.2756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2844/20000 - Train Loss: 16.9535 - Test Loss: 41.7117 - MSE: 41.7117 - MAE: 5.2753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2845/20000 - Train Loss: 16.9512 - Test Loss: 41.7065 - MSE: 41.7065 - MAE: 5.2749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2846/20000 - Train Loss: 16.9489 - Test Loss: 41.7015 - MSE: 41.7015 - MAE: 5.2746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2847/20000 - Train Loss: 16.9465 - Test Loss: 41.6964 - MSE: 41.6964 - MAE: 5.2742\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2848/20000 - Train Loss: 16.9442 - Test Loss: 41.6913 - MSE: 41.6913 - MAE: 5.2739\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2849/20000 - Train Loss: 16.9419 - Test Loss: 41.6862 - MSE: 41.6862 - MAE: 5.2736\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 2850/20000 - Train Loss: 16.9396 - Test Loss: 41.6812 - MSE: 41.6812 - MAE: 5.2732\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2851/20000 - Train Loss: 16.9373 - Test Loss: 41.6761 - MSE: 41.6761 - MAE: 5.2729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2852/20000 - Train Loss: 16.9349 - Test Loss: 41.6710 - MSE: 41.6710 - MAE: 5.2725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2853/20000 - Train Loss: 16.9326 - Test Loss: 41.6659 - MSE: 41.6659 - MAE: 5.2722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2854/20000 - Train Loss: 16.9303 - Test Loss: 41.6608 - MSE: 41.6608 - MAE: 5.2718\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2855/20000 - Train Loss: 16.9280 - Test Loss: 41.6557 - MSE: 41.6557 - MAE: 5.2715\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2856/20000 - Train Loss: 16.9256 - Test Loss: 41.6506 - MSE: 41.6506 - MAE: 5.2712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2857/20000 - Train Loss: 16.9233 - Test Loss: 41.6455 - MSE: 41.6455 - MAE: 5.2708\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2858/20000 - Train Loss: 16.9210 - Test Loss: 41.6405 - MSE: 41.6405 - MAE: 5.2705\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 2859/20000 - Train Loss: 16.9187 - Test Loss: 41.6353 - MSE: 41.6353 - MAE: 5.2701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2860/20000 - Train Loss: 16.9163 - Test Loss: 41.6302 - MSE: 41.6301 - MAE: 5.2698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2861/20000 - Train Loss: 16.9140 - Test Loss: 41.6250 - MSE: 41.6250 - MAE: 5.2694\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2862/20000 - Train Loss: 16.9117 - Test Loss: 41.6199 - MSE: 41.6199 - MAE: 5.2691\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2863/20000 - Train Loss: 16.9093 - Test Loss: 41.6148 - MSE: 41.6148 - MAE: 5.2687\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2864/20000 - Train Loss: 16.9070 - Test Loss: 41.6097 - MSE: 41.6097 - MAE: 5.2684\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2865/20000 - Train Loss: 16.9047 - Test Loss: 41.6045 - MSE: 41.6045 - MAE: 5.2681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2866/20000 - Train Loss: 16.9023 - Test Loss: 41.5995 - MSE: 41.5995 - MAE: 5.2677\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2867/20000 - Train Loss: 16.9000 - Test Loss: 41.5944 - MSE: 41.5944 - MAE: 5.2674\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2868/20000 - Train Loss: 16.8977 - Test Loss: 41.5893 - MSE: 41.5893 - MAE: 5.2670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2869/20000 - Train Loss: 16.8953 - Test Loss: 41.5841 - MSE: 41.5841 - MAE: 5.2667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2870/20000 - Train Loss: 16.8930 - Test Loss: 41.5790 - MSE: 41.5790 - MAE: 5.2663\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2871/20000 - Train Loss: 16.8907 - Test Loss: 41.5739 - MSE: 41.5739 - MAE: 5.2660\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2872/20000 - Train Loss: 16.8883 - Test Loss: 41.5688 - MSE: 41.5688 - MAE: 5.2656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2873/20000 - Train Loss: 16.8860 - Test Loss: 41.5636 - MSE: 41.5636 - MAE: 5.2653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2874/20000 - Train Loss: 16.8837 - Test Loss: 41.5585 - MSE: 41.5585 - MAE: 5.2649\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2875/20000 - Train Loss: 16.8813 - Test Loss: 41.5534 - MSE: 41.5534 - MAE: 5.2646\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2876/20000 - Train Loss: 16.8790 - Test Loss: 41.5482 - MSE: 41.5483 - MAE: 5.2643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2877/20000 - Train Loss: 16.8766 - Test Loss: 41.5432 - MSE: 41.5432 - MAE: 5.2639\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2878/20000 - Train Loss: 16.8743 - Test Loss: 41.5380 - MSE: 41.5380 - MAE: 5.2636\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2879/20000 - Train Loss: 16.8719 - Test Loss: 41.5328 - MSE: 41.5328 - MAE: 5.2632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2880/20000 - Train Loss: 16.8696 - Test Loss: 41.5277 - MSE: 41.5277 - MAE: 5.2629\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2881/20000 - Train Loss: 16.8672 - Test Loss: 41.5224 - MSE: 41.5224 - MAE: 5.2625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2882/20000 - Train Loss: 16.8649 - Test Loss: 41.5173 - MSE: 41.5173 - MAE: 5.2622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2883/20000 - Train Loss: 16.8625 - Test Loss: 41.5121 - MSE: 41.5121 - MAE: 5.2618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2884/20000 - Train Loss: 16.8602 - Test Loss: 41.5069 - MSE: 41.5069 - MAE: 5.2615\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2885/20000 - Train Loss: 16.8578 - Test Loss: 41.5018 - MSE: 41.5018 - MAE: 5.2611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2886/20000 - Train Loss: 16.8555 - Test Loss: 41.4966 - MSE: 41.4966 - MAE: 5.2608\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2887/20000 - Train Loss: 16.8531 - Test Loss: 41.4915 - MSE: 41.4915 - MAE: 5.2604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2888/20000 - Train Loss: 16.8508 - Test Loss: 41.4864 - MSE: 41.4864 - MAE: 5.2601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2889/20000 - Train Loss: 16.8484 - Test Loss: 41.4811 - MSE: 41.4811 - MAE: 5.2597\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2890/20000 - Train Loss: 16.8461 - Test Loss: 41.4760 - MSE: 41.4760 - MAE: 5.2594\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2891/20000 - Train Loss: 16.8437 - Test Loss: 41.4709 - MSE: 41.4709 - MAE: 5.2590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2892/20000 - Train Loss: 16.8414 - Test Loss: 41.4657 - MSE: 41.4657 - MAE: 5.2587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2893/20000 - Train Loss: 16.8390 - Test Loss: 41.4606 - MSE: 41.4606 - MAE: 5.2583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2894/20000 - Train Loss: 16.8367 - Test Loss: 41.4554 - MSE: 41.4554 - MAE: 5.2580\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2895/20000 - Train Loss: 16.8343 - Test Loss: 41.4502 - MSE: 41.4502 - MAE: 5.2576\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2896/20000 - Train Loss: 16.8319 - Test Loss: 41.4450 - MSE: 41.4450 - MAE: 5.2573\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2897/20000 - Train Loss: 16.8296 - Test Loss: 41.4399 - MSE: 41.4399 - MAE: 5.2569\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2898/20000 - Train Loss: 16.8272 - Test Loss: 41.4347 - MSE: 41.4347 - MAE: 5.2566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2899/20000 - Train Loss: 16.8249 - Test Loss: 41.4296 - MSE: 41.4296 - MAE: 5.2562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2900/20000 - Train Loss: 16.8225 - Test Loss: 41.4244 - MSE: 41.4244 - MAE: 5.2559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2901/20000 - Train Loss: 16.8201 - Test Loss: 41.4192 - MSE: 41.4192 - MAE: 5.2555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2902/20000 - Train Loss: 16.8178 - Test Loss: 41.4139 - MSE: 41.4139 - MAE: 5.2552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2903/20000 - Train Loss: 16.8154 - Test Loss: 41.4088 - MSE: 41.4088 - MAE: 5.2548\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2904/20000 - Train Loss: 16.8130 - Test Loss: 41.4036 - MSE: 41.4036 - MAE: 5.2545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2905/20000 - Train Loss: 16.8107 - Test Loss: 41.3983 - MSE: 41.3984 - MAE: 5.2541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2906/20000 - Train Loss: 16.8083 - Test Loss: 41.3932 - MSE: 41.3932 - MAE: 5.2538\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 2907/20000 - Train Loss: 16.8059 - Test Loss: 41.3879 - MSE: 41.3879 - MAE: 5.2534\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2908/20000 - Train Loss: 16.8035 - Test Loss: 41.3827 - MSE: 41.3827 - MAE: 5.2531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2909/20000 - Train Loss: 16.8012 - Test Loss: 41.3774 - MSE: 41.3774 - MAE: 5.2527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2910/20000 - Train Loss: 16.7988 - Test Loss: 41.3723 - MSE: 41.3723 - MAE: 5.2524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2911/20000 - Train Loss: 16.7964 - Test Loss: 41.3671 - MSE: 41.3671 - MAE: 5.2520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2912/20000 - Train Loss: 16.7941 - Test Loss: 41.3619 - MSE: 41.3619 - MAE: 5.2517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2913/20000 - Train Loss: 16.7917 - Test Loss: 41.3567 - MSE: 41.3567 - MAE: 5.2513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2914/20000 - Train Loss: 16.7893 - Test Loss: 41.3515 - MSE: 41.3515 - MAE: 5.2510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2915/20000 - Train Loss: 16.7869 - Test Loss: 41.3463 - MSE: 41.3463 - MAE: 5.2506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2916/20000 - Train Loss: 16.7845 - Test Loss: 41.3411 - MSE: 41.3411 - MAE: 5.2502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2917/20000 - Train Loss: 16.7822 - Test Loss: 41.3359 - MSE: 41.3359 - MAE: 5.2499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2918/20000 - Train Loss: 16.7798 - Test Loss: 41.3307 - MSE: 41.3307 - MAE: 5.2495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2919/20000 - Train Loss: 16.7774 - Test Loss: 41.3255 - MSE: 41.3255 - MAE: 5.2492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2920/20000 - Train Loss: 16.7750 - Test Loss: 41.3203 - MSE: 41.3203 - MAE: 5.2488\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 2921/20000 - Train Loss: 16.7726 - Test Loss: 41.3150 - MSE: 41.3150 - MAE: 5.2485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2922/20000 - Train Loss: 16.7703 - Test Loss: 41.3098 - MSE: 41.3098 - MAE: 5.2481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2923/20000 - Train Loss: 16.7679 - Test Loss: 41.3046 - MSE: 41.3046 - MAE: 5.2478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2924/20000 - Train Loss: 16.7655 - Test Loss: 41.2994 - MSE: 41.2994 - MAE: 5.2474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2925/20000 - Train Loss: 16.7631 - Test Loss: 41.2941 - MSE: 41.2941 - MAE: 5.2471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2926/20000 - Train Loss: 16.7607 - Test Loss: 41.2889 - MSE: 41.2889 - MAE: 5.2467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2927/20000 - Train Loss: 16.7583 - Test Loss: 41.2836 - MSE: 41.2836 - MAE: 5.2464\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2928/20000 - Train Loss: 16.7559 - Test Loss: 41.2784 - MSE: 41.2784 - MAE: 5.2460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2929/20000 - Train Loss: 16.7536 - Test Loss: 41.2732 - MSE: 41.2732 - MAE: 5.2456\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2930/20000 - Train Loss: 16.7512 - Test Loss: 41.2679 - MSE: 41.2679 - MAE: 5.2453\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2931/20000 - Train Loss: 16.7488 - Test Loss: 41.2626 - MSE: 41.2626 - MAE: 5.2449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2932/20000 - Train Loss: 16.7464 - Test Loss: 41.2573 - MSE: 41.2573 - MAE: 5.2446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2933/20000 - Train Loss: 16.7440 - Test Loss: 41.2521 - MSE: 41.2521 - MAE: 5.2442\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2934/20000 - Train Loss: 16.7416 - Test Loss: 41.2468 - MSE: 41.2468 - MAE: 5.2439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2935/20000 - Train Loss: 16.7392 - Test Loss: 41.2416 - MSE: 41.2416 - MAE: 5.2435\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 2936/20000 - Train Loss: 16.7368 - Test Loss: 41.2364 - MSE: 41.2364 - MAE: 5.2431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2937/20000 - Train Loss: 16.7344 - Test Loss: 41.2311 - MSE: 41.2311 - MAE: 5.2428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2938/20000 - Train Loss: 16.7320 - Test Loss: 41.2259 - MSE: 41.2259 - MAE: 5.2424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2939/20000 - Train Loss: 16.7296 - Test Loss: 41.2206 - MSE: 41.2206 - MAE: 5.2421\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2940/20000 - Train Loss: 16.7272 - Test Loss: 41.2154 - MSE: 41.2154 - MAE: 5.2417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2941/20000 - Train Loss: 16.7248 - Test Loss: 41.2101 - MSE: 41.2101 - MAE: 5.2414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2942/20000 - Train Loss: 16.7224 - Test Loss: 41.2049 - MSE: 41.2049 - MAE: 5.2410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2943/20000 - Train Loss: 16.7200 - Test Loss: 41.1996 - MSE: 41.1996 - MAE: 5.2407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2944/20000 - Train Loss: 16.7176 - Test Loss: 41.1943 - MSE: 41.1943 - MAE: 5.2403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2945/20000 - Train Loss: 16.7152 - Test Loss: 41.1891 - MSE: 41.1891 - MAE: 5.2399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2946/20000 - Train Loss: 16.7128 - Test Loss: 41.1838 - MSE: 41.1838 - MAE: 5.2396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2947/20000 - Train Loss: 16.7104 - Test Loss: 41.1785 - MSE: 41.1785 - MAE: 5.2392\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2948/20000 - Train Loss: 16.7080 - Test Loss: 41.1732 - MSE: 41.1732 - MAE: 5.2389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2949/20000 - Train Loss: 16.7056 - Test Loss: 41.1679 - MSE: 41.1679 - MAE: 5.2385\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2950/20000 - Train Loss: 16.7032 - Test Loss: 41.1626 - MSE: 41.1626 - MAE: 5.2381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2951/20000 - Train Loss: 16.7008 - Test Loss: 41.1574 - MSE: 41.1573 - MAE: 5.2378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2952/20000 - Train Loss: 16.6984 - Test Loss: 41.1520 - MSE: 41.1520 - MAE: 5.2374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2953/20000 - Train Loss: 16.6959 - Test Loss: 41.1469 - MSE: 41.1469 - MAE: 5.2371\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 2954/20000 - Train Loss: 16.6935 - Test Loss: 41.1415 - MSE: 41.1415 - MAE: 5.2367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2955/20000 - Train Loss: 16.6911 - Test Loss: 41.1362 - MSE: 41.1362 - MAE: 5.2363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2956/20000 - Train Loss: 16.6887 - Test Loss: 41.1309 - MSE: 41.1309 - MAE: 5.2360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2957/20000 - Train Loss: 16.6863 - Test Loss: 41.1256 - MSE: 41.1256 - MAE: 5.2356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2958/20000 - Train Loss: 16.6839 - Test Loss: 41.1203 - MSE: 41.1203 - MAE: 5.2353\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 2959/20000 - Train Loss: 16.6815 - Test Loss: 41.1150 - MSE: 41.1150 - MAE: 5.2349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2960/20000 - Train Loss: 16.6790 - Test Loss: 41.1097 - MSE: 41.1097 - MAE: 5.2345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2961/20000 - Train Loss: 16.6766 - Test Loss: 41.1044 - MSE: 41.1044 - MAE: 5.2342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2962/20000 - Train Loss: 16.6742 - Test Loss: 41.0991 - MSE: 41.0991 - MAE: 5.2338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2963/20000 - Train Loss: 16.6718 - Test Loss: 41.0938 - MSE: 41.0938 - MAE: 5.2335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2964/20000 - Train Loss: 16.6694 - Test Loss: 41.0885 - MSE: 41.0885 - MAE: 5.2331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2965/20000 - Train Loss: 16.6669 - Test Loss: 41.0832 - MSE: 41.0832 - MAE: 5.2327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2966/20000 - Train Loss: 16.6645 - Test Loss: 41.0779 - MSE: 41.0779 - MAE: 5.2324\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2967/20000 - Train Loss: 16.6621 - Test Loss: 41.0726 - MSE: 41.0726 - MAE: 5.2320\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 2968/20000 - Train Loss: 16.6597 - Test Loss: 41.0673 - MSE: 41.0673 - MAE: 5.2317\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 2969/20000 - Train Loss: 16.6572 - Test Loss: 41.0620 - MSE: 41.0620 - MAE: 5.2313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2970/20000 - Train Loss: 16.6548 - Test Loss: 41.0567 - MSE: 41.0567 - MAE: 5.2309\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 2971/20000 - Train Loss: 16.6524 - Test Loss: 41.0513 - MSE: 41.0513 - MAE: 5.2306\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2972/20000 - Train Loss: 16.6500 - Test Loss: 41.0461 - MSE: 41.0461 - MAE: 5.2302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2973/20000 - Train Loss: 16.6475 - Test Loss: 41.0407 - MSE: 41.0407 - MAE: 5.2299\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 2974/20000 - Train Loss: 16.6451 - Test Loss: 41.0354 - MSE: 41.0354 - MAE: 5.2295\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2975/20000 - Train Loss: 16.6427 - Test Loss: 41.0300 - MSE: 41.0300 - MAE: 5.2291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2976/20000 - Train Loss: 16.6402 - Test Loss: 41.0247 - MSE: 41.0247 - MAE: 5.2288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2977/20000 - Train Loss: 16.6378 - Test Loss: 41.0193 - MSE: 41.0193 - MAE: 5.2284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2978/20000 - Train Loss: 16.6354 - Test Loss: 41.0140 - MSE: 41.0140 - MAE: 5.2280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2979/20000 - Train Loss: 16.6330 - Test Loss: 41.0086 - MSE: 41.0086 - MAE: 5.2277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2980/20000 - Train Loss: 16.6305 - Test Loss: 41.0033 - MSE: 41.0033 - MAE: 5.2273\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 2981/20000 - Train Loss: 16.6281 - Test Loss: 40.9980 - MSE: 40.9980 - MAE: 5.2269\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2982/20000 - Train Loss: 16.6256 - Test Loss: 40.9927 - MSE: 40.9927 - MAE: 5.2266\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2983/20000 - Train Loss: 16.6232 - Test Loss: 40.9873 - MSE: 40.9873 - MAE: 5.2262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2984/20000 - Train Loss: 16.6208 - Test Loss: 40.9819 - MSE: 40.9819 - MAE: 5.2259\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 2985/20000 - Train Loss: 16.6183 - Test Loss: 40.9765 - MSE: 40.9765 - MAE: 5.2255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2986/20000 - Train Loss: 16.6159 - Test Loss: 40.9712 - MSE: 40.9712 - MAE: 5.2251\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 2987/20000 - Train Loss: 16.6134 - Test Loss: 40.9659 - MSE: 40.9659 - MAE: 5.2248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2988/20000 - Train Loss: 16.6110 - Test Loss: 40.9605 - MSE: 40.9605 - MAE: 5.2244\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 2989/20000 - Train Loss: 16.6086 - Test Loss: 40.9552 - MSE: 40.9552 - MAE: 5.2240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2990/20000 - Train Loss: 16.6061 - Test Loss: 40.9498 - MSE: 40.9498 - MAE: 5.2237\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 2991/20000 - Train Loss: 16.6037 - Test Loss: 40.9445 - MSE: 40.9445 - MAE: 5.2233\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2992/20000 - Train Loss: 16.6012 - Test Loss: 40.9392 - MSE: 40.9392 - MAE: 5.2229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2993/20000 - Train Loss: 16.5988 - Test Loss: 40.9338 - MSE: 40.9338 - MAE: 5.2226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2994/20000 - Train Loss: 16.5963 - Test Loss: 40.9285 - MSE: 40.9284 - MAE: 5.2222\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 2995/20000 - Train Loss: 16.5939 - Test Loss: 40.9230 - MSE: 40.9230 - MAE: 5.2218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2996/20000 - Train Loss: 16.5914 - Test Loss: 40.9177 - MSE: 40.9177 - MAE: 5.2215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2997/20000 - Train Loss: 16.5890 - Test Loss: 40.9123 - MSE: 40.9123 - MAE: 5.2211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 2998/20000 - Train Loss: 16.5865 - Test Loss: 40.9070 - MSE: 40.9070 - MAE: 5.2207\n",
      "2/2 [==============================] - 0s 976us/step\n",
      "Epoch 2999/20000 - Train Loss: 16.5841 - Test Loss: 40.9016 - MSE: 40.9016 - MAE: 5.2204\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3000/20000 - Train Loss: 16.5816 - Test Loss: 40.8963 - MSE: 40.8963 - MAE: 5.2200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3001/20000 - Train Loss: 16.5792 - Test Loss: 40.8908 - MSE: 40.8908 - MAE: 5.2196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3002/20000 - Train Loss: 16.5767 - Test Loss: 40.8854 - MSE: 40.8854 - MAE: 5.2193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3003/20000 - Train Loss: 16.5743 - Test Loss: 40.8800 - MSE: 40.8800 - MAE: 5.2189\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3004/20000 - Train Loss: 16.5718 - Test Loss: 40.8746 - MSE: 40.8746 - MAE: 5.2185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3005/20000 - Train Loss: 16.5694 - Test Loss: 40.8692 - MSE: 40.8692 - MAE: 5.2182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3006/20000 - Train Loss: 16.5669 - Test Loss: 40.8639 - MSE: 40.8639 - MAE: 5.2178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3007/20000 - Train Loss: 16.5644 - Test Loss: 40.8584 - MSE: 40.8584 - MAE: 5.2174\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3008/20000 - Train Loss: 16.5620 - Test Loss: 40.8531 - MSE: 40.8531 - MAE: 5.2171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3009/20000 - Train Loss: 16.5595 - Test Loss: 40.8476 - MSE: 40.8476 - MAE: 5.2167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3010/20000 - Train Loss: 16.5570 - Test Loss: 40.8423 - MSE: 40.8423 - MAE: 5.2163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3011/20000 - Train Loss: 16.5546 - Test Loss: 40.8369 - MSE: 40.8369 - MAE: 5.2160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3012/20000 - Train Loss: 16.5521 - Test Loss: 40.8315 - MSE: 40.8315 - MAE: 5.2156\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3013/20000 - Train Loss: 16.5497 - Test Loss: 40.8261 - MSE: 40.8261 - MAE: 5.2152\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3014/20000 - Train Loss: 16.5472 - Test Loss: 40.8207 - MSE: 40.8207 - MAE: 5.2149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3015/20000 - Train Loss: 16.5447 - Test Loss: 40.8153 - MSE: 40.8153 - MAE: 5.2145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3016/20000 - Train Loss: 16.5423 - Test Loss: 40.8099 - MSE: 40.8099 - MAE: 5.2141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3017/20000 - Train Loss: 16.5398 - Test Loss: 40.8045 - MSE: 40.8045 - MAE: 5.2138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3018/20000 - Train Loss: 16.5373 - Test Loss: 40.7991 - MSE: 40.7991 - MAE: 5.2134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3019/20000 - Train Loss: 16.5349 - Test Loss: 40.7937 - MSE: 40.7937 - MAE: 5.2130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3020/20000 - Train Loss: 16.5324 - Test Loss: 40.7883 - MSE: 40.7883 - MAE: 5.2126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3021/20000 - Train Loss: 16.5299 - Test Loss: 40.7828 - MSE: 40.7829 - MAE: 5.2123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3022/20000 - Train Loss: 16.5274 - Test Loss: 40.7775 - MSE: 40.7775 - MAE: 5.2119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3023/20000 - Train Loss: 16.5250 - Test Loss: 40.7720 - MSE: 40.7720 - MAE: 5.2115\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3024/20000 - Train Loss: 16.5225 - Test Loss: 40.7665 - MSE: 40.7665 - MAE: 5.2112\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3025/20000 - Train Loss: 16.5200 - Test Loss: 40.7610 - MSE: 40.7610 - MAE: 5.2108\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3026/20000 - Train Loss: 16.5175 - Test Loss: 40.7557 - MSE: 40.7557 - MAE: 5.2104\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3027/20000 - Train Loss: 16.5151 - Test Loss: 40.7502 - MSE: 40.7502 - MAE: 5.2100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3028/20000 - Train Loss: 16.5126 - Test Loss: 40.7447 - MSE: 40.7447 - MAE: 5.2097\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3029/20000 - Train Loss: 16.5101 - Test Loss: 40.7393 - MSE: 40.7393 - MAE: 5.2093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3030/20000 - Train Loss: 16.5076 - Test Loss: 40.7339 - MSE: 40.7339 - MAE: 5.2089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3031/20000 - Train Loss: 16.5051 - Test Loss: 40.7285 - MSE: 40.7285 - MAE: 5.2086\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3032/20000 - Train Loss: 16.5027 - Test Loss: 40.7231 - MSE: 40.7231 - MAE: 5.2082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3033/20000 - Train Loss: 16.5002 - Test Loss: 40.7177 - MSE: 40.7177 - MAE: 5.2078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3034/20000 - Train Loss: 16.4977 - Test Loss: 40.7122 - MSE: 40.7122 - MAE: 5.2074\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 3035/20000 - Train Loss: 16.4952 - Test Loss: 40.7068 - MSE: 40.7068 - MAE: 5.2071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3036/20000 - Train Loss: 16.4927 - Test Loss: 40.7014 - MSE: 40.7014 - MAE: 5.2067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3037/20000 - Train Loss: 16.4902 - Test Loss: 40.6959 - MSE: 40.6959 - MAE: 5.2063\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3038/20000 - Train Loss: 16.4878 - Test Loss: 40.6905 - MSE: 40.6905 - MAE: 5.2060\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3039/20000 - Train Loss: 16.4853 - Test Loss: 40.6850 - MSE: 40.6850 - MAE: 5.2056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3040/20000 - Train Loss: 16.4828 - Test Loss: 40.6795 - MSE: 40.6795 - MAE: 5.2052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3041/20000 - Train Loss: 16.4803 - Test Loss: 40.6741 - MSE: 40.6741 - MAE: 5.2048\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3042/20000 - Train Loss: 16.4778 - Test Loss: 40.6686 - MSE: 40.6686 - MAE: 5.2045\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3043/20000 - Train Loss: 16.4753 - Test Loss: 40.6631 - MSE: 40.6631 - MAE: 5.2041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3044/20000 - Train Loss: 16.4728 - Test Loss: 40.6576 - MSE: 40.6576 - MAE: 5.2037\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3045/20000 - Train Loss: 16.4703 - Test Loss: 40.6522 - MSE: 40.6522 - MAE: 5.2033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3046/20000 - Train Loss: 16.4678 - Test Loss: 40.6467 - MSE: 40.6467 - MAE: 5.2030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3047/20000 - Train Loss: 16.4653 - Test Loss: 40.6412 - MSE: 40.6412 - MAE: 5.2026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3048/20000 - Train Loss: 16.4628 - Test Loss: 40.6358 - MSE: 40.6358 - MAE: 5.2022\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3049/20000 - Train Loss: 16.4603 - Test Loss: 40.6303 - MSE: 40.6303 - MAE: 5.2018\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3050/20000 - Train Loss: 16.4578 - Test Loss: 40.6248 - MSE: 40.6248 - MAE: 5.2015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3051/20000 - Train Loss: 16.4554 - Test Loss: 40.6194 - MSE: 40.6194 - MAE: 5.2011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3052/20000 - Train Loss: 16.4529 - Test Loss: 40.6139 - MSE: 40.6139 - MAE: 5.2007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3053/20000 - Train Loss: 16.4504 - Test Loss: 40.6084 - MSE: 40.6084 - MAE: 5.2003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3054/20000 - Train Loss: 16.4478 - Test Loss: 40.6029 - MSE: 40.6029 - MAE: 5.2000\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3055/20000 - Train Loss: 16.4453 - Test Loss: 40.5975 - MSE: 40.5975 - MAE: 5.1996\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3056/20000 - Train Loss: 16.4428 - Test Loss: 40.5920 - MSE: 40.5920 - MAE: 5.1992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3057/20000 - Train Loss: 16.4403 - Test Loss: 40.5865 - MSE: 40.5865 - MAE: 5.1988\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3058/20000 - Train Loss: 16.4378 - Test Loss: 40.5810 - MSE: 40.5810 - MAE: 5.1985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3059/20000 - Train Loss: 16.4353 - Test Loss: 40.5756 - MSE: 40.5756 - MAE: 5.1981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3060/20000 - Train Loss: 16.4328 - Test Loss: 40.5701 - MSE: 40.5701 - MAE: 5.1977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3061/20000 - Train Loss: 16.4303 - Test Loss: 40.5646 - MSE: 40.5646 - MAE: 5.1973\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3062/20000 - Train Loss: 16.4278 - Test Loss: 40.5591 - MSE: 40.5591 - MAE: 5.1970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3063/20000 - Train Loss: 16.4253 - Test Loss: 40.5536 - MSE: 40.5536 - MAE: 5.1966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3064/20000 - Train Loss: 16.4228 - Test Loss: 40.5480 - MSE: 40.5480 - MAE: 5.1962\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3065/20000 - Train Loss: 16.4203 - Test Loss: 40.5426 - MSE: 40.5426 - MAE: 5.1958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3066/20000 - Train Loss: 16.4178 - Test Loss: 40.5370 - MSE: 40.5370 - MAE: 5.1954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3067/20000 - Train Loss: 16.4153 - Test Loss: 40.5315 - MSE: 40.5315 - MAE: 5.1951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3068/20000 - Train Loss: 16.4127 - Test Loss: 40.5260 - MSE: 40.5260 - MAE: 5.1947\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3069/20000 - Train Loss: 16.4102 - Test Loss: 40.5204 - MSE: 40.5204 - MAE: 5.1943\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3070/20000 - Train Loss: 16.4077 - Test Loss: 40.5149 - MSE: 40.5149 - MAE: 5.1939\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3071/20000 - Train Loss: 16.4052 - Test Loss: 40.5094 - MSE: 40.5094 - MAE: 5.1935\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3072/20000 - Train Loss: 16.4027 - Test Loss: 40.5039 - MSE: 40.5039 - MAE: 5.1932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3073/20000 - Train Loss: 16.4002 - Test Loss: 40.4984 - MSE: 40.4984 - MAE: 5.1928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3074/20000 - Train Loss: 16.3976 - Test Loss: 40.4929 - MSE: 40.4929 - MAE: 5.1924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3075/20000 - Train Loss: 16.3951 - Test Loss: 40.4873 - MSE: 40.4873 - MAE: 5.1920\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3076/20000 - Train Loss: 16.3926 - Test Loss: 40.4818 - MSE: 40.4818 - MAE: 5.1917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3077/20000 - Train Loss: 16.3901 - Test Loss: 40.4763 - MSE: 40.4763 - MAE: 5.1913\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3078/20000 - Train Loss: 16.3876 - Test Loss: 40.4708 - MSE: 40.4708 - MAE: 5.1909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3079/20000 - Train Loss: 16.3850 - Test Loss: 40.4653 - MSE: 40.4653 - MAE: 5.1905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3080/20000 - Train Loss: 16.3825 - Test Loss: 40.4598 - MSE: 40.4598 - MAE: 5.1901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3081/20000 - Train Loss: 16.3800 - Test Loss: 40.4543 - MSE: 40.4543 - MAE: 5.1898\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 3082/20000 - Train Loss: 16.3775 - Test Loss: 40.4487 - MSE: 40.4487 - MAE: 5.1894\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3083/20000 - Train Loss: 16.3749 - Test Loss: 40.4432 - MSE: 40.4432 - MAE: 5.1890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3084/20000 - Train Loss: 16.3724 - Test Loss: 40.4377 - MSE: 40.4377 - MAE: 5.1886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3085/20000 - Train Loss: 16.3699 - Test Loss: 40.4321 - MSE: 40.4321 - MAE: 5.1882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3086/20000 - Train Loss: 16.3673 - Test Loss: 40.4265 - MSE: 40.4265 - MAE: 5.1879\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3087/20000 - Train Loss: 16.3648 - Test Loss: 40.4210 - MSE: 40.4210 - MAE: 5.1875\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3088/20000 - Train Loss: 16.3623 - Test Loss: 40.4154 - MSE: 40.4154 - MAE: 5.1871\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3089/20000 - Train Loss: 16.3597 - Test Loss: 40.4099 - MSE: 40.4099 - MAE: 5.1867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3090/20000 - Train Loss: 16.3572 - Test Loss: 40.4043 - MSE: 40.4043 - MAE: 5.1863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3091/20000 - Train Loss: 16.3547 - Test Loss: 40.3988 - MSE: 40.3988 - MAE: 5.1859\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3092/20000 - Train Loss: 16.3521 - Test Loss: 40.3931 - MSE: 40.3931 - MAE: 5.1856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3093/20000 - Train Loss: 16.3496 - Test Loss: 40.3876 - MSE: 40.3876 - MAE: 5.1852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3094/20000 - Train Loss: 16.3471 - Test Loss: 40.3820 - MSE: 40.3820 - MAE: 5.1848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3095/20000 - Train Loss: 16.3445 - Test Loss: 40.3764 - MSE: 40.3764 - MAE: 5.1844\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3096/20000 - Train Loss: 16.3420 - Test Loss: 40.3709 - MSE: 40.3709 - MAE: 5.1840\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3097/20000 - Train Loss: 16.3394 - Test Loss: 40.3654 - MSE: 40.3654 - MAE: 5.1836\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3098/20000 - Train Loss: 16.3369 - Test Loss: 40.3599 - MSE: 40.3599 - MAE: 5.1833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3099/20000 - Train Loss: 16.3344 - Test Loss: 40.3543 - MSE: 40.3543 - MAE: 5.1829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3100/20000 - Train Loss: 16.3318 - Test Loss: 40.3487 - MSE: 40.3487 - MAE: 5.1825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3101/20000 - Train Loss: 16.3293 - Test Loss: 40.3431 - MSE: 40.3431 - MAE: 5.1821\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3102/20000 - Train Loss: 16.3267 - Test Loss: 40.3376 - MSE: 40.3376 - MAE: 5.1817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3103/20000 - Train Loss: 16.3242 - Test Loss: 40.3321 - MSE: 40.3321 - MAE: 5.1814\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3104/20000 - Train Loss: 16.3216 - Test Loss: 40.3265 - MSE: 40.3265 - MAE: 5.1810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3105/20000 - Train Loss: 16.3191 - Test Loss: 40.3208 - MSE: 40.3208 - MAE: 5.1806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3106/20000 - Train Loss: 16.3166 - Test Loss: 40.3153 - MSE: 40.3153 - MAE: 5.1802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3107/20000 - Train Loss: 16.3140 - Test Loss: 40.3097 - MSE: 40.3097 - MAE: 5.1798\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3108/20000 - Train Loss: 16.3115 - Test Loss: 40.3041 - MSE: 40.3041 - MAE: 5.1794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3109/20000 - Train Loss: 16.3089 - Test Loss: 40.2985 - MSE: 40.2985 - MAE: 5.1790\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3110/20000 - Train Loss: 16.3064 - Test Loss: 40.2929 - MSE: 40.2929 - MAE: 5.1787\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3111/20000 - Train Loss: 16.3038 - Test Loss: 40.2873 - MSE: 40.2873 - MAE: 5.1783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3112/20000 - Train Loss: 16.3012 - Test Loss: 40.2817 - MSE: 40.2817 - MAE: 5.1779\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3113/20000 - Train Loss: 16.2987 - Test Loss: 40.2761 - MSE: 40.2761 - MAE: 5.1775\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 3114/20000 - Train Loss: 16.2961 - Test Loss: 40.2705 - MSE: 40.2705 - MAE: 5.1771\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3115/20000 - Train Loss: 16.2936 - Test Loss: 40.2649 - MSE: 40.2649 - MAE: 5.1767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3116/20000 - Train Loss: 16.2910 - Test Loss: 40.2593 - MSE: 40.2593 - MAE: 5.1763\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3117/20000 - Train Loss: 16.2885 - Test Loss: 40.2537 - MSE: 40.2537 - MAE: 5.1760\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 3118/20000 - Train Loss: 16.2859 - Test Loss: 40.2481 - MSE: 40.2481 - MAE: 5.1756\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3119/20000 - Train Loss: 16.2833 - Test Loss: 40.2425 - MSE: 40.2425 - MAE: 5.1752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3120/20000 - Train Loss: 16.2808 - Test Loss: 40.2369 - MSE: 40.2369 - MAE: 5.1748\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3121/20000 - Train Loss: 16.2782 - Test Loss: 40.2313 - MSE: 40.2313 - MAE: 5.1744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3122/20000 - Train Loss: 16.2757 - Test Loss: 40.2257 - MSE: 40.2257 - MAE: 5.1740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3123/20000 - Train Loss: 16.2731 - Test Loss: 40.2201 - MSE: 40.2201 - MAE: 5.1736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3124/20000 - Train Loss: 16.2705 - Test Loss: 40.2145 - MSE: 40.2145 - MAE: 5.1733\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3125/20000 - Train Loss: 16.2680 - Test Loss: 40.2089 - MSE: 40.2089 - MAE: 5.1729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3126/20000 - Train Loss: 16.2654 - Test Loss: 40.2033 - MSE: 40.2033 - MAE: 5.1725\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3127/20000 - Train Loss: 16.2628 - Test Loss: 40.1976 - MSE: 40.1976 - MAE: 5.1721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3128/20000 - Train Loss: 16.2603 - Test Loss: 40.1920 - MSE: 40.1920 - MAE: 5.1717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3129/20000 - Train Loss: 16.2577 - Test Loss: 40.1863 - MSE: 40.1863 - MAE: 5.1713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3130/20000 - Train Loss: 16.2551 - Test Loss: 40.1807 - MSE: 40.1807 - MAE: 5.1709\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3131/20000 - Train Loss: 16.2526 - Test Loss: 40.1750 - MSE: 40.1750 - MAE: 5.1705\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3132/20000 - Train Loss: 16.2500 - Test Loss: 40.1694 - MSE: 40.1694 - MAE: 5.1701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3133/20000 - Train Loss: 16.2474 - Test Loss: 40.1637 - MSE: 40.1637 - MAE: 5.1698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3134/20000 - Train Loss: 16.2448 - Test Loss: 40.1581 - MSE: 40.1581 - MAE: 5.1694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3135/20000 - Train Loss: 16.2423 - Test Loss: 40.1524 - MSE: 40.1524 - MAE: 5.1690\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3136/20000 - Train Loss: 16.2397 - Test Loss: 40.1468 - MSE: 40.1468 - MAE: 5.1686\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3137/20000 - Train Loss: 16.2371 - Test Loss: 40.1412 - MSE: 40.1412 - MAE: 5.1682\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3138/20000 - Train Loss: 16.2345 - Test Loss: 40.1355 - MSE: 40.1355 - MAE: 5.1678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3139/20000 - Train Loss: 16.2320 - Test Loss: 40.1299 - MSE: 40.1299 - MAE: 5.1674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3140/20000 - Train Loss: 16.2294 - Test Loss: 40.1243 - MSE: 40.1243 - MAE: 5.1670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3141/20000 - Train Loss: 16.2268 - Test Loss: 40.1186 - MSE: 40.1186 - MAE: 5.1666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3142/20000 - Train Loss: 16.2242 - Test Loss: 40.1131 - MSE: 40.1130 - MAE: 5.1663\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3143/20000 - Train Loss: 16.2216 - Test Loss: 40.1074 - MSE: 40.1074 - MAE: 5.1659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3144/20000 - Train Loss: 16.2191 - Test Loss: 40.1017 - MSE: 40.1017 - MAE: 5.1655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3145/20000 - Train Loss: 16.2165 - Test Loss: 40.0960 - MSE: 40.0960 - MAE: 5.1651\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3146/20000 - Train Loss: 16.2139 - Test Loss: 40.0904 - MSE: 40.0904 - MAE: 5.1647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3147/20000 - Train Loss: 16.2113 - Test Loss: 40.0847 - MSE: 40.0847 - MAE: 5.1643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3148/20000 - Train Loss: 16.2087 - Test Loss: 40.0791 - MSE: 40.0791 - MAE: 5.1639\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3149/20000 - Train Loss: 16.2061 - Test Loss: 40.0734 - MSE: 40.0734 - MAE: 5.1635\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3150/20000 - Train Loss: 16.2035 - Test Loss: 40.0677 - MSE: 40.0677 - MAE: 5.1631\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3151/20000 - Train Loss: 16.2010 - Test Loss: 40.0620 - MSE: 40.0620 - MAE: 5.1627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3152/20000 - Train Loss: 16.1984 - Test Loss: 40.0564 - MSE: 40.0564 - MAE: 5.1623\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3153/20000 - Train Loss: 16.1958 - Test Loss: 40.0506 - MSE: 40.0506 - MAE: 5.1619\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3154/20000 - Train Loss: 16.1932 - Test Loss: 40.0449 - MSE: 40.0449 - MAE: 5.1615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3155/20000 - Train Loss: 16.1906 - Test Loss: 40.0393 - MSE: 40.0393 - MAE: 5.1612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3156/20000 - Train Loss: 16.1880 - Test Loss: 40.0336 - MSE: 40.0336 - MAE: 5.1608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3157/20000 - Train Loss: 16.1854 - Test Loss: 40.0279 - MSE: 40.0279 - MAE: 5.1604\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3158/20000 - Train Loss: 16.1828 - Test Loss: 40.0222 - MSE: 40.0222 - MAE: 5.1600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3159/20000 - Train Loss: 16.1802 - Test Loss: 40.0166 - MSE: 40.0166 - MAE: 5.1596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3160/20000 - Train Loss: 16.1776 - Test Loss: 40.0109 - MSE: 40.0109 - MAE: 5.1592\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3161/20000 - Train Loss: 16.1750 - Test Loss: 40.0052 - MSE: 40.0052 - MAE: 5.1588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3162/20000 - Train Loss: 16.1724 - Test Loss: 39.9996 - MSE: 39.9996 - MAE: 5.1584\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3163/20000 - Train Loss: 16.1698 - Test Loss: 39.9939 - MSE: 39.9939 - MAE: 5.1580\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3164/20000 - Train Loss: 16.1672 - Test Loss: 39.9882 - MSE: 39.9882 - MAE: 5.1576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3165/20000 - Train Loss: 16.1646 - Test Loss: 39.9825 - MSE: 39.9825 - MAE: 5.1572\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3166/20000 - Train Loss: 16.1620 - Test Loss: 39.9768 - MSE: 39.9768 - MAE: 5.1568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3167/20000 - Train Loss: 16.1594 - Test Loss: 39.9711 - MSE: 39.9711 - MAE: 5.1564\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3168/20000 - Train Loss: 16.1568 - Test Loss: 39.9654 - MSE: 39.9654 - MAE: 5.1560\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3169/20000 - Train Loss: 16.1542 - Test Loss: 39.9597 - MSE: 39.9597 - MAE: 5.1556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3170/20000 - Train Loss: 16.1516 - Test Loss: 39.9540 - MSE: 39.9540 - MAE: 5.1553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3171/20000 - Train Loss: 16.1490 - Test Loss: 39.9483 - MSE: 39.9483 - MAE: 5.1549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3172/20000 - Train Loss: 16.1464 - Test Loss: 39.9425 - MSE: 39.9425 - MAE: 5.1545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3173/20000 - Train Loss: 16.1438 - Test Loss: 39.9368 - MSE: 39.9368 - MAE: 5.1541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3174/20000 - Train Loss: 16.1412 - Test Loss: 39.9311 - MSE: 39.9311 - MAE: 5.1537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3175/20000 - Train Loss: 16.1386 - Test Loss: 39.9253 - MSE: 39.9253 - MAE: 5.1533\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3176/20000 - Train Loss: 16.1360 - Test Loss: 39.9196 - MSE: 39.9196 - MAE: 5.1529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3177/20000 - Train Loss: 16.1333 - Test Loss: 39.9139 - MSE: 39.9139 - MAE: 5.1525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3178/20000 - Train Loss: 16.1307 - Test Loss: 39.9081 - MSE: 39.9081 - MAE: 5.1521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3179/20000 - Train Loss: 16.1281 - Test Loss: 39.9024 - MSE: 39.9024 - MAE: 5.1517\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 3180/20000 - Train Loss: 16.1255 - Test Loss: 39.8967 - MSE: 39.8967 - MAE: 5.1513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3181/20000 - Train Loss: 16.1229 - Test Loss: 39.8910 - MSE: 39.8910 - MAE: 5.1509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3182/20000 - Train Loss: 16.1203 - Test Loss: 39.8853 - MSE: 39.8853 - MAE: 5.1505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3183/20000 - Train Loss: 16.1177 - Test Loss: 39.8796 - MSE: 39.8796 - MAE: 5.1501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3184/20000 - Train Loss: 16.1150 - Test Loss: 39.8739 - MSE: 39.8739 - MAE: 5.1497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3185/20000 - Train Loss: 16.1124 - Test Loss: 39.8681 - MSE: 39.8681 - MAE: 5.1493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3186/20000 - Train Loss: 16.1098 - Test Loss: 39.8624 - MSE: 39.8624 - MAE: 5.1489\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3187/20000 - Train Loss: 16.1072 - Test Loss: 39.8567 - MSE: 39.8567 - MAE: 5.1485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3188/20000 - Train Loss: 16.1046 - Test Loss: 39.8510 - MSE: 39.8510 - MAE: 5.1481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3189/20000 - Train Loss: 16.1019 - Test Loss: 39.8452 - MSE: 39.8452 - MAE: 5.1477\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3190/20000 - Train Loss: 16.0993 - Test Loss: 39.8395 - MSE: 39.8395 - MAE: 5.1473\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 3191/20000 - Train Loss: 16.0967 - Test Loss: 39.8337 - MSE: 39.8337 - MAE: 5.1469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3192/20000 - Train Loss: 16.0941 - Test Loss: 39.8279 - MSE: 39.8279 - MAE: 5.1465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3193/20000 - Train Loss: 16.0914 - Test Loss: 39.8222 - MSE: 39.8222 - MAE: 5.1461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3194/20000 - Train Loss: 16.0888 - Test Loss: 39.8164 - MSE: 39.8164 - MAE: 5.1457\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3195/20000 - Train Loss: 16.0862 - Test Loss: 39.8106 - MSE: 39.8106 - MAE: 5.1453\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3196/20000 - Train Loss: 16.0836 - Test Loss: 39.8048 - MSE: 39.8048 - MAE: 5.1449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3197/20000 - Train Loss: 16.0809 - Test Loss: 39.7990 - MSE: 39.7990 - MAE: 5.1445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3198/20000 - Train Loss: 16.0783 - Test Loss: 39.7933 - MSE: 39.7933 - MAE: 5.1441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3199/20000 - Train Loss: 16.0757 - Test Loss: 39.7875 - MSE: 39.7875 - MAE: 5.1437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3200/20000 - Train Loss: 16.0730 - Test Loss: 39.7818 - MSE: 39.7818 - MAE: 5.1433\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3201/20000 - Train Loss: 16.0704 - Test Loss: 39.7761 - MSE: 39.7760 - MAE: 5.1429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3202/20000 - Train Loss: 16.0678 - Test Loss: 39.7703 - MSE: 39.7703 - MAE: 5.1425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3203/20000 - Train Loss: 16.0651 - Test Loss: 39.7645 - MSE: 39.7646 - MAE: 5.1421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3204/20000 - Train Loss: 16.0625 - Test Loss: 39.7588 - MSE: 39.7588 - MAE: 5.1417\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3205/20000 - Train Loss: 16.0599 - Test Loss: 39.7530 - MSE: 39.7530 - MAE: 5.1413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3206/20000 - Train Loss: 16.0572 - Test Loss: 39.7473 - MSE: 39.7473 - MAE: 5.1409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3207/20000 - Train Loss: 16.0546 - Test Loss: 39.7415 - MSE: 39.7415 - MAE: 5.1405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3208/20000 - Train Loss: 16.0519 - Test Loss: 39.7357 - MSE: 39.7358 - MAE: 5.1401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3209/20000 - Train Loss: 16.0493 - Test Loss: 39.7299 - MSE: 39.7299 - MAE: 5.1397\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3210/20000 - Train Loss: 16.0466 - Test Loss: 39.7241 - MSE: 39.7241 - MAE: 5.1393\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3211/20000 - Train Loss: 16.0440 - Test Loss: 39.7183 - MSE: 39.7183 - MAE: 5.1389\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3212/20000 - Train Loss: 16.0414 - Test Loss: 39.7126 - MSE: 39.7126 - MAE: 5.1385\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3213/20000 - Train Loss: 16.0387 - Test Loss: 39.7068 - MSE: 39.7068 - MAE: 5.1381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3214/20000 - Train Loss: 16.0361 - Test Loss: 39.7010 - MSE: 39.7010 - MAE: 5.1377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3215/20000 - Train Loss: 16.0334 - Test Loss: 39.6951 - MSE: 39.6951 - MAE: 5.1373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3216/20000 - Train Loss: 16.0308 - Test Loss: 39.6893 - MSE: 39.6893 - MAE: 5.1369\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3217/20000 - Train Loss: 16.0281 - Test Loss: 39.6835 - MSE: 39.6835 - MAE: 5.1365\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3218/20000 - Train Loss: 16.0255 - Test Loss: 39.6777 - MSE: 39.6777 - MAE: 5.1361\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 3219/20000 - Train Loss: 16.0228 - Test Loss: 39.6719 - MSE: 39.6719 - MAE: 5.1357\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3220/20000 - Train Loss: 16.0202 - Test Loss: 39.6661 - MSE: 39.6661 - MAE: 5.1353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3221/20000 - Train Loss: 16.0175 - Test Loss: 39.6603 - MSE: 39.6603 - MAE: 5.1349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3222/20000 - Train Loss: 16.0149 - Test Loss: 39.6545 - MSE: 39.6545 - MAE: 5.1345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3223/20000 - Train Loss: 16.0122 - Test Loss: 39.6487 - MSE: 39.6487 - MAE: 5.1341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3224/20000 - Train Loss: 16.0096 - Test Loss: 39.6429 - MSE: 39.6429 - MAE: 5.1336\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3225/20000 - Train Loss: 16.0069 - Test Loss: 39.6371 - MSE: 39.6371 - MAE: 5.1332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3226/20000 - Train Loss: 16.0043 - Test Loss: 39.6313 - MSE: 39.6313 - MAE: 5.1328\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3227/20000 - Train Loss: 16.0016 - Test Loss: 39.6255 - MSE: 39.6255 - MAE: 5.1324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3228/20000 - Train Loss: 15.9989 - Test Loss: 39.6196 - MSE: 39.6196 - MAE: 5.1320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3229/20000 - Train Loss: 15.9963 - Test Loss: 39.6139 - MSE: 39.6139 - MAE: 5.1316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3230/20000 - Train Loss: 15.9936 - Test Loss: 39.6081 - MSE: 39.6081 - MAE: 5.1312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3231/20000 - Train Loss: 15.9910 - Test Loss: 39.6023 - MSE: 39.6023 - MAE: 5.1308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3232/20000 - Train Loss: 15.9883 - Test Loss: 39.5964 - MSE: 39.5964 - MAE: 5.1304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3233/20000 - Train Loss: 15.9856 - Test Loss: 39.5905 - MSE: 39.5905 - MAE: 5.1300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3234/20000 - Train Loss: 15.9830 - Test Loss: 39.5847 - MSE: 39.5847 - MAE: 5.1296\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3235/20000 - Train Loss: 15.9803 - Test Loss: 39.5788 - MSE: 39.5788 - MAE: 5.1292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3236/20000 - Train Loss: 15.9777 - Test Loss: 39.5730 - MSE: 39.5730 - MAE: 5.1288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3237/20000 - Train Loss: 15.9750 - Test Loss: 39.5672 - MSE: 39.5672 - MAE: 5.1284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3238/20000 - Train Loss: 15.9723 - Test Loss: 39.5613 - MSE: 39.5613 - MAE: 5.1280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3239/20000 - Train Loss: 15.9697 - Test Loss: 39.5555 - MSE: 39.5555 - MAE: 5.1276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3240/20000 - Train Loss: 15.9670 - Test Loss: 39.5496 - MSE: 39.5496 - MAE: 5.1271\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3241/20000 - Train Loss: 15.9643 - Test Loss: 39.5437 - MSE: 39.5437 - MAE: 5.1267\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3242/20000 - Train Loss: 15.9616 - Test Loss: 39.5379 - MSE: 39.5379 - MAE: 5.1263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3243/20000 - Train Loss: 15.9590 - Test Loss: 39.5321 - MSE: 39.5321 - MAE: 5.1259\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3244/20000 - Train Loss: 15.9563 - Test Loss: 39.5263 - MSE: 39.5263 - MAE: 5.1255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3245/20000 - Train Loss: 15.9536 - Test Loss: 39.5204 - MSE: 39.5204 - MAE: 5.1251\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3246/20000 - Train Loss: 15.9510 - Test Loss: 39.5146 - MSE: 39.5146 - MAE: 5.1247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3247/20000 - Train Loss: 15.9483 - Test Loss: 39.5087 - MSE: 39.5087 - MAE: 5.1243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3248/20000 - Train Loss: 15.9456 - Test Loss: 39.5029 - MSE: 39.5029 - MAE: 5.1239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3249/20000 - Train Loss: 15.9429 - Test Loss: 39.4971 - MSE: 39.4971 - MAE: 5.1235\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3250/20000 - Train Loss: 15.9403 - Test Loss: 39.4911 - MSE: 39.4911 - MAE: 5.1231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3251/20000 - Train Loss: 15.9376 - Test Loss: 39.4853 - MSE: 39.4853 - MAE: 5.1227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3252/20000 - Train Loss: 15.9349 - Test Loss: 39.4795 - MSE: 39.4795 - MAE: 5.1223\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3253/20000 - Train Loss: 15.9322 - Test Loss: 39.4735 - MSE: 39.4735 - MAE: 5.1218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3254/20000 - Train Loss: 15.9295 - Test Loss: 39.4677 - MSE: 39.4677 - MAE: 5.1214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3255/20000 - Train Loss: 15.9268 - Test Loss: 39.4619 - MSE: 39.4619 - MAE: 5.1210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3256/20000 - Train Loss: 15.9242 - Test Loss: 39.4559 - MSE: 39.4559 - MAE: 5.1206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3257/20000 - Train Loss: 15.9215 - Test Loss: 39.4500 - MSE: 39.4500 - MAE: 5.1202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3258/20000 - Train Loss: 15.9188 - Test Loss: 39.4442 - MSE: 39.4442 - MAE: 5.1198\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3259/20000 - Train Loss: 15.9161 - Test Loss: 39.4382 - MSE: 39.4382 - MAE: 5.1194\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3260/20000 - Train Loss: 15.9134 - Test Loss: 39.4324 - MSE: 39.4324 - MAE: 5.1190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3261/20000 - Train Loss: 15.9107 - Test Loss: 39.4265 - MSE: 39.4265 - MAE: 5.1186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3262/20000 - Train Loss: 15.9080 - Test Loss: 39.4206 - MSE: 39.4206 - MAE: 5.1181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3263/20000 - Train Loss: 15.9054 - Test Loss: 39.4148 - MSE: 39.4148 - MAE: 5.1177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3264/20000 - Train Loss: 15.9027 - Test Loss: 39.4088 - MSE: 39.4088 - MAE: 5.1173\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3265/20000 - Train Loss: 15.9000 - Test Loss: 39.4030 - MSE: 39.4030 - MAE: 5.1169\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3266/20000 - Train Loss: 15.8973 - Test Loss: 39.3970 - MSE: 39.3970 - MAE: 5.1165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3267/20000 - Train Loss: 15.8946 - Test Loss: 39.3912 - MSE: 39.3912 - MAE: 5.1161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3268/20000 - Train Loss: 15.8919 - Test Loss: 39.3853 - MSE: 39.3853 - MAE: 5.1157\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3269/20000 - Train Loss: 15.8892 - Test Loss: 39.3794 - MSE: 39.3794 - MAE: 5.1153\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3270/20000 - Train Loss: 15.8865 - Test Loss: 39.3735 - MSE: 39.3735 - MAE: 5.1149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3271/20000 - Train Loss: 15.8838 - Test Loss: 39.3676 - MSE: 39.3676 - MAE: 5.1144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3272/20000 - Train Loss: 15.8811 - Test Loss: 39.3617 - MSE: 39.3617 - MAE: 5.1140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3273/20000 - Train Loss: 15.8784 - Test Loss: 39.3558 - MSE: 39.3558 - MAE: 5.1136\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3274/20000 - Train Loss: 15.8757 - Test Loss: 39.3499 - MSE: 39.3499 - MAE: 5.1132\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3275/20000 - Train Loss: 15.8730 - Test Loss: 39.3440 - MSE: 39.3440 - MAE: 5.1128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3276/20000 - Train Loss: 15.8703 - Test Loss: 39.3380 - MSE: 39.3380 - MAE: 5.1124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3277/20000 - Train Loss: 15.8676 - Test Loss: 39.3321 - MSE: 39.3321 - MAE: 5.1120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3278/20000 - Train Loss: 15.8649 - Test Loss: 39.3262 - MSE: 39.3262 - MAE: 5.1115\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3279/20000 - Train Loss: 15.8622 - Test Loss: 39.3203 - MSE: 39.3203 - MAE: 5.1111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3280/20000 - Train Loss: 15.8595 - Test Loss: 39.3143 - MSE: 39.3143 - MAE: 5.1107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3281/20000 - Train Loss: 15.8568 - Test Loss: 39.3084 - MSE: 39.3084 - MAE: 5.1103\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3282/20000 - Train Loss: 15.8541 - Test Loss: 39.3025 - MSE: 39.3025 - MAE: 5.1099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3283/20000 - Train Loss: 15.8514 - Test Loss: 39.2966 - MSE: 39.2966 - MAE: 5.1095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3284/20000 - Train Loss: 15.8487 - Test Loss: 39.2907 - MSE: 39.2907 - MAE: 5.1091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3285/20000 - Train Loss: 15.8460 - Test Loss: 39.2848 - MSE: 39.2848 - MAE: 5.1086\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3286/20000 - Train Loss: 15.8433 - Test Loss: 39.2789 - MSE: 39.2789 - MAE: 5.1082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3287/20000 - Train Loss: 15.8405 - Test Loss: 39.2730 - MSE: 39.2730 - MAE: 5.1078\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3288/20000 - Train Loss: 15.8378 - Test Loss: 39.2670 - MSE: 39.2670 - MAE: 5.1074\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3289/20000 - Train Loss: 15.8351 - Test Loss: 39.2611 - MSE: 39.2611 - MAE: 5.1070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3290/20000 - Train Loss: 15.8324 - Test Loss: 39.2551 - MSE: 39.2551 - MAE: 5.1066\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3291/20000 - Train Loss: 15.8297 - Test Loss: 39.2492 - MSE: 39.2492 - MAE: 5.1061\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3292/20000 - Train Loss: 15.8270 - Test Loss: 39.2433 - MSE: 39.2433 - MAE: 5.1057\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3293/20000 - Train Loss: 15.8243 - Test Loss: 39.2373 - MSE: 39.2373 - MAE: 5.1053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3294/20000 - Train Loss: 15.8215 - Test Loss: 39.2313 - MSE: 39.2313 - MAE: 5.1049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3295/20000 - Train Loss: 15.8188 - Test Loss: 39.2254 - MSE: 39.2254 - MAE: 5.1045\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3296/20000 - Train Loss: 15.8161 - Test Loss: 39.2194 - MSE: 39.2194 - MAE: 5.1041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3297/20000 - Train Loss: 15.8134 - Test Loss: 39.2134 - MSE: 39.2134 - MAE: 5.1036\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3298/20000 - Train Loss: 15.8107 - Test Loss: 39.2074 - MSE: 39.2074 - MAE: 5.1032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3299/20000 - Train Loss: 15.8079 - Test Loss: 39.2016 - MSE: 39.2016 - MAE: 5.1028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3300/20000 - Train Loss: 15.8052 - Test Loss: 39.1956 - MSE: 39.1956 - MAE: 5.1024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3301/20000 - Train Loss: 15.8025 - Test Loss: 39.1896 - MSE: 39.1896 - MAE: 5.1020\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3302/20000 - Train Loss: 15.7998 - Test Loss: 39.1836 - MSE: 39.1836 - MAE: 5.1016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3303/20000 - Train Loss: 15.7970 - Test Loss: 39.1777 - MSE: 39.1777 - MAE: 5.1011\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3304/20000 - Train Loss: 15.7943 - Test Loss: 39.1718 - MSE: 39.1718 - MAE: 5.1007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3305/20000 - Train Loss: 15.7916 - Test Loss: 39.1658 - MSE: 39.1658 - MAE: 5.1003\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3306/20000 - Train Loss: 15.7889 - Test Loss: 39.1599 - MSE: 39.1599 - MAE: 5.0999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3307/20000 - Train Loss: 15.7861 - Test Loss: 39.1538 - MSE: 39.1538 - MAE: 5.0995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3308/20000 - Train Loss: 15.7834 - Test Loss: 39.1479 - MSE: 39.1479 - MAE: 5.0990\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3309/20000 - Train Loss: 15.7807 - Test Loss: 39.1419 - MSE: 39.1419 - MAE: 5.0986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3310/20000 - Train Loss: 15.7779 - Test Loss: 39.1360 - MSE: 39.1360 - MAE: 5.0982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3311/20000 - Train Loss: 15.7752 - Test Loss: 39.1300 - MSE: 39.1300 - MAE: 5.0978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3312/20000 - Train Loss: 15.7725 - Test Loss: 39.1240 - MSE: 39.1240 - MAE: 5.0974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3313/20000 - Train Loss: 15.7697 - Test Loss: 39.1180 - MSE: 39.1180 - MAE: 5.0969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3314/20000 - Train Loss: 15.7670 - Test Loss: 39.1120 - MSE: 39.1120 - MAE: 5.0965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3315/20000 - Train Loss: 15.7643 - Test Loss: 39.1060 - MSE: 39.1060 - MAE: 5.0961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3316/20000 - Train Loss: 15.7615 - Test Loss: 39.1000 - MSE: 39.1000 - MAE: 5.0957\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3317/20000 - Train Loss: 15.7588 - Test Loss: 39.0940 - MSE: 39.0940 - MAE: 5.0953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3318/20000 - Train Loss: 15.7561 - Test Loss: 39.0880 - MSE: 39.0880 - MAE: 5.0948\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3319/20000 - Train Loss: 15.7533 - Test Loss: 39.0820 - MSE: 39.0820 - MAE: 5.0944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3320/20000 - Train Loss: 15.7506 - Test Loss: 39.0760 - MSE: 39.0760 - MAE: 5.0940\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3321/20000 - Train Loss: 15.7478 - Test Loss: 39.0699 - MSE: 39.0700 - MAE: 5.0936\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3322/20000 - Train Loss: 15.7451 - Test Loss: 39.0640 - MSE: 39.0640 - MAE: 5.0931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3323/20000 - Train Loss: 15.7424 - Test Loss: 39.0580 - MSE: 39.0580 - MAE: 5.0927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3324/20000 - Train Loss: 15.7396 - Test Loss: 39.0520 - MSE: 39.0520 - MAE: 5.0923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3325/20000 - Train Loss: 15.7369 - Test Loss: 39.0460 - MSE: 39.0460 - MAE: 5.0919\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3326/20000 - Train Loss: 15.7341 - Test Loss: 39.0400 - MSE: 39.0400 - MAE: 5.0915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3327/20000 - Train Loss: 15.7314 - Test Loss: 39.0341 - MSE: 39.0340 - MAE: 5.0910\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3328/20000 - Train Loss: 15.7286 - Test Loss: 39.0280 - MSE: 39.0280 - MAE: 5.0906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3329/20000 - Train Loss: 15.7259 - Test Loss: 39.0220 - MSE: 39.0220 - MAE: 5.0902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3330/20000 - Train Loss: 15.7231 - Test Loss: 39.0160 - MSE: 39.0160 - MAE: 5.0898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3331/20000 - Train Loss: 15.7204 - Test Loss: 39.0099 - MSE: 39.0099 - MAE: 5.0893\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3332/20000 - Train Loss: 15.7176 - Test Loss: 39.0040 - MSE: 39.0039 - MAE: 5.0889\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3333/20000 - Train Loss: 15.7149 - Test Loss: 38.9979 - MSE: 38.9979 - MAE: 5.0885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3334/20000 - Train Loss: 15.7121 - Test Loss: 38.9919 - MSE: 38.9919 - MAE: 5.0881\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3335/20000 - Train Loss: 15.7094 - Test Loss: 38.9858 - MSE: 38.9858 - MAE: 5.0876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3336/20000 - Train Loss: 15.7066 - Test Loss: 38.9798 - MSE: 38.9798 - MAE: 5.0872\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 3337/20000 - Train Loss: 15.7039 - Test Loss: 38.9738 - MSE: 38.9738 - MAE: 5.0868\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3338/20000 - Train Loss: 15.7011 - Test Loss: 38.9677 - MSE: 38.9677 - MAE: 5.0864\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3339/20000 - Train Loss: 15.6983 - Test Loss: 38.9617 - MSE: 38.9617 - MAE: 5.0859\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3340/20000 - Train Loss: 15.6956 - Test Loss: 38.9556 - MSE: 38.9556 - MAE: 5.0855\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3341/20000 - Train Loss: 15.6928 - Test Loss: 38.9496 - MSE: 38.9496 - MAE: 5.0851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3342/20000 - Train Loss: 15.6901 - Test Loss: 38.9436 - MSE: 38.9436 - MAE: 5.0847\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3343/20000 - Train Loss: 15.6873 - Test Loss: 38.9375 - MSE: 38.9375 - MAE: 5.0842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3344/20000 - Train Loss: 15.6845 - Test Loss: 38.9315 - MSE: 38.9315 - MAE: 5.0838\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3345/20000 - Train Loss: 15.6818 - Test Loss: 38.9254 - MSE: 38.9254 - MAE: 5.0834\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3346/20000 - Train Loss: 15.6790 - Test Loss: 38.9194 - MSE: 38.9194 - MAE: 5.0830\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3347/20000 - Train Loss: 15.6762 - Test Loss: 38.9134 - MSE: 38.9134 - MAE: 5.0825\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3348/20000 - Train Loss: 15.6735 - Test Loss: 38.9074 - MSE: 38.9074 - MAE: 5.0821\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3349/20000 - Train Loss: 15.6707 - Test Loss: 38.9013 - MSE: 38.9013 - MAE: 5.0817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3350/20000 - Train Loss: 15.6679 - Test Loss: 38.8952 - MSE: 38.8952 - MAE: 5.0813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3351/20000 - Train Loss: 15.6652 - Test Loss: 38.8892 - MSE: 38.8892 - MAE: 5.0808\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 3352/20000 - Train Loss: 15.6624 - Test Loss: 38.8831 - MSE: 38.8831 - MAE: 5.0804\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3353/20000 - Train Loss: 15.6596 - Test Loss: 38.8771 - MSE: 38.8771 - MAE: 5.0800\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3354/20000 - Train Loss: 15.6569 - Test Loss: 38.8710 - MSE: 38.8710 - MAE: 5.0796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3355/20000 - Train Loss: 15.6541 - Test Loss: 38.8649 - MSE: 38.8649 - MAE: 5.0791\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3356/20000 - Train Loss: 15.6513 - Test Loss: 38.8588 - MSE: 38.8588 - MAE: 5.0787\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3357/20000 - Train Loss: 15.6485 - Test Loss: 38.8527 - MSE: 38.8527 - MAE: 5.0783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3358/20000 - Train Loss: 15.6458 - Test Loss: 38.8467 - MSE: 38.8467 - MAE: 5.0778\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3359/20000 - Train Loss: 15.6430 - Test Loss: 38.8406 - MSE: 38.8406 - MAE: 5.0774\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3360/20000 - Train Loss: 15.6402 - Test Loss: 38.8346 - MSE: 38.8346 - MAE: 5.0770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3361/20000 - Train Loss: 15.6374 - Test Loss: 38.8285 - MSE: 38.8285 - MAE: 5.0766\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3362/20000 - Train Loss: 15.6347 - Test Loss: 38.8224 - MSE: 38.8224 - MAE: 5.0761\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3363/20000 - Train Loss: 15.6319 - Test Loss: 38.8163 - MSE: 38.8163 - MAE: 5.0757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3364/20000 - Train Loss: 15.6291 - Test Loss: 38.8103 - MSE: 38.8102 - MAE: 5.0753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3365/20000 - Train Loss: 15.6263 - Test Loss: 38.8042 - MSE: 38.8042 - MAE: 5.0748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3366/20000 - Train Loss: 15.6235 - Test Loss: 38.7982 - MSE: 38.7982 - MAE: 5.0744\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3367/20000 - Train Loss: 15.6208 - Test Loss: 38.7920 - MSE: 38.7920 - MAE: 5.0740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3368/20000 - Train Loss: 15.6180 - Test Loss: 38.7859 - MSE: 38.7859 - MAE: 5.0736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3369/20000 - Train Loss: 15.6152 - Test Loss: 38.7799 - MSE: 38.7799 - MAE: 5.0731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3370/20000 - Train Loss: 15.6124 - Test Loss: 38.7738 - MSE: 38.7738 - MAE: 5.0727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3371/20000 - Train Loss: 15.6096 - Test Loss: 38.7676 - MSE: 38.7676 - MAE: 5.0723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3372/20000 - Train Loss: 15.6068 - Test Loss: 38.7615 - MSE: 38.7615 - MAE: 5.0718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3373/20000 - Train Loss: 15.6040 - Test Loss: 38.7554 - MSE: 38.7554 - MAE: 5.0714\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3374/20000 - Train Loss: 15.6012 - Test Loss: 38.7493 - MSE: 38.7493 - MAE: 5.0710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3375/20000 - Train Loss: 15.5985 - Test Loss: 38.7432 - MSE: 38.7432 - MAE: 5.0705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3376/20000 - Train Loss: 15.5957 - Test Loss: 38.7371 - MSE: 38.7371 - MAE: 5.0701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3377/20000 - Train Loss: 15.5929 - Test Loss: 38.7310 - MSE: 38.7310 - MAE: 5.0697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3378/20000 - Train Loss: 15.5901 - Test Loss: 38.7249 - MSE: 38.7249 - MAE: 5.0692\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3379/20000 - Train Loss: 15.5873 - Test Loss: 38.7188 - MSE: 38.7188 - MAE: 5.0688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3380/20000 - Train Loss: 15.5845 - Test Loss: 38.7127 - MSE: 38.7127 - MAE: 5.0684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3381/20000 - Train Loss: 15.5817 - Test Loss: 38.7066 - MSE: 38.7066 - MAE: 5.0679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3382/20000 - Train Loss: 15.5789 - Test Loss: 38.7005 - MSE: 38.7005 - MAE: 5.0675\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3383/20000 - Train Loss: 15.5761 - Test Loss: 38.6944 - MSE: 38.6944 - MAE: 5.0671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3384/20000 - Train Loss: 15.5733 - Test Loss: 38.6882 - MSE: 38.6882 - MAE: 5.0666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3385/20000 - Train Loss: 15.5705 - Test Loss: 38.6821 - MSE: 38.6821 - MAE: 5.0662\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3386/20000 - Train Loss: 15.5677 - Test Loss: 38.6759 - MSE: 38.6759 - MAE: 5.0658\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3387/20000 - Train Loss: 15.5649 - Test Loss: 38.6698 - MSE: 38.6698 - MAE: 5.0653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3388/20000 - Train Loss: 15.5621 - Test Loss: 38.6637 - MSE: 38.6637 - MAE: 5.0649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3389/20000 - Train Loss: 15.5593 - Test Loss: 38.6576 - MSE: 38.6576 - MAE: 5.0645\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3390/20000 - Train Loss: 15.5565 - Test Loss: 38.6514 - MSE: 38.6514 - MAE: 5.0640\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3391/20000 - Train Loss: 15.5537 - Test Loss: 38.6453 - MSE: 38.6453 - MAE: 5.0636\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3392/20000 - Train Loss: 15.5509 - Test Loss: 38.6391 - MSE: 38.6391 - MAE: 5.0632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3393/20000 - Train Loss: 15.5481 - Test Loss: 38.6330 - MSE: 38.6330 - MAE: 5.0627\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3394/20000 - Train Loss: 15.5453 - Test Loss: 38.6269 - MSE: 38.6269 - MAE: 5.0623\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3395/20000 - Train Loss: 15.5425 - Test Loss: 38.6207 - MSE: 38.6207 - MAE: 5.0619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3396/20000 - Train Loss: 15.5397 - Test Loss: 38.6146 - MSE: 38.6146 - MAE: 5.0614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3397/20000 - Train Loss: 15.5369 - Test Loss: 38.6084 - MSE: 38.6084 - MAE: 5.0610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3398/20000 - Train Loss: 15.5340 - Test Loss: 38.6023 - MSE: 38.6023 - MAE: 5.0606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3399/20000 - Train Loss: 15.5312 - Test Loss: 38.5962 - MSE: 38.5962 - MAE: 5.0601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3400/20000 - Train Loss: 15.5284 - Test Loss: 38.5901 - MSE: 38.5901 - MAE: 5.0597\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3401/20000 - Train Loss: 15.5256 - Test Loss: 38.5840 - MSE: 38.5840 - MAE: 5.0593\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3402/20000 - Train Loss: 15.5228 - Test Loss: 38.5778 - MSE: 38.5778 - MAE: 5.0588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3403/20000 - Train Loss: 15.5200 - Test Loss: 38.5717 - MSE: 38.5717 - MAE: 5.0584\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3404/20000 - Train Loss: 15.5172 - Test Loss: 38.5655 - MSE: 38.5655 - MAE: 5.0580\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3405/20000 - Train Loss: 15.5143 - Test Loss: 38.5593 - MSE: 38.5593 - MAE: 5.0575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3406/20000 - Train Loss: 15.5115 - Test Loss: 38.5531 - MSE: 38.5531 - MAE: 5.0571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3407/20000 - Train Loss: 15.5087 - Test Loss: 38.5470 - MSE: 38.5470 - MAE: 5.0566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3408/20000 - Train Loss: 15.5059 - Test Loss: 38.5408 - MSE: 38.5408 - MAE: 5.0562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3409/20000 - Train Loss: 15.5031 - Test Loss: 38.5345 - MSE: 38.5345 - MAE: 5.0558\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 3410/20000 - Train Loss: 15.5002 - Test Loss: 38.5283 - MSE: 38.5283 - MAE: 5.0553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3411/20000 - Train Loss: 15.4974 - Test Loss: 38.5221 - MSE: 38.5221 - MAE: 5.0549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3412/20000 - Train Loss: 15.4946 - Test Loss: 38.5160 - MSE: 38.5160 - MAE: 5.0544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3413/20000 - Train Loss: 15.4918 - Test Loss: 38.5098 - MSE: 38.5098 - MAE: 5.0540\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3414/20000 - Train Loss: 15.4890 - Test Loss: 38.5037 - MSE: 38.5037 - MAE: 5.0536\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3415/20000 - Train Loss: 15.4861 - Test Loss: 38.4975 - MSE: 38.4975 - MAE: 5.0531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3416/20000 - Train Loss: 15.4833 - Test Loss: 38.4914 - MSE: 38.4914 - MAE: 5.0527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3417/20000 - Train Loss: 15.4805 - Test Loss: 38.4852 - MSE: 38.4852 - MAE: 5.0523\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3418/20000 - Train Loss: 15.4776 - Test Loss: 38.4790 - MSE: 38.4790 - MAE: 5.0518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3419/20000 - Train Loss: 15.4748 - Test Loss: 38.4729 - MSE: 38.4729 - MAE: 5.0514\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3420/20000 - Train Loss: 15.4720 - Test Loss: 38.4667 - MSE: 38.4667 - MAE: 5.0509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3421/20000 - Train Loss: 15.4691 - Test Loss: 38.4605 - MSE: 38.4605 - MAE: 5.0505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3422/20000 - Train Loss: 15.4663 - Test Loss: 38.4543 - MSE: 38.4543 - MAE: 5.0501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3423/20000 - Train Loss: 15.4635 - Test Loss: 38.4481 - MSE: 38.4481 - MAE: 5.0496\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3424/20000 - Train Loss: 15.4606 - Test Loss: 38.4419 - MSE: 38.4419 - MAE: 5.0492\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3425/20000 - Train Loss: 15.4578 - Test Loss: 38.4356 - MSE: 38.4356 - MAE: 5.0487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3426/20000 - Train Loss: 15.4550 - Test Loss: 38.4295 - MSE: 38.4295 - MAE: 5.0483\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3427/20000 - Train Loss: 15.4521 - Test Loss: 38.4233 - MSE: 38.4233 - MAE: 5.0479\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3428/20000 - Train Loss: 15.4493 - Test Loss: 38.4170 - MSE: 38.4170 - MAE: 5.0474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3429/20000 - Train Loss: 15.4465 - Test Loss: 38.4108 - MSE: 38.4108 - MAE: 5.0470\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3430/20000 - Train Loss: 15.4436 - Test Loss: 38.4046 - MSE: 38.4046 - MAE: 5.0465\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3431/20000 - Train Loss: 15.4408 - Test Loss: 38.3984 - MSE: 38.3984 - MAE: 5.0461\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3432/20000 - Train Loss: 15.4379 - Test Loss: 38.3921 - MSE: 38.3921 - MAE: 5.0456\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3433/20000 - Train Loss: 15.4351 - Test Loss: 38.3859 - MSE: 38.3859 - MAE: 5.0452\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3434/20000 - Train Loss: 15.4323 - Test Loss: 38.3797 - MSE: 38.3797 - MAE: 5.0448\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3435/20000 - Train Loss: 15.4294 - Test Loss: 38.3735 - MSE: 38.3735 - MAE: 5.0443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3436/20000 - Train Loss: 15.4266 - Test Loss: 38.3673 - MSE: 38.3673 - MAE: 5.0439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3437/20000 - Train Loss: 15.4237 - Test Loss: 38.3611 - MSE: 38.3611 - MAE: 5.0434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3438/20000 - Train Loss: 15.4209 - Test Loss: 38.3549 - MSE: 38.3549 - MAE: 5.0430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3439/20000 - Train Loss: 15.4180 - Test Loss: 38.3487 - MSE: 38.3487 - MAE: 5.0426\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3440/20000 - Train Loss: 15.4152 - Test Loss: 38.3425 - MSE: 38.3425 - MAE: 5.0421\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3441/20000 - Train Loss: 15.4123 - Test Loss: 38.3362 - MSE: 38.3362 - MAE: 5.0417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3442/20000 - Train Loss: 15.4095 - Test Loss: 38.3301 - MSE: 38.3301 - MAE: 5.0412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3443/20000 - Train Loss: 15.4066 - Test Loss: 38.3238 - MSE: 38.3238 - MAE: 5.0408\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3444/20000 - Train Loss: 15.4038 - Test Loss: 38.3176 - MSE: 38.3176 - MAE: 5.0403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3445/20000 - Train Loss: 15.4009 - Test Loss: 38.3113 - MSE: 38.3113 - MAE: 5.0399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3446/20000 - Train Loss: 15.3981 - Test Loss: 38.3051 - MSE: 38.3051 - MAE: 5.0394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3447/20000 - Train Loss: 15.3952 - Test Loss: 38.2987 - MSE: 38.2987 - MAE: 5.0390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3448/20000 - Train Loss: 15.3924 - Test Loss: 38.2925 - MSE: 38.2925 - MAE: 5.0386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3449/20000 - Train Loss: 15.3895 - Test Loss: 38.2863 - MSE: 38.2863 - MAE: 5.0381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3450/20000 - Train Loss: 15.3866 - Test Loss: 38.2799 - MSE: 38.2799 - MAE: 5.0377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3451/20000 - Train Loss: 15.3838 - Test Loss: 38.2737 - MSE: 38.2737 - MAE: 5.0372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3452/20000 - Train Loss: 15.3809 - Test Loss: 38.2674 - MSE: 38.2674 - MAE: 5.0368\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3453/20000 - Train Loss: 15.3781 - Test Loss: 38.2612 - MSE: 38.2612 - MAE: 5.0363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3454/20000 - Train Loss: 15.3752 - Test Loss: 38.2550 - MSE: 38.2550 - MAE: 5.0359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3455/20000 - Train Loss: 15.3723 - Test Loss: 38.2488 - MSE: 38.2488 - MAE: 5.0354\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3456/20000 - Train Loss: 15.3695 - Test Loss: 38.2425 - MSE: 38.2425 - MAE: 5.0350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3457/20000 - Train Loss: 15.3666 - Test Loss: 38.2363 - MSE: 38.2363 - MAE: 5.0345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3458/20000 - Train Loss: 15.3638 - Test Loss: 38.2301 - MSE: 38.2301 - MAE: 5.0341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3459/20000 - Train Loss: 15.3609 - Test Loss: 38.2238 - MSE: 38.2238 - MAE: 5.0337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3460/20000 - Train Loss: 15.3580 - Test Loss: 38.2175 - MSE: 38.2175 - MAE: 5.0332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3461/20000 - Train Loss: 15.3552 - Test Loss: 38.2113 - MSE: 38.2113 - MAE: 5.0328\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3462/20000 - Train Loss: 15.3523 - Test Loss: 38.2050 - MSE: 38.2050 - MAE: 5.0323\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3463/20000 - Train Loss: 15.3494 - Test Loss: 38.1987 - MSE: 38.1987 - MAE: 5.0319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3464/20000 - Train Loss: 15.3466 - Test Loss: 38.1924 - MSE: 38.1924 - MAE: 5.0314\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3465/20000 - Train Loss: 15.3437 - Test Loss: 38.1861 - MSE: 38.1861 - MAE: 5.0310\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3466/20000 - Train Loss: 15.3408 - Test Loss: 38.1799 - MSE: 38.1799 - MAE: 5.0305\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3467/20000 - Train Loss: 15.3379 - Test Loss: 38.1735 - MSE: 38.1735 - MAE: 5.0301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3468/20000 - Train Loss: 15.3351 - Test Loss: 38.1672 - MSE: 38.1672 - MAE: 5.0296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3469/20000 - Train Loss: 15.3322 - Test Loss: 38.1609 - MSE: 38.1609 - MAE: 5.0292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3470/20000 - Train Loss: 15.3293 - Test Loss: 38.1546 - MSE: 38.1547 - MAE: 5.0287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3471/20000 - Train Loss: 15.3264 - Test Loss: 38.1483 - MSE: 38.1483 - MAE: 5.0283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3472/20000 - Train Loss: 15.3236 - Test Loss: 38.1421 - MSE: 38.1421 - MAE: 5.0278\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3473/20000 - Train Loss: 15.3207 - Test Loss: 38.1359 - MSE: 38.1359 - MAE: 5.0274\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3474/20000 - Train Loss: 15.3178 - Test Loss: 38.1295 - MSE: 38.1295 - MAE: 5.0269\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3475/20000 - Train Loss: 15.3149 - Test Loss: 38.1233 - MSE: 38.1233 - MAE: 5.0265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3476/20000 - Train Loss: 15.3120 - Test Loss: 38.1170 - MSE: 38.1170 - MAE: 5.0260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3477/20000 - Train Loss: 15.3092 - Test Loss: 38.1107 - MSE: 38.1107 - MAE: 5.0256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3478/20000 - Train Loss: 15.3063 - Test Loss: 38.1044 - MSE: 38.1044 - MAE: 5.0251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3479/20000 - Train Loss: 15.3034 - Test Loss: 38.0981 - MSE: 38.0981 - MAE: 5.0247\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3480/20000 - Train Loss: 15.3005 - Test Loss: 38.0918 - MSE: 38.0918 - MAE: 5.0242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3481/20000 - Train Loss: 15.2976 - Test Loss: 38.0855 - MSE: 38.0855 - MAE: 5.0238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3482/20000 - Train Loss: 15.2947 - Test Loss: 38.0791 - MSE: 38.0791 - MAE: 5.0233\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 3483/20000 - Train Loss: 15.2919 - Test Loss: 38.0728 - MSE: 38.0728 - MAE: 5.0229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3484/20000 - Train Loss: 15.2890 - Test Loss: 38.0665 - MSE: 38.0665 - MAE: 5.0224\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3485/20000 - Train Loss: 15.2861 - Test Loss: 38.0602 - MSE: 38.0602 - MAE: 5.0220\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3486/20000 - Train Loss: 15.2832 - Test Loss: 38.0539 - MSE: 38.0539 - MAE: 5.0215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3487/20000 - Train Loss: 15.2803 - Test Loss: 38.0475 - MSE: 38.0475 - MAE: 5.0211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3488/20000 - Train Loss: 15.2774 - Test Loss: 38.0412 - MSE: 38.0412 - MAE: 5.0206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3489/20000 - Train Loss: 15.2745 - Test Loss: 38.0349 - MSE: 38.0349 - MAE: 5.0202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3490/20000 - Train Loss: 15.2716 - Test Loss: 38.0286 - MSE: 38.0286 - MAE: 5.0197\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3491/20000 - Train Loss: 15.2687 - Test Loss: 38.0223 - MSE: 38.0223 - MAE: 5.0193\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3492/20000 - Train Loss: 15.2658 - Test Loss: 38.0159 - MSE: 38.0159 - MAE: 5.0188\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3493/20000 - Train Loss: 15.2629 - Test Loss: 38.0097 - MSE: 38.0097 - MAE: 5.0184\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3494/20000 - Train Loss: 15.2600 - Test Loss: 38.0033 - MSE: 38.0033 - MAE: 5.0179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3495/20000 - Train Loss: 15.2572 - Test Loss: 37.9970 - MSE: 37.9970 - MAE: 5.0174\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 3496/20000 - Train Loss: 15.2543 - Test Loss: 37.9907 - MSE: 37.9907 - MAE: 5.0170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3497/20000 - Train Loss: 15.2514 - Test Loss: 37.9843 - MSE: 37.9843 - MAE: 5.0165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3498/20000 - Train Loss: 15.2485 - Test Loss: 37.9780 - MSE: 37.9780 - MAE: 5.0161\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3499/20000 - Train Loss: 15.2456 - Test Loss: 37.9716 - MSE: 37.9716 - MAE: 5.0156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3500/20000 - Train Loss: 15.2427 - Test Loss: 37.9653 - MSE: 37.9653 - MAE: 5.0152\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3501/20000 - Train Loss: 15.2397 - Test Loss: 37.9589 - MSE: 37.9589 - MAE: 5.0147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3502/20000 - Train Loss: 15.2368 - Test Loss: 37.9526 - MSE: 37.9526 - MAE: 5.0143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3503/20000 - Train Loss: 15.2339 - Test Loss: 37.9462 - MSE: 37.9462 - MAE: 5.0138\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3504/20000 - Train Loss: 15.2310 - Test Loss: 37.9398 - MSE: 37.9398 - MAE: 5.0134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3505/20000 - Train Loss: 15.2281 - Test Loss: 37.9335 - MSE: 37.9335 - MAE: 5.0129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3506/20000 - Train Loss: 15.2252 - Test Loss: 37.9271 - MSE: 37.9271 - MAE: 5.0124\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3507/20000 - Train Loss: 15.2223 - Test Loss: 37.9208 - MSE: 37.9208 - MAE: 5.0120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3508/20000 - Train Loss: 15.2194 - Test Loss: 37.9145 - MSE: 37.9145 - MAE: 5.0115\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3509/20000 - Train Loss: 15.2165 - Test Loss: 37.9081 - MSE: 37.9081 - MAE: 5.0111\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3510/20000 - Train Loss: 15.2136 - Test Loss: 37.9018 - MSE: 37.9018 - MAE: 5.0106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3511/20000 - Train Loss: 15.2107 - Test Loss: 37.8954 - MSE: 37.8954 - MAE: 5.0102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3512/20000 - Train Loss: 15.2078 - Test Loss: 37.8890 - MSE: 37.8890 - MAE: 5.0097\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3513/20000 - Train Loss: 15.2048 - Test Loss: 37.8827 - MSE: 37.8827 - MAE: 5.0093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3514/20000 - Train Loss: 15.2019 - Test Loss: 37.8763 - MSE: 37.8763 - MAE: 5.0088\n",
      "2/2 [==============================] - 0s 976us/step\n",
      "Epoch 3515/20000 - Train Loss: 15.1990 - Test Loss: 37.8699 - MSE: 37.8699 - MAE: 5.0083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3516/20000 - Train Loss: 15.1961 - Test Loss: 37.8636 - MSE: 37.8636 - MAE: 5.0079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3517/20000 - Train Loss: 15.1932 - Test Loss: 37.8572 - MSE: 37.8572 - MAE: 5.0074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3518/20000 - Train Loss: 15.1903 - Test Loss: 37.8508 - MSE: 37.8508 - MAE: 5.0070\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 3519/20000 - Train Loss: 15.1874 - Test Loss: 37.8444 - MSE: 37.8444 - MAE: 5.0065\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3520/20000 - Train Loss: 15.1844 - Test Loss: 37.8380 - MSE: 37.8380 - MAE: 5.0060\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3521/20000 - Train Loss: 15.1815 - Test Loss: 37.8316 - MSE: 37.8316 - MAE: 5.0056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3522/20000 - Train Loss: 15.1786 - Test Loss: 37.8253 - MSE: 37.8253 - MAE: 5.0051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3523/20000 - Train Loss: 15.1757 - Test Loss: 37.8188 - MSE: 37.8188 - MAE: 5.0047\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3524/20000 - Train Loss: 15.1727 - Test Loss: 37.8124 - MSE: 37.8125 - MAE: 5.0042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3525/20000 - Train Loss: 15.1698 - Test Loss: 37.8061 - MSE: 37.8061 - MAE: 5.0038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3526/20000 - Train Loss: 15.1669 - Test Loss: 37.7997 - MSE: 37.7997 - MAE: 5.0033\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 3527/20000 - Train Loss: 15.1640 - Test Loss: 37.7934 - MSE: 37.7934 - MAE: 5.0028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3528/20000 - Train Loss: 15.1610 - Test Loss: 37.7869 - MSE: 37.7869 - MAE: 5.0024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3529/20000 - Train Loss: 15.1581 - Test Loss: 37.7807 - MSE: 37.7807 - MAE: 5.0019\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3530/20000 - Train Loss: 15.1552 - Test Loss: 37.7742 - MSE: 37.7742 - MAE: 5.0015\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3531/20000 - Train Loss: 15.1523 - Test Loss: 37.7678 - MSE: 37.7678 - MAE: 5.0010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3532/20000 - Train Loss: 15.1493 - Test Loss: 37.7614 - MSE: 37.7614 - MAE: 5.0005\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3533/20000 - Train Loss: 15.1464 - Test Loss: 37.7550 - MSE: 37.7550 - MAE: 5.0001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3534/20000 - Train Loss: 15.1435 - Test Loss: 37.7486 - MSE: 37.7486 - MAE: 4.9996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3535/20000 - Train Loss: 15.1405 - Test Loss: 37.7421 - MSE: 37.7421 - MAE: 4.9992\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 3536/20000 - Train Loss: 15.1376 - Test Loss: 37.7357 - MSE: 37.7357 - MAE: 4.9987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3537/20000 - Train Loss: 15.1347 - Test Loss: 37.7293 - MSE: 37.7293 - MAE: 4.9982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3538/20000 - Train Loss: 15.1317 - Test Loss: 37.7229 - MSE: 37.7229 - MAE: 4.9978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3539/20000 - Train Loss: 15.1288 - Test Loss: 37.7164 - MSE: 37.7164 - MAE: 4.9973\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3540/20000 - Train Loss: 15.1259 - Test Loss: 37.7100 - MSE: 37.7100 - MAE: 4.9968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3541/20000 - Train Loss: 15.1229 - Test Loss: 37.7036 - MSE: 37.7036 - MAE: 4.9964\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3542/20000 - Train Loss: 15.1200 - Test Loss: 37.6972 - MSE: 37.6972 - MAE: 4.9959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3543/20000 - Train Loss: 15.1170 - Test Loss: 37.6907 - MSE: 37.6907 - MAE: 4.9955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3544/20000 - Train Loss: 15.1141 - Test Loss: 37.6843 - MSE: 37.6843 - MAE: 4.9950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3545/20000 - Train Loss: 15.1112 - Test Loss: 37.6779 - MSE: 37.6779 - MAE: 4.9945\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3546/20000 - Train Loss: 15.1082 - Test Loss: 37.6715 - MSE: 37.6715 - MAE: 4.9941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3547/20000 - Train Loss: 15.1053 - Test Loss: 37.6651 - MSE: 37.6651 - MAE: 4.9936\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3548/20000 - Train Loss: 15.1023 - Test Loss: 37.6587 - MSE: 37.6587 - MAE: 4.9932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3549/20000 - Train Loss: 15.0994 - Test Loss: 37.6523 - MSE: 37.6523 - MAE: 4.9927\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3550/20000 - Train Loss: 15.0964 - Test Loss: 37.6458 - MSE: 37.6458 - MAE: 4.9922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3551/20000 - Train Loss: 15.0935 - Test Loss: 37.6394 - MSE: 37.6394 - MAE: 4.9918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3552/20000 - Train Loss: 15.0905 - Test Loss: 37.6329 - MSE: 37.6329 - MAE: 4.9913\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3553/20000 - Train Loss: 15.0876 - Test Loss: 37.6264 - MSE: 37.6264 - MAE: 4.9908\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3554/20000 - Train Loss: 15.0846 - Test Loss: 37.6200 - MSE: 37.6200 - MAE: 4.9904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3555/20000 - Train Loss: 15.0817 - Test Loss: 37.6136 - MSE: 37.6136 - MAE: 4.9899\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3556/20000 - Train Loss: 15.0787 - Test Loss: 37.6071 - MSE: 37.6071 - MAE: 4.9894\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3557/20000 - Train Loss: 15.0758 - Test Loss: 37.6006 - MSE: 37.6006 - MAE: 4.9890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3558/20000 - Train Loss: 15.0728 - Test Loss: 37.5942 - MSE: 37.5942 - MAE: 4.9885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3559/20000 - Train Loss: 15.0699 - Test Loss: 37.5877 - MSE: 37.5877 - MAE: 4.9880\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 3560/20000 - Train Loss: 15.0669 - Test Loss: 37.5813 - MSE: 37.5813 - MAE: 4.9876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3561/20000 - Train Loss: 15.0640 - Test Loss: 37.5748 - MSE: 37.5748 - MAE: 4.9871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3562/20000 - Train Loss: 15.0610 - Test Loss: 37.5684 - MSE: 37.5683 - MAE: 4.9866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3563/20000 - Train Loss: 15.0581 - Test Loss: 37.5619 - MSE: 37.5619 - MAE: 4.9862\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3564/20000 - Train Loss: 15.0551 - Test Loss: 37.5555 - MSE: 37.5555 - MAE: 4.9857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3565/20000 - Train Loss: 15.0521 - Test Loss: 37.5490 - MSE: 37.5490 - MAE: 4.9852\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 3566/20000 - Train Loss: 15.0492 - Test Loss: 37.5425 - MSE: 37.5425 - MAE: 4.9848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3567/20000 - Train Loss: 15.0462 - Test Loss: 37.5360 - MSE: 37.5360 - MAE: 4.9843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3568/20000 - Train Loss: 15.0433 - Test Loss: 37.5296 - MSE: 37.5296 - MAE: 4.9838\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3569/20000 - Train Loss: 15.0403 - Test Loss: 37.5231 - MSE: 37.5231 - MAE: 4.9834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3570/20000 - Train Loss: 15.0373 - Test Loss: 37.5166 - MSE: 37.5166 - MAE: 4.9829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3571/20000 - Train Loss: 15.0344 - Test Loss: 37.5102 - MSE: 37.5102 - MAE: 4.9824\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3572/20000 - Train Loss: 15.0314 - Test Loss: 37.5037 - MSE: 37.5037 - MAE: 4.9820\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3573/20000 - Train Loss: 15.0284 - Test Loss: 37.4972 - MSE: 37.4972 - MAE: 4.9815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3574/20000 - Train Loss: 15.0255 - Test Loss: 37.4907 - MSE: 37.4907 - MAE: 4.9810\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3575/20000 - Train Loss: 15.0225 - Test Loss: 37.4842 - MSE: 37.4842 - MAE: 4.9806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3576/20000 - Train Loss: 15.0195 - Test Loss: 37.4777 - MSE: 37.4777 - MAE: 4.9801\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3577/20000 - Train Loss: 15.0166 - Test Loss: 37.4713 - MSE: 37.4713 - MAE: 4.9796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3578/20000 - Train Loss: 15.0136 - Test Loss: 37.4648 - MSE: 37.4648 - MAE: 4.9792\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3579/20000 - Train Loss: 15.0106 - Test Loss: 37.4583 - MSE: 37.4583 - MAE: 4.9787\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 3580/20000 - Train Loss: 15.0076 - Test Loss: 37.4518 - MSE: 37.4518 - MAE: 4.9782\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3581/20000 - Train Loss: 15.0047 - Test Loss: 37.4453 - MSE: 37.4453 - MAE: 4.9778\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3582/20000 - Train Loss: 15.0017 - Test Loss: 37.4389 - MSE: 37.4389 - MAE: 4.9773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3583/20000 - Train Loss: 14.9987 - Test Loss: 37.4323 - MSE: 37.4323 - MAE: 4.9768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3584/20000 - Train Loss: 14.9957 - Test Loss: 37.4258 - MSE: 37.4258 - MAE: 4.9763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3585/20000 - Train Loss: 14.9928 - Test Loss: 37.4193 - MSE: 37.4193 - MAE: 4.9759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3586/20000 - Train Loss: 14.9898 - Test Loss: 37.4129 - MSE: 37.4129 - MAE: 4.9754\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3587/20000 - Train Loss: 14.9868 - Test Loss: 37.4063 - MSE: 37.4063 - MAE: 4.9749\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3588/20000 - Train Loss: 14.9838 - Test Loss: 37.3998 - MSE: 37.3998 - MAE: 4.9745\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3589/20000 - Train Loss: 14.9808 - Test Loss: 37.3933 - MSE: 37.3933 - MAE: 4.9740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3590/20000 - Train Loss: 14.9779 - Test Loss: 37.3867 - MSE: 37.3867 - MAE: 4.9735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3591/20000 - Train Loss: 14.9749 - Test Loss: 37.3802 - MSE: 37.3802 - MAE: 4.9730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3592/20000 - Train Loss: 14.9719 - Test Loss: 37.3737 - MSE: 37.3737 - MAE: 4.9726\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3593/20000 - Train Loss: 14.9689 - Test Loss: 37.3672 - MSE: 37.3672 - MAE: 4.9721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3594/20000 - Train Loss: 14.9659 - Test Loss: 37.3607 - MSE: 37.3607 - MAE: 4.9716\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3595/20000 - Train Loss: 14.9629 - Test Loss: 37.3541 - MSE: 37.3541 - MAE: 4.9712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3596/20000 - Train Loss: 14.9600 - Test Loss: 37.3476 - MSE: 37.3476 - MAE: 4.9707\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 3597/20000 - Train Loss: 14.9570 - Test Loss: 37.3411 - MSE: 37.3411 - MAE: 4.9702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3598/20000 - Train Loss: 14.9540 - Test Loss: 37.3346 - MSE: 37.3346 - MAE: 4.9697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3599/20000 - Train Loss: 14.9510 - Test Loss: 37.3281 - MSE: 37.3281 - MAE: 4.9693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3600/20000 - Train Loss: 14.9480 - Test Loss: 37.3216 - MSE: 37.3216 - MAE: 4.9688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3601/20000 - Train Loss: 14.9450 - Test Loss: 37.3150 - MSE: 37.3150 - MAE: 4.9683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3602/20000 - Train Loss: 14.9420 - Test Loss: 37.3086 - MSE: 37.3086 - MAE: 4.9678\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 3603/20000 - Train Loss: 14.9390 - Test Loss: 37.3020 - MSE: 37.3020 - MAE: 4.9674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3604/20000 - Train Loss: 14.9360 - Test Loss: 37.2955 - MSE: 37.2955 - MAE: 4.9669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3605/20000 - Train Loss: 14.9330 - Test Loss: 37.2889 - MSE: 37.2889 - MAE: 4.9664\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3606/20000 - Train Loss: 14.9300 - Test Loss: 37.2823 - MSE: 37.2823 - MAE: 4.9659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3607/20000 - Train Loss: 14.9270 - Test Loss: 37.2758 - MSE: 37.2758 - MAE: 4.9655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3608/20000 - Train Loss: 14.9240 - Test Loss: 37.2692 - MSE: 37.2692 - MAE: 4.9650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3609/20000 - Train Loss: 14.9210 - Test Loss: 37.2626 - MSE: 37.2626 - MAE: 4.9645\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3610/20000 - Train Loss: 14.9181 - Test Loss: 37.2561 - MSE: 37.2561 - MAE: 4.9640\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3611/20000 - Train Loss: 14.9151 - Test Loss: 37.2495 - MSE: 37.2495 - MAE: 4.9636\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 3612/20000 - Train Loss: 14.9120 - Test Loss: 37.2430 - MSE: 37.2430 - MAE: 4.9631\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3613/20000 - Train Loss: 14.9091 - Test Loss: 37.2364 - MSE: 37.2364 - MAE: 4.9626\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 3614/20000 - Train Loss: 14.9060 - Test Loss: 37.2299 - MSE: 37.2299 - MAE: 4.9621\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3615/20000 - Train Loss: 14.9030 - Test Loss: 37.2233 - MSE: 37.2233 - MAE: 4.9617\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3616/20000 - Train Loss: 14.9000 - Test Loss: 37.2168 - MSE: 37.2168 - MAE: 4.9612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3617/20000 - Train Loss: 14.8970 - Test Loss: 37.2103 - MSE: 37.2103 - MAE: 4.9607\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3618/20000 - Train Loss: 14.8940 - Test Loss: 37.2037 - MSE: 37.2037 - MAE: 4.9602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3619/20000 - Train Loss: 14.8910 - Test Loss: 37.1971 - MSE: 37.1972 - MAE: 4.9598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3620/20000 - Train Loss: 14.8880 - Test Loss: 37.1906 - MSE: 37.1906 - MAE: 4.9593\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3621/20000 - Train Loss: 14.8850 - Test Loss: 37.1840 - MSE: 37.1840 - MAE: 4.9588\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3622/20000 - Train Loss: 14.8820 - Test Loss: 37.1774 - MSE: 37.1774 - MAE: 4.9583\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 3623/20000 - Train Loss: 14.8790 - Test Loss: 37.1708 - MSE: 37.1708 - MAE: 4.9579\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3624/20000 - Train Loss: 14.8760 - Test Loss: 37.1642 - MSE: 37.1642 - MAE: 4.9574\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3625/20000 - Train Loss: 14.8730 - Test Loss: 37.1576 - MSE: 37.1576 - MAE: 4.9569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3626/20000 - Train Loss: 14.8699 - Test Loss: 37.1510 - MSE: 37.1510 - MAE: 4.9564\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3627/20000 - Train Loss: 14.8669 - Test Loss: 37.1445 - MSE: 37.1445 - MAE: 4.9559\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3628/20000 - Train Loss: 14.8639 - Test Loss: 37.1379 - MSE: 37.1379 - MAE: 4.9555\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3629/20000 - Train Loss: 14.8609 - Test Loss: 37.1313 - MSE: 37.1313 - MAE: 4.9550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3630/20000 - Train Loss: 14.8579 - Test Loss: 37.1247 - MSE: 37.1247 - MAE: 4.9545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3631/20000 - Train Loss: 14.8549 - Test Loss: 37.1182 - MSE: 37.1182 - MAE: 4.9540\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3632/20000 - Train Loss: 14.8519 - Test Loss: 37.1116 - MSE: 37.1116 - MAE: 4.9535\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 3633/20000 - Train Loss: 14.8488 - Test Loss: 37.1050 - MSE: 37.1050 - MAE: 4.9531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3634/20000 - Train Loss: 14.8458 - Test Loss: 37.0984 - MSE: 37.0984 - MAE: 4.9526\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3635/20000 - Train Loss: 14.8428 - Test Loss: 37.0918 - MSE: 37.0918 - MAE: 4.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3636/20000 - Train Loss: 14.8398 - Test Loss: 37.0852 - MSE: 37.0852 - MAE: 4.9516\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3637/20000 - Train Loss: 14.8367 - Test Loss: 37.0786 - MSE: 37.0786 - MAE: 4.9511\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3638/20000 - Train Loss: 14.8337 - Test Loss: 37.0720 - MSE: 37.0720 - MAE: 4.9507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3639/20000 - Train Loss: 14.8307 - Test Loss: 37.0654 - MSE: 37.0654 - MAE: 4.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3640/20000 - Train Loss: 14.8277 - Test Loss: 37.0587 - MSE: 37.0587 - MAE: 4.9497\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3641/20000 - Train Loss: 14.8246 - Test Loss: 37.0522 - MSE: 37.0522 - MAE: 4.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3642/20000 - Train Loss: 14.8216 - Test Loss: 37.0455 - MSE: 37.0455 - MAE: 4.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3643/20000 - Train Loss: 14.8186 - Test Loss: 37.0389 - MSE: 37.0389 - MAE: 4.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3644/20000 - Train Loss: 14.8156 - Test Loss: 37.0323 - MSE: 37.0323 - MAE: 4.9478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3645/20000 - Train Loss: 14.8125 - Test Loss: 37.0258 - MSE: 37.0258 - MAE: 4.9473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3646/20000 - Train Loss: 14.8095 - Test Loss: 37.0191 - MSE: 37.0191 - MAE: 4.9468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3647/20000 - Train Loss: 14.8065 - Test Loss: 37.0125 - MSE: 37.0125 - MAE: 4.9463\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 3648/20000 - Train Loss: 14.8034 - Test Loss: 37.0059 - MSE: 37.0059 - MAE: 4.9458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3649/20000 - Train Loss: 14.8004 - Test Loss: 36.9993 - MSE: 36.9993 - MAE: 4.9454\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3650/20000 - Train Loss: 14.7974 - Test Loss: 36.9927 - MSE: 36.9927 - MAE: 4.9449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3651/20000 - Train Loss: 14.7943 - Test Loss: 36.9861 - MSE: 36.9861 - MAE: 4.9444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3652/20000 - Train Loss: 14.7913 - Test Loss: 36.9794 - MSE: 36.9794 - MAE: 4.9439\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3653/20000 - Train Loss: 14.7883 - Test Loss: 36.9728 - MSE: 36.9728 - MAE: 4.9434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3654/20000 - Train Loss: 14.7852 - Test Loss: 36.9662 - MSE: 36.9662 - MAE: 4.9430\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3655/20000 - Train Loss: 14.7822 - Test Loss: 36.9595 - MSE: 36.9595 - MAE: 4.9425\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3656/20000 - Train Loss: 14.7791 - Test Loss: 36.9528 - MSE: 36.9528 - MAE: 4.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3657/20000 - Train Loss: 14.7761 - Test Loss: 36.9462 - MSE: 36.9462 - MAE: 4.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3658/20000 - Train Loss: 14.7731 - Test Loss: 36.9395 - MSE: 36.9395 - MAE: 4.9410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3659/20000 - Train Loss: 14.7700 - Test Loss: 36.9329 - MSE: 36.9329 - MAE: 4.9405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3660/20000 - Train Loss: 14.7670 - Test Loss: 36.9263 - MSE: 36.9263 - MAE: 4.9400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3661/20000 - Train Loss: 14.7639 - Test Loss: 36.9196 - MSE: 36.9196 - MAE: 4.9396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3662/20000 - Train Loss: 14.7609 - Test Loss: 36.9130 - MSE: 36.9130 - MAE: 4.9391\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3663/20000 - Train Loss: 14.7578 - Test Loss: 36.9063 - MSE: 36.9063 - MAE: 4.9386\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3664/20000 - Train Loss: 14.7548 - Test Loss: 36.8997 - MSE: 36.8997 - MAE: 4.9381\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 3665/20000 - Train Loss: 14.7518 - Test Loss: 36.8931 - MSE: 36.8931 - MAE: 4.9376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3666/20000 - Train Loss: 14.7487 - Test Loss: 36.8864 - MSE: 36.8864 - MAE: 4.9371\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3667/20000 - Train Loss: 14.7457 - Test Loss: 36.8798 - MSE: 36.8798 - MAE: 4.9366\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 3668/20000 - Train Loss: 14.7426 - Test Loss: 36.8732 - MSE: 36.8732 - MAE: 4.9362\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3669/20000 - Train Loss: 14.7396 - Test Loss: 36.8665 - MSE: 36.8665 - MAE: 4.9357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3670/20000 - Train Loss: 14.7365 - Test Loss: 36.8598 - MSE: 36.8598 - MAE: 4.9352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3671/20000 - Train Loss: 14.7335 - Test Loss: 36.8531 - MSE: 36.8531 - MAE: 4.9347\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3672/20000 - Train Loss: 14.7304 - Test Loss: 36.8465 - MSE: 36.8465 - MAE: 4.9342\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3673/20000 - Train Loss: 14.7274 - Test Loss: 36.8398 - MSE: 36.8398 - MAE: 4.9337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3674/20000 - Train Loss: 14.7243 - Test Loss: 36.8331 - MSE: 36.8331 - MAE: 4.9332\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3675/20000 - Train Loss: 14.7212 - Test Loss: 36.8264 - MSE: 36.8264 - MAE: 4.9327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3676/20000 - Train Loss: 14.7182 - Test Loss: 36.8197 - MSE: 36.8197 - MAE: 4.9323\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 3677/20000 - Train Loss: 14.7151 - Test Loss: 36.8130 - MSE: 36.8130 - MAE: 4.9318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3678/20000 - Train Loss: 14.7121 - Test Loss: 36.8064 - MSE: 36.8064 - MAE: 4.9313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3679/20000 - Train Loss: 14.7090 - Test Loss: 36.7997 - MSE: 36.7997 - MAE: 4.9308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3680/20000 - Train Loss: 14.7060 - Test Loss: 36.7930 - MSE: 36.7930 - MAE: 4.9303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3681/20000 - Train Loss: 14.7029 - Test Loss: 36.7864 - MSE: 36.7864 - MAE: 4.9298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3682/20000 - Train Loss: 14.6998 - Test Loss: 36.7797 - MSE: 36.7797 - MAE: 4.9293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3683/20000 - Train Loss: 14.6968 - Test Loss: 36.7730 - MSE: 36.7730 - MAE: 4.9288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3684/20000 - Train Loss: 14.6937 - Test Loss: 36.7664 - MSE: 36.7664 - MAE: 4.9284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3685/20000 - Train Loss: 14.6906 - Test Loss: 36.7597 - MSE: 36.7597 - MAE: 4.9279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3686/20000 - Train Loss: 14.6876 - Test Loss: 36.7530 - MSE: 36.7530 - MAE: 4.9274\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3687/20000 - Train Loss: 14.6845 - Test Loss: 36.7463 - MSE: 36.7463 - MAE: 4.9269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3688/20000 - Train Loss: 14.6814 - Test Loss: 36.7396 - MSE: 36.7396 - MAE: 4.9264\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3689/20000 - Train Loss: 14.6784 - Test Loss: 36.7329 - MSE: 36.7329 - MAE: 4.9259\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3690/20000 - Train Loss: 14.6753 - Test Loss: 36.7262 - MSE: 36.7262 - MAE: 4.9254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3691/20000 - Train Loss: 14.6722 - Test Loss: 36.7195 - MSE: 36.7195 - MAE: 4.9249\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3692/20000 - Train Loss: 14.6692 - Test Loss: 36.7128 - MSE: 36.7128 - MAE: 4.9244\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3693/20000 - Train Loss: 14.6661 - Test Loss: 36.7061 - MSE: 36.7061 - MAE: 4.9239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3694/20000 - Train Loss: 14.6630 - Test Loss: 36.6993 - MSE: 36.6993 - MAE: 4.9234\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3695/20000 - Train Loss: 14.6599 - Test Loss: 36.6926 - MSE: 36.6926 - MAE: 4.9230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3696/20000 - Train Loss: 14.6569 - Test Loss: 36.6859 - MSE: 36.6859 - MAE: 4.9225\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3697/20000 - Train Loss: 14.6538 - Test Loss: 36.6792 - MSE: 36.6792 - MAE: 4.9220\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3698/20000 - Train Loss: 14.6507 - Test Loss: 36.6724 - MSE: 36.6724 - MAE: 4.9215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3699/20000 - Train Loss: 14.6476 - Test Loss: 36.6658 - MSE: 36.6658 - MAE: 4.9210\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3700/20000 - Train Loss: 14.6446 - Test Loss: 36.6591 - MSE: 36.6591 - MAE: 4.9205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3701/20000 - Train Loss: 14.6415 - Test Loss: 36.6524 - MSE: 36.6524 - MAE: 4.9200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3702/20000 - Train Loss: 14.6384 - Test Loss: 36.6457 - MSE: 36.6457 - MAE: 4.9195\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3703/20000 - Train Loss: 14.6353 - Test Loss: 36.6389 - MSE: 36.6389 - MAE: 4.9190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3704/20000 - Train Loss: 14.6322 - Test Loss: 36.6322 - MSE: 36.6322 - MAE: 4.9185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3705/20000 - Train Loss: 14.6292 - Test Loss: 36.6255 - MSE: 36.6255 - MAE: 4.9180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3706/20000 - Train Loss: 14.6261 - Test Loss: 36.6188 - MSE: 36.6188 - MAE: 4.9175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3707/20000 - Train Loss: 14.6230 - Test Loss: 36.6121 - MSE: 36.6121 - MAE: 4.9170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3708/20000 - Train Loss: 14.6199 - Test Loss: 36.6054 - MSE: 36.6054 - MAE: 4.9165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3709/20000 - Train Loss: 14.6168 - Test Loss: 36.5986 - MSE: 36.5986 - MAE: 4.9160\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3710/20000 - Train Loss: 14.6137 - Test Loss: 36.5919 - MSE: 36.5919 - MAE: 4.9156\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3711/20000 - Train Loss: 14.6107 - Test Loss: 36.5852 - MSE: 36.5852 - MAE: 4.9151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3712/20000 - Train Loss: 14.6076 - Test Loss: 36.5784 - MSE: 36.5784 - MAE: 4.9146\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3713/20000 - Train Loss: 14.6045 - Test Loss: 36.5716 - MSE: 36.5716 - MAE: 4.9141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3714/20000 - Train Loss: 14.6014 - Test Loss: 36.5649 - MSE: 36.5649 - MAE: 4.9136\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3715/20000 - Train Loss: 14.5983 - Test Loss: 36.5581 - MSE: 36.5581 - MAE: 4.9131\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3716/20000 - Train Loss: 14.5952 - Test Loss: 36.5514 - MSE: 36.5514 - MAE: 4.9126\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3717/20000 - Train Loss: 14.5921 - Test Loss: 36.5446 - MSE: 36.5446 - MAE: 4.9121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3718/20000 - Train Loss: 14.5890 - Test Loss: 36.5379 - MSE: 36.5379 - MAE: 4.9116\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3719/20000 - Train Loss: 14.5859 - Test Loss: 36.5312 - MSE: 36.5312 - MAE: 4.9111\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3720/20000 - Train Loss: 14.5828 - Test Loss: 36.5244 - MSE: 36.5244 - MAE: 4.9106\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3721/20000 - Train Loss: 14.5797 - Test Loss: 36.5176 - MSE: 36.5176 - MAE: 4.9101\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 3722/20000 - Train Loss: 14.5766 - Test Loss: 36.5108 - MSE: 36.5108 - MAE: 4.9096\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 3723/20000 - Train Loss: 14.5735 - Test Loss: 36.5042 - MSE: 36.5042 - MAE: 4.9091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3724/20000 - Train Loss: 14.5704 - Test Loss: 36.4974 - MSE: 36.4974 - MAE: 4.9086\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3725/20000 - Train Loss: 14.5673 - Test Loss: 36.4906 - MSE: 36.4906 - MAE: 4.9081\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3726/20000 - Train Loss: 14.5642 - Test Loss: 36.4838 - MSE: 36.4838 - MAE: 4.9076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3727/20000 - Train Loss: 14.5612 - Test Loss: 36.4771 - MSE: 36.4771 - MAE: 4.9071\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3728/20000 - Train Loss: 14.5580 - Test Loss: 36.4703 - MSE: 36.4703 - MAE: 4.9066\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3729/20000 - Train Loss: 14.5549 - Test Loss: 36.4636 - MSE: 36.4636 - MAE: 4.9061\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3730/20000 - Train Loss: 14.5518 - Test Loss: 36.4568 - MSE: 36.4568 - MAE: 4.9056\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3731/20000 - Train Loss: 14.5487 - Test Loss: 36.4500 - MSE: 36.4500 - MAE: 4.9051\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 3732/20000 - Train Loss: 14.5456 - Test Loss: 36.4433 - MSE: 36.4433 - MAE: 4.9046\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3733/20000 - Train Loss: 14.5425 - Test Loss: 36.4365 - MSE: 36.4365 - MAE: 4.9041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3734/20000 - Train Loss: 14.5394 - Test Loss: 36.4297 - MSE: 36.4297 - MAE: 4.9036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3735/20000 - Train Loss: 14.5363 - Test Loss: 36.4229 - MSE: 36.4229 - MAE: 4.9031\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 3736/20000 - Train Loss: 14.5332 - Test Loss: 36.4161 - MSE: 36.4161 - MAE: 4.9026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3737/20000 - Train Loss: 14.5301 - Test Loss: 36.4093 - MSE: 36.4093 - MAE: 4.9021\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3738/20000 - Train Loss: 14.5270 - Test Loss: 36.4025 - MSE: 36.4025 - MAE: 4.9016\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3739/20000 - Train Loss: 14.5239 - Test Loss: 36.3958 - MSE: 36.3958 - MAE: 4.9011\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3740/20000 - Train Loss: 14.5208 - Test Loss: 36.3890 - MSE: 36.3890 - MAE: 4.9006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3741/20000 - Train Loss: 14.5176 - Test Loss: 36.3821 - MSE: 36.3821 - MAE: 4.9001\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3742/20000 - Train Loss: 14.5145 - Test Loss: 36.3754 - MSE: 36.3754 - MAE: 4.8996\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3743/20000 - Train Loss: 14.5114 - Test Loss: 36.3686 - MSE: 36.3686 - MAE: 4.8991\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3744/20000 - Train Loss: 14.5083 - Test Loss: 36.3618 - MSE: 36.3618 - MAE: 4.8986\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3745/20000 - Train Loss: 14.5052 - Test Loss: 36.3550 - MSE: 36.3550 - MAE: 4.8981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3746/20000 - Train Loss: 14.5021 - Test Loss: 36.3482 - MSE: 36.3482 - MAE: 4.8976\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3747/20000 - Train Loss: 14.4990 - Test Loss: 36.3415 - MSE: 36.3415 - MAE: 4.8971\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 3748/20000 - Train Loss: 14.4958 - Test Loss: 36.3346 - MSE: 36.3346 - MAE: 4.8966\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3749/20000 - Train Loss: 14.4927 - Test Loss: 36.3278 - MSE: 36.3278 - MAE: 4.8961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3750/20000 - Train Loss: 14.4896 - Test Loss: 36.3210 - MSE: 36.3210 - MAE: 4.8956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3751/20000 - Train Loss: 14.4865 - Test Loss: 36.3142 - MSE: 36.3142 - MAE: 4.8951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3752/20000 - Train Loss: 14.4833 - Test Loss: 36.3073 - MSE: 36.3073 - MAE: 4.8946\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3753/20000 - Train Loss: 14.4802 - Test Loss: 36.3005 - MSE: 36.3005 - MAE: 4.8941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3754/20000 - Train Loss: 14.4771 - Test Loss: 36.2937 - MSE: 36.2937 - MAE: 4.8936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3755/20000 - Train Loss: 14.4740 - Test Loss: 36.2869 - MSE: 36.2869 - MAE: 4.8931\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3756/20000 - Train Loss: 14.4709 - Test Loss: 36.2801 - MSE: 36.2801 - MAE: 4.8926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3757/20000 - Train Loss: 14.4677 - Test Loss: 36.2733 - MSE: 36.2733 - MAE: 4.8921\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3758/20000 - Train Loss: 14.4646 - Test Loss: 36.2665 - MSE: 36.2665 - MAE: 4.8916\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 3759/20000 - Train Loss: 14.4615 - Test Loss: 36.2596 - MSE: 36.2596 - MAE: 4.8911\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3760/20000 - Train Loss: 14.4583 - Test Loss: 36.2528 - MSE: 36.2528 - MAE: 4.8906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3761/20000 - Train Loss: 14.4552 - Test Loss: 36.2460 - MSE: 36.2460 - MAE: 4.8901\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3762/20000 - Train Loss: 14.4521 - Test Loss: 36.2392 - MSE: 36.2392 - MAE: 4.8896\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3763/20000 - Train Loss: 14.4490 - Test Loss: 36.2323 - MSE: 36.2323 - MAE: 4.8891\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3764/20000 - Train Loss: 14.4458 - Test Loss: 36.2255 - MSE: 36.2255 - MAE: 4.8886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3765/20000 - Train Loss: 14.4427 - Test Loss: 36.2187 - MSE: 36.2187 - MAE: 4.8881\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3766/20000 - Train Loss: 14.4395 - Test Loss: 36.2118 - MSE: 36.2118 - MAE: 4.8875\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3767/20000 - Train Loss: 14.4364 - Test Loss: 36.2049 - MSE: 36.2049 - MAE: 4.8870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3768/20000 - Train Loss: 14.4333 - Test Loss: 36.1981 - MSE: 36.1981 - MAE: 4.8865\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3769/20000 - Train Loss: 14.4301 - Test Loss: 36.1913 - MSE: 36.1913 - MAE: 4.8860\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3770/20000 - Train Loss: 14.4270 - Test Loss: 36.1845 - MSE: 36.1845 - MAE: 4.8855\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3771/20000 - Train Loss: 14.4239 - Test Loss: 36.1776 - MSE: 36.1776 - MAE: 4.8850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3772/20000 - Train Loss: 14.4207 - Test Loss: 36.1708 - MSE: 36.1708 - MAE: 4.8845\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 3773/20000 - Train Loss: 14.4176 - Test Loss: 36.1639 - MSE: 36.1639 - MAE: 4.8840\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3774/20000 - Train Loss: 14.4144 - Test Loss: 36.1571 - MSE: 36.1571 - MAE: 4.8835\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3775/20000 - Train Loss: 14.4113 - Test Loss: 36.1502 - MSE: 36.1502 - MAE: 4.8830\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3776/20000 - Train Loss: 14.4082 - Test Loss: 36.1434 - MSE: 36.1434 - MAE: 4.8825\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 3777/20000 - Train Loss: 14.4050 - Test Loss: 36.1365 - MSE: 36.1365 - MAE: 4.8820\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3778/20000 - Train Loss: 14.4019 - Test Loss: 36.1296 - MSE: 36.1297 - MAE: 4.8815\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3779/20000 - Train Loss: 14.3987 - Test Loss: 36.1228 - MSE: 36.1228 - MAE: 4.8810\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 3780/20000 - Train Loss: 14.3956 - Test Loss: 36.1159 - MSE: 36.1159 - MAE: 4.8804\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3781/20000 - Train Loss: 14.3924 - Test Loss: 36.1090 - MSE: 36.1090 - MAE: 4.8799\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3782/20000 - Train Loss: 14.3893 - Test Loss: 36.1022 - MSE: 36.1022 - MAE: 4.8794\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3783/20000 - Train Loss: 14.3861 - Test Loss: 36.0953 - MSE: 36.0953 - MAE: 4.8789\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3784/20000 - Train Loss: 14.3830 - Test Loss: 36.0884 - MSE: 36.0884 - MAE: 4.8784\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 3785/20000 - Train Loss: 14.3798 - Test Loss: 36.0816 - MSE: 36.0816 - MAE: 4.8779\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3786/20000 - Train Loss: 14.3767 - Test Loss: 36.0747 - MSE: 36.0747 - MAE: 4.8774\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3787/20000 - Train Loss: 14.3735 - Test Loss: 36.0678 - MSE: 36.0678 - MAE: 4.8769\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3788/20000 - Train Loss: 14.3704 - Test Loss: 36.0610 - MSE: 36.0610 - MAE: 4.8764\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3789/20000 - Train Loss: 14.3672 - Test Loss: 36.0541 - MSE: 36.0541 - MAE: 4.8759\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3790/20000 - Train Loss: 14.3641 - Test Loss: 36.0472 - MSE: 36.0472 - MAE: 4.8754\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 3791/20000 - Train Loss: 14.3609 - Test Loss: 36.0404 - MSE: 36.0404 - MAE: 4.8748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3792/20000 - Train Loss: 14.3578 - Test Loss: 36.0335 - MSE: 36.0335 - MAE: 4.8743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3793/20000 - Train Loss: 14.3546 - Test Loss: 36.0266 - MSE: 36.0266 - MAE: 4.8738\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3794/20000 - Train Loss: 14.3515 - Test Loss: 36.0197 - MSE: 36.0197 - MAE: 4.8733\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 3795/20000 - Train Loss: 14.3483 - Test Loss: 36.0128 - MSE: 36.0128 - MAE: 4.8728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3796/20000 - Train Loss: 14.3451 - Test Loss: 36.0059 - MSE: 36.0059 - MAE: 4.8723\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 3797/20000 - Train Loss: 14.3420 - Test Loss: 35.9989 - MSE: 35.9989 - MAE: 4.8718\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3798/20000 - Train Loss: 14.3388 - Test Loss: 35.9921 - MSE: 35.9920 - MAE: 4.8713\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3799/20000 - Train Loss: 14.3356 - Test Loss: 35.9852 - MSE: 35.9852 - MAE: 4.8707\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 3800/20000 - Train Loss: 14.3325 - Test Loss: 35.9783 - MSE: 35.9783 - MAE: 4.8702\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3801/20000 - Train Loss: 14.3293 - Test Loss: 35.9714 - MSE: 35.9714 - MAE: 4.8697\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3802/20000 - Train Loss: 14.3262 - Test Loss: 35.9645 - MSE: 35.9645 - MAE: 4.8692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3803/20000 - Train Loss: 14.3230 - Test Loss: 35.9576 - MSE: 35.9576 - MAE: 4.8687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3804/20000 - Train Loss: 14.3198 - Test Loss: 35.9507 - MSE: 35.9507 - MAE: 4.8682\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3805/20000 - Train Loss: 14.3167 - Test Loss: 35.9439 - MSE: 35.9439 - MAE: 4.8677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 3806/20000 - Train Loss: 14.3135 - Test Loss: 35.9369 - MSE: 35.9369 - MAE: 4.8672\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3807/20000 - Train Loss: 14.3103 - Test Loss: 35.9301 - MSE: 35.9301 - MAE: 4.8666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3808/20000 - Train Loss: 14.3072 - Test Loss: 35.9232 - MSE: 35.9232 - MAE: 4.8661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3809/20000 - Train Loss: 14.3040 - Test Loss: 35.9163 - MSE: 35.9163 - MAE: 4.8656\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3810/20000 - Train Loss: 14.3008 - Test Loss: 35.9093 - MSE: 35.9093 - MAE: 4.8651\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3811/20000 - Train Loss: 14.2976 - Test Loss: 35.9024 - MSE: 35.9024 - MAE: 4.8646\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3812/20000 - Train Loss: 14.2945 - Test Loss: 35.8954 - MSE: 35.8954 - MAE: 4.8641\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3813/20000 - Train Loss: 14.2913 - Test Loss: 35.8884 - MSE: 35.8884 - MAE: 4.8636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3814/20000 - Train Loss: 14.2881 - Test Loss: 35.8815 - MSE: 35.8815 - MAE: 4.8630\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3815/20000 - Train Loss: 14.2849 - Test Loss: 35.8746 - MSE: 35.8746 - MAE: 4.8625\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3816/20000 - Train Loss: 14.2818 - Test Loss: 35.8677 - MSE: 35.8677 - MAE: 4.8620\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 3817/20000 - Train Loss: 14.2786 - Test Loss: 35.8607 - MSE: 35.8607 - MAE: 4.8615\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3818/20000 - Train Loss: 14.2754 - Test Loss: 35.8538 - MSE: 35.8538 - MAE: 4.8610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3819/20000 - Train Loss: 14.2722 - Test Loss: 35.8470 - MSE: 35.8469 - MAE: 4.8605\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 3820/20000 - Train Loss: 14.2690 - Test Loss: 35.8400 - MSE: 35.8400 - MAE: 4.8599\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3821/20000 - Train Loss: 14.2659 - Test Loss: 35.8331 - MSE: 35.8331 - MAE: 4.8594\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3822/20000 - Train Loss: 14.2627 - Test Loss: 35.8262 - MSE: 35.8262 - MAE: 4.8589\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 3823/20000 - Train Loss: 14.2595 - Test Loss: 35.8192 - MSE: 35.8192 - MAE: 4.8584\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3824/20000 - Train Loss: 14.2563 - Test Loss: 35.8123 - MSE: 35.8123 - MAE: 4.8579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3825/20000 - Train Loss: 14.2531 - Test Loss: 35.8054 - MSE: 35.8054 - MAE: 4.8574\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3826/20000 - Train Loss: 14.2500 - Test Loss: 35.7984 - MSE: 35.7984 - MAE: 4.8568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3827/20000 - Train Loss: 14.2468 - Test Loss: 35.7914 - MSE: 35.7914 - MAE: 4.8563\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3828/20000 - Train Loss: 14.2436 - Test Loss: 35.7845 - MSE: 35.7845 - MAE: 4.8558\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3829/20000 - Train Loss: 14.2404 - Test Loss: 35.7775 - MSE: 35.7775 - MAE: 4.8553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3830/20000 - Train Loss: 14.2372 - Test Loss: 35.7705 - MSE: 35.7705 - MAE: 4.8548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3831/20000 - Train Loss: 14.2340 - Test Loss: 35.7636 - MSE: 35.7636 - MAE: 4.8543\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3832/20000 - Train Loss: 14.2308 - Test Loss: 35.7566 - MSE: 35.7566 - MAE: 4.8537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3833/20000 - Train Loss: 14.2276 - Test Loss: 35.7497 - MSE: 35.7497 - MAE: 4.8532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3834/20000 - Train Loss: 14.2244 - Test Loss: 35.7427 - MSE: 35.7427 - MAE: 4.8527\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3835/20000 - Train Loss: 14.2212 - Test Loss: 35.7358 - MSE: 35.7358 - MAE: 4.8522\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3836/20000 - Train Loss: 14.2181 - Test Loss: 35.7289 - MSE: 35.7289 - MAE: 4.8517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3837/20000 - Train Loss: 14.2149 - Test Loss: 35.7219 - MSE: 35.7219 - MAE: 4.8511\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3838/20000 - Train Loss: 14.2117 - Test Loss: 35.7150 - MSE: 35.7150 - MAE: 4.8506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3839/20000 - Train Loss: 14.2085 - Test Loss: 35.7080 - MSE: 35.7080 - MAE: 4.8501\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3840/20000 - Train Loss: 14.2053 - Test Loss: 35.7010 - MSE: 35.7010 - MAE: 4.8496\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3841/20000 - Train Loss: 14.2021 - Test Loss: 35.6941 - MSE: 35.6941 - MAE: 4.8491\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3842/20000 - Train Loss: 14.1989 - Test Loss: 35.6871 - MSE: 35.6871 - MAE: 4.8485\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3843/20000 - Train Loss: 14.1957 - Test Loss: 35.6801 - MSE: 35.6801 - MAE: 4.8480\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3844/20000 - Train Loss: 14.1925 - Test Loss: 35.6730 - MSE: 35.6730 - MAE: 4.8475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3845/20000 - Train Loss: 14.1893 - Test Loss: 35.6661 - MSE: 35.6661 - MAE: 4.8470\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3846/20000 - Train Loss: 14.1861 - Test Loss: 35.6591 - MSE: 35.6591 - MAE: 4.8466\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3847/20000 - Train Loss: 14.1829 - Test Loss: 35.6521 - MSE: 35.6521 - MAE: 4.8461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3848/20000 - Train Loss: 14.1797 - Test Loss: 35.6451 - MSE: 35.6451 - MAE: 4.8456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3849/20000 - Train Loss: 14.1765 - Test Loss: 35.6381 - MSE: 35.6381 - MAE: 4.8451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3850/20000 - Train Loss: 14.1733 - Test Loss: 35.6312 - MSE: 35.6312 - MAE: 4.8446\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3851/20000 - Train Loss: 14.1701 - Test Loss: 35.6242 - MSE: 35.6242 - MAE: 4.8442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3852/20000 - Train Loss: 14.1669 - Test Loss: 35.6172 - MSE: 35.6172 - MAE: 4.8437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3853/20000 - Train Loss: 14.1636 - Test Loss: 35.6102 - MSE: 35.6102 - MAE: 4.8432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3854/20000 - Train Loss: 14.1604 - Test Loss: 35.6033 - MSE: 35.6033 - MAE: 4.8427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3855/20000 - Train Loss: 14.1572 - Test Loss: 35.5963 - MSE: 35.5963 - MAE: 4.8422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3856/20000 - Train Loss: 14.1540 - Test Loss: 35.5893 - MSE: 35.5893 - MAE: 4.8418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3857/20000 - Train Loss: 14.1508 - Test Loss: 35.5823 - MSE: 35.5823 - MAE: 4.8413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3858/20000 - Train Loss: 14.1476 - Test Loss: 35.5752 - MSE: 35.5752 - MAE: 4.8408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3859/20000 - Train Loss: 14.1444 - Test Loss: 35.5683 - MSE: 35.5683 - MAE: 4.8403\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 3860/20000 - Train Loss: 14.1412 - Test Loss: 35.5612 - MSE: 35.5612 - MAE: 4.8398\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3861/20000 - Train Loss: 14.1380 - Test Loss: 35.5542 - MSE: 35.5542 - MAE: 4.8394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3862/20000 - Train Loss: 14.1347 - Test Loss: 35.5472 - MSE: 35.5472 - MAE: 4.8389\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 3863/20000 - Train Loss: 14.1315 - Test Loss: 35.5402 - MSE: 35.5402 - MAE: 4.8384\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3864/20000 - Train Loss: 14.1283 - Test Loss: 35.5332 - MSE: 35.5332 - MAE: 4.8379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3865/20000 - Train Loss: 14.1251 - Test Loss: 35.5262 - MSE: 35.5262 - MAE: 4.8374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3866/20000 - Train Loss: 14.1219 - Test Loss: 35.5192 - MSE: 35.5192 - MAE: 4.8369\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3867/20000 - Train Loss: 14.1186 - Test Loss: 35.5122 - MSE: 35.5122 - MAE: 4.8365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3868/20000 - Train Loss: 14.1154 - Test Loss: 35.5052 - MSE: 35.5052 - MAE: 4.8360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3869/20000 - Train Loss: 14.1122 - Test Loss: 35.4981 - MSE: 35.4981 - MAE: 4.8355\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3870/20000 - Train Loss: 14.1090 - Test Loss: 35.4911 - MSE: 35.4911 - MAE: 4.8350\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3871/20000 - Train Loss: 14.1058 - Test Loss: 35.4841 - MSE: 35.4841 - MAE: 4.8345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3872/20000 - Train Loss: 14.1025 - Test Loss: 35.4770 - MSE: 35.4770 - MAE: 4.8340\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3873/20000 - Train Loss: 14.0993 - Test Loss: 35.4700 - MSE: 35.4700 - MAE: 4.8335\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3874/20000 - Train Loss: 14.0961 - Test Loss: 35.4630 - MSE: 35.4630 - MAE: 4.8331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3875/20000 - Train Loss: 14.0929 - Test Loss: 35.4560 - MSE: 35.4560 - MAE: 4.8326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3876/20000 - Train Loss: 14.0896 - Test Loss: 35.4489 - MSE: 35.4489 - MAE: 4.8321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3877/20000 - Train Loss: 14.0864 - Test Loss: 35.4419 - MSE: 35.4419 - MAE: 4.8316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3878/20000 - Train Loss: 14.0832 - Test Loss: 35.4349 - MSE: 35.4349 - MAE: 4.8311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3879/20000 - Train Loss: 14.0799 - Test Loss: 35.4278 - MSE: 35.4278 - MAE: 4.8306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3880/20000 - Train Loss: 14.0767 - Test Loss: 35.4208 - MSE: 35.4208 - MAE: 4.8302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3881/20000 - Train Loss: 14.0735 - Test Loss: 35.4138 - MSE: 35.4138 - MAE: 4.8297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3882/20000 - Train Loss: 14.0703 - Test Loss: 35.4067 - MSE: 35.4067 - MAE: 4.8292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3883/20000 - Train Loss: 14.0670 - Test Loss: 35.3998 - MSE: 35.3998 - MAE: 4.8287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3884/20000 - Train Loss: 14.0638 - Test Loss: 35.3927 - MSE: 35.3927 - MAE: 4.8282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3885/20000 - Train Loss: 14.0606 - Test Loss: 35.3857 - MSE: 35.3857 - MAE: 4.8277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3886/20000 - Train Loss: 14.0573 - Test Loss: 35.3785 - MSE: 35.3785 - MAE: 4.8272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3887/20000 - Train Loss: 14.0541 - Test Loss: 35.3715 - MSE: 35.3715 - MAE: 4.8267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3888/20000 - Train Loss: 14.0509 - Test Loss: 35.3644 - MSE: 35.3644 - MAE: 4.8263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3889/20000 - Train Loss: 14.0476 - Test Loss: 35.3573 - MSE: 35.3573 - MAE: 4.8258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3890/20000 - Train Loss: 14.0444 - Test Loss: 35.3503 - MSE: 35.3503 - MAE: 4.8253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3891/20000 - Train Loss: 14.0411 - Test Loss: 35.3432 - MSE: 35.3432 - MAE: 4.8248\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 3892/20000 - Train Loss: 14.0379 - Test Loss: 35.3362 - MSE: 35.3362 - MAE: 4.8243\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3893/20000 - Train Loss: 14.0347 - Test Loss: 35.3291 - MSE: 35.3291 - MAE: 4.8238\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3894/20000 - Train Loss: 14.0314 - Test Loss: 35.3221 - MSE: 35.3221 - MAE: 4.8233\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3895/20000 - Train Loss: 14.0282 - Test Loss: 35.3150 - MSE: 35.3150 - MAE: 4.8228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3896/20000 - Train Loss: 14.0249 - Test Loss: 35.3079 - MSE: 35.3079 - MAE: 4.8224\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3897/20000 - Train Loss: 14.0217 - Test Loss: 35.3009 - MSE: 35.3009 - MAE: 4.8219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3898/20000 - Train Loss: 14.0184 - Test Loss: 35.2938 - MSE: 35.2938 - MAE: 4.8214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3899/20000 - Train Loss: 14.0152 - Test Loss: 35.2868 - MSE: 35.2868 - MAE: 4.8209\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3900/20000 - Train Loss: 14.0119 - Test Loss: 35.2797 - MSE: 35.2797 - MAE: 4.8204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3901/20000 - Train Loss: 14.0087 - Test Loss: 35.2726 - MSE: 35.2726 - MAE: 4.8199\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3902/20000 - Train Loss: 14.0054 - Test Loss: 35.2655 - MSE: 35.2655 - MAE: 4.8194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3903/20000 - Train Loss: 14.0022 - Test Loss: 35.2584 - MSE: 35.2584 - MAE: 4.8189\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3904/20000 - Train Loss: 13.9989 - Test Loss: 35.2513 - MSE: 35.2513 - MAE: 4.8184\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3905/20000 - Train Loss: 13.9957 - Test Loss: 35.2442 - MSE: 35.2442 - MAE: 4.8179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3906/20000 - Train Loss: 13.9925 - Test Loss: 35.2371 - MSE: 35.2371 - MAE: 4.8174\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3907/20000 - Train Loss: 13.9892 - Test Loss: 35.2300 - MSE: 35.2300 - MAE: 4.8170\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3908/20000 - Train Loss: 13.9859 - Test Loss: 35.2230 - MSE: 35.2230 - MAE: 4.8165\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 3909/20000 - Train Loss: 13.9827 - Test Loss: 35.2159 - MSE: 35.2159 - MAE: 4.8160\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3910/20000 - Train Loss: 13.9794 - Test Loss: 35.2088 - MSE: 35.2088 - MAE: 4.8155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3911/20000 - Train Loss: 13.9762 - Test Loss: 35.2018 - MSE: 35.2018 - MAE: 4.8150\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3912/20000 - Train Loss: 13.9729 - Test Loss: 35.1947 - MSE: 35.1947 - MAE: 4.8145\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3913/20000 - Train Loss: 13.9697 - Test Loss: 35.1876 - MSE: 35.1876 - MAE: 4.8140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3914/20000 - Train Loss: 13.9664 - Test Loss: 35.1805 - MSE: 35.1805 - MAE: 4.8135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3915/20000 - Train Loss: 13.9631 - Test Loss: 35.1734 - MSE: 35.1734 - MAE: 4.8130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3916/20000 - Train Loss: 13.9599 - Test Loss: 35.1663 - MSE: 35.1663 - MAE: 4.8125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3917/20000 - Train Loss: 13.9566 - Test Loss: 35.1591 - MSE: 35.1591 - MAE: 4.8120\n",
      "2/2 [==============================] - 0s 986us/step\n",
      "Epoch 3918/20000 - Train Loss: 13.9534 - Test Loss: 35.1521 - MSE: 35.1521 - MAE: 4.8116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3919/20000 - Train Loss: 13.9501 - Test Loss: 35.1449 - MSE: 35.1449 - MAE: 4.8111\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 3920/20000 - Train Loss: 13.9468 - Test Loss: 35.1378 - MSE: 35.1378 - MAE: 4.8106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3921/20000 - Train Loss: 13.9436 - Test Loss: 35.1307 - MSE: 35.1307 - MAE: 4.8101\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 3922/20000 - Train Loss: 13.9403 - Test Loss: 35.1235 - MSE: 35.1236 - MAE: 4.8096\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3923/20000 - Train Loss: 13.9370 - Test Loss: 35.1165 - MSE: 35.1165 - MAE: 4.8091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3924/20000 - Train Loss: 13.9338 - Test Loss: 35.1093 - MSE: 35.1093 - MAE: 4.8086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3925/20000 - Train Loss: 13.9305 - Test Loss: 35.1022 - MSE: 35.1022 - MAE: 4.8081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3926/20000 - Train Loss: 13.9272 - Test Loss: 35.0952 - MSE: 35.0952 - MAE: 4.8076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3927/20000 - Train Loss: 13.9240 - Test Loss: 35.0881 - MSE: 35.0881 - MAE: 4.8071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3928/20000 - Train Loss: 13.9207 - Test Loss: 35.0810 - MSE: 35.0810 - MAE: 4.8066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3929/20000 - Train Loss: 13.9174 - Test Loss: 35.0739 - MSE: 35.0739 - MAE: 4.8061\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3930/20000 - Train Loss: 13.9142 - Test Loss: 35.0668 - MSE: 35.0668 - MAE: 4.8056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3931/20000 - Train Loss: 13.9109 - Test Loss: 35.0596 - MSE: 35.0596 - MAE: 4.8051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3932/20000 - Train Loss: 13.9076 - Test Loss: 35.0524 - MSE: 35.0524 - MAE: 4.8046\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3933/20000 - Train Loss: 13.9043 - Test Loss: 35.0452 - MSE: 35.0452 - MAE: 4.8041\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3934/20000 - Train Loss: 13.9011 - Test Loss: 35.0381 - MSE: 35.0381 - MAE: 4.8036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3935/20000 - Train Loss: 13.8978 - Test Loss: 35.0309 - MSE: 35.0309 - MAE: 4.8031\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 3936/20000 - Train Loss: 13.8945 - Test Loss: 35.0238 - MSE: 35.0238 - MAE: 4.8026\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3937/20000 - Train Loss: 13.8912 - Test Loss: 35.0167 - MSE: 35.0167 - MAE: 4.8021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3938/20000 - Train Loss: 13.8880 - Test Loss: 35.0096 - MSE: 35.0096 - MAE: 4.8017\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3939/20000 - Train Loss: 13.8847 - Test Loss: 35.0024 - MSE: 35.0024 - MAE: 4.8012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3940/20000 - Train Loss: 13.8814 - Test Loss: 34.9953 - MSE: 34.9953 - MAE: 4.8007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3941/20000 - Train Loss: 13.8781 - Test Loss: 34.9882 - MSE: 34.9882 - MAE: 4.8002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3942/20000 - Train Loss: 13.8749 - Test Loss: 34.9811 - MSE: 34.9811 - MAE: 4.7997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3943/20000 - Train Loss: 13.8716 - Test Loss: 34.9739 - MSE: 34.9739 - MAE: 4.7992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3944/20000 - Train Loss: 13.8683 - Test Loss: 34.9668 - MSE: 34.9668 - MAE: 4.7987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3945/20000 - Train Loss: 13.8650 - Test Loss: 34.9596 - MSE: 34.9596 - MAE: 4.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3946/20000 - Train Loss: 13.8617 - Test Loss: 34.9525 - MSE: 34.9525 - MAE: 4.7977\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 3947/20000 - Train Loss: 13.8584 - Test Loss: 34.9453 - MSE: 34.9453 - MAE: 4.7972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3948/20000 - Train Loss: 13.8551 - Test Loss: 34.9381 - MSE: 34.9381 - MAE: 4.7967\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3949/20000 - Train Loss: 13.8519 - Test Loss: 34.9310 - MSE: 34.9310 - MAE: 4.7962\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3950/20000 - Train Loss: 13.8486 - Test Loss: 34.9238 - MSE: 34.9238 - MAE: 4.7957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3951/20000 - Train Loss: 13.8453 - Test Loss: 34.9166 - MSE: 34.9166 - MAE: 4.7952\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3952/20000 - Train Loss: 13.8420 - Test Loss: 34.9095 - MSE: 34.9095 - MAE: 4.7947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3953/20000 - Train Loss: 13.8387 - Test Loss: 34.9023 - MSE: 34.9023 - MAE: 4.7942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3954/20000 - Train Loss: 13.8354 - Test Loss: 34.8952 - MSE: 34.8952 - MAE: 4.7937\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3955/20000 - Train Loss: 13.8321 - Test Loss: 34.8880 - MSE: 34.8880 - MAE: 4.7932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3956/20000 - Train Loss: 13.8288 - Test Loss: 34.8808 - MSE: 34.8808 - MAE: 4.7927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3957/20000 - Train Loss: 13.8255 - Test Loss: 34.8736 - MSE: 34.8736 - MAE: 4.7922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3958/20000 - Train Loss: 13.8222 - Test Loss: 34.8665 - MSE: 34.8665 - MAE: 4.7917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3959/20000 - Train Loss: 13.8189 - Test Loss: 34.8593 - MSE: 34.8593 - MAE: 4.7912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3960/20000 - Train Loss: 13.8157 - Test Loss: 34.8521 - MSE: 34.8521 - MAE: 4.7907\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3961/20000 - Train Loss: 13.8124 - Test Loss: 34.8449 - MSE: 34.8449 - MAE: 4.7902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3962/20000 - Train Loss: 13.8091 - Test Loss: 34.8378 - MSE: 34.8378 - MAE: 4.7897\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3963/20000 - Train Loss: 13.8058 - Test Loss: 34.8306 - MSE: 34.8306 - MAE: 4.7892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3964/20000 - Train Loss: 13.8025 - Test Loss: 34.8234 - MSE: 34.8234 - MAE: 4.7887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3965/20000 - Train Loss: 13.7992 - Test Loss: 34.8162 - MSE: 34.8162 - MAE: 4.7882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3966/20000 - Train Loss: 13.7959 - Test Loss: 34.8090 - MSE: 34.8090 - MAE: 4.7877\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3967/20000 - Train Loss: 13.7926 - Test Loss: 34.8018 - MSE: 34.8018 - MAE: 4.7872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3968/20000 - Train Loss: 13.7893 - Test Loss: 34.7947 - MSE: 34.7947 - MAE: 4.7867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3969/20000 - Train Loss: 13.7860 - Test Loss: 34.7875 - MSE: 34.7875 - MAE: 4.7862\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3970/20000 - Train Loss: 13.7827 - Test Loss: 34.7803 - MSE: 34.7803 - MAE: 4.7857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3971/20000 - Train Loss: 13.7793 - Test Loss: 34.7731 - MSE: 34.7731 - MAE: 4.7852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3972/20000 - Train Loss: 13.7760 - Test Loss: 34.7659 - MSE: 34.7659 - MAE: 4.7847\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3973/20000 - Train Loss: 13.7727 - Test Loss: 34.7587 - MSE: 34.7587 - MAE: 4.7841\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3974/20000 - Train Loss: 13.7694 - Test Loss: 34.7515 - MSE: 34.7515 - MAE: 4.7836\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3975/20000 - Train Loss: 13.7661 - Test Loss: 34.7443 - MSE: 34.7443 - MAE: 4.7831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3976/20000 - Train Loss: 13.7628 - Test Loss: 34.7371 - MSE: 34.7371 - MAE: 4.7826\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 3977/20000 - Train Loss: 13.7595 - Test Loss: 34.7298 - MSE: 34.7298 - MAE: 4.7821\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3978/20000 - Train Loss: 13.7562 - Test Loss: 34.7226 - MSE: 34.7226 - MAE: 4.7816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3979/20000 - Train Loss: 13.7529 - Test Loss: 34.7154 - MSE: 34.7154 - MAE: 4.7811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3980/20000 - Train Loss: 13.7496 - Test Loss: 34.7082 - MSE: 34.7082 - MAE: 4.7806\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 3981/20000 - Train Loss: 13.7463 - Test Loss: 34.7010 - MSE: 34.7010 - MAE: 4.7801\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 3982/20000 - Train Loss: 13.7429 - Test Loss: 34.6938 - MSE: 34.6938 - MAE: 4.7796\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 3983/20000 - Train Loss: 13.7396 - Test Loss: 34.6866 - MSE: 34.6866 - MAE: 4.7791\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3984/20000 - Train Loss: 13.7363 - Test Loss: 34.6794 - MSE: 34.6794 - MAE: 4.7786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3985/20000 - Train Loss: 13.7330 - Test Loss: 34.6722 - MSE: 34.6722 - MAE: 4.7781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3986/20000 - Train Loss: 13.7297 - Test Loss: 34.6650 - MSE: 34.6650 - MAE: 4.7776\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3987/20000 - Train Loss: 13.7264 - Test Loss: 34.6578 - MSE: 34.6578 - MAE: 4.7771\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3988/20000 - Train Loss: 13.7231 - Test Loss: 34.6506 - MSE: 34.6506 - MAE: 4.7766\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3989/20000 - Train Loss: 13.7197 - Test Loss: 34.6433 - MSE: 34.6433 - MAE: 4.7761\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3990/20000 - Train Loss: 13.7164 - Test Loss: 34.6361 - MSE: 34.6361 - MAE: 4.7756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3991/20000 - Train Loss: 13.7131 - Test Loss: 34.6288 - MSE: 34.6288 - MAE: 4.7751\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3992/20000 - Train Loss: 13.7098 - Test Loss: 34.6216 - MSE: 34.6216 - MAE: 4.7745\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3993/20000 - Train Loss: 13.7064 - Test Loss: 34.6143 - MSE: 34.6143 - MAE: 4.7740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3994/20000 - Train Loss: 13.7031 - Test Loss: 34.6071 - MSE: 34.6071 - MAE: 4.7735\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 3995/20000 - Train Loss: 13.6998 - Test Loss: 34.5999 - MSE: 34.5999 - MAE: 4.7730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3996/20000 - Train Loss: 13.6965 - Test Loss: 34.5926 - MSE: 34.5926 - MAE: 4.7725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3997/20000 - Train Loss: 13.6931 - Test Loss: 34.5854 - MSE: 34.5854 - MAE: 4.7720\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3998/20000 - Train Loss: 13.6898 - Test Loss: 34.5782 - MSE: 34.5782 - MAE: 4.7715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 3999/20000 - Train Loss: 13.6865 - Test Loss: 34.5710 - MSE: 34.5710 - MAE: 4.7710\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4000/20000 - Train Loss: 13.6832 - Test Loss: 34.5638 - MSE: 34.5638 - MAE: 4.7705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4001/20000 - Train Loss: 13.6798 - Test Loss: 34.5565 - MSE: 34.5565 - MAE: 4.7700\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4002/20000 - Train Loss: 13.6765 - Test Loss: 34.5492 - MSE: 34.5492 - MAE: 4.7695\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4003/20000 - Train Loss: 13.6732 - Test Loss: 34.5419 - MSE: 34.5419 - MAE: 4.7690\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4004/20000 - Train Loss: 13.6699 - Test Loss: 34.5347 - MSE: 34.5347 - MAE: 4.7684\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4005/20000 - Train Loss: 13.6665 - Test Loss: 34.5274 - MSE: 34.5274 - MAE: 4.7679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4006/20000 - Train Loss: 13.6632 - Test Loss: 34.5202 - MSE: 34.5202 - MAE: 4.7674\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4007/20000 - Train Loss: 13.6599 - Test Loss: 34.5129 - MSE: 34.5129 - MAE: 4.7669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4008/20000 - Train Loss: 13.6565 - Test Loss: 34.5057 - MSE: 34.5057 - MAE: 4.7664\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4009/20000 - Train Loss: 13.6532 - Test Loss: 34.4984 - MSE: 34.4984 - MAE: 4.7659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4010/20000 - Train Loss: 13.6498 - Test Loss: 34.4911 - MSE: 34.4911 - MAE: 4.7654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4011/20000 - Train Loss: 13.6465 - Test Loss: 34.4839 - MSE: 34.4839 - MAE: 4.7649\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4012/20000 - Train Loss: 13.6432 - Test Loss: 34.4767 - MSE: 34.4767 - MAE: 4.7644\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4013/20000 - Train Loss: 13.6398 - Test Loss: 34.4694 - MSE: 34.4694 - MAE: 4.7639\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4014/20000 - Train Loss: 13.6365 - Test Loss: 34.4622 - MSE: 34.4622 - MAE: 4.7633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4015/20000 - Train Loss: 13.6332 - Test Loss: 34.4549 - MSE: 34.4549 - MAE: 4.7628\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4016/20000 - Train Loss: 13.6298 - Test Loss: 34.4476 - MSE: 34.4476 - MAE: 4.7623\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4017/20000 - Train Loss: 13.6265 - Test Loss: 34.4403 - MSE: 34.4403 - MAE: 4.7618\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4018/20000 - Train Loss: 13.6231 - Test Loss: 34.4330 - MSE: 34.4330 - MAE: 4.7613\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4019/20000 - Train Loss: 13.6198 - Test Loss: 34.4257 - MSE: 34.4257 - MAE: 4.7608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4020/20000 - Train Loss: 13.6164 - Test Loss: 34.4184 - MSE: 34.4184 - MAE: 4.7603\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4021/20000 - Train Loss: 13.6131 - Test Loss: 34.4112 - MSE: 34.4112 - MAE: 4.7598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4022/20000 - Train Loss: 13.6098 - Test Loss: 34.4039 - MSE: 34.4039 - MAE: 4.7592\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4023/20000 - Train Loss: 13.6064 - Test Loss: 34.3966 - MSE: 34.3966 - MAE: 4.7587\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4024/20000 - Train Loss: 13.6031 - Test Loss: 34.3893 - MSE: 34.3893 - MAE: 4.7582\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4025/20000 - Train Loss: 13.5997 - Test Loss: 34.3821 - MSE: 34.3821 - MAE: 4.7577\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4026/20000 - Train Loss: 13.5964 - Test Loss: 34.3748 - MSE: 34.3748 - MAE: 4.7572\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4027/20000 - Train Loss: 13.5930 - Test Loss: 34.3675 - MSE: 34.3676 - MAE: 4.7567\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4028/20000 - Train Loss: 13.5897 - Test Loss: 34.3602 - MSE: 34.3602 - MAE: 4.7562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4029/20000 - Train Loss: 13.5863 - Test Loss: 34.3529 - MSE: 34.3529 - MAE: 4.7557\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4030/20000 - Train Loss: 13.5830 - Test Loss: 34.3456 - MSE: 34.3456 - MAE: 4.7551\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4031/20000 - Train Loss: 13.5796 - Test Loss: 34.3383 - MSE: 34.3383 - MAE: 4.7546\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4032/20000 - Train Loss: 13.5763 - Test Loss: 34.3310 - MSE: 34.3310 - MAE: 4.7541\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4033/20000 - Train Loss: 13.5729 - Test Loss: 34.3237 - MSE: 34.3237 - MAE: 4.7536\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4034/20000 - Train Loss: 13.5696 - Test Loss: 34.3164 - MSE: 34.3164 - MAE: 4.7531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4035/20000 - Train Loss: 13.5662 - Test Loss: 34.3091 - MSE: 34.3091 - MAE: 4.7526\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4036/20000 - Train Loss: 13.5628 - Test Loss: 34.3018 - MSE: 34.3018 - MAE: 4.7520\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4037/20000 - Train Loss: 13.5595 - Test Loss: 34.2946 - MSE: 34.2946 - MAE: 4.7515\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4038/20000 - Train Loss: 13.5561 - Test Loss: 34.2872 - MSE: 34.2873 - MAE: 4.7510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4039/20000 - Train Loss: 13.5528 - Test Loss: 34.2799 - MSE: 34.2799 - MAE: 4.7505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4040/20000 - Train Loss: 13.5494 - Test Loss: 34.2726 - MSE: 34.2726 - MAE: 4.7500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4041/20000 - Train Loss: 13.5461 - Test Loss: 34.2653 - MSE: 34.2653 - MAE: 4.7495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4042/20000 - Train Loss: 13.5427 - Test Loss: 34.2580 - MSE: 34.2580 - MAE: 4.7490\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4043/20000 - Train Loss: 13.5393 - Test Loss: 34.2507 - MSE: 34.2507 - MAE: 4.7484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4044/20000 - Train Loss: 13.5360 - Test Loss: 34.2434 - MSE: 34.2434 - MAE: 4.7479\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4045/20000 - Train Loss: 13.5326 - Test Loss: 34.2360 - MSE: 34.2360 - MAE: 4.7474\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4046/20000 - Train Loss: 13.5292 - Test Loss: 34.2287 - MSE: 34.2286 - MAE: 4.7469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4047/20000 - Train Loss: 13.5259 - Test Loss: 34.2214 - MSE: 34.2214 - MAE: 4.7464\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4048/20000 - Train Loss: 13.5225 - Test Loss: 34.2141 - MSE: 34.2141 - MAE: 4.7459\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4049/20000 - Train Loss: 13.5192 - Test Loss: 34.2068 - MSE: 34.2068 - MAE: 4.7453\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4050/20000 - Train Loss: 13.5158 - Test Loss: 34.1994 - MSE: 34.1994 - MAE: 4.7448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4051/20000 - Train Loss: 13.5124 - Test Loss: 34.1921 - MSE: 34.1921 - MAE: 4.7443\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4052/20000 - Train Loss: 13.5090 - Test Loss: 34.1848 - MSE: 34.1848 - MAE: 4.7438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4053/20000 - Train Loss: 13.5057 - Test Loss: 34.1774 - MSE: 34.1774 - MAE: 4.7433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4054/20000 - Train Loss: 13.5023 - Test Loss: 34.1701 - MSE: 34.1701 - MAE: 4.7427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4055/20000 - Train Loss: 13.4989 - Test Loss: 34.1628 - MSE: 34.1628 - MAE: 4.7422\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4056/20000 - Train Loss: 13.4956 - Test Loss: 34.1554 - MSE: 34.1554 - MAE: 4.7417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4057/20000 - Train Loss: 13.4922 - Test Loss: 34.1480 - MSE: 34.1480 - MAE: 4.7412\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4058/20000 - Train Loss: 13.4888 - Test Loss: 34.1407 - MSE: 34.1407 - MAE: 4.7407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4059/20000 - Train Loss: 13.4854 - Test Loss: 34.1334 - MSE: 34.1334 - MAE: 4.7401\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 4060/20000 - Train Loss: 13.4821 - Test Loss: 34.1261 - MSE: 34.1261 - MAE: 4.7396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4061/20000 - Train Loss: 13.4787 - Test Loss: 34.1187 - MSE: 34.1187 - MAE: 4.7391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4062/20000 - Train Loss: 13.4753 - Test Loss: 34.1114 - MSE: 34.1114 - MAE: 4.7386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4063/20000 - Train Loss: 13.4719 - Test Loss: 34.1040 - MSE: 34.1040 - MAE: 4.7381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4064/20000 - Train Loss: 13.4686 - Test Loss: 34.0967 - MSE: 34.0967 - MAE: 4.7375\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4065/20000 - Train Loss: 13.4652 - Test Loss: 34.0894 - MSE: 34.0894 - MAE: 4.7370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4066/20000 - Train Loss: 13.4618 - Test Loss: 34.0820 - MSE: 34.0820 - MAE: 4.7365\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 4067/20000 - Train Loss: 13.4584 - Test Loss: 34.0746 - MSE: 34.0746 - MAE: 4.7360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4068/20000 - Train Loss: 13.4550 - Test Loss: 34.0673 - MSE: 34.0673 - MAE: 4.7355\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4069/20000 - Train Loss: 13.4517 - Test Loss: 34.0599 - MSE: 34.0599 - MAE: 4.7349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4070/20000 - Train Loss: 13.4483 - Test Loss: 34.0525 - MSE: 34.0525 - MAE: 4.7344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4071/20000 - Train Loss: 13.4449 - Test Loss: 34.0452 - MSE: 34.0452 - MAE: 4.7339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4072/20000 - Train Loss: 13.4415 - Test Loss: 34.0378 - MSE: 34.0378 - MAE: 4.7334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4073/20000 - Train Loss: 13.4381 - Test Loss: 34.0305 - MSE: 34.0305 - MAE: 4.7328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4074/20000 - Train Loss: 13.4347 - Test Loss: 34.0231 - MSE: 34.0231 - MAE: 4.7323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4075/20000 - Train Loss: 13.4314 - Test Loss: 34.0157 - MSE: 34.0157 - MAE: 4.7318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4076/20000 - Train Loss: 13.4280 - Test Loss: 34.0084 - MSE: 34.0084 - MAE: 4.7313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4077/20000 - Train Loss: 13.4246 - Test Loss: 34.0010 - MSE: 34.0010 - MAE: 4.7308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4078/20000 - Train Loss: 13.4212 - Test Loss: 33.9937 - MSE: 33.9937 - MAE: 4.7302\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4079/20000 - Train Loss: 13.4178 - Test Loss: 33.9863 - MSE: 33.9863 - MAE: 4.7297\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4080/20000 - Train Loss: 13.4144 - Test Loss: 33.9789 - MSE: 33.9789 - MAE: 4.7292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4081/20000 - Train Loss: 13.4110 - Test Loss: 33.9715 - MSE: 33.9715 - MAE: 4.7287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4082/20000 - Train Loss: 13.4076 - Test Loss: 33.9642 - MSE: 33.9642 - MAE: 4.7281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4083/20000 - Train Loss: 13.4042 - Test Loss: 33.9567 - MSE: 33.9567 - MAE: 4.7276\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 4084/20000 - Train Loss: 13.4008 - Test Loss: 33.9493 - MSE: 33.9493 - MAE: 4.7271\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4085/20000 - Train Loss: 13.3974 - Test Loss: 33.9419 - MSE: 33.9419 - MAE: 4.7266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4086/20000 - Train Loss: 13.3941 - Test Loss: 33.9345 - MSE: 33.9345 - MAE: 4.7260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4087/20000 - Train Loss: 13.3906 - Test Loss: 33.9272 - MSE: 33.9272 - MAE: 4.7255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4088/20000 - Train Loss: 13.3873 - Test Loss: 33.9198 - MSE: 33.9198 - MAE: 4.7250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4089/20000 - Train Loss: 13.3839 - Test Loss: 33.9124 - MSE: 33.9124 - MAE: 4.7245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4090/20000 - Train Loss: 13.3805 - Test Loss: 33.9051 - MSE: 33.9051 - MAE: 4.7239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4091/20000 - Train Loss: 13.3771 - Test Loss: 33.8977 - MSE: 33.8977 - MAE: 4.7234\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4092/20000 - Train Loss: 13.3737 - Test Loss: 33.8902 - MSE: 33.8902 - MAE: 4.7229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4093/20000 - Train Loss: 13.3703 - Test Loss: 33.8829 - MSE: 33.8829 - MAE: 4.7224\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4094/20000 - Train Loss: 13.3669 - Test Loss: 33.8755 - MSE: 33.8755 - MAE: 4.7218\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4095/20000 - Train Loss: 13.3635 - Test Loss: 33.8681 - MSE: 33.8681 - MAE: 4.7213\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4096/20000 - Train Loss: 13.3601 - Test Loss: 33.8607 - MSE: 33.8607 - MAE: 4.7208\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4097/20000 - Train Loss: 13.3567 - Test Loss: 33.8533 - MSE: 33.8533 - MAE: 4.7202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4098/20000 - Train Loss: 13.3532 - Test Loss: 33.8459 - MSE: 33.8459 - MAE: 4.7197\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4099/20000 - Train Loss: 13.3498 - Test Loss: 33.8385 - MSE: 33.8385 - MAE: 4.7192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4100/20000 - Train Loss: 13.3464 - Test Loss: 33.8311 - MSE: 33.8311 - MAE: 4.7187\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4101/20000 - Train Loss: 13.3430 - Test Loss: 33.8236 - MSE: 33.8236 - MAE: 4.7181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4102/20000 - Train Loss: 13.3396 - Test Loss: 33.8162 - MSE: 33.8162 - MAE: 4.7176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4103/20000 - Train Loss: 13.3362 - Test Loss: 33.8088 - MSE: 33.8088 - MAE: 4.7171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4104/20000 - Train Loss: 13.3328 - Test Loss: 33.8014 - MSE: 33.8014 - MAE: 4.7166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4105/20000 - Train Loss: 13.3294 - Test Loss: 33.7940 - MSE: 33.7940 - MAE: 4.7160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4106/20000 - Train Loss: 13.3260 - Test Loss: 33.7866 - MSE: 33.7866 - MAE: 4.7155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4107/20000 - Train Loss: 13.3226 - Test Loss: 33.7792 - MSE: 33.7792 - MAE: 4.7150\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4108/20000 - Train Loss: 13.3192 - Test Loss: 33.7718 - MSE: 33.7718 - MAE: 4.7144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4109/20000 - Train Loss: 13.3158 - Test Loss: 33.7644 - MSE: 33.7644 - MAE: 4.7139\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4110/20000 - Train Loss: 13.3123 - Test Loss: 33.7570 - MSE: 33.7570 - MAE: 4.7134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4111/20000 - Train Loss: 13.3089 - Test Loss: 33.7495 - MSE: 33.7495 - MAE: 4.7129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4112/20000 - Train Loss: 13.3055 - Test Loss: 33.7421 - MSE: 33.7421 - MAE: 4.7123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4113/20000 - Train Loss: 13.3021 - Test Loss: 33.7346 - MSE: 33.7346 - MAE: 4.7118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4114/20000 - Train Loss: 13.2987 - Test Loss: 33.7272 - MSE: 33.7272 - MAE: 4.7113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4115/20000 - Train Loss: 13.2953 - Test Loss: 33.7197 - MSE: 33.7197 - MAE: 4.7107\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4116/20000 - Train Loss: 13.2919 - Test Loss: 33.7123 - MSE: 33.7123 - MAE: 4.7102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4117/20000 - Train Loss: 13.2884 - Test Loss: 33.7049 - MSE: 33.7049 - MAE: 4.7097\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4118/20000 - Train Loss: 13.2850 - Test Loss: 33.6974 - MSE: 33.6974 - MAE: 4.7091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4119/20000 - Train Loss: 13.2816 - Test Loss: 33.6900 - MSE: 33.6900 - MAE: 4.7086\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4120/20000 - Train Loss: 13.2782 - Test Loss: 33.6826 - MSE: 33.6826 - MAE: 4.7081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4121/20000 - Train Loss: 13.2747 - Test Loss: 33.6752 - MSE: 33.6752 - MAE: 4.7075\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4122/20000 - Train Loss: 13.2713 - Test Loss: 33.6677 - MSE: 33.6677 - MAE: 4.7070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4123/20000 - Train Loss: 13.2679 - Test Loss: 33.6604 - MSE: 33.6604 - MAE: 4.7065\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4124/20000 - Train Loss: 13.2645 - Test Loss: 33.6529 - MSE: 33.6529 - MAE: 4.7059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4125/20000 - Train Loss: 13.2610 - Test Loss: 33.6455 - MSE: 33.6455 - MAE: 4.7054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4126/20000 - Train Loss: 13.2576 - Test Loss: 33.6380 - MSE: 33.6380 - MAE: 4.7049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4127/20000 - Train Loss: 13.2542 - Test Loss: 33.6306 - MSE: 33.6306 - MAE: 4.7043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4128/20000 - Train Loss: 13.2508 - Test Loss: 33.6231 - MSE: 33.6231 - MAE: 4.7038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4129/20000 - Train Loss: 13.2473 - Test Loss: 33.6156 - MSE: 33.6156 - MAE: 4.7033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4130/20000 - Train Loss: 13.2439 - Test Loss: 33.6081 - MSE: 33.6081 - MAE: 4.7027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4131/20000 - Train Loss: 13.2405 - Test Loss: 33.6007 - MSE: 33.6007 - MAE: 4.7022\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4132/20000 - Train Loss: 13.2371 - Test Loss: 33.5932 - MSE: 33.5932 - MAE: 4.7017\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4133/20000 - Train Loss: 13.2336 - Test Loss: 33.5857 - MSE: 33.5857 - MAE: 4.7011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4134/20000 - Train Loss: 13.2302 - Test Loss: 33.5782 - MSE: 33.5782 - MAE: 4.7006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4135/20000 - Train Loss: 13.2268 - Test Loss: 33.5708 - MSE: 33.5708 - MAE: 4.7001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4136/20000 - Train Loss: 13.2233 - Test Loss: 33.5634 - MSE: 33.5634 - MAE: 4.6995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4137/20000 - Train Loss: 13.2199 - Test Loss: 33.5559 - MSE: 33.5559 - MAE: 4.6990\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4138/20000 - Train Loss: 13.2165 - Test Loss: 33.5485 - MSE: 33.5485 - MAE: 4.6985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4139/20000 - Train Loss: 13.2130 - Test Loss: 33.5410 - MSE: 33.5410 - MAE: 4.6979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4140/20000 - Train Loss: 13.2096 - Test Loss: 33.5335 - MSE: 33.5335 - MAE: 4.6974\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4141/20000 - Train Loss: 13.2061 - Test Loss: 33.5261 - MSE: 33.5261 - MAE: 4.6969\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4142/20000 - Train Loss: 13.2027 - Test Loss: 33.5186 - MSE: 33.5186 - MAE: 4.6963\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4143/20000 - Train Loss: 13.1993 - Test Loss: 33.5111 - MSE: 33.5111 - MAE: 4.6958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4144/20000 - Train Loss: 13.1958 - Test Loss: 33.5037 - MSE: 33.5037 - MAE: 4.6953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4145/20000 - Train Loss: 13.1924 - Test Loss: 33.4962 - MSE: 33.4962 - MAE: 4.6947\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4146/20000 - Train Loss: 13.1890 - Test Loss: 33.4887 - MSE: 33.4887 - MAE: 4.6942\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4147/20000 - Train Loss: 13.1855 - Test Loss: 33.4812 - MSE: 33.4812 - MAE: 4.6936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4148/20000 - Train Loss: 13.1821 - Test Loss: 33.4737 - MSE: 33.4737 - MAE: 4.6931\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4149/20000 - Train Loss: 13.1786 - Test Loss: 33.4662 - MSE: 33.4662 - MAE: 4.6926\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4150/20000 - Train Loss: 13.1752 - Test Loss: 33.4587 - MSE: 33.4587 - MAE: 4.6920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4151/20000 - Train Loss: 13.1717 - Test Loss: 33.4512 - MSE: 33.4512 - MAE: 4.6915\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4152/20000 - Train Loss: 13.1683 - Test Loss: 33.4437 - MSE: 33.4437 - MAE: 4.6910\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4153/20000 - Train Loss: 13.1649 - Test Loss: 33.4363 - MSE: 33.4363 - MAE: 4.6904\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4154/20000 - Train Loss: 13.1614 - Test Loss: 33.4288 - MSE: 33.4288 - MAE: 4.6899\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4155/20000 - Train Loss: 13.1580 - Test Loss: 33.4213 - MSE: 33.4213 - MAE: 4.6893\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4156/20000 - Train Loss: 13.1545 - Test Loss: 33.4138 - MSE: 33.4138 - MAE: 4.6888\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4157/20000 - Train Loss: 13.1511 - Test Loss: 33.4063 - MSE: 33.4063 - MAE: 4.6883\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4158/20000 - Train Loss: 13.1476 - Test Loss: 33.3989 - MSE: 33.3989 - MAE: 4.6877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4159/20000 - Train Loss: 13.1442 - Test Loss: 33.3913 - MSE: 33.3913 - MAE: 4.6872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4160/20000 - Train Loss: 13.1407 - Test Loss: 33.3838 - MSE: 33.3838 - MAE: 4.6866\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4161/20000 - Train Loss: 13.1373 - Test Loss: 33.3763 - MSE: 33.3763 - MAE: 4.6861\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4162/20000 - Train Loss: 13.1338 - Test Loss: 33.3688 - MSE: 33.3688 - MAE: 4.6856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4163/20000 - Train Loss: 13.1304 - Test Loss: 33.3613 - MSE: 33.3613 - MAE: 4.6850\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4164/20000 - Train Loss: 13.1269 - Test Loss: 33.3538 - MSE: 33.3538 - MAE: 4.6845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4165/20000 - Train Loss: 13.1234 - Test Loss: 33.3463 - MSE: 33.3463 - MAE: 4.6839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4166/20000 - Train Loss: 13.1200 - Test Loss: 33.3387 - MSE: 33.3387 - MAE: 4.6834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4167/20000 - Train Loss: 13.1165 - Test Loss: 33.3312 - MSE: 33.3312 - MAE: 4.6829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4168/20000 - Train Loss: 13.1131 - Test Loss: 33.3238 - MSE: 33.3238 - MAE: 4.6823\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4169/20000 - Train Loss: 13.1096 - Test Loss: 33.3162 - MSE: 33.3162 - MAE: 4.6818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4170/20000 - Train Loss: 13.1062 - Test Loss: 33.3088 - MSE: 33.3088 - MAE: 4.6812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4171/20000 - Train Loss: 13.1027 - Test Loss: 33.3012 - MSE: 33.3012 - MAE: 4.6807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4172/20000 - Train Loss: 13.0992 - Test Loss: 33.2937 - MSE: 33.2937 - MAE: 4.6802\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 4173/20000 - Train Loss: 13.0958 - Test Loss: 33.2862 - MSE: 33.2862 - MAE: 4.6796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4174/20000 - Train Loss: 13.0923 - Test Loss: 33.2787 - MSE: 33.2787 - MAE: 4.6791\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4175/20000 - Train Loss: 13.0889 - Test Loss: 33.2711 - MSE: 33.2711 - MAE: 4.6785\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4176/20000 - Train Loss: 13.0854 - Test Loss: 33.2636 - MSE: 33.2636 - MAE: 4.6780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4177/20000 - Train Loss: 13.0819 - Test Loss: 33.2560 - MSE: 33.2560 - MAE: 4.6774\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4178/20000 - Train Loss: 13.0785 - Test Loss: 33.2485 - MSE: 33.2485 - MAE: 4.6769\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4179/20000 - Train Loss: 13.0750 - Test Loss: 33.2410 - MSE: 33.2410 - MAE: 4.6764\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4180/20000 - Train Loss: 13.0715 - Test Loss: 33.2334 - MSE: 33.2335 - MAE: 4.6758\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4181/20000 - Train Loss: 13.0681 - Test Loss: 33.2260 - MSE: 33.2260 - MAE: 4.6753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4182/20000 - Train Loss: 13.0646 - Test Loss: 33.2184 - MSE: 33.2184 - MAE: 4.6747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4183/20000 - Train Loss: 13.0611 - Test Loss: 33.2109 - MSE: 33.2109 - MAE: 4.6742\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4184/20000 - Train Loss: 13.0577 - Test Loss: 33.2034 - MSE: 33.2034 - MAE: 4.6736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4185/20000 - Train Loss: 13.0542 - Test Loss: 33.1958 - MSE: 33.1958 - MAE: 4.6731\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4186/20000 - Train Loss: 13.0507 - Test Loss: 33.1883 - MSE: 33.1883 - MAE: 4.6726\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4187/20000 - Train Loss: 13.0473 - Test Loss: 33.1807 - MSE: 33.1807 - MAE: 4.6720\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4188/20000 - Train Loss: 13.0438 - Test Loss: 33.1732 - MSE: 33.1732 - MAE: 4.6715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4189/20000 - Train Loss: 13.0403 - Test Loss: 33.1656 - MSE: 33.1656 - MAE: 4.6709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4190/20000 - Train Loss: 13.0368 - Test Loss: 33.1581 - MSE: 33.1581 - MAE: 4.6704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4191/20000 - Train Loss: 13.0334 - Test Loss: 33.1506 - MSE: 33.1506 - MAE: 4.6698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4192/20000 - Train Loss: 13.0299 - Test Loss: 33.1430 - MSE: 33.1430 - MAE: 4.6693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4193/20000 - Train Loss: 13.0264 - Test Loss: 33.1355 - MSE: 33.1355 - MAE: 4.6687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4194/20000 - Train Loss: 13.0229 - Test Loss: 33.1279 - MSE: 33.1279 - MAE: 4.6682\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4195/20000 - Train Loss: 13.0195 - Test Loss: 33.1204 - MSE: 33.1204 - MAE: 4.6676\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4196/20000 - Train Loss: 13.0160 - Test Loss: 33.1128 - MSE: 33.1128 - MAE: 4.6671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4197/20000 - Train Loss: 13.0125 - Test Loss: 33.1053 - MSE: 33.1053 - MAE: 4.6666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4198/20000 - Train Loss: 13.0090 - Test Loss: 33.0977 - MSE: 33.0977 - MAE: 4.6660\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4199/20000 - Train Loss: 13.0056 - Test Loss: 33.0901 - MSE: 33.0901 - MAE: 4.6655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4200/20000 - Train Loss: 13.0021 - Test Loss: 33.0826 - MSE: 33.0826 - MAE: 4.6649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4201/20000 - Train Loss: 12.9986 - Test Loss: 33.0750 - MSE: 33.0750 - MAE: 4.6644\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4202/20000 - Train Loss: 12.9951 - Test Loss: 33.0674 - MSE: 33.0674 - MAE: 4.6638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4203/20000 - Train Loss: 12.9916 - Test Loss: 33.0598 - MSE: 33.0598 - MAE: 4.6633\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4204/20000 - Train Loss: 12.9881 - Test Loss: 33.0522 - MSE: 33.0522 - MAE: 4.6627\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4205/20000 - Train Loss: 12.9847 - Test Loss: 33.0447 - MSE: 33.0447 - MAE: 4.6622\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4206/20000 - Train Loss: 12.9812 - Test Loss: 33.0371 - MSE: 33.0371 - MAE: 4.6616\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4207/20000 - Train Loss: 12.9777 - Test Loss: 33.0296 - MSE: 33.0296 - MAE: 4.6611\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4208/20000 - Train Loss: 12.9742 - Test Loss: 33.0220 - MSE: 33.0220 - MAE: 4.6605\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4209/20000 - Train Loss: 12.9707 - Test Loss: 33.0145 - MSE: 33.0145 - MAE: 4.6600\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4210/20000 - Train Loss: 12.9672 - Test Loss: 33.0070 - MSE: 33.0070 - MAE: 4.6594\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4211/20000 - Train Loss: 12.9637 - Test Loss: 32.9993 - MSE: 32.9993 - MAE: 4.6589\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4212/20000 - Train Loss: 12.9603 - Test Loss: 32.9917 - MSE: 32.9917 - MAE: 4.6583\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4213/20000 - Train Loss: 12.9568 - Test Loss: 32.9841 - MSE: 32.9842 - MAE: 4.6578\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4214/20000 - Train Loss: 12.9533 - Test Loss: 32.9765 - MSE: 32.9765 - MAE: 4.6572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4215/20000 - Train Loss: 12.9498 - Test Loss: 32.9690 - MSE: 32.9690 - MAE: 4.6567\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4216/20000 - Train Loss: 12.9463 - Test Loss: 32.9614 - MSE: 32.9614 - MAE: 4.6561\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4217/20000 - Train Loss: 12.9428 - Test Loss: 32.9537 - MSE: 32.9537 - MAE: 4.6556\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4218/20000 - Train Loss: 12.9393 - Test Loss: 32.9462 - MSE: 32.9462 - MAE: 4.6550\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4219/20000 - Train Loss: 12.9358 - Test Loss: 32.9386 - MSE: 32.9386 - MAE: 4.6545\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4220/20000 - Train Loss: 12.9323 - Test Loss: 32.9310 - MSE: 32.9310 - MAE: 4.6539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4221/20000 - Train Loss: 12.9288 - Test Loss: 32.9234 - MSE: 32.9234 - MAE: 4.6534\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4222/20000 - Train Loss: 12.9253 - Test Loss: 32.9158 - MSE: 32.9159 - MAE: 4.6528\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4223/20000 - Train Loss: 12.9218 - Test Loss: 32.9083 - MSE: 32.9083 - MAE: 4.6523\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4224/20000 - Train Loss: 12.9183 - Test Loss: 32.9007 - MSE: 32.9007 - MAE: 4.6517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4225/20000 - Train Loss: 12.9148 - Test Loss: 32.8931 - MSE: 32.8931 - MAE: 4.6512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4226/20000 - Train Loss: 12.9113 - Test Loss: 32.8855 - MSE: 32.8855 - MAE: 4.6506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4227/20000 - Train Loss: 12.9078 - Test Loss: 32.8779 - MSE: 32.8779 - MAE: 4.6501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4228/20000 - Train Loss: 12.9043 - Test Loss: 32.8702 - MSE: 32.8702 - MAE: 4.6495\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4229/20000 - Train Loss: 12.9008 - Test Loss: 32.8626 - MSE: 32.8626 - MAE: 4.6490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4230/20000 - Train Loss: 12.8973 - Test Loss: 32.8550 - MSE: 32.8550 - MAE: 4.6484\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4231/20000 - Train Loss: 12.8938 - Test Loss: 32.8474 - MSE: 32.8474 - MAE: 4.6478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4232/20000 - Train Loss: 12.8903 - Test Loss: 32.8398 - MSE: 32.8398 - MAE: 4.6473\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4233/20000 - Train Loss: 12.8868 - Test Loss: 32.8322 - MSE: 32.8322 - MAE: 4.6467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4234/20000 - Train Loss: 12.8833 - Test Loss: 32.8246 - MSE: 32.8246 - MAE: 4.6462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4235/20000 - Train Loss: 12.8798 - Test Loss: 32.8169 - MSE: 32.8169 - MAE: 4.6456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4236/20000 - Train Loss: 12.8763 - Test Loss: 32.8094 - MSE: 32.8094 - MAE: 4.6451\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4237/20000 - Train Loss: 12.8728 - Test Loss: 32.8018 - MSE: 32.8018 - MAE: 4.6445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4238/20000 - Train Loss: 12.8693 - Test Loss: 32.7941 - MSE: 32.7941 - MAE: 4.6440\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4239/20000 - Train Loss: 12.8658 - Test Loss: 32.7865 - MSE: 32.7865 - MAE: 4.6434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4240/20000 - Train Loss: 12.8623 - Test Loss: 32.7789 - MSE: 32.7789 - MAE: 4.6429\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 4241/20000 - Train Loss: 12.8588 - Test Loss: 32.7713 - MSE: 32.7713 - MAE: 4.6423\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4242/20000 - Train Loss: 12.8552 - Test Loss: 32.7637 - MSE: 32.7637 - MAE: 4.6417\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4243/20000 - Train Loss: 12.8517 - Test Loss: 32.7560 - MSE: 32.7560 - MAE: 4.6412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4244/20000 - Train Loss: 12.8482 - Test Loss: 32.7484 - MSE: 32.7484 - MAE: 4.6406\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4245/20000 - Train Loss: 12.8447 - Test Loss: 32.7408 - MSE: 32.7408 - MAE: 4.6401\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4246/20000 - Train Loss: 12.8412 - Test Loss: 32.7332 - MSE: 32.7332 - MAE: 4.6395\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4247/20000 - Train Loss: 12.8377 - Test Loss: 32.7255 - MSE: 32.7255 - MAE: 4.6390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4248/20000 - Train Loss: 12.8342 - Test Loss: 32.7178 - MSE: 32.7178 - MAE: 4.6384\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4249/20000 - Train Loss: 12.8306 - Test Loss: 32.7103 - MSE: 32.7103 - MAE: 4.6379\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4250/20000 - Train Loss: 12.8271 - Test Loss: 32.7026 - MSE: 32.7026 - MAE: 4.6373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4251/20000 - Train Loss: 12.8236 - Test Loss: 32.6950 - MSE: 32.6950 - MAE: 4.6367\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4252/20000 - Train Loss: 12.8201 - Test Loss: 32.6873 - MSE: 32.6873 - MAE: 4.6362\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4253/20000 - Train Loss: 12.8166 - Test Loss: 32.6797 - MSE: 32.6797 - MAE: 4.6356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4254/20000 - Train Loss: 12.8131 - Test Loss: 32.6720 - MSE: 32.6720 - MAE: 4.6351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4255/20000 - Train Loss: 12.8095 - Test Loss: 32.6645 - MSE: 32.6645 - MAE: 4.6345\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4256/20000 - Train Loss: 12.8060 - Test Loss: 32.6568 - MSE: 32.6568 - MAE: 4.6340\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4257/20000 - Train Loss: 12.8025 - Test Loss: 32.6492 - MSE: 32.6492 - MAE: 4.6334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4258/20000 - Train Loss: 12.7990 - Test Loss: 32.6415 - MSE: 32.6415 - MAE: 4.6328\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4259/20000 - Train Loss: 12.7955 - Test Loss: 32.6339 - MSE: 32.6339 - MAE: 4.6323\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4260/20000 - Train Loss: 12.7919 - Test Loss: 32.6262 - MSE: 32.6262 - MAE: 4.6317\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4261/20000 - Train Loss: 12.7884 - Test Loss: 32.6186 - MSE: 32.6186 - MAE: 4.6312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4262/20000 - Train Loss: 12.7849 - Test Loss: 32.6109 - MSE: 32.6109 - MAE: 4.6306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4263/20000 - Train Loss: 12.7814 - Test Loss: 32.6033 - MSE: 32.6033 - MAE: 4.6300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4264/20000 - Train Loss: 12.7778 - Test Loss: 32.5956 - MSE: 32.5956 - MAE: 4.6295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4265/20000 - Train Loss: 12.7743 - Test Loss: 32.5879 - MSE: 32.5879 - MAE: 4.6289\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4266/20000 - Train Loss: 12.7708 - Test Loss: 32.5803 - MSE: 32.5803 - MAE: 4.6284\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4267/20000 - Train Loss: 12.7673 - Test Loss: 32.5726 - MSE: 32.5726 - MAE: 4.6278\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4268/20000 - Train Loss: 12.7637 - Test Loss: 32.5649 - MSE: 32.5649 - MAE: 4.6272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4269/20000 - Train Loss: 12.7602 - Test Loss: 32.5573 - MSE: 32.5573 - MAE: 4.6267\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4270/20000 - Train Loss: 12.7567 - Test Loss: 32.5496 - MSE: 32.5496 - MAE: 4.6261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4271/20000 - Train Loss: 12.7531 - Test Loss: 32.5420 - MSE: 32.5420 - MAE: 4.6256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4272/20000 - Train Loss: 12.7496 - Test Loss: 32.5343 - MSE: 32.5343 - MAE: 4.6250\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4273/20000 - Train Loss: 12.7461 - Test Loss: 32.5267 - MSE: 32.5266 - MAE: 4.6244\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4274/20000 - Train Loss: 12.7425 - Test Loss: 32.5190 - MSE: 32.5190 - MAE: 4.6239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4275/20000 - Train Loss: 12.7390 - Test Loss: 32.5113 - MSE: 32.5113 - MAE: 4.6233\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4276/20000 - Train Loss: 12.7355 - Test Loss: 32.5037 - MSE: 32.5037 - MAE: 4.6227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4277/20000 - Train Loss: 12.7319 - Test Loss: 32.4960 - MSE: 32.4960 - MAE: 4.6222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4278/20000 - Train Loss: 12.7284 - Test Loss: 32.4882 - MSE: 32.4882 - MAE: 4.6216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4279/20000 - Train Loss: 12.7249 - Test Loss: 32.4806 - MSE: 32.4806 - MAE: 4.6211\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4280/20000 - Train Loss: 12.7213 - Test Loss: 32.4728 - MSE: 32.4728 - MAE: 4.6205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4281/20000 - Train Loss: 12.7178 - Test Loss: 32.4652 - MSE: 32.4652 - MAE: 4.6199\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4282/20000 - Train Loss: 12.7142 - Test Loss: 32.4575 - MSE: 32.4575 - MAE: 4.6194\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4283/20000 - Train Loss: 12.7107 - Test Loss: 32.4498 - MSE: 32.4498 - MAE: 4.6188\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4284/20000 - Train Loss: 12.7072 - Test Loss: 32.4421 - MSE: 32.4421 - MAE: 4.6182\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4285/20000 - Train Loss: 12.7036 - Test Loss: 32.4345 - MSE: 32.4345 - MAE: 4.6177\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4286/20000 - Train Loss: 12.7001 - Test Loss: 32.4268 - MSE: 32.4268 - MAE: 4.6171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4287/20000 - Train Loss: 12.6965 - Test Loss: 32.4191 - MSE: 32.4191 - MAE: 4.6165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4288/20000 - Train Loss: 12.6930 - Test Loss: 32.4114 - MSE: 32.4114 - MAE: 4.6160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4289/20000 - Train Loss: 12.6895 - Test Loss: 32.4037 - MSE: 32.4037 - MAE: 4.6154\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4290/20000 - Train Loss: 12.6859 - Test Loss: 32.3961 - MSE: 32.3961 - MAE: 4.6149\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4291/20000 - Train Loss: 12.6824 - Test Loss: 32.3884 - MSE: 32.3884 - MAE: 4.6143\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4292/20000 - Train Loss: 12.6788 - Test Loss: 32.3807 - MSE: 32.3807 - MAE: 4.6137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4293/20000 - Train Loss: 12.6753 - Test Loss: 32.3730 - MSE: 32.3730 - MAE: 4.6132\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4294/20000 - Train Loss: 12.6717 - Test Loss: 32.3653 - MSE: 32.3653 - MAE: 4.6126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4295/20000 - Train Loss: 12.6682 - Test Loss: 32.3576 - MSE: 32.3576 - MAE: 4.6120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4296/20000 - Train Loss: 12.6646 - Test Loss: 32.3499 - MSE: 32.3499 - MAE: 4.6115\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4297/20000 - Train Loss: 12.6611 - Test Loss: 32.3422 - MSE: 32.3422 - MAE: 4.6109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4298/20000 - Train Loss: 12.6575 - Test Loss: 32.3345 - MSE: 32.3345 - MAE: 4.6103\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4299/20000 - Train Loss: 12.6540 - Test Loss: 32.3267 - MSE: 32.3267 - MAE: 4.6098\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4300/20000 - Train Loss: 12.6504 - Test Loss: 32.3190 - MSE: 32.3190 - MAE: 4.6092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4301/20000 - Train Loss: 12.6469 - Test Loss: 32.3113 - MSE: 32.3113 - MAE: 4.6086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4302/20000 - Train Loss: 12.6433 - Test Loss: 32.3036 - MSE: 32.3036 - MAE: 4.6081\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 4303/20000 - Train Loss: 12.6398 - Test Loss: 32.2959 - MSE: 32.2959 - MAE: 4.6075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4304/20000 - Train Loss: 12.6362 - Test Loss: 32.2882 - MSE: 32.2882 - MAE: 4.6069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4305/20000 - Train Loss: 12.6327 - Test Loss: 32.2805 - MSE: 32.2805 - MAE: 4.6064\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4306/20000 - Train Loss: 12.6291 - Test Loss: 32.2728 - MSE: 32.2728 - MAE: 4.6058\n",
      "2/2 [==============================] - 0s 988us/step\n",
      "Epoch 4307/20000 - Train Loss: 12.6256 - Test Loss: 32.2651 - MSE: 32.2651 - MAE: 4.6052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4308/20000 - Train Loss: 12.6220 - Test Loss: 32.2574 - MSE: 32.2574 - MAE: 4.6047\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4309/20000 - Train Loss: 12.6184 - Test Loss: 32.2497 - MSE: 32.2497 - MAE: 4.6041\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4310/20000 - Train Loss: 12.6149 - Test Loss: 32.2419 - MSE: 32.2419 - MAE: 4.6035\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4311/20000 - Train Loss: 12.6113 - Test Loss: 32.2342 - MSE: 32.2342 - MAE: 4.6029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4312/20000 - Train Loss: 12.6078 - Test Loss: 32.2264 - MSE: 32.2264 - MAE: 4.6024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4313/20000 - Train Loss: 12.6042 - Test Loss: 32.2187 - MSE: 32.2187 - MAE: 4.6018\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4314/20000 - Train Loss: 12.6006 - Test Loss: 32.2110 - MSE: 32.2110 - MAE: 4.6012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4315/20000 - Train Loss: 12.5971 - Test Loss: 32.2032 - MSE: 32.2032 - MAE: 4.6007\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4316/20000 - Train Loss: 12.5935 - Test Loss: 32.1955 - MSE: 32.1955 - MAE: 4.6001\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4317/20000 - Train Loss: 12.5900 - Test Loss: 32.1878 - MSE: 32.1878 - MAE: 4.5995\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4318/20000 - Train Loss: 12.5864 - Test Loss: 32.1801 - MSE: 32.1801 - MAE: 4.5990\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4319/20000 - Train Loss: 12.5828 - Test Loss: 32.1724 - MSE: 32.1724 - MAE: 4.5984\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4320/20000 - Train Loss: 12.5793 - Test Loss: 32.1647 - MSE: 32.1647 - MAE: 4.5978\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4321/20000 - Train Loss: 12.5757 - Test Loss: 32.1570 - MSE: 32.1570 - MAE: 4.5972\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4322/20000 - Train Loss: 12.5721 - Test Loss: 32.1492 - MSE: 32.1492 - MAE: 4.5967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4323/20000 - Train Loss: 12.5686 - Test Loss: 32.1415 - MSE: 32.1415 - MAE: 4.5961\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4324/20000 - Train Loss: 12.5650 - Test Loss: 32.1337 - MSE: 32.1337 - MAE: 4.5955\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4325/20000 - Train Loss: 12.5614 - Test Loss: 32.1260 - MSE: 32.1260 - MAE: 4.5950\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4326/20000 - Train Loss: 12.5579 - Test Loss: 32.1182 - MSE: 32.1182 - MAE: 4.5944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4327/20000 - Train Loss: 12.5543 - Test Loss: 32.1105 - MSE: 32.1105 - MAE: 4.5938\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4328/20000 - Train Loss: 12.5507 - Test Loss: 32.1027 - MSE: 32.1027 - MAE: 4.5932\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4329/20000 - Train Loss: 12.5472 - Test Loss: 32.0949 - MSE: 32.0949 - MAE: 4.5927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4330/20000 - Train Loss: 12.5436 - Test Loss: 32.0872 - MSE: 32.0872 - MAE: 4.5921\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4331/20000 - Train Loss: 12.5400 - Test Loss: 32.0794 - MSE: 32.0794 - MAE: 4.5915\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4332/20000 - Train Loss: 12.5364 - Test Loss: 32.0716 - MSE: 32.0716 - MAE: 4.5909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4333/20000 - Train Loss: 12.5329 - Test Loss: 32.0639 - MSE: 32.0639 - MAE: 4.5904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4334/20000 - Train Loss: 12.5293 - Test Loss: 32.0562 - MSE: 32.0562 - MAE: 4.5898\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4335/20000 - Train Loss: 12.5257 - Test Loss: 32.0485 - MSE: 32.0485 - MAE: 4.5892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4336/20000 - Train Loss: 12.5221 - Test Loss: 32.0407 - MSE: 32.0407 - MAE: 4.5886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4337/20000 - Train Loss: 12.5186 - Test Loss: 32.0330 - MSE: 32.0330 - MAE: 4.5881\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4338/20000 - Train Loss: 12.5150 - Test Loss: 32.0252 - MSE: 32.0252 - MAE: 4.5875\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4339/20000 - Train Loss: 12.5114 - Test Loss: 32.0175 - MSE: 32.0175 - MAE: 4.5869\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4340/20000 - Train Loss: 12.5078 - Test Loss: 32.0097 - MSE: 32.0097 - MAE: 4.5864\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4341/20000 - Train Loss: 12.5043 - Test Loss: 32.0020 - MSE: 32.0020 - MAE: 4.5858\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 4342/20000 - Train Loss: 12.5007 - Test Loss: 31.9942 - MSE: 31.9942 - MAE: 4.5852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4343/20000 - Train Loss: 12.4971 - Test Loss: 31.9864 - MSE: 31.9864 - MAE: 4.5846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4344/20000 - Train Loss: 12.4935 - Test Loss: 31.9786 - MSE: 31.9786 - MAE: 4.5840\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4345/20000 - Train Loss: 12.4899 - Test Loss: 31.9708 - MSE: 31.9708 - MAE: 4.5835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4346/20000 - Train Loss: 12.4864 - Test Loss: 31.9631 - MSE: 31.9631 - MAE: 4.5829\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4347/20000 - Train Loss: 12.4828 - Test Loss: 31.9553 - MSE: 31.9553 - MAE: 4.5823\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 4348/20000 - Train Loss: 12.4792 - Test Loss: 31.9475 - MSE: 31.9475 - MAE: 4.5817\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4349/20000 - Train Loss: 12.4756 - Test Loss: 31.9397 - MSE: 31.9397 - MAE: 4.5812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4350/20000 - Train Loss: 12.4720 - Test Loss: 31.9319 - MSE: 31.9319 - MAE: 4.5806\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4351/20000 - Train Loss: 12.4684 - Test Loss: 31.9242 - MSE: 31.9242 - MAE: 4.5800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4352/20000 - Train Loss: 12.4649 - Test Loss: 31.9164 - MSE: 31.9164 - MAE: 4.5794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4353/20000 - Train Loss: 12.4613 - Test Loss: 31.9087 - MSE: 31.9087 - MAE: 4.5789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4354/20000 - Train Loss: 12.4577 - Test Loss: 31.9008 - MSE: 31.9008 - MAE: 4.5783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4355/20000 - Train Loss: 12.4541 - Test Loss: 31.8931 - MSE: 31.8931 - MAE: 4.5777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4356/20000 - Train Loss: 12.4505 - Test Loss: 31.8853 - MSE: 31.8853 - MAE: 4.5771\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4357/20000 - Train Loss: 12.4469 - Test Loss: 31.8776 - MSE: 31.8776 - MAE: 4.5766\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4358/20000 - Train Loss: 12.4433 - Test Loss: 31.8697 - MSE: 31.8697 - MAE: 4.5760\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4359/20000 - Train Loss: 12.4397 - Test Loss: 31.8620 - MSE: 31.8620 - MAE: 4.5754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4360/20000 - Train Loss: 12.4361 - Test Loss: 31.8542 - MSE: 31.8542 - MAE: 4.5748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4361/20000 - Train Loss: 12.4325 - Test Loss: 31.8464 - MSE: 31.8464 - MAE: 4.5742\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4362/20000 - Train Loss: 12.4290 - Test Loss: 31.8386 - MSE: 31.8386 - MAE: 4.5737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4363/20000 - Train Loss: 12.4254 - Test Loss: 31.8308 - MSE: 31.8308 - MAE: 4.5731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4364/20000 - Train Loss: 12.4218 - Test Loss: 31.8230 - MSE: 31.8230 - MAE: 4.5725\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4365/20000 - Train Loss: 12.4182 - Test Loss: 31.8152 - MSE: 31.8152 - MAE: 4.5719\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4366/20000 - Train Loss: 12.4146 - Test Loss: 31.8074 - MSE: 31.8074 - MAE: 4.5713\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4367/20000 - Train Loss: 12.4110 - Test Loss: 31.7996 - MSE: 31.7996 - MAE: 4.5707\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 4368/20000 - Train Loss: 12.4074 - Test Loss: 31.7918 - MSE: 31.7918 - MAE: 4.5702\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4369/20000 - Train Loss: 12.4038 - Test Loss: 31.7840 - MSE: 31.7840 - MAE: 4.5696\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4370/20000 - Train Loss: 12.4002 - Test Loss: 31.7761 - MSE: 31.7761 - MAE: 4.5690\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4371/20000 - Train Loss: 12.3966 - Test Loss: 31.7684 - MSE: 31.7684 - MAE: 4.5684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4372/20000 - Train Loss: 12.3930 - Test Loss: 31.7605 - MSE: 31.7605 - MAE: 4.5678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4373/20000 - Train Loss: 12.3894 - Test Loss: 31.7528 - MSE: 31.7528 - MAE: 4.5673\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4374/20000 - Train Loss: 12.3858 - Test Loss: 31.7450 - MSE: 31.7450 - MAE: 4.5667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4375/20000 - Train Loss: 12.3822 - Test Loss: 31.7372 - MSE: 31.7372 - MAE: 4.5661\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4376/20000 - Train Loss: 12.3786 - Test Loss: 31.7294 - MSE: 31.7294 - MAE: 4.5655\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4377/20000 - Train Loss: 12.3750 - Test Loss: 31.7215 - MSE: 31.7215 - MAE: 4.5649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4378/20000 - Train Loss: 12.3714 - Test Loss: 31.7138 - MSE: 31.7138 - MAE: 4.5644\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4379/20000 - Train Loss: 12.3678 - Test Loss: 31.7059 - MSE: 31.7059 - MAE: 4.5638\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4380/20000 - Train Loss: 12.3642 - Test Loss: 31.6982 - MSE: 31.6982 - MAE: 4.5632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4381/20000 - Train Loss: 12.3606 - Test Loss: 31.6903 - MSE: 31.6903 - MAE: 4.5626\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4382/20000 - Train Loss: 12.3570 - Test Loss: 31.6824 - MSE: 31.6824 - MAE: 4.5620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4383/20000 - Train Loss: 12.3534 - Test Loss: 31.6747 - MSE: 31.6747 - MAE: 4.5614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4384/20000 - Train Loss: 12.3498 - Test Loss: 31.6668 - MSE: 31.6668 - MAE: 4.5609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4385/20000 - Train Loss: 12.3462 - Test Loss: 31.6590 - MSE: 31.6590 - MAE: 4.5603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4386/20000 - Train Loss: 12.3425 - Test Loss: 31.6512 - MSE: 31.6512 - MAE: 4.5597\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4387/20000 - Train Loss: 12.3389 - Test Loss: 31.6434 - MSE: 31.6433 - MAE: 4.5591\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 4388/20000 - Train Loss: 12.3353 - Test Loss: 31.6356 - MSE: 31.6355 - MAE: 4.5585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4389/20000 - Train Loss: 12.3317 - Test Loss: 31.6277 - MSE: 31.6277 - MAE: 4.5579\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4390/20000 - Train Loss: 12.3281 - Test Loss: 31.6199 - MSE: 31.6199 - MAE: 4.5573\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4391/20000 - Train Loss: 12.3245 - Test Loss: 31.6121 - MSE: 31.6121 - MAE: 4.5568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4392/20000 - Train Loss: 12.3209 - Test Loss: 31.6042 - MSE: 31.6042 - MAE: 4.5562\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4393/20000 - Train Loss: 12.3173 - Test Loss: 31.5964 - MSE: 31.5964 - MAE: 4.5556\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4394/20000 - Train Loss: 12.3137 - Test Loss: 31.5886 - MSE: 31.5886 - MAE: 4.5550\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4395/20000 - Train Loss: 12.3100 - Test Loss: 31.5808 - MSE: 31.5808 - MAE: 4.5544\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4396/20000 - Train Loss: 12.3064 - Test Loss: 31.5729 - MSE: 31.5729 - MAE: 4.5538\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4397/20000 - Train Loss: 12.3028 - Test Loss: 31.5650 - MSE: 31.5650 - MAE: 4.5532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4398/20000 - Train Loss: 12.2992 - Test Loss: 31.5572 - MSE: 31.5572 - MAE: 4.5527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4399/20000 - Train Loss: 12.2956 - Test Loss: 31.5494 - MSE: 31.5494 - MAE: 4.5521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4400/20000 - Train Loss: 12.2920 - Test Loss: 31.5415 - MSE: 31.5415 - MAE: 4.5515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4401/20000 - Train Loss: 12.2883 - Test Loss: 31.5337 - MSE: 31.5337 - MAE: 4.5509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4402/20000 - Train Loss: 12.2847 - Test Loss: 31.5259 - MSE: 31.5259 - MAE: 4.5503\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4403/20000 - Train Loss: 12.2811 - Test Loss: 31.5180 - MSE: 31.5180 - MAE: 4.5497\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4404/20000 - Train Loss: 12.2775 - Test Loss: 31.5102 - MSE: 31.5102 - MAE: 4.5491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4405/20000 - Train Loss: 12.2739 - Test Loss: 31.5024 - MSE: 31.5024 - MAE: 4.5486\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4406/20000 - Train Loss: 12.2702 - Test Loss: 31.4945 - MSE: 31.4945 - MAE: 4.5480\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4407/20000 - Train Loss: 12.2666 - Test Loss: 31.4866 - MSE: 31.4866 - MAE: 4.5474\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4408/20000 - Train Loss: 12.2630 - Test Loss: 31.4788 - MSE: 31.4788 - MAE: 4.5468\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4409/20000 - Train Loss: 12.2594 - Test Loss: 31.4709 - MSE: 31.4709 - MAE: 4.5462\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4410/20000 - Train Loss: 12.2558 - Test Loss: 31.4631 - MSE: 31.4631 - MAE: 4.5456\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4411/20000 - Train Loss: 12.2521 - Test Loss: 31.4552 - MSE: 31.4552 - MAE: 4.5450\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4412/20000 - Train Loss: 12.2485 - Test Loss: 31.4473 - MSE: 31.4473 - MAE: 4.5444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4413/20000 - Train Loss: 12.2449 - Test Loss: 31.4395 - MSE: 31.4395 - MAE: 4.5438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4414/20000 - Train Loss: 12.2413 - Test Loss: 31.4317 - MSE: 31.4317 - MAE: 4.5433\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4415/20000 - Train Loss: 12.2376 - Test Loss: 31.4238 - MSE: 31.4238 - MAE: 4.5427\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4416/20000 - Train Loss: 12.2340 - Test Loss: 31.4159 - MSE: 31.4159 - MAE: 4.5421\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4417/20000 - Train Loss: 12.2304 - Test Loss: 31.4080 - MSE: 31.4080 - MAE: 4.5415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4418/20000 - Train Loss: 12.2268 - Test Loss: 31.4002 - MSE: 31.4002 - MAE: 4.5409\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 4419/20000 - Train Loss: 12.2231 - Test Loss: 31.3923 - MSE: 31.3923 - MAE: 4.5403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4420/20000 - Train Loss: 12.2195 - Test Loss: 31.3844 - MSE: 31.3844 - MAE: 4.5397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4421/20000 - Train Loss: 12.2159 - Test Loss: 31.3766 - MSE: 31.3766 - MAE: 4.5391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4422/20000 - Train Loss: 12.2122 - Test Loss: 31.3687 - MSE: 31.3687 - MAE: 4.5385\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 4423/20000 - Train Loss: 12.2086 - Test Loss: 31.3609 - MSE: 31.3609 - MAE: 4.5379\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4424/20000 - Train Loss: 12.2050 - Test Loss: 31.3530 - MSE: 31.3530 - MAE: 4.5373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4425/20000 - Train Loss: 12.2013 - Test Loss: 31.3451 - MSE: 31.3451 - MAE: 4.5368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4426/20000 - Train Loss: 12.1977 - Test Loss: 31.3372 - MSE: 31.3372 - MAE: 4.5362\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 4427/20000 - Train Loss: 12.1941 - Test Loss: 31.3294 - MSE: 31.3294 - MAE: 4.5356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4428/20000 - Train Loss: 12.1904 - Test Loss: 31.3215 - MSE: 31.3215 - MAE: 4.5350\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4429/20000 - Train Loss: 12.1868 - Test Loss: 31.3136 - MSE: 31.3136 - MAE: 4.5344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4430/20000 - Train Loss: 12.1832 - Test Loss: 31.3057 - MSE: 31.3057 - MAE: 4.5338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4431/20000 - Train Loss: 12.1795 - Test Loss: 31.2978 - MSE: 31.2978 - MAE: 4.5332\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4432/20000 - Train Loss: 12.1759 - Test Loss: 31.2899 - MSE: 31.2899 - MAE: 4.5326\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4433/20000 - Train Loss: 12.1723 - Test Loss: 31.2820 - MSE: 31.2820 - MAE: 4.5320\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4434/20000 - Train Loss: 12.1686 - Test Loss: 31.2742 - MSE: 31.2742 - MAE: 4.5314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4435/20000 - Train Loss: 12.1650 - Test Loss: 31.2663 - MSE: 31.2663 - MAE: 4.5308\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4436/20000 - Train Loss: 12.1613 - Test Loss: 31.2584 - MSE: 31.2584 - MAE: 4.5302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4437/20000 - Train Loss: 12.1577 - Test Loss: 31.2506 - MSE: 31.2506 - MAE: 4.5296\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4438/20000 - Train Loss: 12.1540 - Test Loss: 31.2427 - MSE: 31.2427 - MAE: 4.5290\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4439/20000 - Train Loss: 12.1504 - Test Loss: 31.2348 - MSE: 31.2348 - MAE: 4.5284\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4440/20000 - Train Loss: 12.1468 - Test Loss: 31.2269 - MSE: 31.2269 - MAE: 4.5279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4441/20000 - Train Loss: 12.1431 - Test Loss: 31.2190 - MSE: 31.2190 - MAE: 4.5273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4442/20000 - Train Loss: 12.1395 - Test Loss: 31.2111 - MSE: 31.2111 - MAE: 4.5267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4443/20000 - Train Loss: 12.1358 - Test Loss: 31.2032 - MSE: 31.2032 - MAE: 4.5261\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4444/20000 - Train Loss: 12.1322 - Test Loss: 31.1953 - MSE: 31.1953 - MAE: 4.5255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4445/20000 - Train Loss: 12.1285 - Test Loss: 31.1874 - MSE: 31.1874 - MAE: 4.5249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4446/20000 - Train Loss: 12.1249 - Test Loss: 31.1795 - MSE: 31.1795 - MAE: 4.5243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4447/20000 - Train Loss: 12.1213 - Test Loss: 31.1716 - MSE: 31.1716 - MAE: 4.5237\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4448/20000 - Train Loss: 12.1176 - Test Loss: 31.1637 - MSE: 31.1637 - MAE: 4.5231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4449/20000 - Train Loss: 12.1140 - Test Loss: 31.1558 - MSE: 31.1558 - MAE: 4.5225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4450/20000 - Train Loss: 12.1103 - Test Loss: 31.1479 - MSE: 31.1479 - MAE: 4.5219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4451/20000 - Train Loss: 12.1067 - Test Loss: 31.1400 - MSE: 31.1400 - MAE: 4.5213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4452/20000 - Train Loss: 12.1030 - Test Loss: 31.1321 - MSE: 31.1321 - MAE: 4.5207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4453/20000 - Train Loss: 12.0994 - Test Loss: 31.1242 - MSE: 31.1242 - MAE: 4.5201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4454/20000 - Train Loss: 12.0957 - Test Loss: 31.1163 - MSE: 31.1163 - MAE: 4.5195\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4455/20000 - Train Loss: 12.0921 - Test Loss: 31.1084 - MSE: 31.1084 - MAE: 4.5189\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4456/20000 - Train Loss: 12.0884 - Test Loss: 31.1005 - MSE: 31.1005 - MAE: 4.5183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4457/20000 - Train Loss: 12.0848 - Test Loss: 31.0926 - MSE: 31.0926 - MAE: 4.5177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4458/20000 - Train Loss: 12.0811 - Test Loss: 31.0847 - MSE: 31.0847 - MAE: 4.5171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4459/20000 - Train Loss: 12.0774 - Test Loss: 31.0768 - MSE: 31.0768 - MAE: 4.5165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4460/20000 - Train Loss: 12.0738 - Test Loss: 31.0688 - MSE: 31.0688 - MAE: 4.5159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4461/20000 - Train Loss: 12.0701 - Test Loss: 31.0608 - MSE: 31.0608 - MAE: 4.5153\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4462/20000 - Train Loss: 12.0665 - Test Loss: 31.0529 - MSE: 31.0529 - MAE: 4.5147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4463/20000 - Train Loss: 12.0628 - Test Loss: 31.0450 - MSE: 31.0450 - MAE: 4.5141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4464/20000 - Train Loss: 12.0592 - Test Loss: 31.0371 - MSE: 31.0371 - MAE: 4.5135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4465/20000 - Train Loss: 12.0555 - Test Loss: 31.0292 - MSE: 31.0292 - MAE: 4.5129\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4466/20000 - Train Loss: 12.0519 - Test Loss: 31.0213 - MSE: 31.0213 - MAE: 4.5123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4467/20000 - Train Loss: 12.0482 - Test Loss: 31.0134 - MSE: 31.0134 - MAE: 4.5117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4468/20000 - Train Loss: 12.0445 - Test Loss: 31.0055 - MSE: 31.0055 - MAE: 4.5111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4469/20000 - Train Loss: 12.0409 - Test Loss: 30.9976 - MSE: 30.9976 - MAE: 4.5105\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4470/20000 - Train Loss: 12.0372 - Test Loss: 30.9896 - MSE: 30.9896 - MAE: 4.5099\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4471/20000 - Train Loss: 12.0336 - Test Loss: 30.9817 - MSE: 30.9817 - MAE: 4.5093\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4472/20000 - Train Loss: 12.0299 - Test Loss: 30.9737 - MSE: 30.9737 - MAE: 4.5087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4473/20000 - Train Loss: 12.0262 - Test Loss: 30.9657 - MSE: 30.9657 - MAE: 4.5081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4474/20000 - Train Loss: 12.0226 - Test Loss: 30.9578 - MSE: 30.9578 - MAE: 4.5075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4475/20000 - Train Loss: 12.0189 - Test Loss: 30.9499 - MSE: 30.9499 - MAE: 4.5069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4476/20000 - Train Loss: 12.0153 - Test Loss: 30.9420 - MSE: 30.9420 - MAE: 4.5063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4477/20000 - Train Loss: 12.0116 - Test Loss: 30.9340 - MSE: 30.9340 - MAE: 4.5057\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4478/20000 - Train Loss: 12.0079 - Test Loss: 30.9261 - MSE: 30.9261 - MAE: 4.5051\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4479/20000 - Train Loss: 12.0043 - Test Loss: 30.9182 - MSE: 30.9182 - MAE: 4.5045\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4480/20000 - Train Loss: 12.0006 - Test Loss: 30.9103 - MSE: 30.9103 - MAE: 4.5039\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4481/20000 - Train Loss: 11.9969 - Test Loss: 30.9023 - MSE: 30.9023 - MAE: 4.5033\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4482/20000 - Train Loss: 11.9932 - Test Loss: 30.8944 - MSE: 30.8944 - MAE: 4.5027\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4483/20000 - Train Loss: 11.9896 - Test Loss: 30.8865 - MSE: 30.8865 - MAE: 4.5021\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4484/20000 - Train Loss: 11.9859 - Test Loss: 30.8785 - MSE: 30.8785 - MAE: 4.5015\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4485/20000 - Train Loss: 11.9823 - Test Loss: 30.8706 - MSE: 30.8706 - MAE: 4.5009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4486/20000 - Train Loss: 11.9786 - Test Loss: 30.8625 - MSE: 30.8625 - MAE: 4.5003\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4487/20000 - Train Loss: 11.9749 - Test Loss: 30.8546 - MSE: 30.8546 - MAE: 4.4997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4488/20000 - Train Loss: 11.9712 - Test Loss: 30.8466 - MSE: 30.8466 - MAE: 4.4991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4489/20000 - Train Loss: 11.9676 - Test Loss: 30.8387 - MSE: 30.8387 - MAE: 4.4985\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 4490/20000 - Train Loss: 11.9639 - Test Loss: 30.8307 - MSE: 30.8307 - MAE: 4.4978\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4491/20000 - Train Loss: 11.9602 - Test Loss: 30.8228 - MSE: 30.8228 - MAE: 4.4972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4492/20000 - Train Loss: 11.9565 - Test Loss: 30.8148 - MSE: 30.8148 - MAE: 4.4966\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4493/20000 - Train Loss: 11.9529 - Test Loss: 30.8069 - MSE: 30.8069 - MAE: 4.4960\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4494/20000 - Train Loss: 11.9492 - Test Loss: 30.7990 - MSE: 30.7990 - MAE: 4.4954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4495/20000 - Train Loss: 11.9455 - Test Loss: 30.7910 - MSE: 30.7910 - MAE: 4.4948\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 4496/20000 - Train Loss: 11.9418 - Test Loss: 30.7830 - MSE: 30.7830 - MAE: 4.4942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4497/20000 - Train Loss: 11.9382 - Test Loss: 30.7751 - MSE: 30.7751 - MAE: 4.4936\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4498/20000 - Train Loss: 11.9345 - Test Loss: 30.7671 - MSE: 30.7671 - MAE: 4.4930\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 4499/20000 - Train Loss: 11.9308 - Test Loss: 30.7592 - MSE: 30.7592 - MAE: 4.4924\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 4500/20000 - Train Loss: 11.9271 - Test Loss: 30.7512 - MSE: 30.7512 - MAE: 4.4918\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4501/20000 - Train Loss: 11.9235 - Test Loss: 30.7432 - MSE: 30.7432 - MAE: 4.4912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4502/20000 - Train Loss: 11.9198 - Test Loss: 30.7352 - MSE: 30.7352 - MAE: 4.4906\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4503/20000 - Train Loss: 11.9161 - Test Loss: 30.7273 - MSE: 30.7273 - MAE: 4.4900\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4504/20000 - Train Loss: 11.9124 - Test Loss: 30.7193 - MSE: 30.7193 - MAE: 4.4894\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4505/20000 - Train Loss: 11.9087 - Test Loss: 30.7113 - MSE: 30.7113 - MAE: 4.4887\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4506/20000 - Train Loss: 11.9051 - Test Loss: 30.7034 - MSE: 30.7034 - MAE: 4.4881\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4507/20000 - Train Loss: 11.9014 - Test Loss: 30.6954 - MSE: 30.6954 - MAE: 4.4875\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4508/20000 - Train Loss: 11.8977 - Test Loss: 30.6874 - MSE: 30.6874 - MAE: 4.4869\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4509/20000 - Train Loss: 11.8940 - Test Loss: 30.6795 - MSE: 30.6795 - MAE: 4.4863\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4510/20000 - Train Loss: 11.8903 - Test Loss: 30.6714 - MSE: 30.6714 - MAE: 4.4857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4511/20000 - Train Loss: 11.8866 - Test Loss: 30.6635 - MSE: 30.6635 - MAE: 4.4851\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4512/20000 - Train Loss: 11.8830 - Test Loss: 30.6556 - MSE: 30.6556 - MAE: 4.4845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4513/20000 - Train Loss: 11.8793 - Test Loss: 30.6476 - MSE: 30.6476 - MAE: 4.4839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4514/20000 - Train Loss: 11.8756 - Test Loss: 30.6396 - MSE: 30.6396 - MAE: 4.4833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4515/20000 - Train Loss: 11.8719 - Test Loss: 30.6316 - MSE: 30.6316 - MAE: 4.4827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4516/20000 - Train Loss: 11.8682 - Test Loss: 30.6236 - MSE: 30.6236 - MAE: 4.4820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4517/20000 - Train Loss: 11.8645 - Test Loss: 30.6156 - MSE: 30.6156 - MAE: 4.4814\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4518/20000 - Train Loss: 11.8608 - Test Loss: 30.6076 - MSE: 30.6076 - MAE: 4.4808\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4519/20000 - Train Loss: 11.8571 - Test Loss: 30.5997 - MSE: 30.5997 - MAE: 4.4802\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4520/20000 - Train Loss: 11.8535 - Test Loss: 30.5917 - MSE: 30.5917 - MAE: 4.4796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4521/20000 - Train Loss: 11.8498 - Test Loss: 30.5837 - MSE: 30.5837 - MAE: 4.4790\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4522/20000 - Train Loss: 11.8461 - Test Loss: 30.5757 - MSE: 30.5757 - MAE: 4.4784\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4523/20000 - Train Loss: 11.8424 - Test Loss: 30.5677 - MSE: 30.5677 - MAE: 4.4778\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4524/20000 - Train Loss: 11.8387 - Test Loss: 30.5597 - MSE: 30.5597 - MAE: 4.4772\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4525/20000 - Train Loss: 11.8350 - Test Loss: 30.5517 - MSE: 30.5517 - MAE: 4.4765\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4526/20000 - Train Loss: 11.8313 - Test Loss: 30.5438 - MSE: 30.5438 - MAE: 4.4759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4527/20000 - Train Loss: 11.8276 - Test Loss: 30.5358 - MSE: 30.5358 - MAE: 4.4753\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4528/20000 - Train Loss: 11.8239 - Test Loss: 30.5278 - MSE: 30.5278 - MAE: 4.4747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4529/20000 - Train Loss: 11.8202 - Test Loss: 30.5198 - MSE: 30.5198 - MAE: 4.4741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4530/20000 - Train Loss: 11.8165 - Test Loss: 30.5118 - MSE: 30.5118 - MAE: 4.4735\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4531/20000 - Train Loss: 11.8128 - Test Loss: 30.5038 - MSE: 30.5038 - MAE: 4.4729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4532/20000 - Train Loss: 11.8091 - Test Loss: 30.4958 - MSE: 30.4958 - MAE: 4.4723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4533/20000 - Train Loss: 11.8054 - Test Loss: 30.4878 - MSE: 30.4878 - MAE: 4.4716\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Epoch 4534/20000 - Train Loss: 11.8018 - Test Loss: 30.4798 - MSE: 30.4798 - MAE: 4.4710\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4535/20000 - Train Loss: 11.7980 - Test Loss: 30.4718 - MSE: 30.4718 - MAE: 4.4704\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 4536/20000 - Train Loss: 11.7943 - Test Loss: 30.4637 - MSE: 30.4637 - MAE: 4.4698\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 4537/20000 - Train Loss: 11.7907 - Test Loss: 30.4557 - MSE: 30.4557 - MAE: 4.4692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4538/20000 - Train Loss: 11.7870 - Test Loss: 30.4477 - MSE: 30.4477 - MAE: 4.4686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4539/20000 - Train Loss: 11.7832 - Test Loss: 30.4397 - MSE: 30.4397 - MAE: 4.4679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4540/20000 - Train Loss: 11.7795 - Test Loss: 30.4317 - MSE: 30.4317 - MAE: 4.4673\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4541/20000 - Train Loss: 11.7758 - Test Loss: 30.4237 - MSE: 30.4237 - MAE: 4.4667\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 4542/20000 - Train Loss: 11.7721 - Test Loss: 30.4157 - MSE: 30.4157 - MAE: 4.4661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4543/20000 - Train Loss: 11.7684 - Test Loss: 30.4077 - MSE: 30.4077 - MAE: 4.4655\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4544/20000 - Train Loss: 11.7647 - Test Loss: 30.3997 - MSE: 30.3997 - MAE: 4.4649\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4545/20000 - Train Loss: 11.7610 - Test Loss: 30.3917 - MSE: 30.3917 - MAE: 4.4643\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4546/20000 - Train Loss: 11.7573 - Test Loss: 30.3837 - MSE: 30.3837 - MAE: 4.4636\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4547/20000 - Train Loss: 11.7536 - Test Loss: 30.3756 - MSE: 30.3756 - MAE: 4.4630\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4548/20000 - Train Loss: 11.7499 - Test Loss: 30.3677 - MSE: 30.3677 - MAE: 4.4624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4549/20000 - Train Loss: 11.7462 - Test Loss: 30.3596 - MSE: 30.3596 - MAE: 4.4618\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4550/20000 - Train Loss: 11.7425 - Test Loss: 30.3515 - MSE: 30.3515 - MAE: 4.4612\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4551/20000 - Train Loss: 11.7388 - Test Loss: 30.3436 - MSE: 30.3436 - MAE: 4.4606\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 4552/20000 - Train Loss: 11.7351 - Test Loss: 30.3355 - MSE: 30.3355 - MAE: 4.4599\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4553/20000 - Train Loss: 11.7314 - Test Loss: 30.3275 - MSE: 30.3275 - MAE: 4.4593\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4554/20000 - Train Loss: 11.7277 - Test Loss: 30.3195 - MSE: 30.3195 - MAE: 4.4587\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4555/20000 - Train Loss: 11.7240 - Test Loss: 30.3115 - MSE: 30.3115 - MAE: 4.4581\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4556/20000 - Train Loss: 11.7203 - Test Loss: 30.3034 - MSE: 30.3034 - MAE: 4.4575\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4557/20000 - Train Loss: 11.7165 - Test Loss: 30.2954 - MSE: 30.2954 - MAE: 4.4569\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4558/20000 - Train Loss: 11.7128 - Test Loss: 30.2874 - MSE: 30.2874 - MAE: 4.4562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4559/20000 - Train Loss: 11.7091 - Test Loss: 30.2793 - MSE: 30.2793 - MAE: 4.4556\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4560/20000 - Train Loss: 11.7054 - Test Loss: 30.2713 - MSE: 30.2713 - MAE: 4.4550\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch 4561/20000 - Train Loss: 11.7017 - Test Loss: 30.2632 - MSE: 30.2632 - MAE: 4.4544\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4562/20000 - Train Loss: 11.6980 - Test Loss: 30.2552 - MSE: 30.2552 - MAE: 4.4538\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4563/20000 - Train Loss: 11.6943 - Test Loss: 30.2472 - MSE: 30.2472 - MAE: 4.4531\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4564/20000 - Train Loss: 11.6906 - Test Loss: 30.2392 - MSE: 30.2392 - MAE: 4.4525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4565/20000 - Train Loss: 11.6869 - Test Loss: 30.2312 - MSE: 30.2312 - MAE: 4.4519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4566/20000 - Train Loss: 11.6831 - Test Loss: 30.2231 - MSE: 30.2231 - MAE: 4.4513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4567/20000 - Train Loss: 11.6794 - Test Loss: 30.2151 - MSE: 30.2151 - MAE: 4.4507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4568/20000 - Train Loss: 11.6757 - Test Loss: 30.2071 - MSE: 30.2071 - MAE: 4.4500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4569/20000 - Train Loss: 11.6720 - Test Loss: 30.1990 - MSE: 30.1990 - MAE: 4.4494\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4570/20000 - Train Loss: 11.6683 - Test Loss: 30.1910 - MSE: 30.1910 - MAE: 4.4488\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4571/20000 - Train Loss: 11.6646 - Test Loss: 30.1829 - MSE: 30.1829 - MAE: 4.4482\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4572/20000 - Train Loss: 11.6608 - Test Loss: 30.1749 - MSE: 30.1749 - MAE: 4.4475\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4573/20000 - Train Loss: 11.6571 - Test Loss: 30.1668 - MSE: 30.1668 - MAE: 4.4469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4574/20000 - Train Loss: 11.6534 - Test Loss: 30.1587 - MSE: 30.1587 - MAE: 4.4463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4575/20000 - Train Loss: 11.6497 - Test Loss: 30.1507 - MSE: 30.1507 - MAE: 4.4457\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4576/20000 - Train Loss: 11.6460 - Test Loss: 30.1427 - MSE: 30.1427 - MAE: 4.4451\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 4577/20000 - Train Loss: 11.6422 - Test Loss: 30.1347 - MSE: 30.1347 - MAE: 4.4444\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4578/20000 - Train Loss: 11.6385 - Test Loss: 30.1266 - MSE: 30.1266 - MAE: 4.4438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4579/20000 - Train Loss: 11.6348 - Test Loss: 30.1186 - MSE: 30.1186 - MAE: 4.4432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4580/20000 - Train Loss: 11.6311 - Test Loss: 30.1105 - MSE: 30.1105 - MAE: 4.4426\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4581/20000 - Train Loss: 11.6273 - Test Loss: 30.1024 - MSE: 30.1024 - MAE: 4.4419\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4582/20000 - Train Loss: 11.6236 - Test Loss: 30.0944 - MSE: 30.0944 - MAE: 4.4413\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 4583/20000 - Train Loss: 11.6199 - Test Loss: 30.0863 - MSE: 30.0863 - MAE: 4.4407\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4584/20000 - Train Loss: 11.6162 - Test Loss: 30.0783 - MSE: 30.0783 - MAE: 4.4401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4585/20000 - Train Loss: 11.6124 - Test Loss: 30.0702 - MSE: 30.0702 - MAE: 4.4395\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4586/20000 - Train Loss: 11.6087 - Test Loss: 30.0622 - MSE: 30.0622 - MAE: 4.4388\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4587/20000 - Train Loss: 11.6050 - Test Loss: 30.0541 - MSE: 30.0541 - MAE: 4.4382\n",
      "2/2 [==============================] - 0s 988us/step\n",
      "Epoch 4588/20000 - Train Loss: 11.6013 - Test Loss: 30.0460 - MSE: 30.0460 - MAE: 4.4376\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4589/20000 - Train Loss: 11.5975 - Test Loss: 30.0380 - MSE: 30.0380 - MAE: 4.4370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4590/20000 - Train Loss: 11.5938 - Test Loss: 30.0299 - MSE: 30.0299 - MAE: 4.4363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4591/20000 - Train Loss: 11.5901 - Test Loss: 30.0219 - MSE: 30.0219 - MAE: 4.4357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4592/20000 - Train Loss: 11.5864 - Test Loss: 30.0138 - MSE: 30.0138 - MAE: 4.4351\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 4593/20000 - Train Loss: 11.5826 - Test Loss: 30.0057 - MSE: 30.0057 - MAE: 4.4344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4594/20000 - Train Loss: 11.5789 - Test Loss: 29.9976 - MSE: 29.9976 - MAE: 4.4338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4595/20000 - Train Loss: 11.5752 - Test Loss: 29.9896 - MSE: 29.9896 - MAE: 4.4332\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4596/20000 - Train Loss: 11.5714 - Test Loss: 29.9815 - MSE: 29.9815 - MAE: 4.4326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4597/20000 - Train Loss: 11.5677 - Test Loss: 29.9734 - MSE: 29.9734 - MAE: 4.4319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4598/20000 - Train Loss: 11.5640 - Test Loss: 29.9653 - MSE: 29.9653 - MAE: 4.4313\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 4599/20000 - Train Loss: 11.5602 - Test Loss: 29.9573 - MSE: 29.9573 - MAE: 4.4307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4600/20000 - Train Loss: 11.5565 - Test Loss: 29.9492 - MSE: 29.9492 - MAE: 4.4301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4601/20000 - Train Loss: 11.5528 - Test Loss: 29.9412 - MSE: 29.9412 - MAE: 4.4294\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4602/20000 - Train Loss: 11.5490 - Test Loss: 29.9331 - MSE: 29.9331 - MAE: 4.4288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4603/20000 - Train Loss: 11.5453 - Test Loss: 29.9251 - MSE: 29.9251 - MAE: 4.4282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4604/20000 - Train Loss: 11.5416 - Test Loss: 29.9170 - MSE: 29.9170 - MAE: 4.4276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4605/20000 - Train Loss: 11.5378 - Test Loss: 29.9089 - MSE: 29.9089 - MAE: 4.4269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4606/20000 - Train Loss: 11.5341 - Test Loss: 29.9008 - MSE: 29.9008 - MAE: 4.4263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4607/20000 - Train Loss: 11.5304 - Test Loss: 29.8927 - MSE: 29.8927 - MAE: 4.4257\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4608/20000 - Train Loss: 11.5266 - Test Loss: 29.8846 - MSE: 29.8846 - MAE: 4.4250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4609/20000 - Train Loss: 11.5229 - Test Loss: 29.8765 - MSE: 29.8765 - MAE: 4.4244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4610/20000 - Train Loss: 11.5191 - Test Loss: 29.8684 - MSE: 29.8684 - MAE: 4.4238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4611/20000 - Train Loss: 11.5154 - Test Loss: 29.8603 - MSE: 29.8603 - MAE: 4.4231\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4612/20000 - Train Loss: 11.5117 - Test Loss: 29.8522 - MSE: 29.8522 - MAE: 4.4225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4613/20000 - Train Loss: 11.5079 - Test Loss: 29.8441 - MSE: 29.8441 - MAE: 4.4219\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4614/20000 - Train Loss: 11.5042 - Test Loss: 29.8361 - MSE: 29.8361 - MAE: 4.4213\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4615/20000 - Train Loss: 11.5004 - Test Loss: 29.8280 - MSE: 29.8280 - MAE: 4.4206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4616/20000 - Train Loss: 11.4967 - Test Loss: 29.8199 - MSE: 29.8199 - MAE: 4.4200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4617/20000 - Train Loss: 11.4930 - Test Loss: 29.8119 - MSE: 29.8119 - MAE: 4.4194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4618/20000 - Train Loss: 11.4892 - Test Loss: 29.8038 - MSE: 29.8038 - MAE: 4.4187\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4619/20000 - Train Loss: 11.4855 - Test Loss: 29.7958 - MSE: 29.7958 - MAE: 4.4181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4620/20000 - Train Loss: 11.4817 - Test Loss: 29.7877 - MSE: 29.7877 - MAE: 4.4175\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4621/20000 - Train Loss: 11.4780 - Test Loss: 29.7795 - MSE: 29.7795 - MAE: 4.4168\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4622/20000 - Train Loss: 11.4742 - Test Loss: 29.7714 - MSE: 29.7714 - MAE: 4.4162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4623/20000 - Train Loss: 11.4705 - Test Loss: 29.7633 - MSE: 29.7633 - MAE: 4.4156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4624/20000 - Train Loss: 11.4667 - Test Loss: 29.7552 - MSE: 29.7552 - MAE: 4.4149\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4625/20000 - Train Loss: 11.4630 - Test Loss: 29.7471 - MSE: 29.7471 - MAE: 4.4143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4626/20000 - Train Loss: 11.4593 - Test Loss: 29.7389 - MSE: 29.7389 - MAE: 4.4137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4627/20000 - Train Loss: 11.4555 - Test Loss: 29.7308 - MSE: 29.7308 - MAE: 4.4130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4628/20000 - Train Loss: 11.4518 - Test Loss: 29.7227 - MSE: 29.7227 - MAE: 4.4124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4629/20000 - Train Loss: 11.4480 - Test Loss: 29.7146 - MSE: 29.7146 - MAE: 4.4118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4630/20000 - Train Loss: 11.4443 - Test Loss: 29.7066 - MSE: 29.7066 - MAE: 4.4112\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 4631/20000 - Train Loss: 11.4405 - Test Loss: 29.6985 - MSE: 29.6985 - MAE: 4.4105\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4632/20000 - Train Loss: 11.4368 - Test Loss: 29.6904 - MSE: 29.6904 - MAE: 4.4099\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4633/20000 - Train Loss: 11.4330 - Test Loss: 29.6823 - MSE: 29.6823 - MAE: 4.4093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4634/20000 - Train Loss: 11.4293 - Test Loss: 29.6742 - MSE: 29.6742 - MAE: 4.4086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4635/20000 - Train Loss: 11.4255 - Test Loss: 29.6661 - MSE: 29.6661 - MAE: 4.4080\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 4636/20000 - Train Loss: 11.4218 - Test Loss: 29.6580 - MSE: 29.6580 - MAE: 4.4073\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4637/20000 - Train Loss: 11.4180 - Test Loss: 29.6499 - MSE: 29.6499 - MAE: 4.4067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4638/20000 - Train Loss: 11.4143 - Test Loss: 29.6417 - MSE: 29.6418 - MAE: 4.4061\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4639/20000 - Train Loss: 11.4105 - Test Loss: 29.6336 - MSE: 29.6336 - MAE: 4.4054\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4640/20000 - Train Loss: 11.4068 - Test Loss: 29.6255 - MSE: 29.6255 - MAE: 4.4048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4641/20000 - Train Loss: 11.4030 - Test Loss: 29.6174 - MSE: 29.6174 - MAE: 4.4042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4642/20000 - Train Loss: 11.3992 - Test Loss: 29.6093 - MSE: 29.6093 - MAE: 4.4035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4643/20000 - Train Loss: 11.3955 - Test Loss: 29.6011 - MSE: 29.6011 - MAE: 4.4029\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4644/20000 - Train Loss: 11.3917 - Test Loss: 29.5930 - MSE: 29.5930 - MAE: 4.4023\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4645/20000 - Train Loss: 11.3880 - Test Loss: 29.5849 - MSE: 29.5849 - MAE: 4.4016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4646/20000 - Train Loss: 11.3842 - Test Loss: 29.5768 - MSE: 29.5768 - MAE: 4.4010\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4647/20000 - Train Loss: 11.3805 - Test Loss: 29.5687 - MSE: 29.5687 - MAE: 4.4004\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4648/20000 - Train Loss: 11.3767 - Test Loss: 29.5606 - MSE: 29.5605 - MAE: 4.3997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4649/20000 - Train Loss: 11.3730 - Test Loss: 29.5525 - MSE: 29.5525 - MAE: 4.3991\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4650/20000 - Train Loss: 11.3692 - Test Loss: 29.5444 - MSE: 29.5444 - MAE: 4.3984\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4651/20000 - Train Loss: 11.3654 - Test Loss: 29.5362 - MSE: 29.5362 - MAE: 4.3978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4652/20000 - Train Loss: 11.3617 - Test Loss: 29.5281 - MSE: 29.5281 - MAE: 4.3972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4653/20000 - Train Loss: 11.3579 - Test Loss: 29.5199 - MSE: 29.5199 - MAE: 4.3965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4654/20000 - Train Loss: 11.3542 - Test Loss: 29.5118 - MSE: 29.5118 - MAE: 4.3959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4655/20000 - Train Loss: 11.3504 - Test Loss: 29.5037 - MSE: 29.5037 - MAE: 4.3952\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4656/20000 - Train Loss: 11.3466 - Test Loss: 29.4956 - MSE: 29.4956 - MAE: 4.3946\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4657/20000 - Train Loss: 11.3429 - Test Loss: 29.4875 - MSE: 29.4875 - MAE: 4.3940\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4658/20000 - Train Loss: 11.3391 - Test Loss: 29.4793 - MSE: 29.4793 - MAE: 4.3933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4659/20000 - Train Loss: 11.3353 - Test Loss: 29.4712 - MSE: 29.4712 - MAE: 4.3927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4660/20000 - Train Loss: 11.3316 - Test Loss: 29.4631 - MSE: 29.4631 - MAE: 4.3921\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4661/20000 - Train Loss: 11.3278 - Test Loss: 29.4550 - MSE: 29.4550 - MAE: 4.3914\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4662/20000 - Train Loss: 11.3241 - Test Loss: 29.4468 - MSE: 29.4468 - MAE: 4.3908\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 4663/20000 - Train Loss: 11.3203 - Test Loss: 29.4387 - MSE: 29.4387 - MAE: 4.3901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4664/20000 - Train Loss: 11.3165 - Test Loss: 29.4305 - MSE: 29.4305 - MAE: 4.3895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4665/20000 - Train Loss: 11.3128 - Test Loss: 29.4223 - MSE: 29.4223 - MAE: 4.3889\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4666/20000 - Train Loss: 11.3090 - Test Loss: 29.4142 - MSE: 29.4142 - MAE: 4.3882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4667/20000 - Train Loss: 11.3052 - Test Loss: 29.4061 - MSE: 29.4061 - MAE: 4.3876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4668/20000 - Train Loss: 11.3015 - Test Loss: 29.3980 - MSE: 29.3980 - MAE: 4.3869\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4669/20000 - Train Loss: 11.2977 - Test Loss: 29.3898 - MSE: 29.3898 - MAE: 4.3863\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4670/20000 - Train Loss: 11.2939 - Test Loss: 29.3817 - MSE: 29.3817 - MAE: 4.3857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4671/20000 - Train Loss: 11.2902 - Test Loss: 29.3736 - MSE: 29.3736 - MAE: 4.3850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4672/20000 - Train Loss: 11.2864 - Test Loss: 29.3654 - MSE: 29.3654 - MAE: 4.3844\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4673/20000 - Train Loss: 11.2826 - Test Loss: 29.3573 - MSE: 29.3573 - MAE: 4.3837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4674/20000 - Train Loss: 11.2788 - Test Loss: 29.3492 - MSE: 29.3492 - MAE: 4.3831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4675/20000 - Train Loss: 11.2751 - Test Loss: 29.3410 - MSE: 29.3410 - MAE: 4.3824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4676/20000 - Train Loss: 11.2713 - Test Loss: 29.3328 - MSE: 29.3328 - MAE: 4.3818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4677/20000 - Train Loss: 11.2675 - Test Loss: 29.3247 - MSE: 29.3247 - MAE: 4.3812\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4678/20000 - Train Loss: 11.2638 - Test Loss: 29.3165 - MSE: 29.3165 - MAE: 4.3805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4679/20000 - Train Loss: 11.2600 - Test Loss: 29.3084 - MSE: 29.3084 - MAE: 4.3799\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4680/20000 - Train Loss: 11.2562 - Test Loss: 29.3002 - MSE: 29.3002 - MAE: 4.3792\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4681/20000 - Train Loss: 11.2524 - Test Loss: 29.2921 - MSE: 29.2921 - MAE: 4.3786\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4682/20000 - Train Loss: 11.2487 - Test Loss: 29.2839 - MSE: 29.2839 - MAE: 4.3779\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4683/20000 - Train Loss: 11.2449 - Test Loss: 29.2758 - MSE: 29.2758 - MAE: 4.3773\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4684/20000 - Train Loss: 11.2411 - Test Loss: 29.2676 - MSE: 29.2676 - MAE: 4.3767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4685/20000 - Train Loss: 11.2373 - Test Loss: 29.2595 - MSE: 29.2595 - MAE: 4.3760\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4686/20000 - Train Loss: 11.2336 - Test Loss: 29.2513 - MSE: 29.2513 - MAE: 4.3754\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4687/20000 - Train Loss: 11.2298 - Test Loss: 29.2432 - MSE: 29.2432 - MAE: 4.3747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4688/20000 - Train Loss: 11.2260 - Test Loss: 29.2350 - MSE: 29.2350 - MAE: 4.3741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4689/20000 - Train Loss: 11.2222 - Test Loss: 29.2269 - MSE: 29.2269 - MAE: 4.3734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4690/20000 - Train Loss: 11.2185 - Test Loss: 29.2186 - MSE: 29.2186 - MAE: 4.3728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4691/20000 - Train Loss: 11.2147 - Test Loss: 29.2106 - MSE: 29.2106 - MAE: 4.3721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4692/20000 - Train Loss: 11.2109 - Test Loss: 29.2024 - MSE: 29.2024 - MAE: 4.3715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4693/20000 - Train Loss: 11.2071 - Test Loss: 29.1942 - MSE: 29.1942 - MAE: 4.3708\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4694/20000 - Train Loss: 11.2033 - Test Loss: 29.1860 - MSE: 29.1860 - MAE: 4.3702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4695/20000 - Train Loss: 11.1996 - Test Loss: 29.1779 - MSE: 29.1779 - MAE: 4.3696\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4696/20000 - Train Loss: 11.1958 - Test Loss: 29.1697 - MSE: 29.1697 - MAE: 4.3689\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4697/20000 - Train Loss: 11.1920 - Test Loss: 29.1615 - MSE: 29.1615 - MAE: 4.3683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4698/20000 - Train Loss: 11.1882 - Test Loss: 29.1534 - MSE: 29.1534 - MAE: 4.3676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4699/20000 - Train Loss: 11.1844 - Test Loss: 29.1452 - MSE: 29.1452 - MAE: 4.3670\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4700/20000 - Train Loss: 11.1807 - Test Loss: 29.1371 - MSE: 29.1371 - MAE: 4.3663\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4701/20000 - Train Loss: 11.1769 - Test Loss: 29.1289 - MSE: 29.1289 - MAE: 4.3657\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4702/20000 - Train Loss: 11.1731 - Test Loss: 29.1208 - MSE: 29.1208 - MAE: 4.3650\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4703/20000 - Train Loss: 11.1693 - Test Loss: 29.1126 - MSE: 29.1126 - MAE: 4.3644\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4704/20000 - Train Loss: 11.1655 - Test Loss: 29.1044 - MSE: 29.1044 - MAE: 4.3637\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4705/20000 - Train Loss: 11.1617 - Test Loss: 29.0962 - MSE: 29.0962 - MAE: 4.3631\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4706/20000 - Train Loss: 11.1580 - Test Loss: 29.0880 - MSE: 29.0880 - MAE: 4.3624\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4707/20000 - Train Loss: 11.1542 - Test Loss: 29.0799 - MSE: 29.0799 - MAE: 4.3618\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4708/20000 - Train Loss: 11.1504 - Test Loss: 29.0717 - MSE: 29.0717 - MAE: 4.3611\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4709/20000 - Train Loss: 11.1466 - Test Loss: 29.0635 - MSE: 29.0635 - MAE: 4.3605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4710/20000 - Train Loss: 11.1428 - Test Loss: 29.0554 - MSE: 29.0553 - MAE: 4.3598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4711/20000 - Train Loss: 11.1390 - Test Loss: 29.0472 - MSE: 29.0472 - MAE: 4.3592\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4712/20000 - Train Loss: 11.1352 - Test Loss: 29.0390 - MSE: 29.0390 - MAE: 4.3585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4713/20000 - Train Loss: 11.1314 - Test Loss: 29.0308 - MSE: 29.0308 - MAE: 4.3579\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4714/20000 - Train Loss: 11.1277 - Test Loss: 29.0227 - MSE: 29.0227 - MAE: 4.3572\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4715/20000 - Train Loss: 11.1239 - Test Loss: 29.0144 - MSE: 29.0144 - MAE: 4.3566\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4716/20000 - Train Loss: 11.1201 - Test Loss: 29.0063 - MSE: 29.0063 - MAE: 4.3559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4717/20000 - Train Loss: 11.1163 - Test Loss: 28.9981 - MSE: 28.9981 - MAE: 4.3553\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 4718/20000 - Train Loss: 11.1125 - Test Loss: 28.9899 - MSE: 28.9899 - MAE: 4.3546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4719/20000 - Train Loss: 11.1087 - Test Loss: 28.9817 - MSE: 28.9817 - MAE: 4.3540\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4720/20000 - Train Loss: 11.1049 - Test Loss: 28.9735 - MSE: 28.9735 - MAE: 4.3533\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4721/20000 - Train Loss: 11.1011 - Test Loss: 28.9653 - MSE: 28.9653 - MAE: 4.3527\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4722/20000 - Train Loss: 11.0973 - Test Loss: 28.9571 - MSE: 28.9571 - MAE: 4.3520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4723/20000 - Train Loss: 11.0935 - Test Loss: 28.9490 - MSE: 28.9490 - MAE: 4.3514\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4724/20000 - Train Loss: 11.0898 - Test Loss: 28.9408 - MSE: 28.9408 - MAE: 4.3507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4725/20000 - Train Loss: 11.0860 - Test Loss: 28.9326 - MSE: 28.9326 - MAE: 4.3501\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4726/20000 - Train Loss: 11.0822 - Test Loss: 28.9244 - MSE: 28.9244 - MAE: 4.3494\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4727/20000 - Train Loss: 11.0784 - Test Loss: 28.9162 - MSE: 28.9162 - MAE: 4.3488\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4728/20000 - Train Loss: 11.0746 - Test Loss: 28.9080 - MSE: 28.9080 - MAE: 4.3481\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4729/20000 - Train Loss: 11.0708 - Test Loss: 28.8998 - MSE: 28.8998 - MAE: 4.3475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4730/20000 - Train Loss: 11.0670 - Test Loss: 28.8917 - MSE: 28.8917 - MAE: 4.3468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4731/20000 - Train Loss: 11.0632 - Test Loss: 28.8835 - MSE: 28.8835 - MAE: 4.3461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4732/20000 - Train Loss: 11.0594 - Test Loss: 28.8752 - MSE: 28.8752 - MAE: 4.3455\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4733/20000 - Train Loss: 11.0556 - Test Loss: 28.8670 - MSE: 28.8670 - MAE: 4.3448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4734/20000 - Train Loss: 11.0518 - Test Loss: 28.8588 - MSE: 28.8588 - MAE: 4.3442\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4735/20000 - Train Loss: 11.0480 - Test Loss: 28.8506 - MSE: 28.8506 - MAE: 4.3435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4736/20000 - Train Loss: 11.0442 - Test Loss: 28.8424 - MSE: 28.8424 - MAE: 4.3429\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4737/20000 - Train Loss: 11.0404 - Test Loss: 28.8342 - MSE: 28.8342 - MAE: 4.3422\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4738/20000 - Train Loss: 11.0366 - Test Loss: 28.8260 - MSE: 28.8260 - MAE: 4.3416\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4739/20000 - Train Loss: 11.0328 - Test Loss: 28.8179 - MSE: 28.8179 - MAE: 4.3409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4740/20000 - Train Loss: 11.0290 - Test Loss: 28.8097 - MSE: 28.8097 - MAE: 4.3403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4741/20000 - Train Loss: 11.0252 - Test Loss: 28.8015 - MSE: 28.8015 - MAE: 4.3396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4742/20000 - Train Loss: 11.0214 - Test Loss: 28.7933 - MSE: 28.7933 - MAE: 4.3389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4743/20000 - Train Loss: 11.0176 - Test Loss: 28.7851 - MSE: 28.7851 - MAE: 4.3383\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4744/20000 - Train Loss: 11.0138 - Test Loss: 28.7768 - MSE: 28.7768 - MAE: 4.3376\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4745/20000 - Train Loss: 11.0100 - Test Loss: 28.7687 - MSE: 28.7687 - MAE: 4.3370\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4746/20000 - Train Loss: 11.0062 - Test Loss: 28.7604 - MSE: 28.7604 - MAE: 4.3363\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4747/20000 - Train Loss: 11.0024 - Test Loss: 28.7522 - MSE: 28.7522 - MAE: 4.3357\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4748/20000 - Train Loss: 10.9986 - Test Loss: 28.7440 - MSE: 28.7440 - MAE: 4.3350\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4749/20000 - Train Loss: 10.9948 - Test Loss: 28.7358 - MSE: 28.7358 - MAE: 4.3343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4750/20000 - Train Loss: 10.9910 - Test Loss: 28.7276 - MSE: 28.7276 - MAE: 4.3337\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4751/20000 - Train Loss: 10.9872 - Test Loss: 28.7194 - MSE: 28.7194 - MAE: 4.3330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4752/20000 - Train Loss: 10.9834 - Test Loss: 28.7112 - MSE: 28.7112 - MAE: 4.3324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4753/20000 - Train Loss: 10.9796 - Test Loss: 28.7030 - MSE: 28.7030 - MAE: 4.3317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4754/20000 - Train Loss: 10.9758 - Test Loss: 28.6948 - MSE: 28.6948 - MAE: 4.3311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4755/20000 - Train Loss: 10.9720 - Test Loss: 28.6866 - MSE: 28.6866 - MAE: 4.3304\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4756/20000 - Train Loss: 10.9681 - Test Loss: 28.6784 - MSE: 28.6784 - MAE: 4.3297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4757/20000 - Train Loss: 10.9643 - Test Loss: 28.6701 - MSE: 28.6701 - MAE: 4.3291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4758/20000 - Train Loss: 10.9605 - Test Loss: 28.6619 - MSE: 28.6619 - MAE: 4.3284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4759/20000 - Train Loss: 10.9567 - Test Loss: 28.6536 - MSE: 28.6536 - MAE: 4.3278\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4760/20000 - Train Loss: 10.9529 - Test Loss: 28.6454 - MSE: 28.6454 - MAE: 4.3271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4761/20000 - Train Loss: 10.9491 - Test Loss: 28.6372 - MSE: 28.6372 - MAE: 4.3264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4762/20000 - Train Loss: 10.9453 - Test Loss: 28.6290 - MSE: 28.6290 - MAE: 4.3258\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 4763/20000 - Train Loss: 10.9415 - Test Loss: 28.6208 - MSE: 28.6208 - MAE: 4.3251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4764/20000 - Train Loss: 10.9377 - Test Loss: 28.6126 - MSE: 28.6126 - MAE: 4.3245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4765/20000 - Train Loss: 10.9339 - Test Loss: 28.6044 - MSE: 28.6044 - MAE: 4.3238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4766/20000 - Train Loss: 10.9301 - Test Loss: 28.5962 - MSE: 28.5962 - MAE: 4.3231\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4767/20000 - Train Loss: 10.9263 - Test Loss: 28.5880 - MSE: 28.5880 - MAE: 4.3225\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4768/20000 - Train Loss: 10.9224 - Test Loss: 28.5798 - MSE: 28.5798 - MAE: 4.3218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4769/20000 - Train Loss: 10.9186 - Test Loss: 28.5716 - MSE: 28.5716 - MAE: 4.3212\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4770/20000 - Train Loss: 10.9148 - Test Loss: 28.5633 - MSE: 28.5633 - MAE: 4.3205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4771/20000 - Train Loss: 10.9110 - Test Loss: 28.5550 - MSE: 28.5550 - MAE: 4.3198\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4772/20000 - Train Loss: 10.9072 - Test Loss: 28.5468 - MSE: 28.5468 - MAE: 4.3192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4773/20000 - Train Loss: 10.9034 - Test Loss: 28.5385 - MSE: 28.5385 - MAE: 4.3185\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4774/20000 - Train Loss: 10.8996 - Test Loss: 28.5303 - MSE: 28.5303 - MAE: 4.3178\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4775/20000 - Train Loss: 10.8957 - Test Loss: 28.5221 - MSE: 28.5221 - MAE: 4.3172\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4776/20000 - Train Loss: 10.8919 - Test Loss: 28.5139 - MSE: 28.5139 - MAE: 4.3165\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4777/20000 - Train Loss: 10.8881 - Test Loss: 28.5057 - MSE: 28.5057 - MAE: 4.3159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4778/20000 - Train Loss: 10.8843 - Test Loss: 28.4974 - MSE: 28.4974 - MAE: 4.3152\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4779/20000 - Train Loss: 10.8805 - Test Loss: 28.4893 - MSE: 28.4892 - MAE: 4.3145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4780/20000 - Train Loss: 10.8767 - Test Loss: 28.4810 - MSE: 28.4810 - MAE: 4.3139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4781/20000 - Train Loss: 10.8729 - Test Loss: 28.4728 - MSE: 28.4728 - MAE: 4.3132\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4782/20000 - Train Loss: 10.8690 - Test Loss: 28.4645 - MSE: 28.4645 - MAE: 4.3125\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4783/20000 - Train Loss: 10.8652 - Test Loss: 28.4563 - MSE: 28.4563 - MAE: 4.3119\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 4784/20000 - Train Loss: 10.8614 - Test Loss: 28.4480 - MSE: 28.4480 - MAE: 4.3112\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4785/20000 - Train Loss: 10.8576 - Test Loss: 28.4397 - MSE: 28.4397 - MAE: 4.3105\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4786/20000 - Train Loss: 10.8538 - Test Loss: 28.4315 - MSE: 28.4315 - MAE: 4.3099\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4787/20000 - Train Loss: 10.8499 - Test Loss: 28.4233 - MSE: 28.4233 - MAE: 4.3092\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4788/20000 - Train Loss: 10.8461 - Test Loss: 28.4151 - MSE: 28.4151 - MAE: 4.3085\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 4789/20000 - Train Loss: 10.8423 - Test Loss: 28.4069 - MSE: 28.4069 - MAE: 4.3079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4790/20000 - Train Loss: 10.8385 - Test Loss: 28.3987 - MSE: 28.3987 - MAE: 4.3072\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 4791/20000 - Train Loss: 10.8347 - Test Loss: 28.3904 - MSE: 28.3904 - MAE: 4.3066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4792/20000 - Train Loss: 10.8308 - Test Loss: 28.3822 - MSE: 28.3822 - MAE: 4.3059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4793/20000 - Train Loss: 10.8270 - Test Loss: 28.3739 - MSE: 28.3739 - MAE: 4.3052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4794/20000 - Train Loss: 10.8232 - Test Loss: 28.3657 - MSE: 28.3657 - MAE: 4.3046\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4795/20000 - Train Loss: 10.8194 - Test Loss: 28.3574 - MSE: 28.3574 - MAE: 4.3039\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4796/20000 - Train Loss: 10.8156 - Test Loss: 28.3492 - MSE: 28.3492 - MAE: 4.3032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4797/20000 - Train Loss: 10.8117 - Test Loss: 28.3409 - MSE: 28.3409 - MAE: 4.3025\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4798/20000 - Train Loss: 10.8079 - Test Loss: 28.3327 - MSE: 28.3327 - MAE: 4.3019\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 4799/20000 - Train Loss: 10.8041 - Test Loss: 28.3244 - MSE: 28.3244 - MAE: 4.3012\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4800/20000 - Train Loss: 10.8003 - Test Loss: 28.3162 - MSE: 28.3162 - MAE: 4.3005\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4801/20000 - Train Loss: 10.7964 - Test Loss: 28.3079 - MSE: 28.3079 - MAE: 4.2999\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4802/20000 - Train Loss: 10.7926 - Test Loss: 28.2997 - MSE: 28.2997 - MAE: 4.2992\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4803/20000 - Train Loss: 10.7888 - Test Loss: 28.2915 - MSE: 28.2915 - MAE: 4.2985\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4804/20000 - Train Loss: 10.7850 - Test Loss: 28.2832 - MSE: 28.2832 - MAE: 4.2979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4805/20000 - Train Loss: 10.7811 - Test Loss: 28.2749 - MSE: 28.2749 - MAE: 4.2972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4806/20000 - Train Loss: 10.7773 - Test Loss: 28.2667 - MSE: 28.2667 - MAE: 4.2965\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 4807/20000 - Train Loss: 10.7735 - Test Loss: 28.2584 - MSE: 28.2584 - MAE: 4.2959\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 4808/20000 - Train Loss: 10.7696 - Test Loss: 28.2502 - MSE: 28.2502 - MAE: 4.2952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4809/20000 - Train Loss: 10.7658 - Test Loss: 28.2419 - MSE: 28.2419 - MAE: 4.2945\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4810/20000 - Train Loss: 10.7620 - Test Loss: 28.2337 - MSE: 28.2337 - MAE: 4.2939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4811/20000 - Train Loss: 10.7582 - Test Loss: 28.2255 - MSE: 28.2255 - MAE: 4.2932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4812/20000 - Train Loss: 10.7543 - Test Loss: 28.2171 - MSE: 28.2171 - MAE: 4.2925\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 4813/20000 - Train Loss: 10.7505 - Test Loss: 28.2089 - MSE: 28.2089 - MAE: 4.2918\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4814/20000 - Train Loss: 10.7467 - Test Loss: 28.2007 - MSE: 28.2007 - MAE: 4.2912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4815/20000 - Train Loss: 10.7429 - Test Loss: 28.1924 - MSE: 28.1924 - MAE: 4.2905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4816/20000 - Train Loss: 10.7390 - Test Loss: 28.1841 - MSE: 28.1841 - MAE: 4.2898\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4817/20000 - Train Loss: 10.7352 - Test Loss: 28.1759 - MSE: 28.1759 - MAE: 4.2892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4818/20000 - Train Loss: 10.7314 - Test Loss: 28.1677 - MSE: 28.1677 - MAE: 4.2885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4819/20000 - Train Loss: 10.7275 - Test Loss: 28.1593 - MSE: 28.1593 - MAE: 4.2878\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 4820/20000 - Train Loss: 10.7237 - Test Loss: 28.1511 - MSE: 28.1511 - MAE: 4.2871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4821/20000 - Train Loss: 10.7199 - Test Loss: 28.1428 - MSE: 28.1428 - MAE: 4.2865\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4822/20000 - Train Loss: 10.7160 - Test Loss: 28.1345 - MSE: 28.1345 - MAE: 4.2858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4823/20000 - Train Loss: 10.7122 - Test Loss: 28.1263 - MSE: 28.1263 - MAE: 4.2851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4824/20000 - Train Loss: 10.7084 - Test Loss: 28.1180 - MSE: 28.1180 - MAE: 4.2845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4825/20000 - Train Loss: 10.7045 - Test Loss: 28.1098 - MSE: 28.1098 - MAE: 4.2838\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 4826/20000 - Train Loss: 10.7007 - Test Loss: 28.1016 - MSE: 28.1016 - MAE: 4.2831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4827/20000 - Train Loss: 10.6969 - Test Loss: 28.0933 - MSE: 28.0933 - MAE: 4.2824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4828/20000 - Train Loss: 10.6930 - Test Loss: 28.0850 - MSE: 28.0850 - MAE: 4.2818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4829/20000 - Train Loss: 10.6892 - Test Loss: 28.0767 - MSE: 28.0767 - MAE: 4.2811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4830/20000 - Train Loss: 10.6854 - Test Loss: 28.0685 - MSE: 28.0685 - MAE: 4.2804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4831/20000 - Train Loss: 10.6815 - Test Loss: 28.0601 - MSE: 28.0601 - MAE: 4.2797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4832/20000 - Train Loss: 10.6777 - Test Loss: 28.0519 - MSE: 28.0519 - MAE: 4.2791\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4833/20000 - Train Loss: 10.6738 - Test Loss: 28.0436 - MSE: 28.0436 - MAE: 4.2784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4834/20000 - Train Loss: 10.6700 - Test Loss: 28.0354 - MSE: 28.0354 - MAE: 4.2777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4835/20000 - Train Loss: 10.6662 - Test Loss: 28.0271 - MSE: 28.0271 - MAE: 4.2771\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4836/20000 - Train Loss: 10.6623 - Test Loss: 28.0189 - MSE: 28.0189 - MAE: 4.2764\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4837/20000 - Train Loss: 10.6585 - Test Loss: 28.0106 - MSE: 28.0106 - MAE: 4.2757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4838/20000 - Train Loss: 10.6547 - Test Loss: 28.0023 - MSE: 28.0023 - MAE: 4.2750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4839/20000 - Train Loss: 10.6508 - Test Loss: 27.9940 - MSE: 27.9940 - MAE: 4.2743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4840/20000 - Train Loss: 10.6470 - Test Loss: 27.9857 - MSE: 27.9857 - MAE: 4.2737\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 4841/20000 - Train Loss: 10.6431 - Test Loss: 27.9775 - MSE: 27.9775 - MAE: 4.2730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4842/20000 - Train Loss: 10.6393 - Test Loss: 27.9692 - MSE: 27.9692 - MAE: 4.2723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4843/20000 - Train Loss: 10.6355 - Test Loss: 27.9609 - MSE: 27.9609 - MAE: 4.2716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4844/20000 - Train Loss: 10.6316 - Test Loss: 27.9527 - MSE: 27.9527 - MAE: 4.2710\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4845/20000 - Train Loss: 10.6278 - Test Loss: 27.9444 - MSE: 27.9444 - MAE: 4.2703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4846/20000 - Train Loss: 10.6239 - Test Loss: 27.9361 - MSE: 27.9361 - MAE: 4.2696\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4847/20000 - Train Loss: 10.6201 - Test Loss: 27.9278 - MSE: 27.9278 - MAE: 4.2689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4848/20000 - Train Loss: 10.6163 - Test Loss: 27.9195 - MSE: 27.9195 - MAE: 4.2683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4849/20000 - Train Loss: 10.6124 - Test Loss: 27.9112 - MSE: 27.9112 - MAE: 4.2676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4850/20000 - Train Loss: 10.6086 - Test Loss: 27.9030 - MSE: 27.9030 - MAE: 4.2669\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4851/20000 - Train Loss: 10.6047 - Test Loss: 27.8947 - MSE: 27.8947 - MAE: 4.2662\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4852/20000 - Train Loss: 10.6009 - Test Loss: 27.8864 - MSE: 27.8864 - MAE: 4.2656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4853/20000 - Train Loss: 10.5970 - Test Loss: 27.8782 - MSE: 27.8782 - MAE: 4.2649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4854/20000 - Train Loss: 10.5932 - Test Loss: 27.8699 - MSE: 27.8699 - MAE: 4.2642\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4855/20000 - Train Loss: 10.5894 - Test Loss: 27.8616 - MSE: 27.8616 - MAE: 4.2635\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4856/20000 - Train Loss: 10.5855 - Test Loss: 27.8533 - MSE: 27.8533 - MAE: 4.2628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4857/20000 - Train Loss: 10.5817 - Test Loss: 27.8450 - MSE: 27.8450 - MAE: 4.2622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4858/20000 - Train Loss: 10.5778 - Test Loss: 27.8367 - MSE: 27.8367 - MAE: 4.2615\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4859/20000 - Train Loss: 10.5740 - Test Loss: 27.8284 - MSE: 27.8284 - MAE: 4.2608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4860/20000 - Train Loss: 10.5701 - Test Loss: 27.8201 - MSE: 27.8201 - MAE: 4.2601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4861/20000 - Train Loss: 10.5663 - Test Loss: 27.8119 - MSE: 27.8119 - MAE: 4.2594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4862/20000 - Train Loss: 10.5624 - Test Loss: 27.8036 - MSE: 27.8036 - MAE: 4.2588\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4863/20000 - Train Loss: 10.5586 - Test Loss: 27.7953 - MSE: 27.7953 - MAE: 4.2581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4864/20000 - Train Loss: 10.5547 - Test Loss: 27.7870 - MSE: 27.7870 - MAE: 4.2574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4865/20000 - Train Loss: 10.5509 - Test Loss: 27.7787 - MSE: 27.7787 - MAE: 4.2567\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4866/20000 - Train Loss: 10.5471 - Test Loss: 27.7704 - MSE: 27.7704 - MAE: 4.2560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4867/20000 - Train Loss: 10.5432 - Test Loss: 27.7621 - MSE: 27.7621 - MAE: 4.2553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4868/20000 - Train Loss: 10.5394 - Test Loss: 27.7539 - MSE: 27.7539 - MAE: 4.2547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4869/20000 - Train Loss: 10.5355 - Test Loss: 27.7456 - MSE: 27.7456 - MAE: 4.2540\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 4870/20000 - Train Loss: 10.5316 - Test Loss: 27.7372 - MSE: 27.7372 - MAE: 4.2533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4871/20000 - Train Loss: 10.5278 - Test Loss: 27.7290 - MSE: 27.7290 - MAE: 4.2526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4872/20000 - Train Loss: 10.5239 - Test Loss: 27.7207 - MSE: 27.7207 - MAE: 4.2519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4873/20000 - Train Loss: 10.5201 - Test Loss: 27.7124 - MSE: 27.7124 - MAE: 4.2513\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 4874/20000 - Train Loss: 10.5163 - Test Loss: 27.7041 - MSE: 27.7041 - MAE: 4.2506\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4875/20000 - Train Loss: 10.5124 - Test Loss: 27.6958 - MSE: 27.6958 - MAE: 4.2499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4876/20000 - Train Loss: 10.5085 - Test Loss: 27.6875 - MSE: 27.6875 - MAE: 4.2492\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4877/20000 - Train Loss: 10.5047 - Test Loss: 27.6792 - MSE: 27.6792 - MAE: 4.2485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4878/20000 - Train Loss: 10.5008 - Test Loss: 27.6709 - MSE: 27.6709 - MAE: 4.2478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4879/20000 - Train Loss: 10.4970 - Test Loss: 27.6626 - MSE: 27.6626 - MAE: 4.2472\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4880/20000 - Train Loss: 10.4931 - Test Loss: 27.6543 - MSE: 27.6543 - MAE: 4.2465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4881/20000 - Train Loss: 10.4893 - Test Loss: 27.6460 - MSE: 27.6460 - MAE: 4.2458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4882/20000 - Train Loss: 10.4854 - Test Loss: 27.6377 - MSE: 27.6377 - MAE: 4.2451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4883/20000 - Train Loss: 10.4816 - Test Loss: 27.6294 - MSE: 27.6294 - MAE: 4.2444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4884/20000 - Train Loss: 10.4777 - Test Loss: 27.6211 - MSE: 27.6211 - MAE: 4.2437\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 4885/20000 - Train Loss: 10.4739 - Test Loss: 27.6128 - MSE: 27.6128 - MAE: 4.2431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4886/20000 - Train Loss: 10.4700 - Test Loss: 27.6045 - MSE: 27.6045 - MAE: 4.2424\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 4887/20000 - Train Loss: 10.4662 - Test Loss: 27.5962 - MSE: 27.5962 - MAE: 4.2417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4888/20000 - Train Loss: 10.4623 - Test Loss: 27.5879 - MSE: 27.5879 - MAE: 4.2410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4889/20000 - Train Loss: 10.4585 - Test Loss: 27.5796 - MSE: 27.5796 - MAE: 4.2403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4890/20000 - Train Loss: 10.4546 - Test Loss: 27.5714 - MSE: 27.5714 - MAE: 4.2396\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4891/20000 - Train Loss: 10.4507 - Test Loss: 27.5630 - MSE: 27.5630 - MAE: 4.2389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4892/20000 - Train Loss: 10.4469 - Test Loss: 27.5547 - MSE: 27.5547 - MAE: 4.2383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4893/20000 - Train Loss: 10.4430 - Test Loss: 27.5464 - MSE: 27.5464 - MAE: 4.2376\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4894/20000 - Train Loss: 10.4392 - Test Loss: 27.5380 - MSE: 27.5380 - MAE: 4.2369\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4895/20000 - Train Loss: 10.4353 - Test Loss: 27.5298 - MSE: 27.5298 - MAE: 4.2362\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4896/20000 - Train Loss: 10.4315 - Test Loss: 27.5215 - MSE: 27.5215 - MAE: 4.2355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4897/20000 - Train Loss: 10.4276 - Test Loss: 27.5131 - MSE: 27.5131 - MAE: 4.2348\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4898/20000 - Train Loss: 10.4237 - Test Loss: 27.5048 - MSE: 27.5048 - MAE: 4.2341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4899/20000 - Train Loss: 10.4199 - Test Loss: 27.4965 - MSE: 27.4965 - MAE: 4.2334\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 4900/20000 - Train Loss: 10.4160 - Test Loss: 27.4882 - MSE: 27.4882 - MAE: 4.2328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4901/20000 - Train Loss: 10.4122 - Test Loss: 27.4799 - MSE: 27.4799 - MAE: 4.2321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4902/20000 - Train Loss: 10.4083 - Test Loss: 27.4716 - MSE: 27.4716 - MAE: 4.2314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4903/20000 - Train Loss: 10.4044 - Test Loss: 27.4633 - MSE: 27.4633 - MAE: 4.2307\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 4904/20000 - Train Loss: 10.4006 - Test Loss: 27.4550 - MSE: 27.4550 - MAE: 4.2300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4905/20000 - Train Loss: 10.3967 - Test Loss: 27.4468 - MSE: 27.4468 - MAE: 4.2293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4906/20000 - Train Loss: 10.3929 - Test Loss: 27.4384 - MSE: 27.4384 - MAE: 4.2286\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4907/20000 - Train Loss: 10.3890 - Test Loss: 27.4301 - MSE: 27.4301 - MAE: 4.2279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4908/20000 - Train Loss: 10.3851 - Test Loss: 27.4218 - MSE: 27.4218 - MAE: 4.2272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4909/20000 - Train Loss: 10.3813 - Test Loss: 27.4134 - MSE: 27.4134 - MAE: 4.2266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4910/20000 - Train Loss: 10.3774 - Test Loss: 27.4051 - MSE: 27.4051 - MAE: 4.2259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4911/20000 - Train Loss: 10.3736 - Test Loss: 27.3968 - MSE: 27.3968 - MAE: 4.2252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4912/20000 - Train Loss: 10.3697 - Test Loss: 27.3884 - MSE: 27.3884 - MAE: 4.2245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4913/20000 - Train Loss: 10.3658 - Test Loss: 27.3801 - MSE: 27.3801 - MAE: 4.2238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4914/20000 - Train Loss: 10.3620 - Test Loss: 27.3719 - MSE: 27.3719 - MAE: 4.2231\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4915/20000 - Train Loss: 10.3581 - Test Loss: 27.3635 - MSE: 27.3635 - MAE: 4.2224\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4916/20000 - Train Loss: 10.3542 - Test Loss: 27.3553 - MSE: 27.3553 - MAE: 4.2217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4917/20000 - Train Loss: 10.3504 - Test Loss: 27.3469 - MSE: 27.3469 - MAE: 4.2210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4918/20000 - Train Loss: 10.3465 - Test Loss: 27.3386 - MSE: 27.3386 - MAE: 4.2203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4919/20000 - Train Loss: 10.3426 - Test Loss: 27.3303 - MSE: 27.3303 - MAE: 4.2197\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4920/20000 - Train Loss: 10.3388 - Test Loss: 27.3220 - MSE: 27.3220 - MAE: 4.2190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4921/20000 - Train Loss: 10.3349 - Test Loss: 27.3136 - MSE: 27.3136 - MAE: 4.2183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4922/20000 - Train Loss: 10.3311 - Test Loss: 27.3053 - MSE: 27.3053 - MAE: 4.2176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4923/20000 - Train Loss: 10.3272 - Test Loss: 27.2970 - MSE: 27.2970 - MAE: 4.2169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4924/20000 - Train Loss: 10.3233 - Test Loss: 27.2887 - MSE: 27.2887 - MAE: 4.2162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4925/20000 - Train Loss: 10.3195 - Test Loss: 27.2804 - MSE: 27.2804 - MAE: 4.2155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4926/20000 - Train Loss: 10.3156 - Test Loss: 27.2720 - MSE: 27.2721 - MAE: 4.2148\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4927/20000 - Train Loss: 10.3117 - Test Loss: 27.2637 - MSE: 27.2637 - MAE: 4.2141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4928/20000 - Train Loss: 10.3079 - Test Loss: 27.2554 - MSE: 27.2554 - MAE: 4.2134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4929/20000 - Train Loss: 10.3040 - Test Loss: 27.2471 - MSE: 27.2471 - MAE: 4.2127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4930/20000 - Train Loss: 10.3001 - Test Loss: 27.2387 - MSE: 27.2387 - MAE: 4.2120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4931/20000 - Train Loss: 10.2963 - Test Loss: 27.2304 - MSE: 27.2304 - MAE: 4.2113\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 4932/20000 - Train Loss: 10.2924 - Test Loss: 27.2221 - MSE: 27.2221 - MAE: 4.2106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4933/20000 - Train Loss: 10.2885 - Test Loss: 27.2137 - MSE: 27.2137 - MAE: 4.2099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4934/20000 - Train Loss: 10.2846 - Test Loss: 27.2054 - MSE: 27.2054 - MAE: 4.2092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4935/20000 - Train Loss: 10.2808 - Test Loss: 27.1970 - MSE: 27.1970 - MAE: 4.2086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4936/20000 - Train Loss: 10.2769 - Test Loss: 27.1888 - MSE: 27.1888 - MAE: 4.2079\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4937/20000 - Train Loss: 10.2730 - Test Loss: 27.1804 - MSE: 27.1804 - MAE: 4.2072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4938/20000 - Train Loss: 10.2692 - Test Loss: 27.1722 - MSE: 27.1722 - MAE: 4.2065\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4939/20000 - Train Loss: 10.2653 - Test Loss: 27.1639 - MSE: 27.1639 - MAE: 4.2058\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4940/20000 - Train Loss: 10.2614 - Test Loss: 27.1555 - MSE: 27.1555 - MAE: 4.2051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4941/20000 - Train Loss: 10.2576 - Test Loss: 27.1472 - MSE: 27.1472 - MAE: 4.2044\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4942/20000 - Train Loss: 10.2537 - Test Loss: 27.1389 - MSE: 27.1389 - MAE: 4.2037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4943/20000 - Train Loss: 10.2498 - Test Loss: 27.1305 - MSE: 27.1305 - MAE: 4.2030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4944/20000 - Train Loss: 10.2459 - Test Loss: 27.1221 - MSE: 27.1221 - MAE: 4.2023\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4945/20000 - Train Loss: 10.2421 - Test Loss: 27.1138 - MSE: 27.1138 - MAE: 4.2016\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4946/20000 - Train Loss: 10.2382 - Test Loss: 27.1055 - MSE: 27.1055 - MAE: 4.2009\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4947/20000 - Train Loss: 10.2343 - Test Loss: 27.0971 - MSE: 27.0971 - MAE: 4.2002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4948/20000 - Train Loss: 10.2305 - Test Loss: 27.0888 - MSE: 27.0888 - MAE: 4.1995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4949/20000 - Train Loss: 10.2266 - Test Loss: 27.0804 - MSE: 27.0804 - MAE: 4.1988\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4950/20000 - Train Loss: 10.2227 - Test Loss: 27.0721 - MSE: 27.0721 - MAE: 4.1981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4951/20000 - Train Loss: 10.2188 - Test Loss: 27.0638 - MSE: 27.0638 - MAE: 4.1974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4952/20000 - Train Loss: 10.2150 - Test Loss: 27.0555 - MSE: 27.0555 - MAE: 4.1967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4953/20000 - Train Loss: 10.2111 - Test Loss: 27.0473 - MSE: 27.0473 - MAE: 4.1960\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4954/20000 - Train Loss: 10.2072 - Test Loss: 27.0389 - MSE: 27.0389 - MAE: 4.1953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4955/20000 - Train Loss: 10.2033 - Test Loss: 27.0306 - MSE: 27.0306 - MAE: 4.1946\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4956/20000 - Train Loss: 10.1995 - Test Loss: 27.0222 - MSE: 27.0222 - MAE: 4.1939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4957/20000 - Train Loss: 10.1956 - Test Loss: 27.0138 - MSE: 27.0138 - MAE: 4.1932\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 4958/20000 - Train Loss: 10.1917 - Test Loss: 27.0055 - MSE: 27.0055 - MAE: 4.1925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4959/20000 - Train Loss: 10.1878 - Test Loss: 26.9971 - MSE: 26.9971 - MAE: 4.1918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4960/20000 - Train Loss: 10.1840 - Test Loss: 26.9888 - MSE: 26.9888 - MAE: 4.1911\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4961/20000 - Train Loss: 10.1801 - Test Loss: 26.9805 - MSE: 26.9805 - MAE: 4.1904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4962/20000 - Train Loss: 10.1762 - Test Loss: 26.9721 - MSE: 26.9721 - MAE: 4.1897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4963/20000 - Train Loss: 10.1723 - Test Loss: 26.9638 - MSE: 26.9638 - MAE: 4.1890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4964/20000 - Train Loss: 10.1685 - Test Loss: 26.9555 - MSE: 26.9555 - MAE: 4.1883\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4965/20000 - Train Loss: 10.1646 - Test Loss: 26.9471 - MSE: 26.9471 - MAE: 4.1876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4966/20000 - Train Loss: 10.1607 - Test Loss: 26.9388 - MSE: 26.9388 - MAE: 4.1869\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 4967/20000 - Train Loss: 10.1568 - Test Loss: 26.9304 - MSE: 26.9304 - MAE: 4.1862\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4968/20000 - Train Loss: 10.1530 - Test Loss: 26.9221 - MSE: 26.9221 - MAE: 4.1855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4969/20000 - Train Loss: 10.1491 - Test Loss: 26.9138 - MSE: 26.9138 - MAE: 4.1848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4970/20000 - Train Loss: 10.1452 - Test Loss: 26.9055 - MSE: 26.9055 - MAE: 4.1841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4971/20000 - Train Loss: 10.1413 - Test Loss: 26.8971 - MSE: 26.8971 - MAE: 4.1834\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 4972/20000 - Train Loss: 10.1374 - Test Loss: 26.8888 - MSE: 26.8888 - MAE: 4.1827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4973/20000 - Train Loss: 10.1336 - Test Loss: 26.8804 - MSE: 26.8804 - MAE: 4.1820\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4974/20000 - Train Loss: 10.1297 - Test Loss: 26.8721 - MSE: 26.8721 - MAE: 4.1813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4975/20000 - Train Loss: 10.1258 - Test Loss: 26.8637 - MSE: 26.8637 - MAE: 4.1806\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4976/20000 - Train Loss: 10.1219 - Test Loss: 26.8553 - MSE: 26.8553 - MAE: 4.1799\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4977/20000 - Train Loss: 10.1180 - Test Loss: 26.8470 - MSE: 26.8470 - MAE: 4.1792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4978/20000 - Train Loss: 10.1142 - Test Loss: 26.8387 - MSE: 26.8387 - MAE: 4.1785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4979/20000 - Train Loss: 10.1103 - Test Loss: 26.8303 - MSE: 26.8303 - MAE: 4.1778\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4980/20000 - Train Loss: 10.1064 - Test Loss: 26.8220 - MSE: 26.8220 - MAE: 4.1771\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 4981/20000 - Train Loss: 10.1025 - Test Loss: 26.8137 - MSE: 26.8137 - MAE: 4.1764\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4982/20000 - Train Loss: 10.0986 - Test Loss: 26.8053 - MSE: 26.8053 - MAE: 4.1757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4983/20000 - Train Loss: 10.0948 - Test Loss: 26.7970 - MSE: 26.7970 - MAE: 4.1750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4984/20000 - Train Loss: 10.0909 - Test Loss: 26.7886 - MSE: 26.7886 - MAE: 4.1743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4985/20000 - Train Loss: 10.0870 - Test Loss: 26.7802 - MSE: 26.7802 - MAE: 4.1736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4986/20000 - Train Loss: 10.0831 - Test Loss: 26.7719 - MSE: 26.7719 - MAE: 4.1729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4987/20000 - Train Loss: 10.0792 - Test Loss: 26.7636 - MSE: 26.7636 - MAE: 4.1722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4988/20000 - Train Loss: 10.0753 - Test Loss: 26.7552 - MSE: 26.7552 - MAE: 4.1714\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4989/20000 - Train Loss: 10.0715 - Test Loss: 26.7469 - MSE: 26.7469 - MAE: 4.1707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4990/20000 - Train Loss: 10.0676 - Test Loss: 26.7385 - MSE: 26.7385 - MAE: 4.1700\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 4991/20000 - Train Loss: 10.0637 - Test Loss: 26.7302 - MSE: 26.7302 - MAE: 4.1693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4992/20000 - Train Loss: 10.0598 - Test Loss: 26.7218 - MSE: 26.7218 - MAE: 4.1686\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 4993/20000 - Train Loss: 10.0559 - Test Loss: 26.7134 - MSE: 26.7134 - MAE: 4.1679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4994/20000 - Train Loss: 10.0520 - Test Loss: 26.7051 - MSE: 26.7051 - MAE: 4.1672\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4995/20000 - Train Loss: 10.0482 - Test Loss: 26.6968 - MSE: 26.6968 - MAE: 4.1665\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 4996/20000 - Train Loss: 10.0443 - Test Loss: 26.6884 - MSE: 26.6884 - MAE: 4.1658\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 4997/20000 - Train Loss: 10.0404 - Test Loss: 26.6801 - MSE: 26.6801 - MAE: 4.1651\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 4998/20000 - Train Loss: 10.0365 - Test Loss: 26.6717 - MSE: 26.6717 - MAE: 4.1644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 4999/20000 - Train Loss: 10.0326 - Test Loss: 26.6633 - MSE: 26.6633 - MAE: 4.1637\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5000/20000 - Train Loss: 10.0287 - Test Loss: 26.6550 - MSE: 26.6550 - MAE: 4.1630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5001/20000 - Train Loss: 10.0248 - Test Loss: 26.6466 - MSE: 26.6466 - MAE: 4.1623\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5002/20000 - Train Loss: 10.0210 - Test Loss: 26.6383 - MSE: 26.6383 - MAE: 4.1615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5003/20000 - Train Loss: 10.0171 - Test Loss: 26.6299 - MSE: 26.6299 - MAE: 4.1608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5004/20000 - Train Loss: 10.0132 - Test Loss: 26.6216 - MSE: 26.6216 - MAE: 4.1601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5005/20000 - Train Loss: 10.0093 - Test Loss: 26.6132 - MSE: 26.6132 - MAE: 4.1594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5006/20000 - Train Loss: 10.0054 - Test Loss: 26.6049 - MSE: 26.6049 - MAE: 4.1587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5007/20000 - Train Loss: 10.0015 - Test Loss: 26.5965 - MSE: 26.5965 - MAE: 4.1580\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 5008/20000 - Train Loss: 9.9976 - Test Loss: 26.5882 - MSE: 26.5882 - MAE: 4.1573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5009/20000 - Train Loss: 9.9937 - Test Loss: 26.5798 - MSE: 26.5798 - MAE: 4.1566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5010/20000 - Train Loss: 9.9899 - Test Loss: 26.5715 - MSE: 26.5715 - MAE: 4.1559\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5011/20000 - Train Loss: 9.9860 - Test Loss: 26.5631 - MSE: 26.5631 - MAE: 4.1552\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5012/20000 - Train Loss: 9.9821 - Test Loss: 26.5547 - MSE: 26.5547 - MAE: 4.1545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5013/20000 - Train Loss: 9.9782 - Test Loss: 26.5464 - MSE: 26.5464 - MAE: 4.1537\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5014/20000 - Train Loss: 9.9743 - Test Loss: 26.5381 - MSE: 26.5381 - MAE: 4.1530\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5015/20000 - Train Loss: 9.9704 - Test Loss: 26.5297 - MSE: 26.5297 - MAE: 4.1523\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5016/20000 - Train Loss: 9.9665 - Test Loss: 26.5213 - MSE: 26.5213 - MAE: 4.1516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5017/20000 - Train Loss: 9.9627 - Test Loss: 26.5130 - MSE: 26.5130 - MAE: 4.1509\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5018/20000 - Train Loss: 9.9588 - Test Loss: 26.5046 - MSE: 26.5046 - MAE: 4.1502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5019/20000 - Train Loss: 9.9549 - Test Loss: 26.4962 - MSE: 26.4962 - MAE: 4.1495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5020/20000 - Train Loss: 9.9510 - Test Loss: 26.4879 - MSE: 26.4879 - MAE: 4.1488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5021/20000 - Train Loss: 9.9471 - Test Loss: 26.4795 - MSE: 26.4795 - MAE: 4.1481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5022/20000 - Train Loss: 9.9432 - Test Loss: 26.4712 - MSE: 26.4712 - MAE: 4.1473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5023/20000 - Train Loss: 9.9393 - Test Loss: 26.4628 - MSE: 26.4628 - MAE: 4.1466\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5024/20000 - Train Loss: 9.9354 - Test Loss: 26.4545 - MSE: 26.4545 - MAE: 4.1459\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5025/20000 - Train Loss: 9.9315 - Test Loss: 26.4461 - MSE: 26.4461 - MAE: 4.1452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5026/20000 - Train Loss: 9.9276 - Test Loss: 26.4377 - MSE: 26.4377 - MAE: 4.1445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5027/20000 - Train Loss: 9.9237 - Test Loss: 26.4293 - MSE: 26.4293 - MAE: 4.1438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5028/20000 - Train Loss: 9.9199 - Test Loss: 26.4210 - MSE: 26.4210 - MAE: 4.1431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5029/20000 - Train Loss: 9.9160 - Test Loss: 26.4126 - MSE: 26.4126 - MAE: 4.1424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5030/20000 - Train Loss: 9.9121 - Test Loss: 26.4043 - MSE: 26.4043 - MAE: 4.1416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5031/20000 - Train Loss: 9.9082 - Test Loss: 26.3959 - MSE: 26.3959 - MAE: 4.1409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5032/20000 - Train Loss: 9.9043 - Test Loss: 26.3876 - MSE: 26.3876 - MAE: 4.1402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5033/20000 - Train Loss: 9.9004 - Test Loss: 26.3792 - MSE: 26.3792 - MAE: 4.1395\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5034/20000 - Train Loss: 9.8965 - Test Loss: 26.3708 - MSE: 26.3708 - MAE: 4.1388\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5035/20000 - Train Loss: 9.8926 - Test Loss: 26.3625 - MSE: 26.3625 - MAE: 4.1381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5036/20000 - Train Loss: 9.8887 - Test Loss: 26.3541 - MSE: 26.3541 - MAE: 4.1373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5037/20000 - Train Loss: 9.8848 - Test Loss: 26.3457 - MSE: 26.3457 - MAE: 4.1366\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5038/20000 - Train Loss: 9.8809 - Test Loss: 26.3374 - MSE: 26.3374 - MAE: 4.1359\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5039/20000 - Train Loss: 9.8770 - Test Loss: 26.3290 - MSE: 26.3290 - MAE: 4.1352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5040/20000 - Train Loss: 9.8731 - Test Loss: 26.3207 - MSE: 26.3207 - MAE: 4.1345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5041/20000 - Train Loss: 9.8693 - Test Loss: 26.3123 - MSE: 26.3123 - MAE: 4.1338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5042/20000 - Train Loss: 9.8654 - Test Loss: 26.3039 - MSE: 26.3039 - MAE: 4.1331\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5043/20000 - Train Loss: 9.8615 - Test Loss: 26.2956 - MSE: 26.2956 - MAE: 4.1323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5044/20000 - Train Loss: 9.8576 - Test Loss: 26.2872 - MSE: 26.2872 - MAE: 4.1316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5045/20000 - Train Loss: 9.8537 - Test Loss: 26.2788 - MSE: 26.2788 - MAE: 4.1309\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5046/20000 - Train Loss: 9.8498 - Test Loss: 26.2704 - MSE: 26.2704 - MAE: 4.1302\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 5047/20000 - Train Loss: 9.8459 - Test Loss: 26.2621 - MSE: 26.2621 - MAE: 4.1295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5048/20000 - Train Loss: 9.8420 - Test Loss: 26.2537 - MSE: 26.2537 - MAE: 4.1288\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5049/20000 - Train Loss: 9.8381 - Test Loss: 26.2454 - MSE: 26.2454 - MAE: 4.1280\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5050/20000 - Train Loss: 9.8342 - Test Loss: 26.2370 - MSE: 26.2370 - MAE: 4.1273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5051/20000 - Train Loss: 9.8303 - Test Loss: 26.2287 - MSE: 26.2287 - MAE: 4.1266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5052/20000 - Train Loss: 9.8264 - Test Loss: 26.2203 - MSE: 26.2203 - MAE: 4.1259\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5053/20000 - Train Loss: 9.8225 - Test Loss: 26.2119 - MSE: 26.2119 - MAE: 4.1252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5054/20000 - Train Loss: 9.8186 - Test Loss: 26.2035 - MSE: 26.2035 - MAE: 4.1244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5055/20000 - Train Loss: 9.8147 - Test Loss: 26.1951 - MSE: 26.1951 - MAE: 4.1237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5056/20000 - Train Loss: 9.8108 - Test Loss: 26.1867 - MSE: 26.1867 - MAE: 4.1230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5057/20000 - Train Loss: 9.8069 - Test Loss: 26.1784 - MSE: 26.1784 - MAE: 4.1223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5058/20000 - Train Loss: 9.8030 - Test Loss: 26.1700 - MSE: 26.1700 - MAE: 4.1216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5059/20000 - Train Loss: 9.7991 - Test Loss: 26.1617 - MSE: 26.1617 - MAE: 4.1209\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5060/20000 - Train Loss: 9.7952 - Test Loss: 26.1533 - MSE: 26.1533 - MAE: 4.1201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5061/20000 - Train Loss: 9.7913 - Test Loss: 26.1449 - MSE: 26.1449 - MAE: 4.1194\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5062/20000 - Train Loss: 9.7874 - Test Loss: 26.1366 - MSE: 26.1366 - MAE: 4.1187\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5063/20000 - Train Loss: 9.7835 - Test Loss: 26.1282 - MSE: 26.1282 - MAE: 4.1180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5064/20000 - Train Loss: 9.7796 - Test Loss: 26.1198 - MSE: 26.1198 - MAE: 4.1173\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 5065/20000 - Train Loss: 9.7757 - Test Loss: 26.1115 - MSE: 26.1115 - MAE: 4.1165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5066/20000 - Train Loss: 9.7719 - Test Loss: 26.1030 - MSE: 26.1030 - MAE: 4.1158\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5067/20000 - Train Loss: 9.7679 - Test Loss: 26.0947 - MSE: 26.0947 - MAE: 4.1151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5068/20000 - Train Loss: 9.7640 - Test Loss: 26.0863 - MSE: 26.0863 - MAE: 4.1144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5069/20000 - Train Loss: 9.7602 - Test Loss: 26.0779 - MSE: 26.0780 - MAE: 4.1136\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5070/20000 - Train Loss: 9.7563 - Test Loss: 26.0696 - MSE: 26.0696 - MAE: 4.1129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5071/20000 - Train Loss: 9.7524 - Test Loss: 26.0612 - MSE: 26.0612 - MAE: 4.1122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5072/20000 - Train Loss: 9.7485 - Test Loss: 26.0529 - MSE: 26.0529 - MAE: 4.1115\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5073/20000 - Train Loss: 9.7446 - Test Loss: 26.0445 - MSE: 26.0445 - MAE: 4.1108\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5074/20000 - Train Loss: 9.7407 - Test Loss: 26.0361 - MSE: 26.0361 - MAE: 4.1100\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 5075/20000 - Train Loss: 9.7368 - Test Loss: 26.0277 - MSE: 26.0277 - MAE: 4.1093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5076/20000 - Train Loss: 9.7329 - Test Loss: 26.0193 - MSE: 26.0193 - MAE: 4.1086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5077/20000 - Train Loss: 9.7290 - Test Loss: 26.0110 - MSE: 26.0110 - MAE: 4.1079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5078/20000 - Train Loss: 9.7251 - Test Loss: 26.0026 - MSE: 26.0026 - MAE: 4.1071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5079/20000 - Train Loss: 9.7212 - Test Loss: 25.9942 - MSE: 25.9942 - MAE: 4.1064\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5080/20000 - Train Loss: 9.7173 - Test Loss: 25.9858 - MSE: 25.9858 - MAE: 4.1057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5081/20000 - Train Loss: 9.7134 - Test Loss: 25.9775 - MSE: 25.9775 - MAE: 4.1050\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 5082/20000 - Train Loss: 9.7095 - Test Loss: 25.9691 - MSE: 25.9691 - MAE: 4.1042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5083/20000 - Train Loss: 9.7056 - Test Loss: 25.9608 - MSE: 25.9608 - MAE: 4.1035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5084/20000 - Train Loss: 9.7016 - Test Loss: 25.9524 - MSE: 25.9524 - MAE: 4.1028\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5085/20000 - Train Loss: 9.6977 - Test Loss: 25.9440 - MSE: 25.9440 - MAE: 4.1021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5086/20000 - Train Loss: 9.6939 - Test Loss: 25.9356 - MSE: 25.9356 - MAE: 4.1014\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5087/20000 - Train Loss: 9.6899 - Test Loss: 25.9272 - MSE: 25.9272 - MAE: 4.1006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5088/20000 - Train Loss: 9.6861 - Test Loss: 25.9188 - MSE: 25.9188 - MAE: 4.0999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5089/20000 - Train Loss: 9.6821 - Test Loss: 25.9105 - MSE: 25.9105 - MAE: 4.0992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5090/20000 - Train Loss: 9.6782 - Test Loss: 25.9021 - MSE: 25.9021 - MAE: 4.0984\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5091/20000 - Train Loss: 9.6743 - Test Loss: 25.8937 - MSE: 25.8937 - MAE: 4.0977\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 5092/20000 - Train Loss: 9.6704 - Test Loss: 25.8854 - MSE: 25.8854 - MAE: 4.0970\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 5093/20000 - Train Loss: 9.6665 - Test Loss: 25.8770 - MSE: 25.8770 - MAE: 4.0963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5094/20000 - Train Loss: 9.6626 - Test Loss: 25.8686 - MSE: 25.8686 - MAE: 4.0956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5095/20000 - Train Loss: 9.6587 - Test Loss: 25.8603 - MSE: 25.8603 - MAE: 4.0948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5096/20000 - Train Loss: 9.6548 - Test Loss: 25.8519 - MSE: 25.8519 - MAE: 4.0941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5097/20000 - Train Loss: 9.6509 - Test Loss: 25.8435 - MSE: 25.8435 - MAE: 4.0934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5098/20000 - Train Loss: 9.6470 - Test Loss: 25.8351 - MSE: 25.8351 - MAE: 4.0926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5099/20000 - Train Loss: 9.6431 - Test Loss: 25.8267 - MSE: 25.8267 - MAE: 4.0919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5100/20000 - Train Loss: 9.6392 - Test Loss: 25.8183 - MSE: 25.8183 - MAE: 4.0912\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5101/20000 - Train Loss: 9.6353 - Test Loss: 25.8100 - MSE: 25.8100 - MAE: 4.0905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5102/20000 - Train Loss: 9.6314 - Test Loss: 25.8016 - MSE: 25.8016 - MAE: 4.0897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5103/20000 - Train Loss: 9.6275 - Test Loss: 25.7932 - MSE: 25.7932 - MAE: 4.0890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5104/20000 - Train Loss: 9.6236 - Test Loss: 25.7848 - MSE: 25.7848 - MAE: 4.0883\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5105/20000 - Train Loss: 9.6197 - Test Loss: 25.7765 - MSE: 25.7765 - MAE: 4.0875\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5106/20000 - Train Loss: 9.6158 - Test Loss: 25.7681 - MSE: 25.7681 - MAE: 4.0868\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5107/20000 - Train Loss: 9.6119 - Test Loss: 25.7597 - MSE: 25.7597 - MAE: 4.0861\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5108/20000 - Train Loss: 9.6080 - Test Loss: 25.7514 - MSE: 25.7514 - MAE: 4.0854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5109/20000 - Train Loss: 9.6041 - Test Loss: 25.7430 - MSE: 25.7430 - MAE: 4.0846\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5110/20000 - Train Loss: 9.6002 - Test Loss: 25.7346 - MSE: 25.7346 - MAE: 4.0839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5111/20000 - Train Loss: 9.5963 - Test Loss: 25.7262 - MSE: 25.7262 - MAE: 4.0832\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5112/20000 - Train Loss: 9.5924 - Test Loss: 25.7178 - MSE: 25.7178 - MAE: 4.0824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5113/20000 - Train Loss: 9.5885 - Test Loss: 25.7094 - MSE: 25.7094 - MAE: 4.0817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5114/20000 - Train Loss: 9.5846 - Test Loss: 25.7011 - MSE: 25.7011 - MAE: 4.0810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5115/20000 - Train Loss: 9.5806 - Test Loss: 25.6927 - MSE: 25.6927 - MAE: 4.0803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5116/20000 - Train Loss: 9.5767 - Test Loss: 25.6843 - MSE: 25.6843 - MAE: 4.0795\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 5117/20000 - Train Loss: 9.5728 - Test Loss: 25.6760 - MSE: 25.6760 - MAE: 4.0788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5118/20000 - Train Loss: 9.5689 - Test Loss: 25.6676 - MSE: 25.6676 - MAE: 4.0781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5119/20000 - Train Loss: 9.5650 - Test Loss: 25.6592 - MSE: 25.6592 - MAE: 4.0773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5120/20000 - Train Loss: 9.5611 - Test Loss: 25.6508 - MSE: 25.6508 - MAE: 4.0766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5121/20000 - Train Loss: 9.5572 - Test Loss: 25.6424 - MSE: 25.6424 - MAE: 4.0759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5122/20000 - Train Loss: 9.5533 - Test Loss: 25.6340 - MSE: 25.6340 - MAE: 4.0751\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5123/20000 - Train Loss: 9.5494 - Test Loss: 25.6257 - MSE: 25.6257 - MAE: 4.0744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5124/20000 - Train Loss: 9.5455 - Test Loss: 25.6173 - MSE: 25.6173 - MAE: 4.0737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5125/20000 - Train Loss: 9.5416 - Test Loss: 25.6089 - MSE: 25.6089 - MAE: 4.0729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5126/20000 - Train Loss: 9.5377 - Test Loss: 25.6005 - MSE: 25.6005 - MAE: 4.0722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5127/20000 - Train Loss: 9.5338 - Test Loss: 25.5921 - MSE: 25.5921 - MAE: 4.0715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5128/20000 - Train Loss: 9.5299 - Test Loss: 25.5837 - MSE: 25.5837 - MAE: 4.0707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5129/20000 - Train Loss: 9.5260 - Test Loss: 25.5754 - MSE: 25.5754 - MAE: 4.0700\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5130/20000 - Train Loss: 9.5221 - Test Loss: 25.5670 - MSE: 25.5670 - MAE: 4.0693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5131/20000 - Train Loss: 9.5181 - Test Loss: 25.5586 - MSE: 25.5586 - MAE: 4.0685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5132/20000 - Train Loss: 9.5142 - Test Loss: 25.5502 - MSE: 25.5502 - MAE: 4.0678\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5133/20000 - Train Loss: 9.5103 - Test Loss: 25.5419 - MSE: 25.5419 - MAE: 4.0671\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5134/20000 - Train Loss: 9.5064 - Test Loss: 25.5335 - MSE: 25.5335 - MAE: 4.0663\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5135/20000 - Train Loss: 9.5025 - Test Loss: 25.5251 - MSE: 25.5251 - MAE: 4.0656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5136/20000 - Train Loss: 9.4986 - Test Loss: 25.5167 - MSE: 25.5167 - MAE: 4.0649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5137/20000 - Train Loss: 9.4947 - Test Loss: 25.5083 - MSE: 25.5083 - MAE: 4.0641\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 5138/20000 - Train Loss: 9.4908 - Test Loss: 25.4999 - MSE: 25.4999 - MAE: 4.0634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5139/20000 - Train Loss: 9.4869 - Test Loss: 25.4916 - MSE: 25.4916 - MAE: 4.0627\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 5140/20000 - Train Loss: 9.4830 - Test Loss: 25.4832 - MSE: 25.4832 - MAE: 4.0619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5141/20000 - Train Loss: 9.4791 - Test Loss: 25.4748 - MSE: 25.4748 - MAE: 4.0612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5142/20000 - Train Loss: 9.4752 - Test Loss: 25.4664 - MSE: 25.4664 - MAE: 4.0605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5143/20000 - Train Loss: 9.4713 - Test Loss: 25.4580 - MSE: 25.4580 - MAE: 4.0597\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 5144/20000 - Train Loss: 9.4674 - Test Loss: 25.4497 - MSE: 25.4497 - MAE: 4.0590\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 5145/20000 - Train Loss: 9.4634 - Test Loss: 25.4413 - MSE: 25.4413 - MAE: 4.0582\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5146/20000 - Train Loss: 9.4595 - Test Loss: 25.4329 - MSE: 25.4329 - MAE: 4.0575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5147/20000 - Train Loss: 9.4556 - Test Loss: 25.4245 - MSE: 25.4245 - MAE: 4.0568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5148/20000 - Train Loss: 9.4517 - Test Loss: 25.4162 - MSE: 25.4162 - MAE: 4.0561\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5149/20000 - Train Loss: 9.4478 - Test Loss: 25.4078 - MSE: 25.4078 - MAE: 4.0554\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5150/20000 - Train Loss: 9.4439 - Test Loss: 25.3994 - MSE: 25.3994 - MAE: 4.0548\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5151/20000 - Train Loss: 9.4400 - Test Loss: 25.3910 - MSE: 25.3910 - MAE: 4.0541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5152/20000 - Train Loss: 9.4361 - Test Loss: 25.3826 - MSE: 25.3826 - MAE: 4.0534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5153/20000 - Train Loss: 9.4322 - Test Loss: 25.3742 - MSE: 25.3742 - MAE: 4.0527\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5154/20000 - Train Loss: 9.4283 - Test Loss: 25.3658 - MSE: 25.3658 - MAE: 4.0520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5155/20000 - Train Loss: 9.4244 - Test Loss: 25.3575 - MSE: 25.3575 - MAE: 4.0513\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5156/20000 - Train Loss: 9.4204 - Test Loss: 25.3491 - MSE: 25.3491 - MAE: 4.0506\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5157/20000 - Train Loss: 9.4165 - Test Loss: 25.3407 - MSE: 25.3407 - MAE: 4.0499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5158/20000 - Train Loss: 9.4126 - Test Loss: 25.3324 - MSE: 25.3324 - MAE: 4.0492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5159/20000 - Train Loss: 9.4087 - Test Loss: 25.3240 - MSE: 25.3240 - MAE: 4.0485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5160/20000 - Train Loss: 9.4048 - Test Loss: 25.3156 - MSE: 25.3156 - MAE: 4.0478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5161/20000 - Train Loss: 9.4009 - Test Loss: 25.3072 - MSE: 25.3072 - MAE: 4.0471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5162/20000 - Train Loss: 9.3970 - Test Loss: 25.2988 - MSE: 25.2988 - MAE: 4.0464\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5163/20000 - Train Loss: 9.3931 - Test Loss: 25.2904 - MSE: 25.2904 - MAE: 4.0457\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5164/20000 - Train Loss: 9.3892 - Test Loss: 25.2821 - MSE: 25.2821 - MAE: 4.0450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5165/20000 - Train Loss: 9.3853 - Test Loss: 25.2736 - MSE: 25.2736 - MAE: 4.0443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5166/20000 - Train Loss: 9.3813 - Test Loss: 25.2653 - MSE: 25.2653 - MAE: 4.0436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5167/20000 - Train Loss: 9.3774 - Test Loss: 25.2568 - MSE: 25.2568 - MAE: 4.0429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5168/20000 - Train Loss: 9.3735 - Test Loss: 25.2485 - MSE: 25.2485 - MAE: 4.0422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5169/20000 - Train Loss: 9.3696 - Test Loss: 25.2401 - MSE: 25.2401 - MAE: 4.0415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5170/20000 - Train Loss: 9.3657 - Test Loss: 25.2317 - MSE: 25.2317 - MAE: 4.0409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5171/20000 - Train Loss: 9.3618 - Test Loss: 25.2234 - MSE: 25.2234 - MAE: 4.0402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5172/20000 - Train Loss: 9.3579 - Test Loss: 25.2150 - MSE: 25.2150 - MAE: 4.0395\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5173/20000 - Train Loss: 9.3540 - Test Loss: 25.2067 - MSE: 25.2067 - MAE: 4.0388\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5174/20000 - Train Loss: 9.3501 - Test Loss: 25.1982 - MSE: 25.1982 - MAE: 4.0381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5175/20000 - Train Loss: 9.3462 - Test Loss: 25.1898 - MSE: 25.1898 - MAE: 4.0374\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5176/20000 - Train Loss: 9.3422 - Test Loss: 25.1814 - MSE: 25.1814 - MAE: 4.0367\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5177/20000 - Train Loss: 9.3383 - Test Loss: 25.1731 - MSE: 25.1731 - MAE: 4.0360\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5178/20000 - Train Loss: 9.3344 - Test Loss: 25.1646 - MSE: 25.1646 - MAE: 4.0353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5179/20000 - Train Loss: 9.3305 - Test Loss: 25.1563 - MSE: 25.1563 - MAE: 4.0346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5180/20000 - Train Loss: 9.3266 - Test Loss: 25.1479 - MSE: 25.1479 - MAE: 4.0339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5181/20000 - Train Loss: 9.3227 - Test Loss: 25.1396 - MSE: 25.1396 - MAE: 4.0332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5182/20000 - Train Loss: 9.3188 - Test Loss: 25.1312 - MSE: 25.1312 - MAE: 4.0325\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5183/20000 - Train Loss: 9.3149 - Test Loss: 25.1228 - MSE: 25.1228 - MAE: 4.0318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5184/20000 - Train Loss: 9.3110 - Test Loss: 25.1144 - MSE: 25.1144 - MAE: 4.0311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5185/20000 - Train Loss: 9.3070 - Test Loss: 25.1061 - MSE: 25.1061 - MAE: 4.0304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5186/20000 - Train Loss: 9.3031 - Test Loss: 25.0976 - MSE: 25.0976 - MAE: 4.0297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5187/20000 - Train Loss: 9.2992 - Test Loss: 25.0892 - MSE: 25.0892 - MAE: 4.0290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5188/20000 - Train Loss: 9.2953 - Test Loss: 25.0809 - MSE: 25.0809 - MAE: 4.0283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5189/20000 - Train Loss: 9.2914 - Test Loss: 25.0725 - MSE: 25.0725 - MAE: 4.0276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5190/20000 - Train Loss: 9.2875 - Test Loss: 25.0641 - MSE: 25.0641 - MAE: 4.0269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5191/20000 - Train Loss: 9.2836 - Test Loss: 25.0557 - MSE: 25.0557 - MAE: 4.0262\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5192/20000 - Train Loss: 9.2797 - Test Loss: 25.0474 - MSE: 25.0474 - MAE: 4.0255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5193/20000 - Train Loss: 9.2758 - Test Loss: 25.0390 - MSE: 25.0390 - MAE: 4.0248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5194/20000 - Train Loss: 9.2718 - Test Loss: 25.0306 - MSE: 25.0306 - MAE: 4.0241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5195/20000 - Train Loss: 9.2679 - Test Loss: 25.0222 - MSE: 25.0222 - MAE: 4.0234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5196/20000 - Train Loss: 9.2640 - Test Loss: 25.0138 - MSE: 25.0138 - MAE: 4.0227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5197/20000 - Train Loss: 9.2601 - Test Loss: 25.0054 - MSE: 25.0054 - MAE: 4.0220\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5198/20000 - Train Loss: 9.2562 - Test Loss: 24.9970 - MSE: 24.9970 - MAE: 4.0213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5199/20000 - Train Loss: 9.2523 - Test Loss: 24.9887 - MSE: 24.9887 - MAE: 4.0206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5200/20000 - Train Loss: 9.2484 - Test Loss: 24.9803 - MSE: 24.9803 - MAE: 4.0199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5201/20000 - Train Loss: 9.2444 - Test Loss: 24.9719 - MSE: 24.9719 - MAE: 4.0192\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5202/20000 - Train Loss: 9.2405 - Test Loss: 24.9635 - MSE: 24.9635 - MAE: 4.0185\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5203/20000 - Train Loss: 9.2366 - Test Loss: 24.9552 - MSE: 24.9552 - MAE: 4.0178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5204/20000 - Train Loss: 9.2327 - Test Loss: 24.9468 - MSE: 24.9468 - MAE: 4.0170\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5205/20000 - Train Loss: 9.2288 - Test Loss: 24.9384 - MSE: 24.9384 - MAE: 4.0163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5206/20000 - Train Loss: 9.2249 - Test Loss: 24.9300 - MSE: 24.9300 - MAE: 4.0156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5207/20000 - Train Loss: 9.2210 - Test Loss: 24.9216 - MSE: 24.9216 - MAE: 4.0149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5208/20000 - Train Loss: 9.2171 - Test Loss: 24.9132 - MSE: 24.9132 - MAE: 4.0142\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5209/20000 - Train Loss: 9.2132 - Test Loss: 24.9049 - MSE: 24.9049 - MAE: 4.0135\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5210/20000 - Train Loss: 9.2092 - Test Loss: 24.8965 - MSE: 24.8965 - MAE: 4.0128\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5211/20000 - Train Loss: 9.2053 - Test Loss: 24.8881 - MSE: 24.8881 - MAE: 4.0121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5212/20000 - Train Loss: 9.2014 - Test Loss: 24.8797 - MSE: 24.8797 - MAE: 4.0114\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5213/20000 - Train Loss: 9.1975 - Test Loss: 24.8713 - MSE: 24.8713 - MAE: 4.0107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5214/20000 - Train Loss: 9.1936 - Test Loss: 24.8629 - MSE: 24.8629 - MAE: 4.0100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5215/20000 - Train Loss: 9.1897 - Test Loss: 24.8546 - MSE: 24.8546 - MAE: 4.0093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5216/20000 - Train Loss: 9.1858 - Test Loss: 24.8462 - MSE: 24.8462 - MAE: 4.0086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5217/20000 - Train Loss: 9.1818 - Test Loss: 24.8378 - MSE: 24.8378 - MAE: 4.0079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5218/20000 - Train Loss: 9.1779 - Test Loss: 24.8295 - MSE: 24.8295 - MAE: 4.0072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5219/20000 - Train Loss: 9.1740 - Test Loss: 24.8211 - MSE: 24.8211 - MAE: 4.0065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5220/20000 - Train Loss: 9.1701 - Test Loss: 24.8127 - MSE: 24.8127 - MAE: 4.0058\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5221/20000 - Train Loss: 9.1662 - Test Loss: 24.8043 - MSE: 24.8043 - MAE: 4.0051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5222/20000 - Train Loss: 9.1623 - Test Loss: 24.7959 - MSE: 24.7959 - MAE: 4.0044\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5223/20000 - Train Loss: 9.1584 - Test Loss: 24.7875 - MSE: 24.7875 - MAE: 4.0036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5224/20000 - Train Loss: 9.1545 - Test Loss: 24.7792 - MSE: 24.7792 - MAE: 4.0029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5225/20000 - Train Loss: 9.1506 - Test Loss: 24.7708 - MSE: 24.7708 - MAE: 4.0022\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5226/20000 - Train Loss: 9.1466 - Test Loss: 24.7624 - MSE: 24.7624 - MAE: 4.0015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5227/20000 - Train Loss: 9.1427 - Test Loss: 24.7541 - MSE: 24.7541 - MAE: 4.0008\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5228/20000 - Train Loss: 9.1388 - Test Loss: 24.7457 - MSE: 24.7457 - MAE: 4.0001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5229/20000 - Train Loss: 9.1349 - Test Loss: 24.7373 - MSE: 24.7373 - MAE: 3.9994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5230/20000 - Train Loss: 9.1310 - Test Loss: 24.7289 - MSE: 24.7289 - MAE: 3.9987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5231/20000 - Train Loss: 9.1271 - Test Loss: 24.7205 - MSE: 24.7205 - MAE: 3.9980\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5232/20000 - Train Loss: 9.1232 - Test Loss: 24.7121 - MSE: 24.7121 - MAE: 3.9973\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5233/20000 - Train Loss: 9.1192 - Test Loss: 24.7038 - MSE: 24.7038 - MAE: 3.9966\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 5234/20000 - Train Loss: 9.1153 - Test Loss: 24.6954 - MSE: 24.6954 - MAE: 3.9959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5235/20000 - Train Loss: 9.1114 - Test Loss: 24.6871 - MSE: 24.6871 - MAE: 3.9952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5236/20000 - Train Loss: 9.1075 - Test Loss: 24.6787 - MSE: 24.6787 - MAE: 3.9945\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5237/20000 - Train Loss: 9.1036 - Test Loss: 24.6703 - MSE: 24.6703 - MAE: 3.9937\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5238/20000 - Train Loss: 9.0997 - Test Loss: 24.6619 - MSE: 24.6619 - MAE: 3.9930\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5239/20000 - Train Loss: 9.0958 - Test Loss: 24.6535 - MSE: 24.6535 - MAE: 3.9923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5240/20000 - Train Loss: 9.0919 - Test Loss: 24.6451 - MSE: 24.6451 - MAE: 3.9916\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5241/20000 - Train Loss: 9.0879 - Test Loss: 24.6368 - MSE: 24.6368 - MAE: 3.9909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5242/20000 - Train Loss: 9.0840 - Test Loss: 24.6284 - MSE: 24.6284 - MAE: 3.9902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5243/20000 - Train Loss: 9.0801 - Test Loss: 24.6201 - MSE: 24.6201 - MAE: 3.9895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5244/20000 - Train Loss: 9.0762 - Test Loss: 24.6117 - MSE: 24.6117 - MAE: 3.9888\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5245/20000 - Train Loss: 9.0723 - Test Loss: 24.6033 - MSE: 24.6033 - MAE: 3.9881\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5246/20000 - Train Loss: 9.0684 - Test Loss: 24.5949 - MSE: 24.5949 - MAE: 3.9874\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5247/20000 - Train Loss: 9.0645 - Test Loss: 24.5865 - MSE: 24.5865 - MAE: 3.9866\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 5248/20000 - Train Loss: 9.0606 - Test Loss: 24.5781 - MSE: 24.5781 - MAE: 3.9859\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5249/20000 - Train Loss: 9.0566 - Test Loss: 24.5698 - MSE: 24.5698 - MAE: 3.9852\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5250/20000 - Train Loss: 9.0527 - Test Loss: 24.5614 - MSE: 24.5614 - MAE: 3.9845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5251/20000 - Train Loss: 9.0488 - Test Loss: 24.5531 - MSE: 24.5531 - MAE: 3.9838\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 5252/20000 - Train Loss: 9.0449 - Test Loss: 24.5446 - MSE: 24.5446 - MAE: 3.9831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5253/20000 - Train Loss: 9.0410 - Test Loss: 24.5363 - MSE: 24.5363 - MAE: 3.9824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5254/20000 - Train Loss: 9.0371 - Test Loss: 24.5279 - MSE: 24.5279 - MAE: 3.9817\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5255/20000 - Train Loss: 9.0332 - Test Loss: 24.5195 - MSE: 24.5195 - MAE: 3.9809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5256/20000 - Train Loss: 9.0292 - Test Loss: 24.5111 - MSE: 24.5111 - MAE: 3.9802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5257/20000 - Train Loss: 9.0253 - Test Loss: 24.5027 - MSE: 24.5027 - MAE: 3.9795\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 5258/20000 - Train Loss: 9.0214 - Test Loss: 24.4944 - MSE: 24.4944 - MAE: 3.9788\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5259/20000 - Train Loss: 9.0175 - Test Loss: 24.4860 - MSE: 24.4860 - MAE: 3.9781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5260/20000 - Train Loss: 9.0136 - Test Loss: 24.4777 - MSE: 24.4777 - MAE: 3.9774\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5261/20000 - Train Loss: 9.0097 - Test Loss: 24.4693 - MSE: 24.4693 - MAE: 3.9767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5262/20000 - Train Loss: 9.0058 - Test Loss: 24.4609 - MSE: 24.4609 - MAE: 3.9760\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5263/20000 - Train Loss: 9.0019 - Test Loss: 24.4526 - MSE: 24.4526 - MAE: 3.9752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5264/20000 - Train Loss: 8.9979 - Test Loss: 24.4442 - MSE: 24.4442 - MAE: 3.9745\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 5265/20000 - Train Loss: 8.9940 - Test Loss: 24.4358 - MSE: 24.4358 - MAE: 3.9738\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5266/20000 - Train Loss: 8.9901 - Test Loss: 24.4274 - MSE: 24.4274 - MAE: 3.9731\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5267/20000 - Train Loss: 8.9862 - Test Loss: 24.4191 - MSE: 24.4191 - MAE: 3.9724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5268/20000 - Train Loss: 8.9823 - Test Loss: 24.4106 - MSE: 24.4106 - MAE: 3.9717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5269/20000 - Train Loss: 8.9784 - Test Loss: 24.4023 - MSE: 24.4023 - MAE: 3.9710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5270/20000 - Train Loss: 8.9745 - Test Loss: 24.3939 - MSE: 24.3939 - MAE: 3.9702\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5271/20000 - Train Loss: 8.9706 - Test Loss: 24.3855 - MSE: 24.3855 - MAE: 3.9695\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5272/20000 - Train Loss: 8.9666 - Test Loss: 24.3772 - MSE: 24.3772 - MAE: 3.9688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5273/20000 - Train Loss: 8.9627 - Test Loss: 24.3688 - MSE: 24.3688 - MAE: 3.9681\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5274/20000 - Train Loss: 8.9588 - Test Loss: 24.3604 - MSE: 24.3604 - MAE: 3.9674\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5275/20000 - Train Loss: 8.9549 - Test Loss: 24.3521 - MSE: 24.3521 - MAE: 3.9667\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5276/20000 - Train Loss: 8.9510 - Test Loss: 24.3437 - MSE: 24.3437 - MAE: 3.9659\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5277/20000 - Train Loss: 8.9471 - Test Loss: 24.3353 - MSE: 24.3353 - MAE: 3.9652\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5278/20000 - Train Loss: 8.9432 - Test Loss: 24.3270 - MSE: 24.3270 - MAE: 3.9645\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5279/20000 - Train Loss: 8.9393 - Test Loss: 24.3187 - MSE: 24.3187 - MAE: 3.9638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5280/20000 - Train Loss: 8.9353 - Test Loss: 24.3103 - MSE: 24.3103 - MAE: 3.9631\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5281/20000 - Train Loss: 8.9314 - Test Loss: 24.3019 - MSE: 24.3019 - MAE: 3.9624\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5282/20000 - Train Loss: 8.9275 - Test Loss: 24.2935 - MSE: 24.2935 - MAE: 3.9616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5283/20000 - Train Loss: 8.9236 - Test Loss: 24.2851 - MSE: 24.2851 - MAE: 3.9609\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5284/20000 - Train Loss: 8.9197 - Test Loss: 24.2767 - MSE: 24.2767 - MAE: 3.9602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5285/20000 - Train Loss: 8.9158 - Test Loss: 24.2684 - MSE: 24.2684 - MAE: 3.9595\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5286/20000 - Train Loss: 8.9119 - Test Loss: 24.2600 - MSE: 24.2600 - MAE: 3.9588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5287/20000 - Train Loss: 8.9080 - Test Loss: 24.2517 - MSE: 24.2517 - MAE: 3.9581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5288/20000 - Train Loss: 8.9040 - Test Loss: 24.2433 - MSE: 24.2433 - MAE: 3.9573\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5289/20000 - Train Loss: 8.9001 - Test Loss: 24.2350 - MSE: 24.2350 - MAE: 3.9566\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5290/20000 - Train Loss: 8.8962 - Test Loss: 24.2266 - MSE: 24.2266 - MAE: 3.9559\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5291/20000 - Train Loss: 8.8923 - Test Loss: 24.2182 - MSE: 24.2182 - MAE: 3.9552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5292/20000 - Train Loss: 8.8884 - Test Loss: 24.2098 - MSE: 24.2098 - MAE: 3.9545\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 5293/20000 - Train Loss: 8.8845 - Test Loss: 24.2015 - MSE: 24.2015 - MAE: 3.9537\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5294/20000 - Train Loss: 8.8806 - Test Loss: 24.1931 - MSE: 24.1931 - MAE: 3.9530\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5295/20000 - Train Loss: 8.8767 - Test Loss: 24.1848 - MSE: 24.1848 - MAE: 3.9523\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5296/20000 - Train Loss: 8.8728 - Test Loss: 24.1764 - MSE: 24.1764 - MAE: 3.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5297/20000 - Train Loss: 8.8688 - Test Loss: 24.1680 - MSE: 24.1680 - MAE: 3.9509\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Epoch 5298/20000 - Train Loss: 8.8649 - Test Loss: 24.1597 - MSE: 24.1597 - MAE: 3.9501\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5299/20000 - Train Loss: 8.8610 - Test Loss: 24.1513 - MSE: 24.1513 - MAE: 3.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5300/20000 - Train Loss: 8.8571 - Test Loss: 24.1430 - MSE: 24.1430 - MAE: 3.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5301/20000 - Train Loss: 8.8532 - Test Loss: 24.1345 - MSE: 24.1345 - MAE: 3.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5302/20000 - Train Loss: 8.8493 - Test Loss: 24.1262 - MSE: 24.1262 - MAE: 3.9473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5303/20000 - Train Loss: 8.8454 - Test Loss: 24.1178 - MSE: 24.1178 - MAE: 3.9465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5304/20000 - Train Loss: 8.8415 - Test Loss: 24.1095 - MSE: 24.1095 - MAE: 3.9458\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5305/20000 - Train Loss: 8.8376 - Test Loss: 24.1011 - MSE: 24.1011 - MAE: 3.9451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5306/20000 - Train Loss: 8.8336 - Test Loss: 24.0927 - MSE: 24.0927 - MAE: 3.9444\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5307/20000 - Train Loss: 8.8297 - Test Loss: 24.0844 - MSE: 24.0844 - MAE: 3.9437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5308/20000 - Train Loss: 8.8258 - Test Loss: 24.0760 - MSE: 24.0760 - MAE: 3.9429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5309/20000 - Train Loss: 8.8219 - Test Loss: 24.0676 - MSE: 24.0676 - MAE: 3.9422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5310/20000 - Train Loss: 8.8180 - Test Loss: 24.0593 - MSE: 24.0593 - MAE: 3.9415\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 5311/20000 - Train Loss: 8.8141 - Test Loss: 24.0509 - MSE: 24.0509 - MAE: 3.9408\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5312/20000 - Train Loss: 8.8102 - Test Loss: 24.0426 - MSE: 24.0426 - MAE: 3.9400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5313/20000 - Train Loss: 8.8063 - Test Loss: 24.0342 - MSE: 24.0342 - MAE: 3.9393\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5314/20000 - Train Loss: 8.8024 - Test Loss: 24.0259 - MSE: 24.0259 - MAE: 3.9386\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 5315/20000 - Train Loss: 8.7984 - Test Loss: 24.0175 - MSE: 24.0175 - MAE: 3.9379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5316/20000 - Train Loss: 8.7945 - Test Loss: 24.0092 - MSE: 24.0092 - MAE: 3.9372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5317/20000 - Train Loss: 8.7906 - Test Loss: 24.0008 - MSE: 24.0008 - MAE: 3.9364\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5318/20000 - Train Loss: 8.7867 - Test Loss: 23.9925 - MSE: 23.9925 - MAE: 3.9357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5319/20000 - Train Loss: 8.7828 - Test Loss: 23.9841 - MSE: 23.9841 - MAE: 3.9350\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5320/20000 - Train Loss: 8.7789 - Test Loss: 23.9757 - MSE: 23.9757 - MAE: 3.9343\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5321/20000 - Train Loss: 8.7750 - Test Loss: 23.9674 - MSE: 23.9674 - MAE: 3.9335\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5322/20000 - Train Loss: 8.7711 - Test Loss: 23.9590 - MSE: 23.9590 - MAE: 3.9328\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5323/20000 - Train Loss: 8.7672 - Test Loss: 23.9506 - MSE: 23.9506 - MAE: 3.9321\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5324/20000 - Train Loss: 8.7633 - Test Loss: 23.9423 - MSE: 23.9423 - MAE: 3.9314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5325/20000 - Train Loss: 8.7593 - Test Loss: 23.9339 - MSE: 23.9339 - MAE: 3.9306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5326/20000 - Train Loss: 8.7554 - Test Loss: 23.9256 - MSE: 23.9256 - MAE: 3.9299\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5327/20000 - Train Loss: 8.7515 - Test Loss: 23.9173 - MSE: 23.9173 - MAE: 3.9292\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5328/20000 - Train Loss: 8.7476 - Test Loss: 23.9089 - MSE: 23.9089 - MAE: 3.9285\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5329/20000 - Train Loss: 8.7437 - Test Loss: 23.9005 - MSE: 23.9005 - MAE: 3.9277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5330/20000 - Train Loss: 8.7398 - Test Loss: 23.8922 - MSE: 23.8922 - MAE: 3.9270\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5331/20000 - Train Loss: 8.7359 - Test Loss: 23.8838 - MSE: 23.8838 - MAE: 3.9263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5332/20000 - Train Loss: 8.7320 - Test Loss: 23.8755 - MSE: 23.8755 - MAE: 3.9256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5333/20000 - Train Loss: 8.7281 - Test Loss: 23.8671 - MSE: 23.8671 - MAE: 3.9248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5334/20000 - Train Loss: 8.7242 - Test Loss: 23.8588 - MSE: 23.8588 - MAE: 3.9241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5335/20000 - Train Loss: 8.7203 - Test Loss: 23.8504 - MSE: 23.8504 - MAE: 3.9234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5336/20000 - Train Loss: 8.7164 - Test Loss: 23.8421 - MSE: 23.8421 - MAE: 3.9227\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5337/20000 - Train Loss: 8.7124 - Test Loss: 23.8337 - MSE: 23.8337 - MAE: 3.9219\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5338/20000 - Train Loss: 8.7085 - Test Loss: 23.8253 - MSE: 23.8253 - MAE: 3.9212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5339/20000 - Train Loss: 8.7046 - Test Loss: 23.8170 - MSE: 23.8170 - MAE: 3.9205\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5340/20000 - Train Loss: 8.7007 - Test Loss: 23.8087 - MSE: 23.8087 - MAE: 3.9197\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5341/20000 - Train Loss: 8.6968 - Test Loss: 23.8003 - MSE: 23.8003 - MAE: 3.9190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5342/20000 - Train Loss: 8.6929 - Test Loss: 23.7920 - MSE: 23.7920 - MAE: 3.9183\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5343/20000 - Train Loss: 8.6890 - Test Loss: 23.7837 - MSE: 23.7837 - MAE: 3.9176\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5344/20000 - Train Loss: 8.6851 - Test Loss: 23.7753 - MSE: 23.7753 - MAE: 3.9168\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5345/20000 - Train Loss: 8.6812 - Test Loss: 23.7670 - MSE: 23.7670 - MAE: 3.9161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5346/20000 - Train Loss: 8.6773 - Test Loss: 23.7586 - MSE: 23.7586 - MAE: 3.9154\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5347/20000 - Train Loss: 8.6734 - Test Loss: 23.7502 - MSE: 23.7502 - MAE: 3.9146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5348/20000 - Train Loss: 8.6695 - Test Loss: 23.7419 - MSE: 23.7419 - MAE: 3.9139\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5349/20000 - Train Loss: 8.6655 - Test Loss: 23.7335 - MSE: 23.7335 - MAE: 3.9132\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5350/20000 - Train Loss: 8.6616 - Test Loss: 23.7251 - MSE: 23.7251 - MAE: 3.9125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5351/20000 - Train Loss: 8.6577 - Test Loss: 23.7168 - MSE: 23.7168 - MAE: 3.9117\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5352/20000 - Train Loss: 8.6538 - Test Loss: 23.7085 - MSE: 23.7085 - MAE: 3.9110\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5353/20000 - Train Loss: 8.6499 - Test Loss: 23.7001 - MSE: 23.7001 - MAE: 3.9103\n",
      "2/2 [==============================] - 0s 37ms/step\n",
      "Epoch 5354/20000 - Train Loss: 8.6460 - Test Loss: 23.6918 - MSE: 23.6918 - MAE: 3.9095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5355/20000 - Train Loss: 8.6421 - Test Loss: 23.6835 - MSE: 23.6835 - MAE: 3.9088\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5356/20000 - Train Loss: 8.6382 - Test Loss: 23.6752 - MSE: 23.6752 - MAE: 3.9081\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5357/20000 - Train Loss: 8.6343 - Test Loss: 23.6669 - MSE: 23.6668 - MAE: 3.9074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5358/20000 - Train Loss: 8.6304 - Test Loss: 23.6585 - MSE: 23.6585 - MAE: 3.9066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5359/20000 - Train Loss: 8.6265 - Test Loss: 23.6501 - MSE: 23.6501 - MAE: 3.9059\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5360/20000 - Train Loss: 8.6226 - Test Loss: 23.6417 - MSE: 23.6417 - MAE: 3.9052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5361/20000 - Train Loss: 8.6187 - Test Loss: 23.6334 - MSE: 23.6334 - MAE: 3.9044\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5362/20000 - Train Loss: 8.6148 - Test Loss: 23.6250 - MSE: 23.6250 - MAE: 3.9037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5363/20000 - Train Loss: 8.6109 - Test Loss: 23.6167 - MSE: 23.6167 - MAE: 3.9030\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5364/20000 - Train Loss: 8.6070 - Test Loss: 23.6084 - MSE: 23.6084 - MAE: 3.9022\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5365/20000 - Train Loss: 8.6030 - Test Loss: 23.6000 - MSE: 23.6000 - MAE: 3.9015\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5366/20000 - Train Loss: 8.5991 - Test Loss: 23.5917 - MSE: 23.5917 - MAE: 3.9008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5367/20000 - Train Loss: 8.5952 - Test Loss: 23.5834 - MSE: 23.5834 - MAE: 3.9000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5368/20000 - Train Loss: 8.5913 - Test Loss: 23.5750 - MSE: 23.5750 - MAE: 3.8993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5369/20000 - Train Loss: 8.5874 - Test Loss: 23.5667 - MSE: 23.5667 - MAE: 3.8986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5370/20000 - Train Loss: 8.5835 - Test Loss: 23.5584 - MSE: 23.5584 - MAE: 3.8978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5371/20000 - Train Loss: 8.5796 - Test Loss: 23.5500 - MSE: 23.5500 - MAE: 3.8971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5372/20000 - Train Loss: 8.5757 - Test Loss: 23.5417 - MSE: 23.5417 - MAE: 3.8964\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5373/20000 - Train Loss: 8.5718 - Test Loss: 23.5333 - MSE: 23.5333 - MAE: 3.8956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5374/20000 - Train Loss: 8.5679 - Test Loss: 23.5250 - MSE: 23.5250 - MAE: 3.8949\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5375/20000 - Train Loss: 8.5640 - Test Loss: 23.5166 - MSE: 23.5166 - MAE: 3.8942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5376/20000 - Train Loss: 8.5601 - Test Loss: 23.5083 - MSE: 23.5083 - MAE: 3.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5377/20000 - Train Loss: 8.5562 - Test Loss: 23.5000 - MSE: 23.5000 - MAE: 3.8927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5378/20000 - Train Loss: 8.5523 - Test Loss: 23.4917 - MSE: 23.4917 - MAE: 3.8920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5379/20000 - Train Loss: 8.5484 - Test Loss: 23.4834 - MSE: 23.4834 - MAE: 3.8912\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 5380/20000 - Train Loss: 8.5445 - Test Loss: 23.4750 - MSE: 23.4750 - MAE: 3.8905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5381/20000 - Train Loss: 8.5406 - Test Loss: 23.4667 - MSE: 23.4667 - MAE: 3.8898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5382/20000 - Train Loss: 8.5367 - Test Loss: 23.4583 - MSE: 23.4583 - MAE: 3.8890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5383/20000 - Train Loss: 8.5328 - Test Loss: 23.4500 - MSE: 23.4500 - MAE: 3.8883\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5384/20000 - Train Loss: 8.5289 - Test Loss: 23.4417 - MSE: 23.4417 - MAE: 3.8876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5385/20000 - Train Loss: 8.5250 - Test Loss: 23.4333 - MSE: 23.4333 - MAE: 3.8868\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5386/20000 - Train Loss: 8.5211 - Test Loss: 23.4250 - MSE: 23.4250 - MAE: 3.8861\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5387/20000 - Train Loss: 8.5172 - Test Loss: 23.4166 - MSE: 23.4166 - MAE: 3.8854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5388/20000 - Train Loss: 8.5133 - Test Loss: 23.4084 - MSE: 23.4084 - MAE: 3.8846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5389/20000 - Train Loss: 8.5094 - Test Loss: 23.4001 - MSE: 23.4001 - MAE: 3.8839\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5390/20000 - Train Loss: 8.5055 - Test Loss: 23.3917 - MSE: 23.3917 - MAE: 3.8831\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5391/20000 - Train Loss: 8.5016 - Test Loss: 23.3834 - MSE: 23.3834 - MAE: 3.8824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5392/20000 - Train Loss: 8.4977 - Test Loss: 23.3751 - MSE: 23.3751 - MAE: 3.8817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5393/20000 - Train Loss: 8.4938 - Test Loss: 23.3667 - MSE: 23.3667 - MAE: 3.8809\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5394/20000 - Train Loss: 8.4899 - Test Loss: 23.3583 - MSE: 23.3583 - MAE: 3.8802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5395/20000 - Train Loss: 8.4860 - Test Loss: 23.3500 - MSE: 23.3500 - MAE: 3.8795\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5396/20000 - Train Loss: 8.4820 - Test Loss: 23.3417 - MSE: 23.3417 - MAE: 3.8787\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5397/20000 - Train Loss: 8.4781 - Test Loss: 23.3334 - MSE: 23.3334 - MAE: 3.8780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5398/20000 - Train Loss: 8.4742 - Test Loss: 23.3250 - MSE: 23.3250 - MAE: 3.8772\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5399/20000 - Train Loss: 8.4703 - Test Loss: 23.3168 - MSE: 23.3168 - MAE: 3.8765\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5400/20000 - Train Loss: 8.4664 - Test Loss: 23.3085 - MSE: 23.3085 - MAE: 3.8758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5401/20000 - Train Loss: 8.4625 - Test Loss: 23.3002 - MSE: 23.3002 - MAE: 3.8750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5402/20000 - Train Loss: 8.4586 - Test Loss: 23.2918 - MSE: 23.2918 - MAE: 3.8743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5403/20000 - Train Loss: 8.4547 - Test Loss: 23.2835 - MSE: 23.2835 - MAE: 3.8736\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5404/20000 - Train Loss: 8.4508 - Test Loss: 23.2751 - MSE: 23.2751 - MAE: 3.8728\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5405/20000 - Train Loss: 8.4469 - Test Loss: 23.2668 - MSE: 23.2668 - MAE: 3.8721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5406/20000 - Train Loss: 8.4431 - Test Loss: 23.2585 - MSE: 23.2585 - MAE: 3.8713\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 5407/20000 - Train Loss: 8.4392 - Test Loss: 23.2502 - MSE: 23.2502 - MAE: 3.8706\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5408/20000 - Train Loss: 8.4352 - Test Loss: 23.2418 - MSE: 23.2418 - MAE: 3.8699\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5409/20000 - Train Loss: 8.4313 - Test Loss: 23.2335 - MSE: 23.2335 - MAE: 3.8691\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5410/20000 - Train Loss: 8.4274 - Test Loss: 23.2252 - MSE: 23.2252 - MAE: 3.8684\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 5411/20000 - Train Loss: 8.4235 - Test Loss: 23.2169 - MSE: 23.2169 - MAE: 3.8676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5412/20000 - Train Loss: 8.4197 - Test Loss: 23.2087 - MSE: 23.2087 - MAE: 3.8669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5413/20000 - Train Loss: 8.4158 - Test Loss: 23.2003 - MSE: 23.2003 - MAE: 3.8662\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5414/20000 - Train Loss: 8.4119 - Test Loss: 23.1920 - MSE: 23.1920 - MAE: 3.8654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5415/20000 - Train Loss: 8.4080 - Test Loss: 23.1837 - MSE: 23.1837 - MAE: 3.8647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5416/20000 - Train Loss: 8.4041 - Test Loss: 23.1753 - MSE: 23.1753 - MAE: 3.8639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5417/20000 - Train Loss: 8.4002 - Test Loss: 23.1670 - MSE: 23.1670 - MAE: 3.8632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5418/20000 - Train Loss: 8.3963 - Test Loss: 23.1587 - MSE: 23.1587 - MAE: 3.8625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5419/20000 - Train Loss: 8.3924 - Test Loss: 23.1504 - MSE: 23.1504 - MAE: 3.8617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5420/20000 - Train Loss: 8.3885 - Test Loss: 23.1421 - MSE: 23.1421 - MAE: 3.8610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5421/20000 - Train Loss: 8.3846 - Test Loss: 23.1338 - MSE: 23.1338 - MAE: 3.8602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5422/20000 - Train Loss: 8.3807 - Test Loss: 23.1255 - MSE: 23.1255 - MAE: 3.8595\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5423/20000 - Train Loss: 8.3768 - Test Loss: 23.1172 - MSE: 23.1172 - MAE: 3.8588\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5424/20000 - Train Loss: 8.3729 - Test Loss: 23.1089 - MSE: 23.1089 - MAE: 3.8580\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5425/20000 - Train Loss: 8.3690 - Test Loss: 23.1005 - MSE: 23.1005 - MAE: 3.8573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5426/20000 - Train Loss: 8.3651 - Test Loss: 23.0922 - MSE: 23.0922 - MAE: 3.8565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5427/20000 - Train Loss: 8.3612 - Test Loss: 23.0839 - MSE: 23.0839 - MAE: 3.8558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5428/20000 - Train Loss: 8.3573 - Test Loss: 23.0756 - MSE: 23.0756 - MAE: 3.8550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5429/20000 - Train Loss: 8.3534 - Test Loss: 23.0673 - MSE: 23.0673 - MAE: 3.8543\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5430/20000 - Train Loss: 8.3495 - Test Loss: 23.0590 - MSE: 23.0590 - MAE: 3.8536\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5431/20000 - Train Loss: 8.3456 - Test Loss: 23.0507 - MSE: 23.0507 - MAE: 3.8528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5432/20000 - Train Loss: 8.3417 - Test Loss: 23.0424 - MSE: 23.0424 - MAE: 3.8521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5433/20000 - Train Loss: 8.3378 - Test Loss: 23.0341 - MSE: 23.0341 - MAE: 3.8513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5434/20000 - Train Loss: 8.3339 - Test Loss: 23.0258 - MSE: 23.0258 - MAE: 3.8506\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5435/20000 - Train Loss: 8.3300 - Test Loss: 23.0175 - MSE: 23.0175 - MAE: 3.8498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5436/20000 - Train Loss: 8.3261 - Test Loss: 23.0092 - MSE: 23.0092 - MAE: 3.8491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5437/20000 - Train Loss: 8.3223 - Test Loss: 23.0009 - MSE: 23.0009 - MAE: 3.8484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5438/20000 - Train Loss: 8.3184 - Test Loss: 22.9925 - MSE: 22.9925 - MAE: 3.8476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5439/20000 - Train Loss: 8.3145 - Test Loss: 22.9843 - MSE: 22.9843 - MAE: 3.8469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5440/20000 - Train Loss: 8.3106 - Test Loss: 22.9760 - MSE: 22.9760 - MAE: 3.8461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5441/20000 - Train Loss: 8.3067 - Test Loss: 22.9677 - MSE: 22.9677 - MAE: 3.8454\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5442/20000 - Train Loss: 8.3028 - Test Loss: 22.9594 - MSE: 22.9594 - MAE: 3.8446\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5443/20000 - Train Loss: 8.2989 - Test Loss: 22.9511 - MSE: 22.9511 - MAE: 3.8439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5444/20000 - Train Loss: 8.2950 - Test Loss: 22.9427 - MSE: 22.9427 - MAE: 3.8431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5445/20000 - Train Loss: 8.2911 - Test Loss: 22.9345 - MSE: 22.9345 - MAE: 3.8424\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5446/20000 - Train Loss: 8.2872 - Test Loss: 22.9262 - MSE: 22.9262 - MAE: 3.8416\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5447/20000 - Train Loss: 8.2833 - Test Loss: 22.9179 - MSE: 22.9179 - MAE: 3.8409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5448/20000 - Train Loss: 8.2794 - Test Loss: 22.9096 - MSE: 22.9096 - MAE: 3.8402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5449/20000 - Train Loss: 8.2755 - Test Loss: 22.9013 - MSE: 22.9013 - MAE: 3.8394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5450/20000 - Train Loss: 8.2717 - Test Loss: 22.8930 - MSE: 22.8930 - MAE: 3.8387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5451/20000 - Train Loss: 8.2678 - Test Loss: 22.8847 - MSE: 22.8847 - MAE: 3.8379\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5452/20000 - Train Loss: 8.2639 - Test Loss: 22.8764 - MSE: 22.8764 - MAE: 3.8372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5453/20000 - Train Loss: 8.2600 - Test Loss: 22.8681 - MSE: 22.8681 - MAE: 3.8364\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5454/20000 - Train Loss: 8.2561 - Test Loss: 22.8598 - MSE: 22.8598 - MAE: 3.8357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5455/20000 - Train Loss: 8.2522 - Test Loss: 22.8515 - MSE: 22.8515 - MAE: 3.8349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5456/20000 - Train Loss: 8.2483 - Test Loss: 22.8433 - MSE: 22.8433 - MAE: 3.8342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5457/20000 - Train Loss: 8.2444 - Test Loss: 22.8350 - MSE: 22.8350 - MAE: 3.8334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5458/20000 - Train Loss: 8.2405 - Test Loss: 22.8267 - MSE: 22.8267 - MAE: 3.8327\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5459/20000 - Train Loss: 8.2366 - Test Loss: 22.8184 - MSE: 22.8184 - MAE: 3.8319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5460/20000 - Train Loss: 8.2328 - Test Loss: 22.8101 - MSE: 22.8101 - MAE: 3.8312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5461/20000 - Train Loss: 8.2289 - Test Loss: 22.8018 - MSE: 22.8018 - MAE: 3.8304\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5462/20000 - Train Loss: 8.2250 - Test Loss: 22.7934 - MSE: 22.7934 - MAE: 3.8297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5463/20000 - Train Loss: 8.2211 - Test Loss: 22.7852 - MSE: 22.7852 - MAE: 3.8289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5464/20000 - Train Loss: 8.2172 - Test Loss: 22.7769 - MSE: 22.7769 - MAE: 3.8282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5465/20000 - Train Loss: 8.2133 - Test Loss: 22.7686 - MSE: 22.7686 - MAE: 3.8274\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5466/20000 - Train Loss: 8.2094 - Test Loss: 22.7604 - MSE: 22.7604 - MAE: 3.8267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5467/20000 - Train Loss: 8.2055 - Test Loss: 22.7521 - MSE: 22.7521 - MAE: 3.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5468/20000 - Train Loss: 8.2017 - Test Loss: 22.7438 - MSE: 22.7438 - MAE: 3.8252\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5469/20000 - Train Loss: 8.1978 - Test Loss: 22.7356 - MSE: 22.7356 - MAE: 3.8245\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5470/20000 - Train Loss: 8.1939 - Test Loss: 22.7273 - MSE: 22.7273 - MAE: 3.8237\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5471/20000 - Train Loss: 8.1900 - Test Loss: 22.7190 - MSE: 22.7190 - MAE: 3.8230\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5472/20000 - Train Loss: 8.1861 - Test Loss: 22.7107 - MSE: 22.7107 - MAE: 3.8222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5473/20000 - Train Loss: 8.1822 - Test Loss: 22.7024 - MSE: 22.7024 - MAE: 3.8214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5474/20000 - Train Loss: 8.1783 - Test Loss: 22.6940 - MSE: 22.6940 - MAE: 3.8207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5475/20000 - Train Loss: 8.1745 - Test Loss: 22.6858 - MSE: 22.6858 - MAE: 3.8199\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5476/20000 - Train Loss: 8.1706 - Test Loss: 22.6775 - MSE: 22.6775 - MAE: 3.8192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5477/20000 - Train Loss: 8.1667 - Test Loss: 22.6693 - MSE: 22.6693 - MAE: 3.8184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5478/20000 - Train Loss: 8.1628 - Test Loss: 22.6610 - MSE: 22.6610 - MAE: 3.8177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5479/20000 - Train Loss: 8.1589 - Test Loss: 22.6528 - MSE: 22.6528 - MAE: 3.8169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5480/20000 - Train Loss: 8.1550 - Test Loss: 22.6445 - MSE: 22.6445 - MAE: 3.8162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5481/20000 - Train Loss: 8.1511 - Test Loss: 22.6363 - MSE: 22.6363 - MAE: 3.8154\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5482/20000 - Train Loss: 8.1473 - Test Loss: 22.6280 - MSE: 22.6280 - MAE: 3.8147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5483/20000 - Train Loss: 8.1434 - Test Loss: 22.6197 - MSE: 22.6197 - MAE: 3.8139\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5484/20000 - Train Loss: 8.1395 - Test Loss: 22.6114 - MSE: 22.6114 - MAE: 3.8132\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5485/20000 - Train Loss: 8.1356 - Test Loss: 22.6031 - MSE: 22.6031 - MAE: 3.8125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5486/20000 - Train Loss: 8.1317 - Test Loss: 22.5948 - MSE: 22.5948 - MAE: 3.8117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5487/20000 - Train Loss: 8.1278 - Test Loss: 22.5865 - MSE: 22.5865 - MAE: 3.8110\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 5488/20000 - Train Loss: 8.1240 - Test Loss: 22.5783 - MSE: 22.5783 - MAE: 3.8102\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5489/20000 - Train Loss: 8.1201 - Test Loss: 22.5700 - MSE: 22.5700 - MAE: 3.8095\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5490/20000 - Train Loss: 8.1162 - Test Loss: 22.5617 - MSE: 22.5617 - MAE: 3.8087\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5491/20000 - Train Loss: 8.1123 - Test Loss: 22.5535 - MSE: 22.5535 - MAE: 3.8080\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 5492/20000 - Train Loss: 8.1084 - Test Loss: 22.5453 - MSE: 22.5453 - MAE: 3.8073\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5493/20000 - Train Loss: 8.1046 - Test Loss: 22.5370 - MSE: 22.5370 - MAE: 3.8065\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5494/20000 - Train Loss: 8.1007 - Test Loss: 22.5287 - MSE: 22.5287 - MAE: 3.8058\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5495/20000 - Train Loss: 8.0968 - Test Loss: 22.5204 - MSE: 22.5204 - MAE: 3.8050\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5496/20000 - Train Loss: 8.0929 - Test Loss: 22.5121 - MSE: 22.5121 - MAE: 3.8043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5497/20000 - Train Loss: 8.0890 - Test Loss: 22.5039 - MSE: 22.5039 - MAE: 3.8035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5498/20000 - Train Loss: 8.0852 - Test Loss: 22.4956 - MSE: 22.4956 - MAE: 3.8028\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5499/20000 - Train Loss: 8.0813 - Test Loss: 22.4874 - MSE: 22.4874 - MAE: 3.8020\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 5500/20000 - Train Loss: 8.0774 - Test Loss: 22.4792 - MSE: 22.4792 - MAE: 3.8013\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5501/20000 - Train Loss: 8.0735 - Test Loss: 22.4709 - MSE: 22.4709 - MAE: 3.8006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5502/20000 - Train Loss: 8.0696 - Test Loss: 22.4626 - MSE: 22.4626 - MAE: 3.7998\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5503/20000 - Train Loss: 8.0658 - Test Loss: 22.4543 - MSE: 22.4543 - MAE: 3.7991\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 5504/20000 - Train Loss: 8.0619 - Test Loss: 22.4461 - MSE: 22.4461 - MAE: 3.7983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5505/20000 - Train Loss: 8.0580 - Test Loss: 22.4378 - MSE: 22.4378 - MAE: 3.7976\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5506/20000 - Train Loss: 8.0541 - Test Loss: 22.4296 - MSE: 22.4296 - MAE: 3.7968\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5507/20000 - Train Loss: 8.0503 - Test Loss: 22.4213 - MSE: 22.4213 - MAE: 3.7961\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5508/20000 - Train Loss: 8.0464 - Test Loss: 22.4130 - MSE: 22.4130 - MAE: 3.7953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5509/20000 - Train Loss: 8.0425 - Test Loss: 22.4048 - MSE: 22.4048 - MAE: 3.7946\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5510/20000 - Train Loss: 8.0386 - Test Loss: 22.3965 - MSE: 22.3965 - MAE: 3.7938\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5511/20000 - Train Loss: 8.0347 - Test Loss: 22.3883 - MSE: 22.3883 - MAE: 3.7931\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 5512/20000 - Train Loss: 8.0309 - Test Loss: 22.3801 - MSE: 22.3801 - MAE: 3.7924\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5513/20000 - Train Loss: 8.0270 - Test Loss: 22.3718 - MSE: 22.3718 - MAE: 3.7916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5514/20000 - Train Loss: 8.0231 - Test Loss: 22.3636 - MSE: 22.3636 - MAE: 3.7909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5515/20000 - Train Loss: 8.0192 - Test Loss: 22.3553 - MSE: 22.3553 - MAE: 3.7901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5516/20000 - Train Loss: 8.0154 - Test Loss: 22.3471 - MSE: 22.3471 - MAE: 3.7894\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5517/20000 - Train Loss: 8.0115 - Test Loss: 22.3388 - MSE: 22.3388 - MAE: 3.7886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5518/20000 - Train Loss: 8.0076 - Test Loss: 22.3306 - MSE: 22.3306 - MAE: 3.7879\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5519/20000 - Train Loss: 8.0037 - Test Loss: 22.3223 - MSE: 22.3223 - MAE: 3.7871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5520/20000 - Train Loss: 7.9999 - Test Loss: 22.3141 - MSE: 22.3141 - MAE: 3.7864\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5521/20000 - Train Loss: 7.9960 - Test Loss: 22.3058 - MSE: 22.3058 - MAE: 3.7856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5522/20000 - Train Loss: 7.9921 - Test Loss: 22.2976 - MSE: 22.2976 - MAE: 3.7849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5523/20000 - Train Loss: 7.9883 - Test Loss: 22.2894 - MSE: 22.2894 - MAE: 3.7841\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5524/20000 - Train Loss: 7.9844 - Test Loss: 22.2811 - MSE: 22.2811 - MAE: 3.7834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5525/20000 - Train Loss: 7.9805 - Test Loss: 22.2729 - MSE: 22.2729 - MAE: 3.7826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5526/20000 - Train Loss: 7.9766 - Test Loss: 22.2647 - MSE: 22.2647 - MAE: 3.7819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5527/20000 - Train Loss: 7.9728 - Test Loss: 22.2564 - MSE: 22.2564 - MAE: 3.7811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5528/20000 - Train Loss: 7.9689 - Test Loss: 22.2481 - MSE: 22.2481 - MAE: 3.7804\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5529/20000 - Train Loss: 7.9650 - Test Loss: 22.2399 - MSE: 22.2399 - MAE: 3.7796\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5530/20000 - Train Loss: 7.9612 - Test Loss: 22.2317 - MSE: 22.2317 - MAE: 3.7789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5531/20000 - Train Loss: 7.9573 - Test Loss: 22.2234 - MSE: 22.2234 - MAE: 3.7781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5532/20000 - Train Loss: 7.9534 - Test Loss: 22.2152 - MSE: 22.2152 - MAE: 3.7774\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 5533/20000 - Train Loss: 7.9495 - Test Loss: 22.2069 - MSE: 22.2069 - MAE: 3.7766\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5534/20000 - Train Loss: 7.9457 - Test Loss: 22.1987 - MSE: 22.1987 - MAE: 3.7759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5535/20000 - Train Loss: 7.9418 - Test Loss: 22.1905 - MSE: 22.1905 - MAE: 3.7751\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5536/20000 - Train Loss: 7.9379 - Test Loss: 22.1823 - MSE: 22.1823 - MAE: 3.7744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5537/20000 - Train Loss: 7.9341 - Test Loss: 22.1741 - MSE: 22.1741 - MAE: 3.7736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5538/20000 - Train Loss: 7.9302 - Test Loss: 22.1658 - MSE: 22.1658 - MAE: 3.7729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5539/20000 - Train Loss: 7.9263 - Test Loss: 22.1576 - MSE: 22.1576 - MAE: 3.7721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5540/20000 - Train Loss: 7.9225 - Test Loss: 22.1494 - MSE: 22.1494 - MAE: 3.7714\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5541/20000 - Train Loss: 7.9186 - Test Loss: 22.1411 - MSE: 22.1411 - MAE: 3.7706\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5542/20000 - Train Loss: 7.9147 - Test Loss: 22.1329 - MSE: 22.1329 - MAE: 3.7699\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5543/20000 - Train Loss: 7.9109 - Test Loss: 22.1247 - MSE: 22.1247 - MAE: 3.7691\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5544/20000 - Train Loss: 7.9070 - Test Loss: 22.1164 - MSE: 22.1164 - MAE: 3.7684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5545/20000 - Train Loss: 7.9031 - Test Loss: 22.1082 - MSE: 22.1082 - MAE: 3.7676\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch 5546/20000 - Train Loss: 7.8993 - Test Loss: 22.1000 - MSE: 22.1000 - MAE: 3.7669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5547/20000 - Train Loss: 7.8954 - Test Loss: 22.0918 - MSE: 22.0918 - MAE: 3.7661\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5548/20000 - Train Loss: 7.8915 - Test Loss: 22.0836 - MSE: 22.0836 - MAE: 3.7654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5549/20000 - Train Loss: 7.8877 - Test Loss: 22.0754 - MSE: 22.0754 - MAE: 3.7646\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5550/20000 - Train Loss: 7.8838 - Test Loss: 22.0672 - MSE: 22.0672 - MAE: 3.7639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5551/20000 - Train Loss: 7.8799 - Test Loss: 22.0589 - MSE: 22.0589 - MAE: 3.7631\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5552/20000 - Train Loss: 7.8761 - Test Loss: 22.0507 - MSE: 22.0507 - MAE: 3.7624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5553/20000 - Train Loss: 7.8722 - Test Loss: 22.0425 - MSE: 22.0425 - MAE: 3.7616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5554/20000 - Train Loss: 7.8684 - Test Loss: 22.0342 - MSE: 22.0342 - MAE: 3.7608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5555/20000 - Train Loss: 7.8645 - Test Loss: 22.0260 - MSE: 22.0260 - MAE: 3.7601\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 5556/20000 - Train Loss: 7.8606 - Test Loss: 22.0178 - MSE: 22.0178 - MAE: 3.7593\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5557/20000 - Train Loss: 7.8568 - Test Loss: 22.0096 - MSE: 22.0096 - MAE: 3.7586\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5558/20000 - Train Loss: 7.8529 - Test Loss: 22.0014 - MSE: 22.0014 - MAE: 3.7578\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5559/20000 - Train Loss: 7.8490 - Test Loss: 21.9932 - MSE: 21.9932 - MAE: 3.7571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5560/20000 - Train Loss: 7.8452 - Test Loss: 21.9850 - MSE: 21.9850 - MAE: 3.7563\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5561/20000 - Train Loss: 7.8413 - Test Loss: 21.9768 - MSE: 21.9768 - MAE: 3.7556\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5562/20000 - Train Loss: 7.8375 - Test Loss: 21.9686 - MSE: 21.9686 - MAE: 3.7548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5563/20000 - Train Loss: 7.8336 - Test Loss: 21.9604 - MSE: 21.9604 - MAE: 3.7541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5564/20000 - Train Loss: 7.8297 - Test Loss: 21.9521 - MSE: 21.9521 - MAE: 3.7533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5565/20000 - Train Loss: 7.8259 - Test Loss: 21.9439 - MSE: 21.9439 - MAE: 3.7525\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5566/20000 - Train Loss: 7.8220 - Test Loss: 21.9357 - MSE: 21.9357 - MAE: 3.7518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5567/20000 - Train Loss: 7.8182 - Test Loss: 21.9275 - MSE: 21.9275 - MAE: 3.7510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5568/20000 - Train Loss: 7.8143 - Test Loss: 21.9193 - MSE: 21.9193 - MAE: 3.7503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5569/20000 - Train Loss: 7.8104 - Test Loss: 21.9112 - MSE: 21.9112 - MAE: 3.7495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5570/20000 - Train Loss: 7.8066 - Test Loss: 21.9029 - MSE: 21.9029 - MAE: 3.7488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5571/20000 - Train Loss: 7.8027 - Test Loss: 21.8947 - MSE: 21.8947 - MAE: 3.7480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5572/20000 - Train Loss: 7.7989 - Test Loss: 21.8865 - MSE: 21.8865 - MAE: 3.7473\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 5573/20000 - Train Loss: 7.7950 - Test Loss: 21.8783 - MSE: 21.8783 - MAE: 3.7465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5574/20000 - Train Loss: 7.7912 - Test Loss: 21.8701 - MSE: 21.8701 - MAE: 3.7457\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 5575/20000 - Train Loss: 7.7873 - Test Loss: 21.8619 - MSE: 21.8619 - MAE: 3.7450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5576/20000 - Train Loss: 7.7834 - Test Loss: 21.8537 - MSE: 21.8537 - MAE: 3.7442\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5577/20000 - Train Loss: 7.7796 - Test Loss: 21.8455 - MSE: 21.8455 - MAE: 3.7435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5578/20000 - Train Loss: 7.7757 - Test Loss: 21.8373 - MSE: 21.8373 - MAE: 3.7427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5579/20000 - Train Loss: 7.7719 - Test Loss: 21.8291 - MSE: 21.8291 - MAE: 3.7420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5580/20000 - Train Loss: 7.7680 - Test Loss: 21.8210 - MSE: 21.8210 - MAE: 3.7412\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5581/20000 - Train Loss: 7.7642 - Test Loss: 21.8128 - MSE: 21.8128 - MAE: 3.7404\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5582/20000 - Train Loss: 7.7603 - Test Loss: 21.8046 - MSE: 21.8046 - MAE: 3.7397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5583/20000 - Train Loss: 7.7565 - Test Loss: 21.7964 - MSE: 21.7964 - MAE: 3.7389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5584/20000 - Train Loss: 7.7526 - Test Loss: 21.7882 - MSE: 21.7882 - MAE: 3.7382\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5585/20000 - Train Loss: 7.7488 - Test Loss: 21.7800 - MSE: 21.7800 - MAE: 3.7374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5586/20000 - Train Loss: 7.7449 - Test Loss: 21.7718 - MSE: 21.7718 - MAE: 3.7366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5587/20000 - Train Loss: 7.7411 - Test Loss: 21.7636 - MSE: 21.7636 - MAE: 3.7359\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5588/20000 - Train Loss: 7.7372 - Test Loss: 21.7554 - MSE: 21.7554 - MAE: 3.7351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5589/20000 - Train Loss: 7.7334 - Test Loss: 21.7473 - MSE: 21.7473 - MAE: 3.7344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5590/20000 - Train Loss: 7.7295 - Test Loss: 21.7391 - MSE: 21.7391 - MAE: 3.7336\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5591/20000 - Train Loss: 7.7257 - Test Loss: 21.7309 - MSE: 21.7309 - MAE: 3.7329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5592/20000 - Train Loss: 7.7218 - Test Loss: 21.7227 - MSE: 21.7227 - MAE: 3.7321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5593/20000 - Train Loss: 7.7180 - Test Loss: 21.7146 - MSE: 21.7146 - MAE: 3.7313\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5594/20000 - Train Loss: 7.7141 - Test Loss: 21.7064 - MSE: 21.7064 - MAE: 3.7306\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5595/20000 - Train Loss: 7.7103 - Test Loss: 21.6982 - MSE: 21.6982 - MAE: 3.7298\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5596/20000 - Train Loss: 7.7064 - Test Loss: 21.6900 - MSE: 21.6900 - MAE: 3.7291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5597/20000 - Train Loss: 7.7026 - Test Loss: 21.6818 - MSE: 21.6818 - MAE: 3.7283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5598/20000 - Train Loss: 7.6987 - Test Loss: 21.6737 - MSE: 21.6737 - MAE: 3.7275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5599/20000 - Train Loss: 7.6949 - Test Loss: 21.6655 - MSE: 21.6655 - MAE: 3.7268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5600/20000 - Train Loss: 7.6910 - Test Loss: 21.6573 - MSE: 21.6573 - MAE: 3.7260\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5601/20000 - Train Loss: 7.6872 - Test Loss: 21.6491 - MSE: 21.6491 - MAE: 3.7253\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Epoch 5602/20000 - Train Loss: 7.6833 - Test Loss: 21.6409 - MSE: 21.6409 - MAE: 3.7245\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5603/20000 - Train Loss: 7.6795 - Test Loss: 21.6328 - MSE: 21.6328 - MAE: 3.7237\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5604/20000 - Train Loss: 7.6756 - Test Loss: 21.6246 - MSE: 21.6246 - MAE: 3.7230\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5605/20000 - Train Loss: 7.6718 - Test Loss: 21.6164 - MSE: 21.6164 - MAE: 3.7222\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 5606/20000 - Train Loss: 7.6679 - Test Loss: 21.6083 - MSE: 21.6083 - MAE: 3.7214\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5607/20000 - Train Loss: 7.6641 - Test Loss: 21.6002 - MSE: 21.6002 - MAE: 3.7207\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5608/20000 - Train Loss: 7.6603 - Test Loss: 21.5920 - MSE: 21.5920 - MAE: 3.7199\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5609/20000 - Train Loss: 7.6564 - Test Loss: 21.5838 - MSE: 21.5838 - MAE: 3.7192\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5610/20000 - Train Loss: 7.6526 - Test Loss: 21.5756 - MSE: 21.5756 - MAE: 3.7184\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5611/20000 - Train Loss: 7.6487 - Test Loss: 21.5674 - MSE: 21.5674 - MAE: 3.7176\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5612/20000 - Train Loss: 7.6449 - Test Loss: 21.5592 - MSE: 21.5592 - MAE: 3.7169\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5613/20000 - Train Loss: 7.6410 - Test Loss: 21.5511 - MSE: 21.5511 - MAE: 3.7161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5614/20000 - Train Loss: 7.6372 - Test Loss: 21.5430 - MSE: 21.5430 - MAE: 3.7153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5615/20000 - Train Loss: 7.6334 - Test Loss: 21.5348 - MSE: 21.5348 - MAE: 3.7146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5616/20000 - Train Loss: 7.6295 - Test Loss: 21.5267 - MSE: 21.5267 - MAE: 3.7138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5617/20000 - Train Loss: 7.6257 - Test Loss: 21.5185 - MSE: 21.5185 - MAE: 3.7131\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5618/20000 - Train Loss: 7.6218 - Test Loss: 21.5104 - MSE: 21.5104 - MAE: 3.7123\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5619/20000 - Train Loss: 7.6180 - Test Loss: 21.5022 - MSE: 21.5022 - MAE: 3.7115\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5620/20000 - Train Loss: 7.6142 - Test Loss: 21.4941 - MSE: 21.4941 - MAE: 3.7108\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5621/20000 - Train Loss: 7.6103 - Test Loss: 21.4859 - MSE: 21.4859 - MAE: 3.7100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5622/20000 - Train Loss: 7.6065 - Test Loss: 21.4777 - MSE: 21.4777 - MAE: 3.7092\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5623/20000 - Train Loss: 7.6026 - Test Loss: 21.4696 - MSE: 21.4696 - MAE: 3.7085\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5624/20000 - Train Loss: 7.5988 - Test Loss: 21.4614 - MSE: 21.4614 - MAE: 3.7077\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5625/20000 - Train Loss: 7.5950 - Test Loss: 21.4533 - MSE: 21.4533 - MAE: 3.7069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5626/20000 - Train Loss: 7.5911 - Test Loss: 21.4451 - MSE: 21.4451 - MAE: 3.7062\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5627/20000 - Train Loss: 7.5873 - Test Loss: 21.4370 - MSE: 21.4370 - MAE: 3.7054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5628/20000 - Train Loss: 7.5835 - Test Loss: 21.4289 - MSE: 21.4289 - MAE: 3.7047\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5629/20000 - Train Loss: 7.5796 - Test Loss: 21.4208 - MSE: 21.4208 - MAE: 3.7039\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5630/20000 - Train Loss: 7.5758 - Test Loss: 21.4126 - MSE: 21.4126 - MAE: 3.7031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5631/20000 - Train Loss: 7.5720 - Test Loss: 21.4045 - MSE: 21.4045 - MAE: 3.7024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5632/20000 - Train Loss: 7.5681 - Test Loss: 21.3963 - MSE: 21.3963 - MAE: 3.7016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5633/20000 - Train Loss: 7.5643 - Test Loss: 21.3881 - MSE: 21.3881 - MAE: 3.7008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5634/20000 - Train Loss: 7.5605 - Test Loss: 21.3800 - MSE: 21.3800 - MAE: 3.7001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5635/20000 - Train Loss: 7.5566 - Test Loss: 21.3719 - MSE: 21.3718 - MAE: 3.6993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5636/20000 - Train Loss: 7.5528 - Test Loss: 21.3637 - MSE: 21.3637 - MAE: 3.6985\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5637/20000 - Train Loss: 7.5490 - Test Loss: 21.3555 - MSE: 21.3555 - MAE: 3.6978\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5638/20000 - Train Loss: 7.5451 - Test Loss: 21.3474 - MSE: 21.3474 - MAE: 3.6970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5639/20000 - Train Loss: 7.5413 - Test Loss: 21.3393 - MSE: 21.3393 - MAE: 3.6962\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5640/20000 - Train Loss: 7.5375 - Test Loss: 21.3312 - MSE: 21.3312 - MAE: 3.6955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5641/20000 - Train Loss: 7.5336 - Test Loss: 21.3231 - MSE: 21.3231 - MAE: 3.6947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5642/20000 - Train Loss: 7.5298 - Test Loss: 21.3150 - MSE: 21.3150 - MAE: 3.6939\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 5643/20000 - Train Loss: 7.5260 - Test Loss: 21.3069 - MSE: 21.3069 - MAE: 3.6932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5644/20000 - Train Loss: 7.5221 - Test Loss: 21.2987 - MSE: 21.2987 - MAE: 3.6924\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5645/20000 - Train Loss: 7.5183 - Test Loss: 21.2906 - MSE: 21.2906 - MAE: 3.6916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5646/20000 - Train Loss: 7.5145 - Test Loss: 21.2824 - MSE: 21.2824 - MAE: 3.6909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5647/20000 - Train Loss: 7.5107 - Test Loss: 21.2743 - MSE: 21.2743 - MAE: 3.6901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5648/20000 - Train Loss: 7.5068 - Test Loss: 21.2661 - MSE: 21.2661 - MAE: 3.6893\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5649/20000 - Train Loss: 7.5030 - Test Loss: 21.2580 - MSE: 21.2580 - MAE: 3.6885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5650/20000 - Train Loss: 7.4992 - Test Loss: 21.2499 - MSE: 21.2499 - MAE: 3.6878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5651/20000 - Train Loss: 7.4953 - Test Loss: 21.2418 - MSE: 21.2418 - MAE: 3.6870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5652/20000 - Train Loss: 7.4915 - Test Loss: 21.2338 - MSE: 21.2338 - MAE: 3.6863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5653/20000 - Train Loss: 7.4877 - Test Loss: 21.2256 - MSE: 21.2256 - MAE: 3.6855\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5654/20000 - Train Loss: 7.4839 - Test Loss: 21.2175 - MSE: 21.2175 - MAE: 3.6847\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5655/20000 - Train Loss: 7.4800 - Test Loss: 21.2094 - MSE: 21.2094 - MAE: 3.6839\n",
      "2/2 [==============================] - 0s 27ms/step\n",
      "Epoch 5656/20000 - Train Loss: 7.4762 - Test Loss: 21.2012 - MSE: 21.2012 - MAE: 3.6832\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5657/20000 - Train Loss: 7.4724 - Test Loss: 21.1931 - MSE: 21.1931 - MAE: 3.6824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5658/20000 - Train Loss: 7.4686 - Test Loss: 21.1850 - MSE: 21.1850 - MAE: 3.6816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5659/20000 - Train Loss: 7.4648 - Test Loss: 21.1769 - MSE: 21.1769 - MAE: 3.6809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5660/20000 - Train Loss: 7.4609 - Test Loss: 21.1688 - MSE: 21.1688 - MAE: 3.6801\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5661/20000 - Train Loss: 7.4571 - Test Loss: 21.1607 - MSE: 21.1607 - MAE: 3.6793\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5662/20000 - Train Loss: 7.4533 - Test Loss: 21.1526 - MSE: 21.1526 - MAE: 3.6786\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5663/20000 - Train Loss: 7.4495 - Test Loss: 21.1445 - MSE: 21.1445 - MAE: 3.6778\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5664/20000 - Train Loss: 7.4456 - Test Loss: 21.1363 - MSE: 21.1363 - MAE: 3.6770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5665/20000 - Train Loss: 7.4418 - Test Loss: 21.1282 - MSE: 21.1282 - MAE: 3.6762\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5666/20000 - Train Loss: 7.4380 - Test Loss: 21.1202 - MSE: 21.1202 - MAE: 3.6755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5667/20000 - Train Loss: 7.4342 - Test Loss: 21.1121 - MSE: 21.1121 - MAE: 3.6747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5668/20000 - Train Loss: 7.4304 - Test Loss: 21.1040 - MSE: 21.1040 - MAE: 3.6739\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5669/20000 - Train Loss: 7.4265 - Test Loss: 21.0958 - MSE: 21.0958 - MAE: 3.6732\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5670/20000 - Train Loss: 7.4227 - Test Loss: 21.0877 - MSE: 21.0877 - MAE: 3.6724\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "Epoch 5671/20000 - Train Loss: 7.4189 - Test Loss: 21.0796 - MSE: 21.0796 - MAE: 3.6716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5672/20000 - Train Loss: 7.4151 - Test Loss: 21.0716 - MSE: 21.0716 - MAE: 3.6708\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5673/20000 - Train Loss: 7.4113 - Test Loss: 21.0634 - MSE: 21.0634 - MAE: 3.6701\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 5674/20000 - Train Loss: 7.4075 - Test Loss: 21.0554 - MSE: 21.0554 - MAE: 3.6693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5675/20000 - Train Loss: 7.4036 - Test Loss: 21.0473 - MSE: 21.0473 - MAE: 3.6685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5676/20000 - Train Loss: 7.3998 - Test Loss: 21.0392 - MSE: 21.0392 - MAE: 3.6678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5677/20000 - Train Loss: 7.3960 - Test Loss: 21.0311 - MSE: 21.0311 - MAE: 3.6670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5678/20000 - Train Loss: 7.3922 - Test Loss: 21.0230 - MSE: 21.0230 - MAE: 3.6662\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5679/20000 - Train Loss: 7.3884 - Test Loss: 21.0149 - MSE: 21.0149 - MAE: 3.6654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5680/20000 - Train Loss: 7.3846 - Test Loss: 21.0069 - MSE: 21.0069 - MAE: 3.6647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5681/20000 - Train Loss: 7.3808 - Test Loss: 20.9988 - MSE: 20.9988 - MAE: 3.6639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5682/20000 - Train Loss: 7.3770 - Test Loss: 20.9907 - MSE: 20.9907 - MAE: 3.6631\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5683/20000 - Train Loss: 7.3731 - Test Loss: 20.9826 - MSE: 20.9826 - MAE: 3.6623\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5684/20000 - Train Loss: 7.3693 - Test Loss: 20.9745 - MSE: 20.9745 - MAE: 3.6616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5685/20000 - Train Loss: 7.3655 - Test Loss: 20.9664 - MSE: 20.9664 - MAE: 3.6608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5686/20000 - Train Loss: 7.3617 - Test Loss: 20.9583 - MSE: 20.9583 - MAE: 3.6600\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5687/20000 - Train Loss: 7.3579 - Test Loss: 20.9502 - MSE: 20.9502 - MAE: 3.6592\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5688/20000 - Train Loss: 7.3541 - Test Loss: 20.9422 - MSE: 20.9422 - MAE: 3.6585\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5689/20000 - Train Loss: 7.3503 - Test Loss: 20.9341 - MSE: 20.9341 - MAE: 3.6577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5690/20000 - Train Loss: 7.3465 - Test Loss: 20.9260 - MSE: 20.9260 - MAE: 3.6569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5691/20000 - Train Loss: 7.3427 - Test Loss: 20.9180 - MSE: 20.9180 - MAE: 3.6562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5692/20000 - Train Loss: 7.3389 - Test Loss: 20.9099 - MSE: 20.9099 - MAE: 3.6554\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5693/20000 - Train Loss: 7.3350 - Test Loss: 20.9019 - MSE: 20.9019 - MAE: 3.6546\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5694/20000 - Train Loss: 7.3312 - Test Loss: 20.8938 - MSE: 20.8938 - MAE: 3.6538\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 5695/20000 - Train Loss: 7.3274 - Test Loss: 20.8857 - MSE: 20.8857 - MAE: 3.6531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5696/20000 - Train Loss: 7.3236 - Test Loss: 20.8776 - MSE: 20.8776 - MAE: 3.6523\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5697/20000 - Train Loss: 7.3198 - Test Loss: 20.8696 - MSE: 20.8696 - MAE: 3.6515\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5698/20000 - Train Loss: 7.3160 - Test Loss: 20.8614 - MSE: 20.8614 - MAE: 3.6507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5699/20000 - Train Loss: 7.3122 - Test Loss: 20.8534 - MSE: 20.8534 - MAE: 3.6499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5700/20000 - Train Loss: 7.3084 - Test Loss: 20.8453 - MSE: 20.8453 - MAE: 3.6492\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5701/20000 - Train Loss: 7.3046 - Test Loss: 20.8373 - MSE: 20.8373 - MAE: 3.6484\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5702/20000 - Train Loss: 7.3008 - Test Loss: 20.8292 - MSE: 20.8292 - MAE: 3.6476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5703/20000 - Train Loss: 7.2970 - Test Loss: 20.8212 - MSE: 20.8212 - MAE: 3.6468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5704/20000 - Train Loss: 7.2932 - Test Loss: 20.8132 - MSE: 20.8132 - MAE: 3.6461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5705/20000 - Train Loss: 7.2894 - Test Loss: 20.8051 - MSE: 20.8051 - MAE: 3.6453\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5706/20000 - Train Loss: 7.2856 - Test Loss: 20.7970 - MSE: 20.7970 - MAE: 3.6445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5707/20000 - Train Loss: 7.2818 - Test Loss: 20.7889 - MSE: 20.7889 - MAE: 3.6437\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5708/20000 - Train Loss: 7.2780 - Test Loss: 20.7809 - MSE: 20.7809 - MAE: 3.6430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5709/20000 - Train Loss: 7.2742 - Test Loss: 20.7728 - MSE: 20.7728 - MAE: 3.6422\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5710/20000 - Train Loss: 7.2704 - Test Loss: 20.7648 - MSE: 20.7648 - MAE: 3.6414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5711/20000 - Train Loss: 7.2666 - Test Loss: 20.7567 - MSE: 20.7567 - MAE: 3.6406\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5712/20000 - Train Loss: 7.2628 - Test Loss: 20.7487 - MSE: 20.7487 - MAE: 3.6399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5713/20000 - Train Loss: 7.2590 - Test Loss: 20.7407 - MSE: 20.7407 - MAE: 3.6391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5714/20000 - Train Loss: 7.2552 - Test Loss: 20.7326 - MSE: 20.7326 - MAE: 3.6383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5715/20000 - Train Loss: 7.2514 - Test Loss: 20.7246 - MSE: 20.7246 - MAE: 3.6375\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5716/20000 - Train Loss: 7.2476 - Test Loss: 20.7165 - MSE: 20.7165 - MAE: 3.6367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5717/20000 - Train Loss: 7.2438 - Test Loss: 20.7085 - MSE: 20.7085 - MAE: 3.6360\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5718/20000 - Train Loss: 7.2400 - Test Loss: 20.7004 - MSE: 20.7004 - MAE: 3.6352\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 5719/20000 - Train Loss: 7.2362 - Test Loss: 20.6924 - MSE: 20.6924 - MAE: 3.6344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5720/20000 - Train Loss: 7.2324 - Test Loss: 20.6844 - MSE: 20.6844 - MAE: 3.6336\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5721/20000 - Train Loss: 7.2286 - Test Loss: 20.6763 - MSE: 20.6763 - MAE: 3.6328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5722/20000 - Train Loss: 7.2248 - Test Loss: 20.6683 - MSE: 20.6683 - MAE: 3.6321\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5723/20000 - Train Loss: 7.2211 - Test Loss: 20.6603 - MSE: 20.6603 - MAE: 3.6313\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5724/20000 - Train Loss: 7.2173 - Test Loss: 20.6523 - MSE: 20.6523 - MAE: 3.6305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5725/20000 - Train Loss: 7.2135 - Test Loss: 20.6442 - MSE: 20.6442 - MAE: 3.6297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5726/20000 - Train Loss: 7.2097 - Test Loss: 20.6362 - MSE: 20.6362 - MAE: 3.6290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5727/20000 - Train Loss: 7.2059 - Test Loss: 20.6281 - MSE: 20.6281 - MAE: 3.6282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5728/20000 - Train Loss: 7.2021 - Test Loss: 20.6201 - MSE: 20.6201 - MAE: 3.6274\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5729/20000 - Train Loss: 7.1983 - Test Loss: 20.6121 - MSE: 20.6121 - MAE: 3.6266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5730/20000 - Train Loss: 7.1945 - Test Loss: 20.6040 - MSE: 20.6040 - MAE: 3.6258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5731/20000 - Train Loss: 7.1907 - Test Loss: 20.5960 - MSE: 20.5960 - MAE: 3.6251\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5732/20000 - Train Loss: 7.1869 - Test Loss: 20.5880 - MSE: 20.5880 - MAE: 3.6243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5733/20000 - Train Loss: 7.1832 - Test Loss: 20.5800 - MSE: 20.5800 - MAE: 3.6235\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5734/20000 - Train Loss: 7.1794 - Test Loss: 20.5720 - MSE: 20.5720 - MAE: 3.6227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5735/20000 - Train Loss: 7.1756 - Test Loss: 20.5639 - MSE: 20.5639 - MAE: 3.6219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5736/20000 - Train Loss: 7.1718 - Test Loss: 20.5559 - MSE: 20.5559 - MAE: 3.6211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5737/20000 - Train Loss: 7.1680 - Test Loss: 20.5479 - MSE: 20.5479 - MAE: 3.6204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5738/20000 - Train Loss: 7.1642 - Test Loss: 20.5400 - MSE: 20.5400 - MAE: 3.6196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5739/20000 - Train Loss: 7.1604 - Test Loss: 20.5319 - MSE: 20.5319 - MAE: 3.6188\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5740/20000 - Train Loss: 7.1567 - Test Loss: 20.5239 - MSE: 20.5239 - MAE: 3.6180\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 5741/20000 - Train Loss: 7.1529 - Test Loss: 20.5159 - MSE: 20.5159 - MAE: 3.6172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5742/20000 - Train Loss: 7.1491 - Test Loss: 20.5078 - MSE: 20.5079 - MAE: 3.6165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5743/20000 - Train Loss: 7.1453 - Test Loss: 20.4999 - MSE: 20.4999 - MAE: 3.6157\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5744/20000 - Train Loss: 7.1415 - Test Loss: 20.4919 - MSE: 20.4919 - MAE: 3.6149\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5745/20000 - Train Loss: 7.1378 - Test Loss: 20.4838 - MSE: 20.4838 - MAE: 3.6141\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5746/20000 - Train Loss: 7.1340 - Test Loss: 20.4759 - MSE: 20.4759 - MAE: 3.6133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5747/20000 - Train Loss: 7.1302 - Test Loss: 20.4678 - MSE: 20.4678 - MAE: 3.6125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5748/20000 - Train Loss: 7.1264 - Test Loss: 20.4598 - MSE: 20.4598 - MAE: 3.6118\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 5749/20000 - Train Loss: 7.1226 - Test Loss: 20.4518 - MSE: 20.4518 - MAE: 3.6110\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5750/20000 - Train Loss: 7.1189 - Test Loss: 20.4438 - MSE: 20.4438 - MAE: 3.6102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5751/20000 - Train Loss: 7.1151 - Test Loss: 20.4358 - MSE: 20.4358 - MAE: 3.6094\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5752/20000 - Train Loss: 7.1113 - Test Loss: 20.4278 - MSE: 20.4278 - MAE: 3.6086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5753/20000 - Train Loss: 7.1075 - Test Loss: 20.4198 - MSE: 20.4198 - MAE: 3.6078\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5754/20000 - Train Loss: 7.1038 - Test Loss: 20.4119 - MSE: 20.4119 - MAE: 3.6071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5755/20000 - Train Loss: 7.1000 - Test Loss: 20.4039 - MSE: 20.4039 - MAE: 3.6063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5756/20000 - Train Loss: 7.0962 - Test Loss: 20.3959 - MSE: 20.3959 - MAE: 3.6055\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 5757/20000 - Train Loss: 7.0924 - Test Loss: 20.3879 - MSE: 20.3879 - MAE: 3.6047\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5758/20000 - Train Loss: 7.0887 - Test Loss: 20.3799 - MSE: 20.3799 - MAE: 3.6039\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5759/20000 - Train Loss: 7.0849 - Test Loss: 20.3719 - MSE: 20.3719 - MAE: 3.6031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5760/20000 - Train Loss: 7.0811 - Test Loss: 20.3639 - MSE: 20.3639 - MAE: 3.6024\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5761/20000 - Train Loss: 7.0773 - Test Loss: 20.3559 - MSE: 20.3559 - MAE: 3.6016\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5762/20000 - Train Loss: 7.0736 - Test Loss: 20.3479 - MSE: 20.3479 - MAE: 3.6008\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5763/20000 - Train Loss: 7.0698 - Test Loss: 20.3400 - MSE: 20.3400 - MAE: 3.6000\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch 5764/20000 - Train Loss: 7.0660 - Test Loss: 20.3320 - MSE: 20.3320 - MAE: 3.5992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5765/20000 - Train Loss: 7.0623 - Test Loss: 20.3240 - MSE: 20.3240 - MAE: 3.5984\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5766/20000 - Train Loss: 7.0585 - Test Loss: 20.3161 - MSE: 20.3161 - MAE: 3.5976\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5767/20000 - Train Loss: 7.0547 - Test Loss: 20.3081 - MSE: 20.3081 - MAE: 3.5969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5768/20000 - Train Loss: 7.0509 - Test Loss: 20.3001 - MSE: 20.3001 - MAE: 3.5961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5769/20000 - Train Loss: 7.0472 - Test Loss: 20.2921 - MSE: 20.2921 - MAE: 3.5953\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5770/20000 - Train Loss: 7.0434 - Test Loss: 20.2841 - MSE: 20.2841 - MAE: 3.5945\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5771/20000 - Train Loss: 7.0396 - Test Loss: 20.2762 - MSE: 20.2762 - MAE: 3.5937\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 5772/20000 - Train Loss: 7.0359 - Test Loss: 20.2682 - MSE: 20.2682 - MAE: 3.5929\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5773/20000 - Train Loss: 7.0321 - Test Loss: 20.2602 - MSE: 20.2602 - MAE: 3.5921\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5774/20000 - Train Loss: 7.0283 - Test Loss: 20.2523 - MSE: 20.2523 - MAE: 3.5914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5775/20000 - Train Loss: 7.0246 - Test Loss: 20.2444 - MSE: 20.2444 - MAE: 3.5906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5776/20000 - Train Loss: 7.0208 - Test Loss: 20.2364 - MSE: 20.2364 - MAE: 3.5898\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5777/20000 - Train Loss: 7.0171 - Test Loss: 20.2284 - MSE: 20.2284 - MAE: 3.5890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5778/20000 - Train Loss: 7.0133 - Test Loss: 20.2204 - MSE: 20.2204 - MAE: 3.5882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5779/20000 - Train Loss: 7.0095 - Test Loss: 20.2125 - MSE: 20.2125 - MAE: 3.5874\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5780/20000 - Train Loss: 7.0058 - Test Loss: 20.2045 - MSE: 20.2045 - MAE: 3.5866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5781/20000 - Train Loss: 7.0020 - Test Loss: 20.1966 - MSE: 20.1966 - MAE: 3.5859\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5782/20000 - Train Loss: 6.9983 - Test Loss: 20.1886 - MSE: 20.1886 - MAE: 3.5851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5783/20000 - Train Loss: 6.9945 - Test Loss: 20.1806 - MSE: 20.1806 - MAE: 3.5843\n",
      "2/2 [==============================] - 0s 27ms/step\n",
      "Epoch 5784/20000 - Train Loss: 6.9907 - Test Loss: 20.1727 - MSE: 20.1727 - MAE: 3.5835\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5785/20000 - Train Loss: 6.9870 - Test Loss: 20.1648 - MSE: 20.1648 - MAE: 3.5827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5786/20000 - Train Loss: 6.9832 - Test Loss: 20.1568 - MSE: 20.1568 - MAE: 3.5819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5787/20000 - Train Loss: 6.9795 - Test Loss: 20.1489 - MSE: 20.1489 - MAE: 3.5811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5788/20000 - Train Loss: 6.9757 - Test Loss: 20.1409 - MSE: 20.1409 - MAE: 3.5803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5789/20000 - Train Loss: 6.9719 - Test Loss: 20.1330 - MSE: 20.1330 - MAE: 3.5795\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5790/20000 - Train Loss: 6.9682 - Test Loss: 20.1251 - MSE: 20.1251 - MAE: 3.5788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5791/20000 - Train Loss: 6.9644 - Test Loss: 20.1171 - MSE: 20.1171 - MAE: 3.5780\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5792/20000 - Train Loss: 6.9607 - Test Loss: 20.1092 - MSE: 20.1092 - MAE: 3.5772\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5793/20000 - Train Loss: 6.9569 - Test Loss: 20.1012 - MSE: 20.1012 - MAE: 3.5764\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5794/20000 - Train Loss: 6.9532 - Test Loss: 20.0933 - MSE: 20.0933 - MAE: 3.5756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5795/20000 - Train Loss: 6.9494 - Test Loss: 20.0853 - MSE: 20.0853 - MAE: 3.5748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5796/20000 - Train Loss: 6.9457 - Test Loss: 20.0774 - MSE: 20.0774 - MAE: 3.5740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5797/20000 - Train Loss: 6.9419 - Test Loss: 20.0695 - MSE: 20.0695 - MAE: 3.5732\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5798/20000 - Train Loss: 6.9382 - Test Loss: 20.0615 - MSE: 20.0615 - MAE: 3.5724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5799/20000 - Train Loss: 6.9344 - Test Loss: 20.0536 - MSE: 20.0536 - MAE: 3.5717\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5800/20000 - Train Loss: 6.9307 - Test Loss: 20.0457 - MSE: 20.0457 - MAE: 3.5709\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 5801/20000 - Train Loss: 6.9269 - Test Loss: 20.0378 - MSE: 20.0378 - MAE: 3.5701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5802/20000 - Train Loss: 6.9232 - Test Loss: 20.0298 - MSE: 20.0298 - MAE: 3.5693\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5803/20000 - Train Loss: 6.9194 - Test Loss: 20.0219 - MSE: 20.0219 - MAE: 3.5685\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5804/20000 - Train Loss: 6.9157 - Test Loss: 20.0140 - MSE: 20.0140 - MAE: 3.5677\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5805/20000 - Train Loss: 6.9119 - Test Loss: 20.0061 - MSE: 20.0061 - MAE: 3.5669\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5806/20000 - Train Loss: 6.9082 - Test Loss: 19.9982 - MSE: 19.9982 - MAE: 3.5661\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5807/20000 - Train Loss: 6.9044 - Test Loss: 19.9903 - MSE: 19.9903 - MAE: 3.5653\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 5808/20000 - Train Loss: 6.9007 - Test Loss: 19.9823 - MSE: 19.9823 - MAE: 3.5645\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5809/20000 - Train Loss: 6.8969 - Test Loss: 19.9744 - MSE: 19.9744 - MAE: 3.5637\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5810/20000 - Train Loss: 6.8932 - Test Loss: 19.9665 - MSE: 19.9665 - MAE: 3.5630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5811/20000 - Train Loss: 6.8895 - Test Loss: 19.9586 - MSE: 19.9586 - MAE: 3.5622\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5812/20000 - Train Loss: 6.8857 - Test Loss: 19.9507 - MSE: 19.9507 - MAE: 3.5614\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5813/20000 - Train Loss: 6.8820 - Test Loss: 19.9428 - MSE: 19.9428 - MAE: 3.5606\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 5814/20000 - Train Loss: 6.8782 - Test Loss: 19.9349 - MSE: 19.9349 - MAE: 3.5598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5815/20000 - Train Loss: 6.8745 - Test Loss: 19.9270 - MSE: 19.9270 - MAE: 3.5590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5816/20000 - Train Loss: 6.8708 - Test Loss: 19.9190 - MSE: 19.9190 - MAE: 3.5582\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5817/20000 - Train Loss: 6.8670 - Test Loss: 19.9112 - MSE: 19.9112 - MAE: 3.5574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5818/20000 - Train Loss: 6.8633 - Test Loss: 19.9033 - MSE: 19.9033 - MAE: 3.5566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5819/20000 - Train Loss: 6.8595 - Test Loss: 19.8954 - MSE: 19.8954 - MAE: 3.5558\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5820/20000 - Train Loss: 6.8558 - Test Loss: 19.8875 - MSE: 19.8875 - MAE: 3.5550\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5821/20000 - Train Loss: 6.8521 - Test Loss: 19.8796 - MSE: 19.8796 - MAE: 3.5542\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5822/20000 - Train Loss: 6.8483 - Test Loss: 19.8717 - MSE: 19.8717 - MAE: 3.5534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5823/20000 - Train Loss: 6.8446 - Test Loss: 19.8638 - MSE: 19.8638 - MAE: 3.5527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5824/20000 - Train Loss: 6.8409 - Test Loss: 19.8559 - MSE: 19.8559 - MAE: 3.5519\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 5825/20000 - Train Loss: 6.8371 - Test Loss: 19.8480 - MSE: 19.8480 - MAE: 3.5511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5826/20000 - Train Loss: 6.8334 - Test Loss: 19.8401 - MSE: 19.8401 - MAE: 3.5503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5827/20000 - Train Loss: 6.8297 - Test Loss: 19.8322 - MSE: 19.8322 - MAE: 3.5495\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5828/20000 - Train Loss: 6.8259 - Test Loss: 19.8243 - MSE: 19.8243 - MAE: 3.5487\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5829/20000 - Train Loss: 6.8222 - Test Loss: 19.8165 - MSE: 19.8165 - MAE: 3.5479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5830/20000 - Train Loss: 6.8185 - Test Loss: 19.8086 - MSE: 19.8086 - MAE: 3.5471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5831/20000 - Train Loss: 6.8147 - Test Loss: 19.8007 - MSE: 19.8007 - MAE: 3.5463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5832/20000 - Train Loss: 6.8110 - Test Loss: 19.7928 - MSE: 19.7928 - MAE: 3.5455\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5833/20000 - Train Loss: 6.8073 - Test Loss: 19.7849 - MSE: 19.7849 - MAE: 3.5447\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5834/20000 - Train Loss: 6.8035 - Test Loss: 19.7770 - MSE: 19.7770 - MAE: 3.5439\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5835/20000 - Train Loss: 6.7998 - Test Loss: 19.7691 - MSE: 19.7691 - MAE: 3.5431\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5836/20000 - Train Loss: 6.7961 - Test Loss: 19.7613 - MSE: 19.7613 - MAE: 3.5423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5837/20000 - Train Loss: 6.7924 - Test Loss: 19.7534 - MSE: 19.7534 - MAE: 3.5415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5838/20000 - Train Loss: 6.7886 - Test Loss: 19.7456 - MSE: 19.7456 - MAE: 3.5407\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5839/20000 - Train Loss: 6.7849 - Test Loss: 19.7377 - MSE: 19.7377 - MAE: 3.5399\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5840/20000 - Train Loss: 6.7812 - Test Loss: 19.7298 - MSE: 19.7298 - MAE: 3.5392\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5841/20000 - Train Loss: 6.7775 - Test Loss: 19.7220 - MSE: 19.7220 - MAE: 3.5384\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5842/20000 - Train Loss: 6.7737 - Test Loss: 19.7141 - MSE: 19.7141 - MAE: 3.5376\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5843/20000 - Train Loss: 6.7700 - Test Loss: 19.7062 - MSE: 19.7062 - MAE: 3.5368\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5844/20000 - Train Loss: 6.7663 - Test Loss: 19.6983 - MSE: 19.6983 - MAE: 3.5360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5845/20000 - Train Loss: 6.7626 - Test Loss: 19.6905 - MSE: 19.6905 - MAE: 3.5352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5846/20000 - Train Loss: 6.7589 - Test Loss: 19.6826 - MSE: 19.6826 - MAE: 3.5344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5847/20000 - Train Loss: 6.7551 - Test Loss: 19.6747 - MSE: 19.6747 - MAE: 3.5336\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5848/20000 - Train Loss: 6.7514 - Test Loss: 19.6669 - MSE: 19.6669 - MAE: 3.5328\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 5849/20000 - Train Loss: 6.7477 - Test Loss: 19.6591 - MSE: 19.6591 - MAE: 3.5320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5850/20000 - Train Loss: 6.7440 - Test Loss: 19.6513 - MSE: 19.6513 - MAE: 3.5312\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5851/20000 - Train Loss: 6.7403 - Test Loss: 19.6435 - MSE: 19.6435 - MAE: 3.5304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5852/20000 - Train Loss: 6.7365 - Test Loss: 19.6356 - MSE: 19.6356 - MAE: 3.5296\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5853/20000 - Train Loss: 6.7328 - Test Loss: 19.6277 - MSE: 19.6277 - MAE: 3.5288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5854/20000 - Train Loss: 6.7291 - Test Loss: 19.6198 - MSE: 19.6198 - MAE: 3.5280\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5855/20000 - Train Loss: 6.7254 - Test Loss: 19.6119 - MSE: 19.6119 - MAE: 3.5272\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5856/20000 - Train Loss: 6.7217 - Test Loss: 19.6041 - MSE: 19.6041 - MAE: 3.5264\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5857/20000 - Train Loss: 6.7180 - Test Loss: 19.5963 - MSE: 19.5963 - MAE: 3.5256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5858/20000 - Train Loss: 6.7142 - Test Loss: 19.5885 - MSE: 19.5885 - MAE: 3.5248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5859/20000 - Train Loss: 6.7105 - Test Loss: 19.5807 - MSE: 19.5807 - MAE: 3.5240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5860/20000 - Train Loss: 6.7068 - Test Loss: 19.5728 - MSE: 19.5728 - MAE: 3.5232\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5861/20000 - Train Loss: 6.7031 - Test Loss: 19.5650 - MSE: 19.5650 - MAE: 3.5224\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5862/20000 - Train Loss: 6.6994 - Test Loss: 19.5572 - MSE: 19.5572 - MAE: 3.5216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5863/20000 - Train Loss: 6.6957 - Test Loss: 19.5493 - MSE: 19.5493 - MAE: 3.5208\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 5864/20000 - Train Loss: 6.6920 - Test Loss: 19.5415 - MSE: 19.5415 - MAE: 3.5200\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 5865/20000 - Train Loss: 6.6883 - Test Loss: 19.5336 - MSE: 19.5336 - MAE: 3.5192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5866/20000 - Train Loss: 6.6846 - Test Loss: 19.5258 - MSE: 19.5258 - MAE: 3.5184\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5867/20000 - Train Loss: 6.6809 - Test Loss: 19.5180 - MSE: 19.5180 - MAE: 3.5176\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5868/20000 - Train Loss: 6.6771 - Test Loss: 19.5102 - MSE: 19.5102 - MAE: 3.5168\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5869/20000 - Train Loss: 6.6734 - Test Loss: 19.5024 - MSE: 19.5024 - MAE: 3.5160\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5870/20000 - Train Loss: 6.6697 - Test Loss: 19.4946 - MSE: 19.4946 - MAE: 3.5152\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5871/20000 - Train Loss: 6.6660 - Test Loss: 19.4868 - MSE: 19.4868 - MAE: 3.5144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5872/20000 - Train Loss: 6.6623 - Test Loss: 19.4789 - MSE: 19.4789 - MAE: 3.5136\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5873/20000 - Train Loss: 6.6586 - Test Loss: 19.4711 - MSE: 19.4711 - MAE: 3.5128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5874/20000 - Train Loss: 6.6549 - Test Loss: 19.4632 - MSE: 19.4632 - MAE: 3.5120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5875/20000 - Train Loss: 6.6512 - Test Loss: 19.4555 - MSE: 19.4555 - MAE: 3.5112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5876/20000 - Train Loss: 6.6475 - Test Loss: 19.4476 - MSE: 19.4476 - MAE: 3.5104\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5877/20000 - Train Loss: 6.6438 - Test Loss: 19.4398 - MSE: 19.4398 - MAE: 3.5096\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5878/20000 - Train Loss: 6.6401 - Test Loss: 19.4320 - MSE: 19.4320 - MAE: 3.5088\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5879/20000 - Train Loss: 6.6364 - Test Loss: 19.4243 - MSE: 19.4243 - MAE: 3.5080\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5880/20000 - Train Loss: 6.6327 - Test Loss: 19.4165 - MSE: 19.4165 - MAE: 3.5072\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5881/20000 - Train Loss: 6.6290 - Test Loss: 19.4086 - MSE: 19.4086 - MAE: 3.5064\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 5882/20000 - Train Loss: 6.6253 - Test Loss: 19.4008 - MSE: 19.4008 - MAE: 3.5056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5883/20000 - Train Loss: 6.6216 - Test Loss: 19.3931 - MSE: 19.3931 - MAE: 3.5048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5884/20000 - Train Loss: 6.6179 - Test Loss: 19.3853 - MSE: 19.3853 - MAE: 3.5040\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5885/20000 - Train Loss: 6.6142 - Test Loss: 19.3774 - MSE: 19.3774 - MAE: 3.5032\n",
      "2/2 [==============================] - 0s 21ms/step\n",
      "Epoch 5886/20000 - Train Loss: 6.6105 - Test Loss: 19.3696 - MSE: 19.3696 - MAE: 3.5024\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5887/20000 - Train Loss: 6.6069 - Test Loss: 19.3619 - MSE: 19.3619 - MAE: 3.5016\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 5888/20000 - Train Loss: 6.6032 - Test Loss: 19.3540 - MSE: 19.3540 - MAE: 3.5008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5889/20000 - Train Loss: 6.5995 - Test Loss: 19.3463 - MSE: 19.3463 - MAE: 3.5000\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5890/20000 - Train Loss: 6.5958 - Test Loss: 19.3385 - MSE: 19.3385 - MAE: 3.4992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5891/20000 - Train Loss: 6.5921 - Test Loss: 19.3308 - MSE: 19.3308 - MAE: 3.4984\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5892/20000 - Train Loss: 6.5884 - Test Loss: 19.3230 - MSE: 19.3230 - MAE: 3.4976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5893/20000 - Train Loss: 6.5847 - Test Loss: 19.3152 - MSE: 19.3152 - MAE: 3.4968\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5894/20000 - Train Loss: 6.5810 - Test Loss: 19.3074 - MSE: 19.3074 - MAE: 3.4960\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5895/20000 - Train Loss: 6.5773 - Test Loss: 19.2996 - MSE: 19.2996 - MAE: 3.4952\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5896/20000 - Train Loss: 6.5737 - Test Loss: 19.2918 - MSE: 19.2918 - MAE: 3.4944\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5897/20000 - Train Loss: 6.5700 - Test Loss: 19.2841 - MSE: 19.2841 - MAE: 3.4936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5898/20000 - Train Loss: 6.5663 - Test Loss: 19.2762 - MSE: 19.2762 - MAE: 3.4928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5899/20000 - Train Loss: 6.5626 - Test Loss: 19.2685 - MSE: 19.2685 - MAE: 3.4920\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5900/20000 - Train Loss: 6.5589 - Test Loss: 19.2607 - MSE: 19.2607 - MAE: 3.4912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5901/20000 - Train Loss: 6.5552 - Test Loss: 19.2529 - MSE: 19.2529 - MAE: 3.4904\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5902/20000 - Train Loss: 6.5515 - Test Loss: 19.2452 - MSE: 19.2452 - MAE: 3.4896\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5903/20000 - Train Loss: 6.5479 - Test Loss: 19.2375 - MSE: 19.2375 - MAE: 3.4888\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5904/20000 - Train Loss: 6.5442 - Test Loss: 19.2297 - MSE: 19.2297 - MAE: 3.4880\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5905/20000 - Train Loss: 6.5405 - Test Loss: 19.2220 - MSE: 19.2220 - MAE: 3.4872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5906/20000 - Train Loss: 6.5368 - Test Loss: 19.2142 - MSE: 19.2142 - MAE: 3.4864\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5907/20000 - Train Loss: 6.5331 - Test Loss: 19.2064 - MSE: 19.2064 - MAE: 3.4856\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 5908/20000 - Train Loss: 6.5295 - Test Loss: 19.1987 - MSE: 19.1987 - MAE: 3.4848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5909/20000 - Train Loss: 6.5258 - Test Loss: 19.1909 - MSE: 19.1909 - MAE: 3.4839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5910/20000 - Train Loss: 6.5221 - Test Loss: 19.1831 - MSE: 19.1831 - MAE: 3.4831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5911/20000 - Train Loss: 6.5184 - Test Loss: 19.1754 - MSE: 19.1754 - MAE: 3.4823\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5912/20000 - Train Loss: 6.5148 - Test Loss: 19.1676 - MSE: 19.1676 - MAE: 3.4815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5913/20000 - Train Loss: 6.5111 - Test Loss: 19.1599 - MSE: 19.1599 - MAE: 3.4807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5914/20000 - Train Loss: 6.5074 - Test Loss: 19.1522 - MSE: 19.1522 - MAE: 3.4799\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5915/20000 - Train Loss: 6.5037 - Test Loss: 19.1444 - MSE: 19.1444 - MAE: 3.4791\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5916/20000 - Train Loss: 6.5001 - Test Loss: 19.1367 - MSE: 19.1367 - MAE: 3.4783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5917/20000 - Train Loss: 6.4964 - Test Loss: 19.1289 - MSE: 19.1289 - MAE: 3.4775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5918/20000 - Train Loss: 6.4927 - Test Loss: 19.1212 - MSE: 19.1212 - MAE: 3.4767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5919/20000 - Train Loss: 6.4890 - Test Loss: 19.1135 - MSE: 19.1135 - MAE: 3.4759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5920/20000 - Train Loss: 6.4854 - Test Loss: 19.1057 - MSE: 19.1057 - MAE: 3.4751\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5921/20000 - Train Loss: 6.4817 - Test Loss: 19.0980 - MSE: 19.0980 - MAE: 3.4743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5922/20000 - Train Loss: 6.4780 - Test Loss: 19.0902 - MSE: 19.0902 - MAE: 3.4735\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5923/20000 - Train Loss: 6.4744 - Test Loss: 19.0825 - MSE: 19.0825 - MAE: 3.4727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5924/20000 - Train Loss: 6.4707 - Test Loss: 19.0748 - MSE: 19.0748 - MAE: 3.4719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5925/20000 - Train Loss: 6.4670 - Test Loss: 19.0671 - MSE: 19.0671 - MAE: 3.4711\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 5926/20000 - Train Loss: 6.4634 - Test Loss: 19.0594 - MSE: 19.0594 - MAE: 3.4703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5927/20000 - Train Loss: 6.4597 - Test Loss: 19.0517 - MSE: 19.0517 - MAE: 3.4694\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 5928/20000 - Train Loss: 6.4560 - Test Loss: 19.0439 - MSE: 19.0439 - MAE: 3.4686\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 5929/20000 - Train Loss: 6.4524 - Test Loss: 19.0361 - MSE: 19.0361 - MAE: 3.4678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5930/20000 - Train Loss: 6.4487 - Test Loss: 19.0285 - MSE: 19.0285 - MAE: 3.4670\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5931/20000 - Train Loss: 6.4451 - Test Loss: 19.0207 - MSE: 19.0207 - MAE: 3.4662\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5932/20000 - Train Loss: 6.4414 - Test Loss: 19.0131 - MSE: 19.0131 - MAE: 3.4654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5933/20000 - Train Loss: 6.4377 - Test Loss: 19.0053 - MSE: 19.0053 - MAE: 3.4646\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 5934/20000 - Train Loss: 6.4341 - Test Loss: 18.9976 - MSE: 18.9976 - MAE: 3.4638\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 5935/20000 - Train Loss: 6.4304 - Test Loss: 18.9899 - MSE: 18.9899 - MAE: 3.4630\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5936/20000 - Train Loss: 6.4268 - Test Loss: 18.9822 - MSE: 18.9822 - MAE: 3.4622\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5937/20000 - Train Loss: 6.4231 - Test Loss: 18.9745 - MSE: 18.9745 - MAE: 3.4614\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5938/20000 - Train Loss: 6.4194 - Test Loss: 18.9668 - MSE: 18.9668 - MAE: 3.4606\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 5939/20000 - Train Loss: 6.4158 - Test Loss: 18.9591 - MSE: 18.9591 - MAE: 3.4598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5940/20000 - Train Loss: 6.4121 - Test Loss: 18.9514 - MSE: 18.9514 - MAE: 3.4590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5941/20000 - Train Loss: 6.4085 - Test Loss: 18.9437 - MSE: 18.9437 - MAE: 3.4581\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 5942/20000 - Train Loss: 6.4048 - Test Loss: 18.9361 - MSE: 18.9361 - MAE: 3.4573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5943/20000 - Train Loss: 6.4012 - Test Loss: 18.9283 - MSE: 18.9283 - MAE: 3.4565\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5944/20000 - Train Loss: 6.3975 - Test Loss: 18.9206 - MSE: 18.9206 - MAE: 3.4557\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 5945/20000 - Train Loss: 6.3939 - Test Loss: 18.9129 - MSE: 18.9129 - MAE: 3.4549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5946/20000 - Train Loss: 6.3902 - Test Loss: 18.9053 - MSE: 18.9053 - MAE: 3.4541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5947/20000 - Train Loss: 6.3866 - Test Loss: 18.8976 - MSE: 18.8976 - MAE: 3.4533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5948/20000 - Train Loss: 6.3829 - Test Loss: 18.8899 - MSE: 18.8899 - MAE: 3.4525\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5949/20000 - Train Loss: 6.3793 - Test Loss: 18.8822 - MSE: 18.8822 - MAE: 3.4517\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 5950/20000 - Train Loss: 6.3756 - Test Loss: 18.8745 - MSE: 18.8745 - MAE: 3.4509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5951/20000 - Train Loss: 6.3720 - Test Loss: 18.8668 - MSE: 18.8668 - MAE: 3.4501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5952/20000 - Train Loss: 6.3683 - Test Loss: 18.8592 - MSE: 18.8592 - MAE: 3.4492\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5953/20000 - Train Loss: 6.3647 - Test Loss: 18.8515 - MSE: 18.8515 - MAE: 3.4484\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5954/20000 - Train Loss: 6.3610 - Test Loss: 18.8438 - MSE: 18.8438 - MAE: 3.4476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5955/20000 - Train Loss: 6.3574 - Test Loss: 18.8362 - MSE: 18.8362 - MAE: 3.4468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5956/20000 - Train Loss: 6.3538 - Test Loss: 18.8285 - MSE: 18.8285 - MAE: 3.4460\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 5957/20000 - Train Loss: 6.3501 - Test Loss: 18.8208 - MSE: 18.8208 - MAE: 3.4452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5958/20000 - Train Loss: 6.3465 - Test Loss: 18.8131 - MSE: 18.8131 - MAE: 3.4444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5959/20000 - Train Loss: 6.3428 - Test Loss: 18.8054 - MSE: 18.8054 - MAE: 3.4436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5960/20000 - Train Loss: 6.3392 - Test Loss: 18.7978 - MSE: 18.7978 - MAE: 3.4428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5961/20000 - Train Loss: 6.3355 - Test Loss: 18.7901 - MSE: 18.7901 - MAE: 3.4419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5962/20000 - Train Loss: 6.3319 - Test Loss: 18.7825 - MSE: 18.7825 - MAE: 3.4411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5963/20000 - Train Loss: 6.3283 - Test Loss: 18.7748 - MSE: 18.7748 - MAE: 3.4403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5964/20000 - Train Loss: 6.3246 - Test Loss: 18.7672 - MSE: 18.7672 - MAE: 3.4395\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5965/20000 - Train Loss: 6.3210 - Test Loss: 18.7595 - MSE: 18.7595 - MAE: 3.4387\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5966/20000 - Train Loss: 6.3174 - Test Loss: 18.7518 - MSE: 18.7518 - MAE: 3.4379\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5967/20000 - Train Loss: 6.3137 - Test Loss: 18.7442 - MSE: 18.7442 - MAE: 3.4371\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5968/20000 - Train Loss: 6.3101 - Test Loss: 18.7366 - MSE: 18.7366 - MAE: 3.4363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5969/20000 - Train Loss: 6.3065 - Test Loss: 18.7289 - MSE: 18.7289 - MAE: 3.4355\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 5970/20000 - Train Loss: 6.3028 - Test Loss: 18.7213 - MSE: 18.7213 - MAE: 3.4346\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 5971/20000 - Train Loss: 6.2992 - Test Loss: 18.7137 - MSE: 18.7137 - MAE: 3.4338\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5972/20000 - Train Loss: 6.2956 - Test Loss: 18.7060 - MSE: 18.7060 - MAE: 3.4330\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5973/20000 - Train Loss: 6.2919 - Test Loss: 18.6984 - MSE: 18.6984 - MAE: 3.4322\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5974/20000 - Train Loss: 6.2883 - Test Loss: 18.6907 - MSE: 18.6907 - MAE: 3.4314\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 5975/20000 - Train Loss: 6.2847 - Test Loss: 18.6831 - MSE: 18.6831 - MAE: 3.4306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5976/20000 - Train Loss: 6.2811 - Test Loss: 18.6754 - MSE: 18.6754 - MAE: 3.4298\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5977/20000 - Train Loss: 6.2774 - Test Loss: 18.6678 - MSE: 18.6678 - MAE: 3.4290\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 5978/20000 - Train Loss: 6.2738 - Test Loss: 18.6602 - MSE: 18.6602 - MAE: 3.4281\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5979/20000 - Train Loss: 6.2702 - Test Loss: 18.6526 - MSE: 18.6526 - MAE: 3.4273\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 5980/20000 - Train Loss: 6.2666 - Test Loss: 18.6450 - MSE: 18.6450 - MAE: 3.4265\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5981/20000 - Train Loss: 6.2629 - Test Loss: 18.6373 - MSE: 18.6373 - MAE: 3.4257\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5982/20000 - Train Loss: 6.2593 - Test Loss: 18.6297 - MSE: 18.6297 - MAE: 3.4249\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5983/20000 - Train Loss: 6.2557 - Test Loss: 18.6221 - MSE: 18.6221 - MAE: 3.4241\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5984/20000 - Train Loss: 6.2521 - Test Loss: 18.6145 - MSE: 18.6145 - MAE: 3.4233\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 5985/20000 - Train Loss: 6.2484 - Test Loss: 18.6068 - MSE: 18.6068 - MAE: 3.4225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5986/20000 - Train Loss: 6.2448 - Test Loss: 18.5992 - MSE: 18.5992 - MAE: 3.4216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5987/20000 - Train Loss: 6.2412 - Test Loss: 18.5915 - MSE: 18.5915 - MAE: 3.4208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5988/20000 - Train Loss: 6.2376 - Test Loss: 18.5840 - MSE: 18.5840 - MAE: 3.4200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5989/20000 - Train Loss: 6.2340 - Test Loss: 18.5764 - MSE: 18.5764 - MAE: 3.4192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5990/20000 - Train Loss: 6.2304 - Test Loss: 18.5688 - MSE: 18.5688 - MAE: 3.4184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5991/20000 - Train Loss: 6.2267 - Test Loss: 18.5612 - MSE: 18.5612 - MAE: 3.4176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5992/20000 - Train Loss: 6.2231 - Test Loss: 18.5536 - MSE: 18.5536 - MAE: 3.4168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5993/20000 - Train Loss: 6.2195 - Test Loss: 18.5460 - MSE: 18.5460 - MAE: 3.4159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5994/20000 - Train Loss: 6.2159 - Test Loss: 18.5384 - MSE: 18.5384 - MAE: 3.4151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5995/20000 - Train Loss: 6.2123 - Test Loss: 18.5308 - MSE: 18.5308 - MAE: 3.4143\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 5996/20000 - Train Loss: 6.2087 - Test Loss: 18.5232 - MSE: 18.5232 - MAE: 3.4135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5997/20000 - Train Loss: 6.2051 - Test Loss: 18.5156 - MSE: 18.5156 - MAE: 3.4127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5998/20000 - Train Loss: 6.2015 - Test Loss: 18.5080 - MSE: 18.5080 - MAE: 3.4119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 5999/20000 - Train Loss: 6.1979 - Test Loss: 18.5004 - MSE: 18.5004 - MAE: 3.4111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6000/20000 - Train Loss: 6.1942 - Test Loss: 18.4928 - MSE: 18.4928 - MAE: 3.4102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6001/20000 - Train Loss: 6.1906 - Test Loss: 18.4853 - MSE: 18.4853 - MAE: 3.4094\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6002/20000 - Train Loss: 6.1870 - Test Loss: 18.4777 - MSE: 18.4777 - MAE: 3.4086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6003/20000 - Train Loss: 6.1834 - Test Loss: 18.4701 - MSE: 18.4701 - MAE: 3.4078\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6004/20000 - Train Loss: 6.1798 - Test Loss: 18.4625 - MSE: 18.4625 - MAE: 3.4070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6005/20000 - Train Loss: 6.1762 - Test Loss: 18.4549 - MSE: 18.4549 - MAE: 3.4062\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6006/20000 - Train Loss: 6.1726 - Test Loss: 18.4474 - MSE: 18.4474 - MAE: 3.4053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6007/20000 - Train Loss: 6.1690 - Test Loss: 18.4398 - MSE: 18.4398 - MAE: 3.4045\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6008/20000 - Train Loss: 6.1654 - Test Loss: 18.4322 - MSE: 18.4322 - MAE: 3.4037\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6009/20000 - Train Loss: 6.1618 - Test Loss: 18.4246 - MSE: 18.4246 - MAE: 3.4029\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6010/20000 - Train Loss: 6.1582 - Test Loss: 18.4171 - MSE: 18.4171 - MAE: 3.4021\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6011/20000 - Train Loss: 6.1546 - Test Loss: 18.4095 - MSE: 18.4095 - MAE: 3.4013\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6012/20000 - Train Loss: 6.1510 - Test Loss: 18.4019 - MSE: 18.4019 - MAE: 3.4004\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 6013/20000 - Train Loss: 6.1474 - Test Loss: 18.3944 - MSE: 18.3944 - MAE: 3.3996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6014/20000 - Train Loss: 6.1438 - Test Loss: 18.3869 - MSE: 18.3869 - MAE: 3.3988\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 6015/20000 - Train Loss: 6.1402 - Test Loss: 18.3793 - MSE: 18.3793 - MAE: 3.3980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6016/20000 - Train Loss: 6.1366 - Test Loss: 18.3717 - MSE: 18.3717 - MAE: 3.3972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6017/20000 - Train Loss: 6.1330 - Test Loss: 18.3641 - MSE: 18.3641 - MAE: 3.3964\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6018/20000 - Train Loss: 6.1294 - Test Loss: 18.3566 - MSE: 18.3566 - MAE: 3.3955\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6019/20000 - Train Loss: 6.1259 - Test Loss: 18.3491 - MSE: 18.3491 - MAE: 3.3947\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 6020/20000 - Train Loss: 6.1223 - Test Loss: 18.3415 - MSE: 18.3415 - MAE: 3.3939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6021/20000 - Train Loss: 6.1187 - Test Loss: 18.3339 - MSE: 18.3340 - MAE: 3.3931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6022/20000 - Train Loss: 6.1151 - Test Loss: 18.3264 - MSE: 18.3264 - MAE: 3.3923\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6023/20000 - Train Loss: 6.1115 - Test Loss: 18.3189 - MSE: 18.3189 - MAE: 3.3915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6024/20000 - Train Loss: 6.1079 - Test Loss: 18.3113 - MSE: 18.3113 - MAE: 3.3906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6025/20000 - Train Loss: 6.1043 - Test Loss: 18.3038 - MSE: 18.3038 - MAE: 3.3898\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 6026/20000 - Train Loss: 6.1007 - Test Loss: 18.2963 - MSE: 18.2963 - MAE: 3.3890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6027/20000 - Train Loss: 6.0971 - Test Loss: 18.2887 - MSE: 18.2887 - MAE: 3.3882\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 6028/20000 - Train Loss: 6.0936 - Test Loss: 18.2812 - MSE: 18.2812 - MAE: 3.3874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6029/20000 - Train Loss: 6.0900 - Test Loss: 18.2736 - MSE: 18.2736 - MAE: 3.3865\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6030/20000 - Train Loss: 6.0864 - Test Loss: 18.2661 - MSE: 18.2661 - MAE: 3.3857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6031/20000 - Train Loss: 6.0828 - Test Loss: 18.2586 - MSE: 18.2586 - MAE: 3.3849\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6032/20000 - Train Loss: 6.0792 - Test Loss: 18.2511 - MSE: 18.2511 - MAE: 3.3841\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 6033/20000 - Train Loss: 6.0757 - Test Loss: 18.2436 - MSE: 18.2436 - MAE: 3.3833\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6034/20000 - Train Loss: 6.0721 - Test Loss: 18.2361 - MSE: 18.2361 - MAE: 3.3825\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 6035/20000 - Train Loss: 6.0685 - Test Loss: 18.2286 - MSE: 18.2286 - MAE: 3.3816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6036/20000 - Train Loss: 6.0649 - Test Loss: 18.2211 - MSE: 18.2211 - MAE: 3.3808\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6037/20000 - Train Loss: 6.0613 - Test Loss: 18.2135 - MSE: 18.2135 - MAE: 3.3800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6038/20000 - Train Loss: 6.0578 - Test Loss: 18.2060 - MSE: 18.2060 - MAE: 3.3792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6039/20000 - Train Loss: 6.0542 - Test Loss: 18.1984 - MSE: 18.1984 - MAE: 3.3784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6040/20000 - Train Loss: 6.0506 - Test Loss: 18.1909 - MSE: 18.1909 - MAE: 3.3775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6041/20000 - Train Loss: 6.0470 - Test Loss: 18.1834 - MSE: 18.1834 - MAE: 3.3767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6042/20000 - Train Loss: 6.0435 - Test Loss: 18.1759 - MSE: 18.1760 - MAE: 3.3759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6043/20000 - Train Loss: 6.0399 - Test Loss: 18.1685 - MSE: 18.1685 - MAE: 3.3751\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6044/20000 - Train Loss: 6.0363 - Test Loss: 18.1610 - MSE: 18.1610 - MAE: 3.3743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6045/20000 - Train Loss: 6.0328 - Test Loss: 18.1535 - MSE: 18.1535 - MAE: 3.3734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6046/20000 - Train Loss: 6.0292 - Test Loss: 18.1460 - MSE: 18.1460 - MAE: 3.3726\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6047/20000 - Train Loss: 6.0256 - Test Loss: 18.1385 - MSE: 18.1385 - MAE: 3.3718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6048/20000 - Train Loss: 6.0221 - Test Loss: 18.1310 - MSE: 18.1310 - MAE: 3.3710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6049/20000 - Train Loss: 6.0185 - Test Loss: 18.1235 - MSE: 18.1235 - MAE: 3.3701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6050/20000 - Train Loss: 6.0149 - Test Loss: 18.1160 - MSE: 18.1160 - MAE: 3.3693\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 6051/20000 - Train Loss: 6.0114 - Test Loss: 18.1085 - MSE: 18.1085 - MAE: 3.3685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6052/20000 - Train Loss: 6.0078 - Test Loss: 18.1010 - MSE: 18.1010 - MAE: 3.3677\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6053/20000 - Train Loss: 6.0042 - Test Loss: 18.0936 - MSE: 18.0936 - MAE: 3.3669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6054/20000 - Train Loss: 6.0007 - Test Loss: 18.0861 - MSE: 18.0861 - MAE: 3.3661\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6055/20000 - Train Loss: 5.9971 - Test Loss: 18.0786 - MSE: 18.0786 - MAE: 3.3652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6056/20000 - Train Loss: 5.9935 - Test Loss: 18.0712 - MSE: 18.0712 - MAE: 3.3644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6057/20000 - Train Loss: 5.9900 - Test Loss: 18.0637 - MSE: 18.0637 - MAE: 3.3636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6058/20000 - Train Loss: 5.9864 - Test Loss: 18.0562 - MSE: 18.0562 - MAE: 3.3628\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6059/20000 - Train Loss: 5.9829 - Test Loss: 18.0487 - MSE: 18.0487 - MAE: 3.3619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6060/20000 - Train Loss: 5.9793 - Test Loss: 18.0412 - MSE: 18.0412 - MAE: 3.3611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6061/20000 - Train Loss: 5.9758 - Test Loss: 18.0338 - MSE: 18.0338 - MAE: 3.3603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6062/20000 - Train Loss: 5.9722 - Test Loss: 18.0263 - MSE: 18.0263 - MAE: 3.3595\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 6063/20000 - Train Loss: 5.9686 - Test Loss: 18.0189 - MSE: 18.0189 - MAE: 3.3587\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 6064/20000 - Train Loss: 5.9651 - Test Loss: 18.0115 - MSE: 18.0115 - MAE: 3.3578\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6065/20000 - Train Loss: 5.9615 - Test Loss: 18.0040 - MSE: 18.0040 - MAE: 3.3570\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6066/20000 - Train Loss: 5.9580 - Test Loss: 17.9965 - MSE: 17.9965 - MAE: 3.3562\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6067/20000 - Train Loss: 5.9544 - Test Loss: 17.9890 - MSE: 17.9890 - MAE: 3.3554\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6068/20000 - Train Loss: 5.9509 - Test Loss: 17.9816 - MSE: 17.9816 - MAE: 3.3545\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6069/20000 - Train Loss: 5.9473 - Test Loss: 17.9741 - MSE: 17.9741 - MAE: 3.3537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6070/20000 - Train Loss: 5.9438 - Test Loss: 17.9667 - MSE: 17.9667 - MAE: 3.3529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6071/20000 - Train Loss: 5.9402 - Test Loss: 17.9593 - MSE: 17.9593 - MAE: 3.3521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6072/20000 - Train Loss: 5.9367 - Test Loss: 17.9518 - MSE: 17.9518 - MAE: 3.3512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6073/20000 - Train Loss: 5.9332 - Test Loss: 17.9444 - MSE: 17.9444 - MAE: 3.3504\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6074/20000 - Train Loss: 5.9296 - Test Loss: 17.9370 - MSE: 17.9370 - MAE: 3.3496\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6075/20000 - Train Loss: 5.9261 - Test Loss: 17.9296 - MSE: 17.9296 - MAE: 3.3488\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6076/20000 - Train Loss: 5.9225 - Test Loss: 17.9221 - MSE: 17.9221 - MAE: 3.3480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6077/20000 - Train Loss: 5.9190 - Test Loss: 17.9147 - MSE: 17.9147 - MAE: 3.3471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6078/20000 - Train Loss: 5.9154 - Test Loss: 17.9072 - MSE: 17.9072 - MAE: 3.3463\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6079/20000 - Train Loss: 5.9119 - Test Loss: 17.8998 - MSE: 17.8998 - MAE: 3.3455\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6080/20000 - Train Loss: 5.9084 - Test Loss: 17.8923 - MSE: 17.8923 - MAE: 3.3447\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6081/20000 - Train Loss: 5.9048 - Test Loss: 17.8849 - MSE: 17.8849 - MAE: 3.3438\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6082/20000 - Train Loss: 5.9013 - Test Loss: 17.8775 - MSE: 17.8775 - MAE: 3.3430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6083/20000 - Train Loss: 5.8978 - Test Loss: 17.8701 - MSE: 17.8701 - MAE: 3.3422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6084/20000 - Train Loss: 5.8942 - Test Loss: 17.8627 - MSE: 17.8627 - MAE: 3.3414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6085/20000 - Train Loss: 5.8907 - Test Loss: 17.8553 - MSE: 17.8553 - MAE: 3.3405\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6086/20000 - Train Loss: 5.8871 - Test Loss: 17.8479 - MSE: 17.8479 - MAE: 3.3397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6087/20000 - Train Loss: 5.8836 - Test Loss: 17.8405 - MSE: 17.8405 - MAE: 3.3389\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 6088/20000 - Train Loss: 5.8801 - Test Loss: 17.8331 - MSE: 17.8331 - MAE: 3.3381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6089/20000 - Train Loss: 5.8766 - Test Loss: 17.8256 - MSE: 17.8256 - MAE: 3.3372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6090/20000 - Train Loss: 5.8730 - Test Loss: 17.8182 - MSE: 17.8182 - MAE: 3.3364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6091/20000 - Train Loss: 5.8695 - Test Loss: 17.8108 - MSE: 17.8108 - MAE: 3.3356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6092/20000 - Train Loss: 5.8660 - Test Loss: 17.8034 - MSE: 17.8034 - MAE: 3.3348\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6093/20000 - Train Loss: 5.8624 - Test Loss: 17.7960 - MSE: 17.7960 - MAE: 3.3339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6094/20000 - Train Loss: 5.8589 - Test Loss: 17.7887 - MSE: 17.7887 - MAE: 3.3331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6095/20000 - Train Loss: 5.8554 - Test Loss: 17.7813 - MSE: 17.7813 - MAE: 3.3323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6096/20000 - Train Loss: 5.8519 - Test Loss: 17.7739 - MSE: 17.7739 - MAE: 3.3315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6097/20000 - Train Loss: 5.8483 - Test Loss: 17.7665 - MSE: 17.7665 - MAE: 3.3306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6098/20000 - Train Loss: 5.8448 - Test Loss: 17.7591 - MSE: 17.7591 - MAE: 3.3298\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6099/20000 - Train Loss: 5.8413 - Test Loss: 17.7517 - MSE: 17.7517 - MAE: 3.3290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6100/20000 - Train Loss: 5.8378 - Test Loss: 17.7443 - MSE: 17.7443 - MAE: 3.3282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6101/20000 - Train Loss: 5.8343 - Test Loss: 17.7369 - MSE: 17.7369 - MAE: 3.3273\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6102/20000 - Train Loss: 5.8307 - Test Loss: 17.7295 - MSE: 17.7295 - MAE: 3.3265\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 6103/20000 - Train Loss: 5.8272 - Test Loss: 17.7222 - MSE: 17.7222 - MAE: 3.3257\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6104/20000 - Train Loss: 5.8237 - Test Loss: 17.7148 - MSE: 17.7148 - MAE: 3.3249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6105/20000 - Train Loss: 5.8202 - Test Loss: 17.7075 - MSE: 17.7075 - MAE: 3.3240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6106/20000 - Train Loss: 5.8167 - Test Loss: 17.7001 - MSE: 17.7001 - MAE: 3.3232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6107/20000 - Train Loss: 5.8132 - Test Loss: 17.6927 - MSE: 17.6927 - MAE: 3.3224\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6108/20000 - Train Loss: 5.8096 - Test Loss: 17.6853 - MSE: 17.6853 - MAE: 3.3215\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6109/20000 - Train Loss: 5.8061 - Test Loss: 17.6780 - MSE: 17.6780 - MAE: 3.3207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6110/20000 - Train Loss: 5.8026 - Test Loss: 17.6706 - MSE: 17.6706 - MAE: 3.3199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6111/20000 - Train Loss: 5.7991 - Test Loss: 17.6632 - MSE: 17.6632 - MAE: 3.3191\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 6112/20000 - Train Loss: 5.7956 - Test Loss: 17.6559 - MSE: 17.6559 - MAE: 3.3182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6113/20000 - Train Loss: 5.7921 - Test Loss: 17.6486 - MSE: 17.6486 - MAE: 3.3174\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6114/20000 - Train Loss: 5.7886 - Test Loss: 17.6412 - MSE: 17.6412 - MAE: 3.3166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6115/20000 - Train Loss: 5.7851 - Test Loss: 17.6339 - MSE: 17.6339 - MAE: 3.3158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6116/20000 - Train Loss: 5.7816 - Test Loss: 17.6265 - MSE: 17.6265 - MAE: 3.3149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6117/20000 - Train Loss: 5.7781 - Test Loss: 17.6192 - MSE: 17.6192 - MAE: 3.3141\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6118/20000 - Train Loss: 5.7746 - Test Loss: 17.6118 - MSE: 17.6118 - MAE: 3.3133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6119/20000 - Train Loss: 5.7711 - Test Loss: 17.6045 - MSE: 17.6045 - MAE: 3.3124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6120/20000 - Train Loss: 5.7676 - Test Loss: 17.5971 - MSE: 17.5971 - MAE: 3.3116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6121/20000 - Train Loss: 5.7641 - Test Loss: 17.5898 - MSE: 17.5898 - MAE: 3.3108\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6122/20000 - Train Loss: 5.7606 - Test Loss: 17.5825 - MSE: 17.5825 - MAE: 3.3100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6123/20000 - Train Loss: 5.7571 - Test Loss: 17.5751 - MSE: 17.5751 - MAE: 3.3091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6124/20000 - Train Loss: 5.7536 - Test Loss: 17.5678 - MSE: 17.5678 - MAE: 3.3083\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 6125/20000 - Train Loss: 5.7501 - Test Loss: 17.5605 - MSE: 17.5605 - MAE: 3.3075\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6126/20000 - Train Loss: 5.7466 - Test Loss: 17.5532 - MSE: 17.5532 - MAE: 3.3067\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6127/20000 - Train Loss: 5.7431 - Test Loss: 17.5458 - MSE: 17.5458 - MAE: 3.3058\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6128/20000 - Train Loss: 5.7396 - Test Loss: 17.5385 - MSE: 17.5385 - MAE: 3.3050\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6129/20000 - Train Loss: 5.7361 - Test Loss: 17.5312 - MSE: 17.5312 - MAE: 3.3042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6130/20000 - Train Loss: 5.7326 - Test Loss: 17.5239 - MSE: 17.5239 - MAE: 3.3033\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6131/20000 - Train Loss: 5.7291 - Test Loss: 17.5166 - MSE: 17.5166 - MAE: 3.3025\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6132/20000 - Train Loss: 5.7256 - Test Loss: 17.5093 - MSE: 17.5093 - MAE: 3.3017\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6133/20000 - Train Loss: 5.7221 - Test Loss: 17.5020 - MSE: 17.5020 - MAE: 3.3008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6134/20000 - Train Loss: 5.7186 - Test Loss: 17.4947 - MSE: 17.4947 - MAE: 3.3000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6135/20000 - Train Loss: 5.7151 - Test Loss: 17.4874 - MSE: 17.4874 - MAE: 3.2992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6136/20000 - Train Loss: 5.7117 - Test Loss: 17.4800 - MSE: 17.4800 - MAE: 3.2984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6137/20000 - Train Loss: 5.7082 - Test Loss: 17.4727 - MSE: 17.4727 - MAE: 3.2975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6138/20000 - Train Loss: 5.7047 - Test Loss: 17.4654 - MSE: 17.4654 - MAE: 3.2967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6139/20000 - Train Loss: 5.7012 - Test Loss: 17.4581 - MSE: 17.4581 - MAE: 3.2959\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6140/20000 - Train Loss: 5.6977 - Test Loss: 17.4508 - MSE: 17.4508 - MAE: 3.2950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6141/20000 - Train Loss: 5.6942 - Test Loss: 17.4436 - MSE: 17.4436 - MAE: 3.2942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6142/20000 - Train Loss: 5.6908 - Test Loss: 17.4363 - MSE: 17.4363 - MAE: 3.2934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6143/20000 - Train Loss: 5.6873 - Test Loss: 17.4290 - MSE: 17.4290 - MAE: 3.2925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6144/20000 - Train Loss: 5.6838 - Test Loss: 17.4217 - MSE: 17.4217 - MAE: 3.2917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6145/20000 - Train Loss: 5.6803 - Test Loss: 17.4144 - MSE: 17.4144 - MAE: 3.2909\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 6146/20000 - Train Loss: 5.6768 - Test Loss: 17.4071 - MSE: 17.4071 - MAE: 3.2901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6147/20000 - Train Loss: 5.6734 - Test Loss: 17.3999 - MSE: 17.3999 - MAE: 3.2892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6148/20000 - Train Loss: 5.6699 - Test Loss: 17.3926 - MSE: 17.3926 - MAE: 3.2884\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6149/20000 - Train Loss: 5.6664 - Test Loss: 17.3853 - MSE: 17.3853 - MAE: 3.2876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6150/20000 - Train Loss: 5.6630 - Test Loss: 17.3781 - MSE: 17.3781 - MAE: 3.2867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6151/20000 - Train Loss: 5.6595 - Test Loss: 17.3708 - MSE: 17.3708 - MAE: 3.2859\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6152/20000 - Train Loss: 5.6560 - Test Loss: 17.3635 - MSE: 17.3635 - MAE: 3.2851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6153/20000 - Train Loss: 5.6525 - Test Loss: 17.3562 - MSE: 17.3562 - MAE: 3.2843\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6154/20000 - Train Loss: 5.6491 - Test Loss: 17.3490 - MSE: 17.3490 - MAE: 3.2836\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6155/20000 - Train Loss: 5.6456 - Test Loss: 17.3417 - MSE: 17.3417 - MAE: 3.2828\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 6156/20000 - Train Loss: 5.6421 - Test Loss: 17.3345 - MSE: 17.3345 - MAE: 3.2820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6157/20000 - Train Loss: 5.6387 - Test Loss: 17.3273 - MSE: 17.3273 - MAE: 3.2812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6158/20000 - Train Loss: 5.6352 - Test Loss: 17.3200 - MSE: 17.3200 - MAE: 3.2804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6159/20000 - Train Loss: 5.6317 - Test Loss: 17.3127 - MSE: 17.3127 - MAE: 3.2796\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6160/20000 - Train Loss: 5.6283 - Test Loss: 17.3055 - MSE: 17.3055 - MAE: 3.2788\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6161/20000 - Train Loss: 5.6248 - Test Loss: 17.2982 - MSE: 17.2982 - MAE: 3.2780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6162/20000 - Train Loss: 5.6214 - Test Loss: 17.2909 - MSE: 17.2909 - MAE: 3.2772\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 6163/20000 - Train Loss: 5.6179 - Test Loss: 17.2837 - MSE: 17.2837 - MAE: 3.2764\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6164/20000 - Train Loss: 5.6144 - Test Loss: 17.2765 - MSE: 17.2765 - MAE: 3.2756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6165/20000 - Train Loss: 5.6110 - Test Loss: 17.2693 - MSE: 17.2693 - MAE: 3.2748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6166/20000 - Train Loss: 5.6075 - Test Loss: 17.2621 - MSE: 17.2621 - MAE: 3.2740\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6167/20000 - Train Loss: 5.6041 - Test Loss: 17.2548 - MSE: 17.2548 - MAE: 3.2732\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 6168/20000 - Train Loss: 5.6006 - Test Loss: 17.2476 - MSE: 17.2476 - MAE: 3.2725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6169/20000 - Train Loss: 5.5972 - Test Loss: 17.2403 - MSE: 17.2403 - MAE: 3.2717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6170/20000 - Train Loss: 5.5937 - Test Loss: 17.2331 - MSE: 17.2331 - MAE: 3.2709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6171/20000 - Train Loss: 5.5902 - Test Loss: 17.2259 - MSE: 17.2259 - MAE: 3.2701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6172/20000 - Train Loss: 5.5868 - Test Loss: 17.2187 - MSE: 17.2187 - MAE: 3.2693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6173/20000 - Train Loss: 5.5833 - Test Loss: 17.2115 - MSE: 17.2115 - MAE: 3.2685\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 6174/20000 - Train Loss: 5.5799 - Test Loss: 17.2042 - MSE: 17.2042 - MAE: 3.2677\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6175/20000 - Train Loss: 5.5764 - Test Loss: 17.1970 - MSE: 17.1970 - MAE: 3.2669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6176/20000 - Train Loss: 5.5730 - Test Loss: 17.1898 - MSE: 17.1898 - MAE: 3.2661\n",
      "2/2 [==============================] - 0s 986us/step\n",
      "Epoch 6177/20000 - Train Loss: 5.5696 - Test Loss: 17.1826 - MSE: 17.1826 - MAE: 3.2653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6178/20000 - Train Loss: 5.5661 - Test Loss: 17.1754 - MSE: 17.1754 - MAE: 3.2645\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6179/20000 - Train Loss: 5.5627 - Test Loss: 17.1682 - MSE: 17.1682 - MAE: 3.2637\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6180/20000 - Train Loss: 5.5592 - Test Loss: 17.1610 - MSE: 17.1610 - MAE: 3.2629\n",
      "2/2 [==============================] - 0s 981us/step\n",
      "Epoch 6181/20000 - Train Loss: 5.5558 - Test Loss: 17.1538 - MSE: 17.1538 - MAE: 3.2621\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6182/20000 - Train Loss: 5.5523 - Test Loss: 17.1466 - MSE: 17.1466 - MAE: 3.2613\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6183/20000 - Train Loss: 5.5489 - Test Loss: 17.1394 - MSE: 17.1394 - MAE: 3.2605\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6184/20000 - Train Loss: 5.5455 - Test Loss: 17.1322 - MSE: 17.1322 - MAE: 3.2597\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6185/20000 - Train Loss: 5.5420 - Test Loss: 17.1250 - MSE: 17.1250 - MAE: 3.2589\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6186/20000 - Train Loss: 5.5386 - Test Loss: 17.1178 - MSE: 17.1178 - MAE: 3.2581\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6187/20000 - Train Loss: 5.5351 - Test Loss: 17.1106 - MSE: 17.1106 - MAE: 3.2574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6188/20000 - Train Loss: 5.5317 - Test Loss: 17.1035 - MSE: 17.1035 - MAE: 3.2566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6189/20000 - Train Loss: 5.5283 - Test Loss: 17.0963 - MSE: 17.0963 - MAE: 3.2558\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6190/20000 - Train Loss: 5.5248 - Test Loss: 17.0891 - MSE: 17.0891 - MAE: 3.2550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6191/20000 - Train Loss: 5.5214 - Test Loss: 17.0819 - MSE: 17.0819 - MAE: 3.2542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6192/20000 - Train Loss: 5.5180 - Test Loss: 17.0747 - MSE: 17.0747 - MAE: 3.2534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6193/20000 - Train Loss: 5.5146 - Test Loss: 17.0675 - MSE: 17.0675 - MAE: 3.2526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6194/20000 - Train Loss: 5.5111 - Test Loss: 17.0604 - MSE: 17.0604 - MAE: 3.2518\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6195/20000 - Train Loss: 5.5077 - Test Loss: 17.0533 - MSE: 17.0533 - MAE: 3.2510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6196/20000 - Train Loss: 5.5043 - Test Loss: 17.0461 - MSE: 17.0461 - MAE: 3.2502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6197/20000 - Train Loss: 5.5008 - Test Loss: 17.0389 - MSE: 17.0389 - MAE: 3.2494\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6198/20000 - Train Loss: 5.4974 - Test Loss: 17.0318 - MSE: 17.0318 - MAE: 3.2486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6199/20000 - Train Loss: 5.4940 - Test Loss: 17.0246 - MSE: 17.0246 - MAE: 3.2478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6200/20000 - Train Loss: 5.4906 - Test Loss: 17.0175 - MSE: 17.0175 - MAE: 3.2470\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6201/20000 - Train Loss: 5.4871 - Test Loss: 17.0103 - MSE: 17.0103 - MAE: 3.2462\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 6202/20000 - Train Loss: 5.4837 - Test Loss: 17.0031 - MSE: 17.0031 - MAE: 3.2454\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6203/20000 - Train Loss: 5.4803 - Test Loss: 16.9960 - MSE: 16.9960 - MAE: 3.2446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6204/20000 - Train Loss: 5.4769 - Test Loss: 16.9888 - MSE: 16.9888 - MAE: 3.2438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6205/20000 - Train Loss: 5.4735 - Test Loss: 16.9817 - MSE: 16.9817 - MAE: 3.2430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6206/20000 - Train Loss: 5.4701 - Test Loss: 16.9746 - MSE: 16.9746 - MAE: 3.2422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6207/20000 - Train Loss: 5.4666 - Test Loss: 16.9674 - MSE: 16.9674 - MAE: 3.2414\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6208/20000 - Train Loss: 5.4632 - Test Loss: 16.9603 - MSE: 16.9603 - MAE: 3.2406\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6209/20000 - Train Loss: 5.4598 - Test Loss: 16.9532 - MSE: 16.9532 - MAE: 3.2398\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6210/20000 - Train Loss: 5.4564 - Test Loss: 16.9460 - MSE: 16.9460 - MAE: 3.2390\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6211/20000 - Train Loss: 5.4530 - Test Loss: 16.9389 - MSE: 16.9389 - MAE: 3.2382\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6212/20000 - Train Loss: 5.4496 - Test Loss: 16.9318 - MSE: 16.9318 - MAE: 3.2374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6213/20000 - Train Loss: 5.4462 - Test Loss: 16.9246 - MSE: 16.9246 - MAE: 3.2366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6214/20000 - Train Loss: 5.4428 - Test Loss: 16.9175 - MSE: 16.9175 - MAE: 3.2359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6215/20000 - Train Loss: 5.4394 - Test Loss: 16.9104 - MSE: 16.9104 - MAE: 3.2350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6216/20000 - Train Loss: 5.4359 - Test Loss: 16.9033 - MSE: 16.9033 - MAE: 3.2343\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6217/20000 - Train Loss: 5.4325 - Test Loss: 16.8962 - MSE: 16.8962 - MAE: 3.2335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6218/20000 - Train Loss: 5.4291 - Test Loss: 16.8891 - MSE: 16.8891 - MAE: 3.2327\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6219/20000 - Train Loss: 5.4257 - Test Loss: 16.8820 - MSE: 16.8820 - MAE: 3.2319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6220/20000 - Train Loss: 5.4223 - Test Loss: 16.8749 - MSE: 16.8749 - MAE: 3.2311\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6221/20000 - Train Loss: 5.4189 - Test Loss: 16.8678 - MSE: 16.8678 - MAE: 3.2303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6222/20000 - Train Loss: 5.4155 - Test Loss: 16.8607 - MSE: 16.8607 - MAE: 3.2295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6223/20000 - Train Loss: 5.4121 - Test Loss: 16.8535 - MSE: 16.8535 - MAE: 3.2287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6224/20000 - Train Loss: 5.4087 - Test Loss: 16.8464 - MSE: 16.8464 - MAE: 3.2279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6225/20000 - Train Loss: 5.4053 - Test Loss: 16.8393 - MSE: 16.8393 - MAE: 3.2271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6226/20000 - Train Loss: 5.4019 - Test Loss: 16.8322 - MSE: 16.8322 - MAE: 3.2263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6227/20000 - Train Loss: 5.3986 - Test Loss: 16.8252 - MSE: 16.8252 - MAE: 3.2255\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6228/20000 - Train Loss: 5.3952 - Test Loss: 16.8181 - MSE: 16.8181 - MAE: 3.2247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6229/20000 - Train Loss: 5.3918 - Test Loss: 16.8110 - MSE: 16.8110 - MAE: 3.2239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6230/20000 - Train Loss: 5.3884 - Test Loss: 16.8039 - MSE: 16.8039 - MAE: 3.2231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6231/20000 - Train Loss: 5.3850 - Test Loss: 16.7968 - MSE: 16.7968 - MAE: 3.2223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6232/20000 - Train Loss: 5.3816 - Test Loss: 16.7897 - MSE: 16.7897 - MAE: 3.2215\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 6233/20000 - Train Loss: 5.3782 - Test Loss: 16.7826 - MSE: 16.7826 - MAE: 3.2207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6234/20000 - Train Loss: 5.3748 - Test Loss: 16.7756 - MSE: 16.7756 - MAE: 3.2199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6235/20000 - Train Loss: 5.3714 - Test Loss: 16.7685 - MSE: 16.7685 - MAE: 3.2191\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6236/20000 - Train Loss: 5.3680 - Test Loss: 16.7615 - MSE: 16.7615 - MAE: 3.2183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6237/20000 - Train Loss: 5.3647 - Test Loss: 16.7544 - MSE: 16.7544 - MAE: 3.2175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6238/20000 - Train Loss: 5.3613 - Test Loss: 16.7474 - MSE: 16.7474 - MAE: 3.2167\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6239/20000 - Train Loss: 5.3579 - Test Loss: 16.7403 - MSE: 16.7403 - MAE: 3.2159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6240/20000 - Train Loss: 5.3545 - Test Loss: 16.7332 - MSE: 16.7332 - MAE: 3.2151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6241/20000 - Train Loss: 5.3511 - Test Loss: 16.7262 - MSE: 16.7262 - MAE: 3.2143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6242/20000 - Train Loss: 5.3478 - Test Loss: 16.7191 - MSE: 16.7191 - MAE: 3.2135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6243/20000 - Train Loss: 5.3444 - Test Loss: 16.7121 - MSE: 16.7121 - MAE: 3.2127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6244/20000 - Train Loss: 5.3410 - Test Loss: 16.7050 - MSE: 16.7050 - MAE: 3.2119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6245/20000 - Train Loss: 5.3376 - Test Loss: 16.6980 - MSE: 16.6980 - MAE: 3.2111\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6246/20000 - Train Loss: 5.3343 - Test Loss: 16.6910 - MSE: 16.6910 - MAE: 3.2103\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6247/20000 - Train Loss: 5.3309 - Test Loss: 16.6839 - MSE: 16.6839 - MAE: 3.2095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6248/20000 - Train Loss: 5.3275 - Test Loss: 16.6768 - MSE: 16.6768 - MAE: 3.2087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6249/20000 - Train Loss: 5.3241 - Test Loss: 16.6698 - MSE: 16.6698 - MAE: 3.2079\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6250/20000 - Train Loss: 5.3208 - Test Loss: 16.6627 - MSE: 16.6627 - MAE: 3.2071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6251/20000 - Train Loss: 5.3174 - Test Loss: 16.6557 - MSE: 16.6557 - MAE: 3.2063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6252/20000 - Train Loss: 5.3140 - Test Loss: 16.6488 - MSE: 16.6488 - MAE: 3.2055\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6253/20000 - Train Loss: 5.3107 - Test Loss: 16.6417 - MSE: 16.6417 - MAE: 3.2047\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6254/20000 - Train Loss: 5.3073 - Test Loss: 16.6347 - MSE: 16.6347 - MAE: 3.2039\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 6255/20000 - Train Loss: 5.3039 - Test Loss: 16.6277 - MSE: 16.6277 - MAE: 3.2031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6256/20000 - Train Loss: 5.3006 - Test Loss: 16.6206 - MSE: 16.6206 - MAE: 3.2023\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6257/20000 - Train Loss: 5.2972 - Test Loss: 16.6136 - MSE: 16.6136 - MAE: 3.2015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6258/20000 - Train Loss: 5.2938 - Test Loss: 16.6066 - MSE: 16.6066 - MAE: 3.2007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6259/20000 - Train Loss: 5.2905 - Test Loss: 16.5996 - MSE: 16.5996 - MAE: 3.1999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6260/20000 - Train Loss: 5.2871 - Test Loss: 16.5926 - MSE: 16.5926 - MAE: 3.1991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6261/20000 - Train Loss: 5.2838 - Test Loss: 16.5856 - MSE: 16.5856 - MAE: 3.1983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6262/20000 - Train Loss: 5.2804 - Test Loss: 16.5786 - MSE: 16.5786 - MAE: 3.1975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6263/20000 - Train Loss: 5.2771 - Test Loss: 16.5716 - MSE: 16.5716 - MAE: 3.1967\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 6264/20000 - Train Loss: 5.2737 - Test Loss: 16.5646 - MSE: 16.5646 - MAE: 3.1959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6265/20000 - Train Loss: 5.2703 - Test Loss: 16.5576 - MSE: 16.5576 - MAE: 3.1951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6266/20000 - Train Loss: 5.2670 - Test Loss: 16.5506 - MSE: 16.5506 - MAE: 3.1943\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6267/20000 - Train Loss: 5.2636 - Test Loss: 16.5436 - MSE: 16.5436 - MAE: 3.1935\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6268/20000 - Train Loss: 5.2603 - Test Loss: 16.5366 - MSE: 16.5366 - MAE: 3.1927\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6269/20000 - Train Loss: 5.2569 - Test Loss: 16.5296 - MSE: 16.5296 - MAE: 3.1919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6270/20000 - Train Loss: 5.2536 - Test Loss: 16.5226 - MSE: 16.5226 - MAE: 3.1911\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6271/20000 - Train Loss: 5.2502 - Test Loss: 16.5156 - MSE: 16.5156 - MAE: 3.1903\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6272/20000 - Train Loss: 5.2469 - Test Loss: 16.5087 - MSE: 16.5087 - MAE: 3.1895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6273/20000 - Train Loss: 5.2436 - Test Loss: 16.5017 - MSE: 16.5017 - MAE: 3.1887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6274/20000 - Train Loss: 5.2402 - Test Loss: 16.4947 - MSE: 16.4947 - MAE: 3.1879\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6275/20000 - Train Loss: 5.2369 - Test Loss: 16.4877 - MSE: 16.4877 - MAE: 3.1870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6276/20000 - Train Loss: 5.2335 - Test Loss: 16.4807 - MSE: 16.4807 - MAE: 3.1862\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 6277/20000 - Train Loss: 5.2302 - Test Loss: 16.4738 - MSE: 16.4738 - MAE: 3.1854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6278/20000 - Train Loss: 5.2268 - Test Loss: 16.4669 - MSE: 16.4669 - MAE: 3.1846\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6279/20000 - Train Loss: 5.2235 - Test Loss: 16.4599 - MSE: 16.4599 - MAE: 3.1838\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6280/20000 - Train Loss: 5.2202 - Test Loss: 16.4530 - MSE: 16.4530 - MAE: 3.1830\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6281/20000 - Train Loss: 5.2168 - Test Loss: 16.4460 - MSE: 16.4460 - MAE: 3.1822\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 6282/20000 - Train Loss: 5.2135 - Test Loss: 16.4391 - MSE: 16.4390 - MAE: 3.1814\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6283/20000 - Train Loss: 5.2102 - Test Loss: 16.4320 - MSE: 16.4320 - MAE: 3.1806\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6284/20000 - Train Loss: 5.2068 - Test Loss: 16.4251 - MSE: 16.4251 - MAE: 3.1798\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6285/20000 - Train Loss: 5.2035 - Test Loss: 16.4181 - MSE: 16.4181 - MAE: 3.1790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6286/20000 - Train Loss: 5.2002 - Test Loss: 16.4112 - MSE: 16.4112 - MAE: 3.1782\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6287/20000 - Train Loss: 5.1968 - Test Loss: 16.4043 - MSE: 16.4043 - MAE: 3.1774\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6288/20000 - Train Loss: 5.1935 - Test Loss: 16.3974 - MSE: 16.3974 - MAE: 3.1766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6289/20000 - Train Loss: 5.1902 - Test Loss: 16.3905 - MSE: 16.3905 - MAE: 3.1758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6290/20000 - Train Loss: 5.1869 - Test Loss: 16.3835 - MSE: 16.3835 - MAE: 3.1750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6291/20000 - Train Loss: 5.1835 - Test Loss: 16.3766 - MSE: 16.3766 - MAE: 3.1742\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6292/20000 - Train Loss: 5.1802 - Test Loss: 16.3697 - MSE: 16.3697 - MAE: 3.1734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6293/20000 - Train Loss: 5.1769 - Test Loss: 16.3627 - MSE: 16.3627 - MAE: 3.1726\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6294/20000 - Train Loss: 5.1736 - Test Loss: 16.3557 - MSE: 16.3557 - MAE: 3.1718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6295/20000 - Train Loss: 5.1702 - Test Loss: 16.3488 - MSE: 16.3488 - MAE: 3.1710\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6296/20000 - Train Loss: 5.1669 - Test Loss: 16.3419 - MSE: 16.3419 - MAE: 3.1702\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 6297/20000 - Train Loss: 5.1636 - Test Loss: 16.3350 - MSE: 16.3350 - MAE: 3.1694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6298/20000 - Train Loss: 5.1603 - Test Loss: 16.3281 - MSE: 16.3281 - MAE: 3.1686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6299/20000 - Train Loss: 5.1570 - Test Loss: 16.3212 - MSE: 16.3212 - MAE: 3.1678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6300/20000 - Train Loss: 5.1537 - Test Loss: 16.3143 - MSE: 16.3143 - MAE: 3.1670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6301/20000 - Train Loss: 5.1503 - Test Loss: 16.3074 - MSE: 16.3074 - MAE: 3.1662\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6302/20000 - Train Loss: 5.1470 - Test Loss: 16.3005 - MSE: 16.3005 - MAE: 3.1654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6303/20000 - Train Loss: 5.1437 - Test Loss: 16.2936 - MSE: 16.2936 - MAE: 3.1646\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6304/20000 - Train Loss: 5.1404 - Test Loss: 16.2867 - MSE: 16.2867 - MAE: 3.1638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6305/20000 - Train Loss: 5.1371 - Test Loss: 16.2798 - MSE: 16.2798 - MAE: 3.1630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6306/20000 - Train Loss: 5.1338 - Test Loss: 16.2729 - MSE: 16.2729 - MAE: 3.1622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6307/20000 - Train Loss: 5.1305 - Test Loss: 16.2660 - MSE: 16.2660 - MAE: 3.1613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6308/20000 - Train Loss: 5.1272 - Test Loss: 16.2591 - MSE: 16.2591 - MAE: 3.1605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6309/20000 - Train Loss: 5.1239 - Test Loss: 16.2523 - MSE: 16.2523 - MAE: 3.1597\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6310/20000 - Train Loss: 5.1206 - Test Loss: 16.2454 - MSE: 16.2454 - MAE: 3.1589\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6311/20000 - Train Loss: 5.1173 - Test Loss: 16.2385 - MSE: 16.2385 - MAE: 3.1581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6312/20000 - Train Loss: 5.1140 - Test Loss: 16.2316 - MSE: 16.2316 - MAE: 3.1573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6313/20000 - Train Loss: 5.1107 - Test Loss: 16.2247 - MSE: 16.2247 - MAE: 3.1565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6314/20000 - Train Loss: 5.1074 - Test Loss: 16.2178 - MSE: 16.2178 - MAE: 3.1557\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6315/20000 - Train Loss: 5.1041 - Test Loss: 16.2110 - MSE: 16.2110 - MAE: 3.1549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6316/20000 - Train Loss: 5.1008 - Test Loss: 16.2042 - MSE: 16.2042 - MAE: 3.1541\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6317/20000 - Train Loss: 5.0975 - Test Loss: 16.1973 - MSE: 16.1973 - MAE: 3.1533\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6318/20000 - Train Loss: 5.0942 - Test Loss: 16.1904 - MSE: 16.1904 - MAE: 3.1525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6319/20000 - Train Loss: 5.0909 - Test Loss: 16.1836 - MSE: 16.1836 - MAE: 3.1517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6320/20000 - Train Loss: 5.0876 - Test Loss: 16.1767 - MSE: 16.1767 - MAE: 3.1509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6321/20000 - Train Loss: 5.0843 - Test Loss: 16.1699 - MSE: 16.1699 - MAE: 3.1501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6322/20000 - Train Loss: 5.0810 - Test Loss: 16.1630 - MSE: 16.1630 - MAE: 3.1493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6323/20000 - Train Loss: 5.0777 - Test Loss: 16.1562 - MSE: 16.1562 - MAE: 3.1485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6324/20000 - Train Loss: 5.0744 - Test Loss: 16.1493 - MSE: 16.1493 - MAE: 3.1477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6325/20000 - Train Loss: 5.0712 - Test Loss: 16.1425 - MSE: 16.1425 - MAE: 3.1469\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6326/20000 - Train Loss: 5.0679 - Test Loss: 16.1356 - MSE: 16.1356 - MAE: 3.1461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6327/20000 - Train Loss: 5.0646 - Test Loss: 16.1288 - MSE: 16.1288 - MAE: 3.1453\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6328/20000 - Train Loss: 5.0613 - Test Loss: 16.1220 - MSE: 16.1220 - MAE: 3.1445\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6329/20000 - Train Loss: 5.0580 - Test Loss: 16.1152 - MSE: 16.1152 - MAE: 3.1436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6330/20000 - Train Loss: 5.0547 - Test Loss: 16.1083 - MSE: 16.1083 - MAE: 3.1428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6331/20000 - Train Loss: 5.0515 - Test Loss: 16.1014 - MSE: 16.1014 - MAE: 3.1420\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6332/20000 - Train Loss: 5.0482 - Test Loss: 16.0946 - MSE: 16.0946 - MAE: 3.1412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6333/20000 - Train Loss: 5.0449 - Test Loss: 16.0878 - MSE: 16.0878 - MAE: 3.1404\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6334/20000 - Train Loss: 5.0416 - Test Loss: 16.0810 - MSE: 16.0810 - MAE: 3.1396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6335/20000 - Train Loss: 5.0384 - Test Loss: 16.0742 - MSE: 16.0742 - MAE: 3.1388\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6336/20000 - Train Loss: 5.0351 - Test Loss: 16.0674 - MSE: 16.0674 - MAE: 3.1380\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6337/20000 - Train Loss: 5.0318 - Test Loss: 16.0606 - MSE: 16.0606 - MAE: 3.1372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6338/20000 - Train Loss: 5.0285 - Test Loss: 16.0538 - MSE: 16.0538 - MAE: 3.1364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6339/20000 - Train Loss: 5.0253 - Test Loss: 16.0469 - MSE: 16.0469 - MAE: 3.1356\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 6340/20000 - Train Loss: 5.0220 - Test Loss: 16.0401 - MSE: 16.0401 - MAE: 3.1348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6341/20000 - Train Loss: 5.0187 - Test Loss: 16.0333 - MSE: 16.0333 - MAE: 3.1340\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6342/20000 - Train Loss: 5.0155 - Test Loss: 16.0265 - MSE: 16.0265 - MAE: 3.1332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6343/20000 - Train Loss: 5.0122 - Test Loss: 16.0197 - MSE: 16.0197 - MAE: 3.1324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6344/20000 - Train Loss: 5.0089 - Test Loss: 16.0130 - MSE: 16.0130 - MAE: 3.1316\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6345/20000 - Train Loss: 5.0057 - Test Loss: 16.0062 - MSE: 16.0062 - MAE: 3.1307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6346/20000 - Train Loss: 5.0024 - Test Loss: 15.9994 - MSE: 15.9994 - MAE: 3.1299\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6347/20000 - Train Loss: 4.9991 - Test Loss: 15.9926 - MSE: 15.9926 - MAE: 3.1291\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6348/20000 - Train Loss: 4.9959 - Test Loss: 15.9858 - MSE: 15.9858 - MAE: 3.1283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6349/20000 - Train Loss: 4.9926 - Test Loss: 15.9790 - MSE: 15.9790 - MAE: 3.1275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6350/20000 - Train Loss: 4.9894 - Test Loss: 15.9722 - MSE: 15.9722 - MAE: 3.1267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6351/20000 - Train Loss: 4.9861 - Test Loss: 15.9655 - MSE: 15.9655 - MAE: 3.1259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6352/20000 - Train Loss: 4.9829 - Test Loss: 15.9587 - MSE: 15.9587 - MAE: 3.1251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6353/20000 - Train Loss: 4.9796 - Test Loss: 15.9520 - MSE: 15.9520 - MAE: 3.1243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6354/20000 - Train Loss: 4.9763 - Test Loss: 15.9452 - MSE: 15.9452 - MAE: 3.1235\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6355/20000 - Train Loss: 4.9731 - Test Loss: 15.9385 - MSE: 15.9385 - MAE: 3.1227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6356/20000 - Train Loss: 4.9698 - Test Loss: 15.9317 - MSE: 15.9317 - MAE: 3.1219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6357/20000 - Train Loss: 4.9666 - Test Loss: 15.9249 - MSE: 15.9249 - MAE: 3.1211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6358/20000 - Train Loss: 4.9634 - Test Loss: 15.9181 - MSE: 15.9181 - MAE: 3.1202\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 6359/20000 - Train Loss: 4.9601 - Test Loss: 15.9113 - MSE: 15.9113 - MAE: 3.1194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6360/20000 - Train Loss: 4.9569 - Test Loss: 15.9046 - MSE: 15.9046 - MAE: 3.1186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6361/20000 - Train Loss: 4.9536 - Test Loss: 15.8979 - MSE: 15.8979 - MAE: 3.1178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6362/20000 - Train Loss: 4.9504 - Test Loss: 15.8912 - MSE: 15.8912 - MAE: 3.1170\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6363/20000 - Train Loss: 4.9471 - Test Loss: 15.8844 - MSE: 15.8844 - MAE: 3.1162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6364/20000 - Train Loss: 4.9439 - Test Loss: 15.8777 - MSE: 15.8777 - MAE: 3.1154\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6365/20000 - Train Loss: 4.9406 - Test Loss: 15.8709 - MSE: 15.8709 - MAE: 3.1146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6366/20000 - Train Loss: 4.9374 - Test Loss: 15.8642 - MSE: 15.8642 - MAE: 3.1138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6367/20000 - Train Loss: 4.9342 - Test Loss: 15.8575 - MSE: 15.8575 - MAE: 3.1130\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 6368/20000 - Train Loss: 4.9309 - Test Loss: 15.8507 - MSE: 15.8507 - MAE: 3.1122\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 6369/20000 - Train Loss: 4.9277 - Test Loss: 15.8440 - MSE: 15.8440 - MAE: 3.1114\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6370/20000 - Train Loss: 4.9245 - Test Loss: 15.8373 - MSE: 15.8373 - MAE: 3.1106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6371/20000 - Train Loss: 4.9212 - Test Loss: 15.8306 - MSE: 15.8306 - MAE: 3.1098\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6372/20000 - Train Loss: 4.9180 - Test Loss: 15.8239 - MSE: 15.8239 - MAE: 3.1090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6373/20000 - Train Loss: 4.9148 - Test Loss: 15.8172 - MSE: 15.8172 - MAE: 3.1081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6374/20000 - Train Loss: 4.9115 - Test Loss: 15.8104 - MSE: 15.8104 - MAE: 3.1074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6375/20000 - Train Loss: 4.9083 - Test Loss: 15.8037 - MSE: 15.8037 - MAE: 3.1066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6376/20000 - Train Loss: 4.9051 - Test Loss: 15.7970 - MSE: 15.7970 - MAE: 3.1058\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6377/20000 - Train Loss: 4.9019 - Test Loss: 15.7903 - MSE: 15.7903 - MAE: 3.1051\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 6378/20000 - Train Loss: 4.8986 - Test Loss: 15.7836 - MSE: 15.7836 - MAE: 3.1043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6379/20000 - Train Loss: 4.8954 - Test Loss: 15.7769 - MSE: 15.7769 - MAE: 3.1035\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6380/20000 - Train Loss: 4.8922 - Test Loss: 15.7703 - MSE: 15.7703 - MAE: 3.1028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6381/20000 - Train Loss: 4.8890 - Test Loss: 15.7636 - MSE: 15.7636 - MAE: 3.1020\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6382/20000 - Train Loss: 4.8858 - Test Loss: 15.7569 - MSE: 15.7569 - MAE: 3.1012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6383/20000 - Train Loss: 4.8825 - Test Loss: 15.7502 - MSE: 15.7502 - MAE: 3.1005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6384/20000 - Train Loss: 4.8793 - Test Loss: 15.7435 - MSE: 15.7435 - MAE: 3.0997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6385/20000 - Train Loss: 4.8761 - Test Loss: 15.7368 - MSE: 15.7368 - MAE: 3.0989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6386/20000 - Train Loss: 4.8729 - Test Loss: 15.7301 - MSE: 15.7301 - MAE: 3.0982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6387/20000 - Train Loss: 4.8697 - Test Loss: 15.7234 - MSE: 15.7234 - MAE: 3.0974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6388/20000 - Train Loss: 4.8665 - Test Loss: 15.7167 - MSE: 15.7167 - MAE: 3.0966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6389/20000 - Train Loss: 4.8633 - Test Loss: 15.7101 - MSE: 15.7101 - MAE: 3.0959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6390/20000 - Train Loss: 4.8600 - Test Loss: 15.7035 - MSE: 15.7035 - MAE: 3.0951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6391/20000 - Train Loss: 4.8568 - Test Loss: 15.6968 - MSE: 15.6968 - MAE: 3.0943\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6392/20000 - Train Loss: 4.8536 - Test Loss: 15.6901 - MSE: 15.6901 - MAE: 3.0936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6393/20000 - Train Loss: 4.8504 - Test Loss: 15.6834 - MSE: 15.6834 - MAE: 3.0928\n",
      "2/2 [==============================] - 0s 975us/step\n",
      "Epoch 6394/20000 - Train Loss: 4.8472 - Test Loss: 15.6767 - MSE: 15.6767 - MAE: 3.0920\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6395/20000 - Train Loss: 4.8440 - Test Loss: 15.6701 - MSE: 15.6701 - MAE: 3.0913\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6396/20000 - Train Loss: 4.8408 - Test Loss: 15.6635 - MSE: 15.6635 - MAE: 3.0905\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6397/20000 - Train Loss: 4.8376 - Test Loss: 15.6568 - MSE: 15.6568 - MAE: 3.0897\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6398/20000 - Train Loss: 4.8344 - Test Loss: 15.6502 - MSE: 15.6502 - MAE: 3.0890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6399/20000 - Train Loss: 4.8312 - Test Loss: 15.6436 - MSE: 15.6436 - MAE: 3.0882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6400/20000 - Train Loss: 4.8280 - Test Loss: 15.6369 - MSE: 15.6369 - MAE: 3.0874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6401/20000 - Train Loss: 4.8248 - Test Loss: 15.6303 - MSE: 15.6303 - MAE: 3.0867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6402/20000 - Train Loss: 4.8216 - Test Loss: 15.6236 - MSE: 15.6236 - MAE: 3.0859\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6403/20000 - Train Loss: 4.8184 - Test Loss: 15.6170 - MSE: 15.6170 - MAE: 3.0851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6404/20000 - Train Loss: 4.8152 - Test Loss: 15.6103 - MSE: 15.6103 - MAE: 3.0844\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6405/20000 - Train Loss: 4.8120 - Test Loss: 15.6037 - MSE: 15.6037 - MAE: 3.0836\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6406/20000 - Train Loss: 4.8088 - Test Loss: 15.5971 - MSE: 15.5971 - MAE: 3.0828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6407/20000 - Train Loss: 4.8057 - Test Loss: 15.5905 - MSE: 15.5905 - MAE: 3.0821\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6408/20000 - Train Loss: 4.8025 - Test Loss: 15.5838 - MSE: 15.5838 - MAE: 3.0813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6409/20000 - Train Loss: 4.7993 - Test Loss: 15.5772 - MSE: 15.5772 - MAE: 3.0805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6410/20000 - Train Loss: 4.7961 - Test Loss: 15.5706 - MSE: 15.5706 - MAE: 3.0798\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6411/20000 - Train Loss: 4.7929 - Test Loss: 15.5640 - MSE: 15.5640 - MAE: 3.0790\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 6412/20000 - Train Loss: 4.7897 - Test Loss: 15.5575 - MSE: 15.5575 - MAE: 3.0782\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6413/20000 - Train Loss: 4.7866 - Test Loss: 15.5508 - MSE: 15.5508 - MAE: 3.0775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6414/20000 - Train Loss: 4.7834 - Test Loss: 15.5442 - MSE: 15.5442 - MAE: 3.0767\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6415/20000 - Train Loss: 4.7802 - Test Loss: 15.5376 - MSE: 15.5376 - MAE: 3.0759\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6416/20000 - Train Loss: 4.7770 - Test Loss: 15.5310 - MSE: 15.5310 - MAE: 3.0752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6417/20000 - Train Loss: 4.7738 - Test Loss: 15.5244 - MSE: 15.5244 - MAE: 3.0744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6418/20000 - Train Loss: 4.7707 - Test Loss: 15.5178 - MSE: 15.5178 - MAE: 3.0736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6419/20000 - Train Loss: 4.7675 - Test Loss: 15.5112 - MSE: 15.5112 - MAE: 3.0728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6420/20000 - Train Loss: 4.7643 - Test Loss: 15.5046 - MSE: 15.5046 - MAE: 3.0721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6421/20000 - Train Loss: 4.7611 - Test Loss: 15.4980 - MSE: 15.4980 - MAE: 3.0713\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 6422/20000 - Train Loss: 4.7580 - Test Loss: 15.4915 - MSE: 15.4915 - MAE: 3.0705\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6423/20000 - Train Loss: 4.7548 - Test Loss: 15.4849 - MSE: 15.4849 - MAE: 3.0698\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6424/20000 - Train Loss: 4.7516 - Test Loss: 15.4784 - MSE: 15.4784 - MAE: 3.0690\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 6425/20000 - Train Loss: 4.7485 - Test Loss: 15.4718 - MSE: 15.4718 - MAE: 3.0682\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6426/20000 - Train Loss: 4.7453 - Test Loss: 15.4652 - MSE: 15.4652 - MAE: 3.0675\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6427/20000 - Train Loss: 4.7421 - Test Loss: 15.4586 - MSE: 15.4586 - MAE: 3.0667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6428/20000 - Train Loss: 4.7390 - Test Loss: 15.4520 - MSE: 15.4520 - MAE: 3.0659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6429/20000 - Train Loss: 4.7358 - Test Loss: 15.4455 - MSE: 15.4455 - MAE: 3.0652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6430/20000 - Train Loss: 4.7327 - Test Loss: 15.4390 - MSE: 15.4390 - MAE: 3.0644\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 6431/20000 - Train Loss: 4.7295 - Test Loss: 15.4324 - MSE: 15.4324 - MAE: 3.0636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6432/20000 - Train Loss: 4.7263 - Test Loss: 15.4258 - MSE: 15.4258 - MAE: 3.0629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6433/20000 - Train Loss: 4.7232 - Test Loss: 15.4193 - MSE: 15.4193 - MAE: 3.0621\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6434/20000 - Train Loss: 4.7200 - Test Loss: 15.4127 - MSE: 15.4127 - MAE: 3.0613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6435/20000 - Train Loss: 4.7169 - Test Loss: 15.4062 - MSE: 15.4062 - MAE: 3.0606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6436/20000 - Train Loss: 4.7137 - Test Loss: 15.3997 - MSE: 15.3997 - MAE: 3.0598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6437/20000 - Train Loss: 4.7106 - Test Loss: 15.3932 - MSE: 15.3932 - MAE: 3.0590\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6438/20000 - Train Loss: 4.7074 - Test Loss: 15.3866 - MSE: 15.3866 - MAE: 3.0583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6439/20000 - Train Loss: 4.7043 - Test Loss: 15.3801 - MSE: 15.3801 - MAE: 3.0575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6440/20000 - Train Loss: 4.7011 - Test Loss: 15.3735 - MSE: 15.3735 - MAE: 3.0567\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6441/20000 - Train Loss: 4.6980 - Test Loss: 15.3670 - MSE: 15.3670 - MAE: 3.0559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6442/20000 - Train Loss: 4.6948 - Test Loss: 15.3605 - MSE: 15.3605 - MAE: 3.0552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6443/20000 - Train Loss: 4.6917 - Test Loss: 15.3540 - MSE: 15.3540 - MAE: 3.0544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6444/20000 - Train Loss: 4.6885 - Test Loss: 15.3475 - MSE: 15.3475 - MAE: 3.0536\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6445/20000 - Train Loss: 4.6854 - Test Loss: 15.3410 - MSE: 15.3410 - MAE: 3.0529\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 6446/20000 - Train Loss: 4.6822 - Test Loss: 15.3344 - MSE: 15.3344 - MAE: 3.0521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6447/20000 - Train Loss: 4.6791 - Test Loss: 15.3279 - MSE: 15.3279 - MAE: 3.0513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6448/20000 - Train Loss: 4.6760 - Test Loss: 15.3214 - MSE: 15.3214 - MAE: 3.0506\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 6449/20000 - Train Loss: 4.6728 - Test Loss: 15.3148 - MSE: 15.3148 - MAE: 3.0498\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6450/20000 - Train Loss: 4.6697 - Test Loss: 15.3084 - MSE: 15.3084 - MAE: 3.0490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6451/20000 - Train Loss: 4.6666 - Test Loss: 15.3019 - MSE: 15.3019 - MAE: 3.0483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6452/20000 - Train Loss: 4.6634 - Test Loss: 15.2955 - MSE: 15.2955 - MAE: 3.0475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6453/20000 - Train Loss: 4.6603 - Test Loss: 15.2890 - MSE: 15.2890 - MAE: 3.0467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6454/20000 - Train Loss: 4.6572 - Test Loss: 15.2825 - MSE: 15.2825 - MAE: 3.0460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6455/20000 - Train Loss: 4.6540 - Test Loss: 15.2759 - MSE: 15.2759 - MAE: 3.0452\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 6456/20000 - Train Loss: 4.6509 - Test Loss: 15.2694 - MSE: 15.2694 - MAE: 3.0444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6457/20000 - Train Loss: 4.6478 - Test Loss: 15.2629 - MSE: 15.2629 - MAE: 3.0436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6458/20000 - Train Loss: 4.6447 - Test Loss: 15.2564 - MSE: 15.2564 - MAE: 3.0429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6459/20000 - Train Loss: 4.6415 - Test Loss: 15.2500 - MSE: 15.2500 - MAE: 3.0421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6460/20000 - Train Loss: 4.6384 - Test Loss: 15.2436 - MSE: 15.2436 - MAE: 3.0413\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6461/20000 - Train Loss: 4.6353 - Test Loss: 15.2371 - MSE: 15.2371 - MAE: 3.0406\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6462/20000 - Train Loss: 4.6322 - Test Loss: 15.2307 - MSE: 15.2307 - MAE: 3.0398\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 6463/20000 - Train Loss: 4.6291 - Test Loss: 15.2242 - MSE: 15.2242 - MAE: 3.0390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6464/20000 - Train Loss: 4.6259 - Test Loss: 15.2177 - MSE: 15.2177 - MAE: 3.0382\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6465/20000 - Train Loss: 4.6228 - Test Loss: 15.2112 - MSE: 15.2112 - MAE: 3.0375\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6466/20000 - Train Loss: 4.6197 - Test Loss: 15.2048 - MSE: 15.2048 - MAE: 3.0367\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6467/20000 - Train Loss: 4.6166 - Test Loss: 15.1983 - MSE: 15.1983 - MAE: 3.0359\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6468/20000 - Train Loss: 4.6135 - Test Loss: 15.1919 - MSE: 15.1919 - MAE: 3.0352\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6469/20000 - Train Loss: 4.6104 - Test Loss: 15.1854 - MSE: 15.1854 - MAE: 3.0344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6470/20000 - Train Loss: 4.6073 - Test Loss: 15.1790 - MSE: 15.1790 - MAE: 3.0336\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6471/20000 - Train Loss: 4.6041 - Test Loss: 15.1726 - MSE: 15.1726 - MAE: 3.0329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6472/20000 - Train Loss: 4.6010 - Test Loss: 15.1661 - MSE: 15.1661 - MAE: 3.0321\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6473/20000 - Train Loss: 4.5979 - Test Loss: 15.1597 - MSE: 15.1597 - MAE: 3.0313\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6474/20000 - Train Loss: 4.5948 - Test Loss: 15.1532 - MSE: 15.1532 - MAE: 3.0305\n",
      "2/2 [==============================] - 0s 984us/step\n",
      "Epoch 6475/20000 - Train Loss: 4.5917 - Test Loss: 15.1468 - MSE: 15.1468 - MAE: 3.0298\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6476/20000 - Train Loss: 4.5886 - Test Loss: 15.1403 - MSE: 15.1403 - MAE: 3.0290\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6477/20000 - Train Loss: 4.5855 - Test Loss: 15.1339 - MSE: 15.1339 - MAE: 3.0282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6478/20000 - Train Loss: 4.5824 - Test Loss: 15.1275 - MSE: 15.1275 - MAE: 3.0275\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6479/20000 - Train Loss: 4.5793 - Test Loss: 15.1211 - MSE: 15.1211 - MAE: 3.0267\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6480/20000 - Train Loss: 4.5762 - Test Loss: 15.1147 - MSE: 15.1147 - MAE: 3.0259\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6481/20000 - Train Loss: 4.5731 - Test Loss: 15.1083 - MSE: 15.1083 - MAE: 3.0252\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 6482/20000 - Train Loss: 4.5700 - Test Loss: 15.1019 - MSE: 15.1019 - MAE: 3.0244\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6483/20000 - Train Loss: 4.5669 - Test Loss: 15.0955 - MSE: 15.0955 - MAE: 3.0236\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 6484/20000 - Train Loss: 4.5638 - Test Loss: 15.0891 - MSE: 15.0891 - MAE: 3.0228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6485/20000 - Train Loss: 4.5608 - Test Loss: 15.0827 - MSE: 15.0827 - MAE: 3.0221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6486/20000 - Train Loss: 4.5577 - Test Loss: 15.0762 - MSE: 15.0762 - MAE: 3.0213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6487/20000 - Train Loss: 4.5546 - Test Loss: 15.0699 - MSE: 15.0699 - MAE: 3.0205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6488/20000 - Train Loss: 4.5515 - Test Loss: 15.0635 - MSE: 15.0635 - MAE: 3.0198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6489/20000 - Train Loss: 4.5484 - Test Loss: 15.0571 - MSE: 15.0571 - MAE: 3.0190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6490/20000 - Train Loss: 4.5453 - Test Loss: 15.0507 - MSE: 15.0507 - MAE: 3.0182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6491/20000 - Train Loss: 4.5422 - Test Loss: 15.0443 - MSE: 15.0443 - MAE: 3.0175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6492/20000 - Train Loss: 4.5391 - Test Loss: 15.0380 - MSE: 15.0380 - MAE: 3.0167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6493/20000 - Train Loss: 4.5361 - Test Loss: 15.0316 - MSE: 15.0316 - MAE: 3.0159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6494/20000 - Train Loss: 4.5330 - Test Loss: 15.0252 - MSE: 15.0252 - MAE: 3.0151\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6495/20000 - Train Loss: 4.5299 - Test Loss: 15.0188 - MSE: 15.0188 - MAE: 3.0144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6496/20000 - Train Loss: 4.5268 - Test Loss: 15.0125 - MSE: 15.0125 - MAE: 3.0136\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6497/20000 - Train Loss: 4.5238 - Test Loss: 15.0061 - MSE: 15.0061 - MAE: 3.0128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6498/20000 - Train Loss: 4.5207 - Test Loss: 14.9997 - MSE: 14.9997 - MAE: 3.0121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6499/20000 - Train Loss: 4.5176 - Test Loss: 14.9933 - MSE: 14.9933 - MAE: 3.0113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6500/20000 - Train Loss: 4.5145 - Test Loss: 14.9870 - MSE: 14.9870 - MAE: 3.0105\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6501/20000 - Train Loss: 4.5115 - Test Loss: 14.9806 - MSE: 14.9806 - MAE: 3.0097\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6502/20000 - Train Loss: 4.5084 - Test Loss: 14.9743 - MSE: 14.9743 - MAE: 3.0090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6503/20000 - Train Loss: 4.5053 - Test Loss: 14.9679 - MSE: 14.9679 - MAE: 3.0082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6504/20000 - Train Loss: 4.5023 - Test Loss: 14.9616 - MSE: 14.9616 - MAE: 3.0074\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6505/20000 - Train Loss: 4.4992 - Test Loss: 14.9553 - MSE: 14.9553 - MAE: 3.0067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6506/20000 - Train Loss: 4.4961 - Test Loss: 14.9489 - MSE: 14.9489 - MAE: 3.0059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6507/20000 - Train Loss: 4.4931 - Test Loss: 14.9426 - MSE: 14.9426 - MAE: 3.0051\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6508/20000 - Train Loss: 4.4900 - Test Loss: 14.9363 - MSE: 14.9363 - MAE: 3.0043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6509/20000 - Train Loss: 4.4870 - Test Loss: 14.9300 - MSE: 14.9300 - MAE: 3.0036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6510/20000 - Train Loss: 4.4839 - Test Loss: 14.9236 - MSE: 14.9236 - MAE: 3.0028\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 6511/20000 - Train Loss: 4.4808 - Test Loss: 14.9172 - MSE: 14.9172 - MAE: 3.0020\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6512/20000 - Train Loss: 4.4778 - Test Loss: 14.9109 - MSE: 14.9109 - MAE: 3.0013\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6513/20000 - Train Loss: 4.4747 - Test Loss: 14.9046 - MSE: 14.9046 - MAE: 3.0005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6514/20000 - Train Loss: 4.4717 - Test Loss: 14.8983 - MSE: 14.8983 - MAE: 2.9997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6515/20000 - Train Loss: 4.4686 - Test Loss: 14.8920 - MSE: 14.8920 - MAE: 2.9989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6516/20000 - Train Loss: 4.4656 - Test Loss: 14.8856 - MSE: 14.8856 - MAE: 2.9982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6517/20000 - Train Loss: 4.4625 - Test Loss: 14.8793 - MSE: 14.8793 - MAE: 2.9974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6518/20000 - Train Loss: 4.4595 - Test Loss: 14.8730 - MSE: 14.8731 - MAE: 2.9966\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6519/20000 - Train Loss: 4.4564 - Test Loss: 14.8667 - MSE: 14.8667 - MAE: 2.9959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6520/20000 - Train Loss: 4.4534 - Test Loss: 14.8605 - MSE: 14.8605 - MAE: 2.9951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6521/20000 - Train Loss: 4.4503 - Test Loss: 14.8542 - MSE: 14.8542 - MAE: 2.9943\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6522/20000 - Train Loss: 4.4473 - Test Loss: 14.8479 - MSE: 14.8479 - MAE: 2.9935\n",
      "2/2 [==============================] - 0s 957us/step\n",
      "Epoch 6523/20000 - Train Loss: 4.4443 - Test Loss: 14.8416 - MSE: 14.8416 - MAE: 2.9928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6524/20000 - Train Loss: 4.4412 - Test Loss: 14.8353 - MSE: 14.8353 - MAE: 2.9920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6525/20000 - Train Loss: 4.4382 - Test Loss: 14.8290 - MSE: 14.8290 - MAE: 2.9912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6526/20000 - Train Loss: 4.4351 - Test Loss: 14.8227 - MSE: 14.8227 - MAE: 2.9905\n",
      "2/2 [==============================] - 0s 986us/step\n",
      "Epoch 6527/20000 - Train Loss: 4.4321 - Test Loss: 14.8164 - MSE: 14.8164 - MAE: 2.9898\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6528/20000 - Train Loss: 4.4291 - Test Loss: 14.8102 - MSE: 14.8102 - MAE: 2.9891\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6529/20000 - Train Loss: 4.4260 - Test Loss: 14.8039 - MSE: 14.8039 - MAE: 2.9884\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6530/20000 - Train Loss: 4.4230 - Test Loss: 14.7977 - MSE: 14.7977 - MAE: 2.9877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6531/20000 - Train Loss: 4.4200 - Test Loss: 14.7914 - MSE: 14.7914 - MAE: 2.9870\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6532/20000 - Train Loss: 4.4169 - Test Loss: 14.7851 - MSE: 14.7851 - MAE: 2.9863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6533/20000 - Train Loss: 4.4139 - Test Loss: 14.7788 - MSE: 14.7788 - MAE: 2.9856\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6534/20000 - Train Loss: 4.4109 - Test Loss: 14.7725 - MSE: 14.7726 - MAE: 2.9848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6535/20000 - Train Loss: 4.4079 - Test Loss: 14.7663 - MSE: 14.7663 - MAE: 2.9841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6536/20000 - Train Loss: 4.4048 - Test Loss: 14.7601 - MSE: 14.7601 - MAE: 2.9834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6537/20000 - Train Loss: 4.4018 - Test Loss: 14.7538 - MSE: 14.7538 - MAE: 2.9827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6538/20000 - Train Loss: 4.3988 - Test Loss: 14.7476 - MSE: 14.7476 - MAE: 2.9820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6539/20000 - Train Loss: 4.3958 - Test Loss: 14.7414 - MSE: 14.7414 - MAE: 2.9813\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6540/20000 - Train Loss: 4.3928 - Test Loss: 14.7352 - MSE: 14.7352 - MAE: 2.9806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6541/20000 - Train Loss: 4.3897 - Test Loss: 14.7289 - MSE: 14.7289 - MAE: 2.9799\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6542/20000 - Train Loss: 4.3867 - Test Loss: 14.7226 - MSE: 14.7226 - MAE: 2.9792\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6543/20000 - Train Loss: 4.3837 - Test Loss: 14.7164 - MSE: 14.7164 - MAE: 2.9785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6544/20000 - Train Loss: 4.3807 - Test Loss: 14.7102 - MSE: 14.7102 - MAE: 2.9777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6545/20000 - Train Loss: 4.3777 - Test Loss: 14.7040 - MSE: 14.7040 - MAE: 2.9770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6546/20000 - Train Loss: 4.3747 - Test Loss: 14.6978 - MSE: 14.6978 - MAE: 2.9763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6547/20000 - Train Loss: 4.3717 - Test Loss: 14.6915 - MSE: 14.6915 - MAE: 2.9756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6548/20000 - Train Loss: 4.3686 - Test Loss: 14.6853 - MSE: 14.6853 - MAE: 2.9749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6549/20000 - Train Loss: 4.3656 - Test Loss: 14.6791 - MSE: 14.6791 - MAE: 2.9742\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6550/20000 - Train Loss: 4.3626 - Test Loss: 14.6728 - MSE: 14.6728 - MAE: 2.9735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6551/20000 - Train Loss: 4.3596 - Test Loss: 14.6666 - MSE: 14.6666 - MAE: 2.9728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6552/20000 - Train Loss: 4.3566 - Test Loss: 14.6605 - MSE: 14.6605 - MAE: 2.9721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6553/20000 - Train Loss: 4.3536 - Test Loss: 14.6543 - MSE: 14.6543 - MAE: 2.9714\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6554/20000 - Train Loss: 4.3506 - Test Loss: 14.6481 - MSE: 14.6481 - MAE: 2.9706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6555/20000 - Train Loss: 4.3476 - Test Loss: 14.6419 - MSE: 14.6419 - MAE: 2.9699\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 6556/20000 - Train Loss: 4.3446 - Test Loss: 14.6357 - MSE: 14.6357 - MAE: 2.9692\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6557/20000 - Train Loss: 4.3416 - Test Loss: 14.6295 - MSE: 14.6295 - MAE: 2.9685\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6558/20000 - Train Loss: 4.3386 - Test Loss: 14.6233 - MSE: 14.6233 - MAE: 2.9678\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6559/20000 - Train Loss: 4.3356 - Test Loss: 14.6171 - MSE: 14.6171 - MAE: 2.9671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6560/20000 - Train Loss: 4.3326 - Test Loss: 14.6109 - MSE: 14.6109 - MAE: 2.9664\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6561/20000 - Train Loss: 4.3297 - Test Loss: 14.6047 - MSE: 14.6047 - MAE: 2.9657\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6562/20000 - Train Loss: 4.3267 - Test Loss: 14.5986 - MSE: 14.5986 - MAE: 2.9650\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6563/20000 - Train Loss: 4.3237 - Test Loss: 14.5924 - MSE: 14.5924 - MAE: 2.9643\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6564/20000 - Train Loss: 4.3207 - Test Loss: 14.5863 - MSE: 14.5863 - MAE: 2.9635\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6565/20000 - Train Loss: 4.3177 - Test Loss: 14.5801 - MSE: 14.5801 - MAE: 2.9628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6566/20000 - Train Loss: 4.3147 - Test Loss: 14.5739 - MSE: 14.5739 - MAE: 2.9621\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6567/20000 - Train Loss: 4.3117 - Test Loss: 14.5678 - MSE: 14.5678 - MAE: 2.9614\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 6568/20000 - Train Loss: 4.3088 - Test Loss: 14.5616 - MSE: 14.5616 - MAE: 2.9607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6569/20000 - Train Loss: 4.3058 - Test Loss: 14.5554 - MSE: 14.5554 - MAE: 2.9600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6570/20000 - Train Loss: 4.3028 - Test Loss: 14.5493 - MSE: 14.5493 - MAE: 2.9593\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6571/20000 - Train Loss: 4.2998 - Test Loss: 14.5432 - MSE: 14.5432 - MAE: 2.9586\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6572/20000 - Train Loss: 4.2968 - Test Loss: 14.5370 - MSE: 14.5370 - MAE: 2.9578\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6573/20000 - Train Loss: 4.2939 - Test Loss: 14.5309 - MSE: 14.5309 - MAE: 2.9571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6574/20000 - Train Loss: 4.2909 - Test Loss: 14.5248 - MSE: 14.5248 - MAE: 2.9564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6575/20000 - Train Loss: 4.2879 - Test Loss: 14.5186 - MSE: 14.5186 - MAE: 2.9557\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6576/20000 - Train Loss: 4.2850 - Test Loss: 14.5125 - MSE: 14.5125 - MAE: 2.9550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6577/20000 - Train Loss: 4.2820 - Test Loss: 14.5064 - MSE: 14.5064 - MAE: 2.9543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6578/20000 - Train Loss: 4.2790 - Test Loss: 14.5002 - MSE: 14.5002 - MAE: 2.9536\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6579/20000 - Train Loss: 4.2761 - Test Loss: 14.4941 - MSE: 14.4941 - MAE: 2.9529\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6580/20000 - Train Loss: 4.2731 - Test Loss: 14.4879 - MSE: 14.4879 - MAE: 2.9522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6581/20000 - Train Loss: 4.2701 - Test Loss: 14.4818 - MSE: 14.4818 - MAE: 2.9514\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 6582/20000 - Train Loss: 4.2672 - Test Loss: 14.4757 - MSE: 14.4757 - MAE: 2.9507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6583/20000 - Train Loss: 4.2642 - Test Loss: 14.4696 - MSE: 14.4696 - MAE: 2.9500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6584/20000 - Train Loss: 4.2612 - Test Loss: 14.4636 - MSE: 14.4636 - MAE: 2.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6585/20000 - Train Loss: 4.2583 - Test Loss: 14.4575 - MSE: 14.4575 - MAE: 2.9486\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 6586/20000 - Train Loss: 4.2553 - Test Loss: 14.4513 - MSE: 14.4513 - MAE: 2.9479\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6587/20000 - Train Loss: 4.2524 - Test Loss: 14.4452 - MSE: 14.4452 - MAE: 2.9472\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6588/20000 - Train Loss: 4.2494 - Test Loss: 14.4391 - MSE: 14.4391 - MAE: 2.9465\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 6589/20000 - Train Loss: 4.2465 - Test Loss: 14.4330 - MSE: 14.4330 - MAE: 2.9458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6590/20000 - Train Loss: 4.2435 - Test Loss: 14.4269 - MSE: 14.4269 - MAE: 2.9450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6591/20000 - Train Loss: 4.2406 - Test Loss: 14.4209 - MSE: 14.4209 - MAE: 2.9443\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6592/20000 - Train Loss: 4.2376 - Test Loss: 14.4148 - MSE: 14.4148 - MAE: 2.9436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6593/20000 - Train Loss: 4.2347 - Test Loss: 14.4087 - MSE: 14.4087 - MAE: 2.9429\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 6594/20000 - Train Loss: 4.2317 - Test Loss: 14.4026 - MSE: 14.4026 - MAE: 2.9422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6595/20000 - Train Loss: 4.2288 - Test Loss: 14.3965 - MSE: 14.3965 - MAE: 2.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6596/20000 - Train Loss: 4.2258 - Test Loss: 14.3905 - MSE: 14.3905 - MAE: 2.9408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6597/20000 - Train Loss: 4.2229 - Test Loss: 14.3844 - MSE: 14.3844 - MAE: 2.9401\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6598/20000 - Train Loss: 4.2199 - Test Loss: 14.3783 - MSE: 14.3783 - MAE: 2.9394\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6599/20000 - Train Loss: 4.2170 - Test Loss: 14.3723 - MSE: 14.3723 - MAE: 2.9386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6600/20000 - Train Loss: 4.2141 - Test Loss: 14.3662 - MSE: 14.3662 - MAE: 2.9379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6601/20000 - Train Loss: 4.2111 - Test Loss: 14.3602 - MSE: 14.3602 - MAE: 2.9372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6602/20000 - Train Loss: 4.2082 - Test Loss: 14.3541 - MSE: 14.3541 - MAE: 2.9365\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6603/20000 - Train Loss: 4.2053 - Test Loss: 14.3481 - MSE: 14.3481 - MAE: 2.9358\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6604/20000 - Train Loss: 4.2023 - Test Loss: 14.3420 - MSE: 14.3420 - MAE: 2.9351\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 6605/20000 - Train Loss: 4.1994 - Test Loss: 14.3359 - MSE: 14.3359 - MAE: 2.9344\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 6606/20000 - Train Loss: 4.1965 - Test Loss: 14.3299 - MSE: 14.3299 - MAE: 2.9337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6607/20000 - Train Loss: 4.1935 - Test Loss: 14.3239 - MSE: 14.3239 - MAE: 2.9330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6608/20000 - Train Loss: 4.1906 - Test Loss: 14.3178 - MSE: 14.3178 - MAE: 2.9322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6609/20000 - Train Loss: 4.1877 - Test Loss: 14.3118 - MSE: 14.3118 - MAE: 2.9315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6610/20000 - Train Loss: 4.1848 - Test Loss: 14.3058 - MSE: 14.3058 - MAE: 2.9308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6611/20000 - Train Loss: 4.1818 - Test Loss: 14.2998 - MSE: 14.2998 - MAE: 2.9301\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6612/20000 - Train Loss: 4.1789 - Test Loss: 14.2937 - MSE: 14.2937 - MAE: 2.9294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6613/20000 - Train Loss: 4.1760 - Test Loss: 14.2877 - MSE: 14.2877 - MAE: 2.9287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6614/20000 - Train Loss: 4.1731 - Test Loss: 14.2817 - MSE: 14.2817 - MAE: 2.9280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6615/20000 - Train Loss: 4.1702 - Test Loss: 14.2757 - MSE: 14.2757 - MAE: 2.9273\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6616/20000 - Train Loss: 4.1673 - Test Loss: 14.2697 - MSE: 14.2697 - MAE: 2.9265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6617/20000 - Train Loss: 4.1643 - Test Loss: 14.2637 - MSE: 14.2637 - MAE: 2.9258\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6618/20000 - Train Loss: 4.1614 - Test Loss: 14.2577 - MSE: 14.2577 - MAE: 2.9252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6619/20000 - Train Loss: 4.1585 - Test Loss: 14.2517 - MSE: 14.2517 - MAE: 2.9246\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6620/20000 - Train Loss: 4.1556 - Test Loss: 14.2457 - MSE: 14.2457 - MAE: 2.9240\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6621/20000 - Train Loss: 4.1527 - Test Loss: 14.2397 - MSE: 14.2397 - MAE: 2.9234\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6622/20000 - Train Loss: 4.1498 - Test Loss: 14.2337 - MSE: 14.2337 - MAE: 2.9228\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 6623/20000 - Train Loss: 4.1469 - Test Loss: 14.2277 - MSE: 14.2277 - MAE: 2.9222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6624/20000 - Train Loss: 4.1440 - Test Loss: 14.2217 - MSE: 14.2217 - MAE: 2.9216\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6625/20000 - Train Loss: 4.1411 - Test Loss: 14.2157 - MSE: 14.2157 - MAE: 2.9210\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6626/20000 - Train Loss: 4.1382 - Test Loss: 14.2097 - MSE: 14.2097 - MAE: 2.9204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6627/20000 - Train Loss: 4.1353 - Test Loss: 14.2038 - MSE: 14.2038 - MAE: 2.9199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6628/20000 - Train Loss: 4.1324 - Test Loss: 14.1978 - MSE: 14.1978 - MAE: 2.9193\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6629/20000 - Train Loss: 4.1295 - Test Loss: 14.1918 - MSE: 14.1918 - MAE: 2.9187\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6630/20000 - Train Loss: 4.1266 - Test Loss: 14.1859 - MSE: 14.1859 - MAE: 2.9181\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6631/20000 - Train Loss: 4.1237 - Test Loss: 14.1799 - MSE: 14.1799 - MAE: 2.9175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6632/20000 - Train Loss: 4.1208 - Test Loss: 14.1740 - MSE: 14.1740 - MAE: 2.9169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6633/20000 - Train Loss: 4.1179 - Test Loss: 14.1680 - MSE: 14.1680 - MAE: 2.9163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6634/20000 - Train Loss: 4.1150 - Test Loss: 14.1620 - MSE: 14.1620 - MAE: 2.9157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6635/20000 - Train Loss: 4.1121 - Test Loss: 14.1560 - MSE: 14.1560 - MAE: 2.9151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6636/20000 - Train Loss: 4.1092 - Test Loss: 14.1501 - MSE: 14.1501 - MAE: 2.9146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6637/20000 - Train Loss: 4.1063 - Test Loss: 14.1441 - MSE: 14.1441 - MAE: 2.9140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6638/20000 - Train Loss: 4.1035 - Test Loss: 14.1382 - MSE: 14.1382 - MAE: 2.9134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6639/20000 - Train Loss: 4.1006 - Test Loss: 14.1324 - MSE: 14.1324 - MAE: 2.9128\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6640/20000 - Train Loss: 4.0977 - Test Loss: 14.1264 - MSE: 14.1264 - MAE: 2.9122\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6641/20000 - Train Loss: 4.0948 - Test Loss: 14.1205 - MSE: 14.1205 - MAE: 2.9116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6642/20000 - Train Loss: 4.0919 - Test Loss: 14.1145 - MSE: 14.1145 - MAE: 2.9110\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6643/20000 - Train Loss: 4.0891 - Test Loss: 14.1086 - MSE: 14.1086 - MAE: 2.9104\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6644/20000 - Train Loss: 4.0862 - Test Loss: 14.1026 - MSE: 14.1026 - MAE: 2.9098\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6645/20000 - Train Loss: 4.0833 - Test Loss: 14.0967 - MSE: 14.0967 - MAE: 2.9092\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6646/20000 - Train Loss: 4.0804 - Test Loss: 14.0908 - MSE: 14.0908 - MAE: 2.9087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6647/20000 - Train Loss: 4.0776 - Test Loss: 14.0849 - MSE: 14.0849 - MAE: 2.9081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6648/20000 - Train Loss: 4.0747 - Test Loss: 14.0790 - MSE: 14.0790 - MAE: 2.9075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6649/20000 - Train Loss: 4.0718 - Test Loss: 14.0731 - MSE: 14.0731 - MAE: 2.9069\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6650/20000 - Train Loss: 4.0689 - Test Loss: 14.0672 - MSE: 14.0672 - MAE: 2.9063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6651/20000 - Train Loss: 4.0661 - Test Loss: 14.0612 - MSE: 14.0612 - MAE: 2.9057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6652/20000 - Train Loss: 4.0632 - Test Loss: 14.0554 - MSE: 14.0554 - MAE: 2.9051\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6653/20000 - Train Loss: 4.0603 - Test Loss: 14.0495 - MSE: 14.0495 - MAE: 2.9045\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6654/20000 - Train Loss: 4.0575 - Test Loss: 14.0436 - MSE: 14.0436 - MAE: 2.9039\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 6655/20000 - Train Loss: 4.0546 - Test Loss: 14.0377 - MSE: 14.0377 - MAE: 2.9034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6656/20000 - Train Loss: 4.0518 - Test Loss: 14.0318 - MSE: 14.0318 - MAE: 2.9028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6657/20000 - Train Loss: 4.0489 - Test Loss: 14.0259 - MSE: 14.0259 - MAE: 2.9022\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6658/20000 - Train Loss: 4.0460 - Test Loss: 14.0200 - MSE: 14.0200 - MAE: 2.9016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6659/20000 - Train Loss: 4.0432 - Test Loss: 14.0142 - MSE: 14.0142 - MAE: 2.9010\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6660/20000 - Train Loss: 4.0403 - Test Loss: 14.0083 - MSE: 14.0083 - MAE: 2.9004\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6661/20000 - Train Loss: 4.0375 - Test Loss: 14.0024 - MSE: 14.0024 - MAE: 2.8998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6662/20000 - Train Loss: 4.0346 - Test Loss: 13.9966 - MSE: 13.9966 - MAE: 2.8992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6663/20000 - Train Loss: 4.0318 - Test Loss: 13.9907 - MSE: 13.9907 - MAE: 2.8986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6664/20000 - Train Loss: 4.0289 - Test Loss: 13.9848 - MSE: 13.9848 - MAE: 2.8980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6665/20000 - Train Loss: 4.0261 - Test Loss: 13.9790 - MSE: 13.9790 - MAE: 2.8974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6666/20000 - Train Loss: 4.0232 - Test Loss: 13.9731 - MSE: 13.9731 - MAE: 2.8969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6667/20000 - Train Loss: 4.0204 - Test Loss: 13.9673 - MSE: 13.9673 - MAE: 2.8963\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 6668/20000 - Train Loss: 4.0176 - Test Loss: 13.9614 - MSE: 13.9614 - MAE: 2.8957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6669/20000 - Train Loss: 4.0147 - Test Loss: 13.9556 - MSE: 13.9556 - MAE: 2.8951\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6670/20000 - Train Loss: 4.0119 - Test Loss: 13.9497 - MSE: 13.9497 - MAE: 2.8945\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6671/20000 - Train Loss: 4.0090 - Test Loss: 13.9439 - MSE: 13.9439 - MAE: 2.8939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6672/20000 - Train Loss: 4.0062 - Test Loss: 13.9380 - MSE: 13.9380 - MAE: 2.8933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6673/20000 - Train Loss: 4.0034 - Test Loss: 13.9322 - MSE: 13.9322 - MAE: 2.8927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6674/20000 - Train Loss: 4.0005 - Test Loss: 13.9264 - MSE: 13.9264 - MAE: 2.8921\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6675/20000 - Train Loss: 3.9977 - Test Loss: 13.9206 - MSE: 13.9206 - MAE: 2.8916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6676/20000 - Train Loss: 3.9949 - Test Loss: 13.9147 - MSE: 13.9147 - MAE: 2.8910\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6677/20000 - Train Loss: 3.9920 - Test Loss: 13.9089 - MSE: 13.9089 - MAE: 2.8904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6678/20000 - Train Loss: 3.9892 - Test Loss: 13.9031 - MSE: 13.9031 - MAE: 2.8898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6679/20000 - Train Loss: 3.9864 - Test Loss: 13.8972 - MSE: 13.8972 - MAE: 2.8892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6680/20000 - Train Loss: 3.9836 - Test Loss: 13.8914 - MSE: 13.8914 - MAE: 2.8886\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6681/20000 - Train Loss: 3.9807 - Test Loss: 13.8856 - MSE: 13.8856 - MAE: 2.8880\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6682/20000 - Train Loss: 3.9779 - Test Loss: 13.8799 - MSE: 13.8799 - MAE: 2.8874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6683/20000 - Train Loss: 3.9751 - Test Loss: 13.8741 - MSE: 13.8741 - MAE: 2.8868\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6684/20000 - Train Loss: 3.9723 - Test Loss: 13.8683 - MSE: 13.8683 - MAE: 2.8862\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6685/20000 - Train Loss: 3.9694 - Test Loss: 13.8625 - MSE: 13.8625 - MAE: 2.8856\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6686/20000 - Train Loss: 3.9666 - Test Loss: 13.8567 - MSE: 13.8567 - MAE: 2.8851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6687/20000 - Train Loss: 3.9638 - Test Loss: 13.8509 - MSE: 13.8509 - MAE: 2.8845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6688/20000 - Train Loss: 3.9610 - Test Loss: 13.8451 - MSE: 13.8451 - MAE: 2.8839\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6689/20000 - Train Loss: 3.9582 - Test Loss: 13.8393 - MSE: 13.8393 - MAE: 2.8833\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6690/20000 - Train Loss: 3.9554 - Test Loss: 13.8335 - MSE: 13.8335 - MAE: 2.8827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6691/20000 - Train Loss: 3.9526 - Test Loss: 13.8278 - MSE: 13.8278 - MAE: 2.8821\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6692/20000 - Train Loss: 3.9498 - Test Loss: 13.8220 - MSE: 13.8220 - MAE: 2.8815\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6693/20000 - Train Loss: 3.9469 - Test Loss: 13.8162 - MSE: 13.8162 - MAE: 2.8809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6694/20000 - Train Loss: 3.9441 - Test Loss: 13.8104 - MSE: 13.8104 - MAE: 2.8803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6695/20000 - Train Loss: 3.9413 - Test Loss: 13.8047 - MSE: 13.8047 - MAE: 2.8797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6696/20000 - Train Loss: 3.9385 - Test Loss: 13.7989 - MSE: 13.7989 - MAE: 2.8792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6697/20000 - Train Loss: 3.9357 - Test Loss: 13.7932 - MSE: 13.7932 - MAE: 2.8786\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6698/20000 - Train Loss: 3.9329 - Test Loss: 13.7874 - MSE: 13.7874 - MAE: 2.8780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6699/20000 - Train Loss: 3.9301 - Test Loss: 13.7816 - MSE: 13.7816 - MAE: 2.8774\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6700/20000 - Train Loss: 3.9273 - Test Loss: 13.7759 - MSE: 13.7759 - MAE: 2.8768\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6701/20000 - Train Loss: 3.9245 - Test Loss: 13.7702 - MSE: 13.7702 - MAE: 2.8762\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6702/20000 - Train Loss: 3.9217 - Test Loss: 13.7644 - MSE: 13.7644 - MAE: 2.8756\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 6703/20000 - Train Loss: 3.9190 - Test Loss: 13.7587 - MSE: 13.7587 - MAE: 2.8750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6704/20000 - Train Loss: 3.9162 - Test Loss: 13.7529 - MSE: 13.7529 - MAE: 2.8744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6705/20000 - Train Loss: 3.9134 - Test Loss: 13.7472 - MSE: 13.7472 - MAE: 2.8738\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6706/20000 - Train Loss: 3.9106 - Test Loss: 13.7415 - MSE: 13.7415 - MAE: 2.8733\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6707/20000 - Train Loss: 3.9078 - Test Loss: 13.7357 - MSE: 13.7357 - MAE: 2.8727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6708/20000 - Train Loss: 3.9050 - Test Loss: 13.7300 - MSE: 13.7300 - MAE: 2.8721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6709/20000 - Train Loss: 3.9022 - Test Loss: 13.7243 - MSE: 13.7243 - MAE: 2.8715\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6710/20000 - Train Loss: 3.8994 - Test Loss: 13.7186 - MSE: 13.7186 - MAE: 2.8709\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6711/20000 - Train Loss: 3.8967 - Test Loss: 13.7129 - MSE: 13.7129 - MAE: 2.8703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6712/20000 - Train Loss: 3.8939 - Test Loss: 13.7072 - MSE: 13.7072 - MAE: 2.8697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6713/20000 - Train Loss: 3.8911 - Test Loss: 13.7015 - MSE: 13.7015 - MAE: 2.8691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6714/20000 - Train Loss: 3.8883 - Test Loss: 13.6958 - MSE: 13.6958 - MAE: 2.8685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6715/20000 - Train Loss: 3.8855 - Test Loss: 13.6900 - MSE: 13.6900 - MAE: 2.8679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6716/20000 - Train Loss: 3.8828 - Test Loss: 13.6843 - MSE: 13.6843 - MAE: 2.8673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6717/20000 - Train Loss: 3.8800 - Test Loss: 13.6786 - MSE: 13.6786 - MAE: 2.8668\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6718/20000 - Train Loss: 3.8772 - Test Loss: 13.6729 - MSE: 13.6729 - MAE: 2.8662\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6719/20000 - Train Loss: 3.8745 - Test Loss: 13.6673 - MSE: 13.6673 - MAE: 2.8656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6720/20000 - Train Loss: 3.8717 - Test Loss: 13.6616 - MSE: 13.6616 - MAE: 2.8650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6721/20000 - Train Loss: 3.8689 - Test Loss: 13.6559 - MSE: 13.6559 - MAE: 2.8644\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6722/20000 - Train Loss: 3.8662 - Test Loss: 13.6503 - MSE: 13.6503 - MAE: 2.8638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6723/20000 - Train Loss: 3.8634 - Test Loss: 13.6445 - MSE: 13.6445 - MAE: 2.8632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6724/20000 - Train Loss: 3.8606 - Test Loss: 13.6389 - MSE: 13.6389 - MAE: 2.8626\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 6725/20000 - Train Loss: 3.8579 - Test Loss: 13.6332 - MSE: 13.6332 - MAE: 2.8620\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6726/20000 - Train Loss: 3.8551 - Test Loss: 13.6275 - MSE: 13.6275 - MAE: 2.8614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6727/20000 - Train Loss: 3.8524 - Test Loss: 13.6219 - MSE: 13.6219 - MAE: 2.8609\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6728/20000 - Train Loss: 3.8496 - Test Loss: 13.6163 - MSE: 13.6163 - MAE: 2.8603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6729/20000 - Train Loss: 3.8468 - Test Loss: 13.6106 - MSE: 13.6106 - MAE: 2.8597\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6730/20000 - Train Loss: 3.8441 - Test Loss: 13.6049 - MSE: 13.6049 - MAE: 2.8591\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6731/20000 - Train Loss: 3.8413 - Test Loss: 13.5993 - MSE: 13.5993 - MAE: 2.8585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6732/20000 - Train Loss: 3.8386 - Test Loss: 13.5936 - MSE: 13.5936 - MAE: 2.8579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6733/20000 - Train Loss: 3.8358 - Test Loss: 13.5880 - MSE: 13.5880 - MAE: 2.8573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6734/20000 - Train Loss: 3.8331 - Test Loss: 13.5823 - MSE: 13.5823 - MAE: 2.8567\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6735/20000 - Train Loss: 3.8303 - Test Loss: 13.5767 - MSE: 13.5767 - MAE: 2.8561\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6736/20000 - Train Loss: 3.8276 - Test Loss: 13.5711 - MSE: 13.5711 - MAE: 2.8555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6737/20000 - Train Loss: 3.8249 - Test Loss: 13.5655 - MSE: 13.5655 - MAE: 2.8550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6738/20000 - Train Loss: 3.8221 - Test Loss: 13.5598 - MSE: 13.5598 - MAE: 2.8544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6739/20000 - Train Loss: 3.8194 - Test Loss: 13.5542 - MSE: 13.5542 - MAE: 2.8538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6740/20000 - Train Loss: 3.8166 - Test Loss: 13.5485 - MSE: 13.5485 - MAE: 2.8532\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6741/20000 - Train Loss: 3.8139 - Test Loss: 13.5429 - MSE: 13.5429 - MAE: 2.8526\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 6742/20000 - Train Loss: 3.8112 - Test Loss: 13.5373 - MSE: 13.5373 - MAE: 2.8520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6743/20000 - Train Loss: 3.8084 - Test Loss: 13.5317 - MSE: 13.5317 - MAE: 2.8514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6744/20000 - Train Loss: 3.8057 - Test Loss: 13.5261 - MSE: 13.5261 - MAE: 2.8508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6745/20000 - Train Loss: 3.8030 - Test Loss: 13.5205 - MSE: 13.5205 - MAE: 2.8502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6746/20000 - Train Loss: 3.8002 - Test Loss: 13.5149 - MSE: 13.5149 - MAE: 2.8496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6747/20000 - Train Loss: 3.7975 - Test Loss: 13.5093 - MSE: 13.5093 - MAE: 2.8490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6748/20000 - Train Loss: 3.7948 - Test Loss: 13.5037 - MSE: 13.5037 - MAE: 2.8485\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 6749/20000 - Train Loss: 3.7920 - Test Loss: 13.4981 - MSE: 13.4981 - MAE: 2.8479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6750/20000 - Train Loss: 3.7893 - Test Loss: 13.4925 - MSE: 13.4925 - MAE: 2.8473\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 6751/20000 - Train Loss: 3.7866 - Test Loss: 13.4869 - MSE: 13.4869 - MAE: 2.8467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6752/20000 - Train Loss: 3.7839 - Test Loss: 13.4813 - MSE: 13.4813 - MAE: 2.8461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6753/20000 - Train Loss: 3.7811 - Test Loss: 13.4758 - MSE: 13.4758 - MAE: 2.8455\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 6754/20000 - Train Loss: 3.7784 - Test Loss: 13.4702 - MSE: 13.4702 - MAE: 2.8449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6755/20000 - Train Loss: 3.7757 - Test Loss: 13.4646 - MSE: 13.4646 - MAE: 2.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6756/20000 - Train Loss: 3.7730 - Test Loss: 13.4590 - MSE: 13.4590 - MAE: 2.8437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6757/20000 - Train Loss: 3.7703 - Test Loss: 13.4535 - MSE: 13.4535 - MAE: 2.8431\n",
      "2/2 [==============================] - 0s 986us/step\n",
      "Epoch 6758/20000 - Train Loss: 3.7676 - Test Loss: 13.4479 - MSE: 13.4479 - MAE: 2.8425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6759/20000 - Train Loss: 3.7649 - Test Loss: 13.4423 - MSE: 13.4423 - MAE: 2.8420\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6760/20000 - Train Loss: 3.7622 - Test Loss: 13.4368 - MSE: 13.4368 - MAE: 2.8414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6761/20000 - Train Loss: 3.7594 - Test Loss: 13.4313 - MSE: 13.4313 - MAE: 2.8408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6762/20000 - Train Loss: 3.7567 - Test Loss: 13.4257 - MSE: 13.4257 - MAE: 2.8402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6763/20000 - Train Loss: 3.7540 - Test Loss: 13.4201 - MSE: 13.4201 - MAE: 2.8396\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6764/20000 - Train Loss: 3.7513 - Test Loss: 13.4146 - MSE: 13.4146 - MAE: 2.8390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6765/20000 - Train Loss: 3.7486 - Test Loss: 13.4091 - MSE: 13.4091 - MAE: 2.8384\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 6766/20000 - Train Loss: 3.7459 - Test Loss: 13.4035 - MSE: 13.4035 - MAE: 2.8378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6767/20000 - Train Loss: 3.7432 - Test Loss: 13.3980 - MSE: 13.3980 - MAE: 2.8372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6768/20000 - Train Loss: 3.7405 - Test Loss: 13.3924 - MSE: 13.3924 - MAE: 2.8366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6769/20000 - Train Loss: 3.7378 - Test Loss: 13.3869 - MSE: 13.3869 - MAE: 2.8361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6770/20000 - Train Loss: 3.7351 - Test Loss: 13.3814 - MSE: 13.3814 - MAE: 2.8355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6771/20000 - Train Loss: 3.7324 - Test Loss: 13.3759 - MSE: 13.3759 - MAE: 2.8349\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 6772/20000 - Train Loss: 3.7297 - Test Loss: 13.3703 - MSE: 13.3703 - MAE: 2.8343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6773/20000 - Train Loss: 3.7271 - Test Loss: 13.3648 - MSE: 13.3648 - MAE: 2.8337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6774/20000 - Train Loss: 3.7244 - Test Loss: 13.3593 - MSE: 13.3593 - MAE: 2.8331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6775/20000 - Train Loss: 3.7217 - Test Loss: 13.3538 - MSE: 13.3538 - MAE: 2.8325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6776/20000 - Train Loss: 3.7190 - Test Loss: 13.3483 - MSE: 13.3483 - MAE: 2.8319\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6777/20000 - Train Loss: 3.7163 - Test Loss: 13.3428 - MSE: 13.3428 - MAE: 2.8313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6778/20000 - Train Loss: 3.7136 - Test Loss: 13.3373 - MSE: 13.3373 - MAE: 2.8307\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6779/20000 - Train Loss: 3.7109 - Test Loss: 13.3318 - MSE: 13.3318 - MAE: 2.8302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6780/20000 - Train Loss: 3.7083 - Test Loss: 13.3263 - MSE: 13.3263 - MAE: 2.8296\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6781/20000 - Train Loss: 3.7056 - Test Loss: 13.3208 - MSE: 13.3208 - MAE: 2.8290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6782/20000 - Train Loss: 3.7029 - Test Loss: 13.3153 - MSE: 13.3153 - MAE: 2.8284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6783/20000 - Train Loss: 3.7002 - Test Loss: 13.3098 - MSE: 13.3098 - MAE: 2.8278\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6784/20000 - Train Loss: 3.6975 - Test Loss: 13.3044 - MSE: 13.3044 - MAE: 2.8272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6785/20000 - Train Loss: 3.6949 - Test Loss: 13.2989 - MSE: 13.2989 - MAE: 2.8266\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 6786/20000 - Train Loss: 3.6922 - Test Loss: 13.2934 - MSE: 13.2934 - MAE: 2.8260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6787/20000 - Train Loss: 3.6895 - Test Loss: 13.2880 - MSE: 13.2880 - MAE: 2.8254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6788/20000 - Train Loss: 3.6869 - Test Loss: 13.2824 - MSE: 13.2824 - MAE: 2.8248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6789/20000 - Train Loss: 3.6842 - Test Loss: 13.2770 - MSE: 13.2770 - MAE: 2.8242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6790/20000 - Train Loss: 3.6815 - Test Loss: 13.2715 - MSE: 13.2715 - MAE: 2.8237\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6791/20000 - Train Loss: 3.6789 - Test Loss: 13.2661 - MSE: 13.2661 - MAE: 2.8231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6792/20000 - Train Loss: 3.6762 - Test Loss: 13.2607 - MSE: 13.2607 - MAE: 2.8225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6793/20000 - Train Loss: 3.6735 - Test Loss: 13.2552 - MSE: 13.2552 - MAE: 2.8219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6794/20000 - Train Loss: 3.6709 - Test Loss: 13.2497 - MSE: 13.2497 - MAE: 2.8213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6795/20000 - Train Loss: 3.6682 - Test Loss: 13.2443 - MSE: 13.2443 - MAE: 2.8207\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6796/20000 - Train Loss: 3.6656 - Test Loss: 13.2388 - MSE: 13.2388 - MAE: 2.8201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6797/20000 - Train Loss: 3.6629 - Test Loss: 13.2334 - MSE: 13.2334 - MAE: 2.8195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6798/20000 - Train Loss: 3.6603 - Test Loss: 13.2280 - MSE: 13.2280 - MAE: 2.8189\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6799/20000 - Train Loss: 3.6576 - Test Loss: 13.2226 - MSE: 13.2226 - MAE: 2.8183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6800/20000 - Train Loss: 3.6550 - Test Loss: 13.2171 - MSE: 13.2171 - MAE: 2.8178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6801/20000 - Train Loss: 3.6523 - Test Loss: 13.2117 - MSE: 13.2117 - MAE: 2.8172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6802/20000 - Train Loss: 3.6497 - Test Loss: 13.2063 - MSE: 13.2063 - MAE: 2.8166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6803/20000 - Train Loss: 3.6470 - Test Loss: 13.2009 - MSE: 13.2009 - MAE: 2.8160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6804/20000 - Train Loss: 3.6444 - Test Loss: 13.1954 - MSE: 13.1954 - MAE: 2.8154\n",
      "2/2 [==============================] - 0s 982us/step\n",
      "Epoch 6805/20000 - Train Loss: 3.6417 - Test Loss: 13.1900 - MSE: 13.1900 - MAE: 2.8148\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6806/20000 - Train Loss: 3.6391 - Test Loss: 13.1846 - MSE: 13.1846 - MAE: 2.8142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6807/20000 - Train Loss: 3.6364 - Test Loss: 13.1792 - MSE: 13.1792 - MAE: 2.8136\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6808/20000 - Train Loss: 3.6338 - Test Loss: 13.1738 - MSE: 13.1738 - MAE: 2.8130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6809/20000 - Train Loss: 3.6312 - Test Loss: 13.1684 - MSE: 13.1684 - MAE: 2.8124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6810/20000 - Train Loss: 3.6285 - Test Loss: 13.1630 - MSE: 13.1630 - MAE: 2.8119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6811/20000 - Train Loss: 3.6259 - Test Loss: 13.1576 - MSE: 13.1576 - MAE: 2.8113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6812/20000 - Train Loss: 3.6233 - Test Loss: 13.1522 - MSE: 13.1522 - MAE: 2.8107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6813/20000 - Train Loss: 3.6206 - Test Loss: 13.1468 - MSE: 13.1468 - MAE: 2.8101\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6814/20000 - Train Loss: 3.6180 - Test Loss: 13.1415 - MSE: 13.1415 - MAE: 2.8095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6815/20000 - Train Loss: 3.6154 - Test Loss: 13.1361 - MSE: 13.1361 - MAE: 2.8089\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6816/20000 - Train Loss: 3.6127 - Test Loss: 13.1308 - MSE: 13.1308 - MAE: 2.8083\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6817/20000 - Train Loss: 3.6101 - Test Loss: 13.1254 - MSE: 13.1254 - MAE: 2.8077\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6818/20000 - Train Loss: 3.6075 - Test Loss: 13.1200 - MSE: 13.1200 - MAE: 2.8071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6819/20000 - Train Loss: 3.6049 - Test Loss: 13.1146 - MSE: 13.1146 - MAE: 2.8065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6820/20000 - Train Loss: 3.6022 - Test Loss: 13.1092 - MSE: 13.1092 - MAE: 2.8059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6821/20000 - Train Loss: 3.5996 - Test Loss: 13.1039 - MSE: 13.1039 - MAE: 2.8054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6822/20000 - Train Loss: 3.5970 - Test Loss: 13.0985 - MSE: 13.0985 - MAE: 2.8048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6823/20000 - Train Loss: 3.5944 - Test Loss: 13.0932 - MSE: 13.0932 - MAE: 2.8042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6824/20000 - Train Loss: 3.5918 - Test Loss: 13.0878 - MSE: 13.0878 - MAE: 2.8036\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 6825/20000 - Train Loss: 3.5892 - Test Loss: 13.0825 - MSE: 13.0825 - MAE: 2.8030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6826/20000 - Train Loss: 3.5866 - Test Loss: 13.0771 - MSE: 13.0771 - MAE: 2.8024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6827/20000 - Train Loss: 3.5839 - Test Loss: 13.0718 - MSE: 13.0718 - MAE: 2.8018\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6828/20000 - Train Loss: 3.5813 - Test Loss: 13.0664 - MSE: 13.0664 - MAE: 2.8012\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6829/20000 - Train Loss: 3.5787 - Test Loss: 13.0611 - MSE: 13.0611 - MAE: 2.8006\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6830/20000 - Train Loss: 3.5761 - Test Loss: 13.0558 - MSE: 13.0558 - MAE: 2.8000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6831/20000 - Train Loss: 3.5735 - Test Loss: 13.0504 - MSE: 13.0504 - MAE: 2.7995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6832/20000 - Train Loss: 3.5709 - Test Loss: 13.0451 - MSE: 13.0451 - MAE: 2.7989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6833/20000 - Train Loss: 3.5683 - Test Loss: 13.0398 - MSE: 13.0398 - MAE: 2.7983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6834/20000 - Train Loss: 3.5657 - Test Loss: 13.0345 - MSE: 13.0345 - MAE: 2.7977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6835/20000 - Train Loss: 3.5631 - Test Loss: 13.0292 - MSE: 13.0292 - MAE: 2.7971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6836/20000 - Train Loss: 3.5605 - Test Loss: 13.0238 - MSE: 13.0238 - MAE: 2.7965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6837/20000 - Train Loss: 3.5579 - Test Loss: 13.0186 - MSE: 13.0186 - MAE: 2.7959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6838/20000 - Train Loss: 3.5553 - Test Loss: 13.0133 - MSE: 13.0133 - MAE: 2.7953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6839/20000 - Train Loss: 3.5527 - Test Loss: 13.0080 - MSE: 13.0080 - MAE: 2.7947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6840/20000 - Train Loss: 3.5501 - Test Loss: 13.0026 - MSE: 13.0026 - MAE: 2.7941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6841/20000 - Train Loss: 3.5476 - Test Loss: 12.9973 - MSE: 12.9973 - MAE: 2.7936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6842/20000 - Train Loss: 3.5450 - Test Loss: 12.9920 - MSE: 12.9920 - MAE: 2.7930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6843/20000 - Train Loss: 3.5424 - Test Loss: 12.9868 - MSE: 12.9868 - MAE: 2.7924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6844/20000 - Train Loss: 3.5398 - Test Loss: 12.9815 - MSE: 12.9815 - MAE: 2.7918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6845/20000 - Train Loss: 3.5372 - Test Loss: 12.9762 - MSE: 12.9762 - MAE: 2.7912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6846/20000 - Train Loss: 3.5346 - Test Loss: 12.9709 - MSE: 12.9709 - MAE: 2.7906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6847/20000 - Train Loss: 3.5320 - Test Loss: 12.9657 - MSE: 12.9657 - MAE: 2.7900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6848/20000 - Train Loss: 3.5295 - Test Loss: 12.9604 - MSE: 12.9604 - MAE: 2.7894\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6849/20000 - Train Loss: 3.5269 - Test Loss: 12.9551 - MSE: 12.9551 - MAE: 2.7888\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6850/20000 - Train Loss: 3.5243 - Test Loss: 12.9498 - MSE: 12.9498 - MAE: 2.7883\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6851/20000 - Train Loss: 3.5217 - Test Loss: 12.9446 - MSE: 12.9446 - MAE: 2.7877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6852/20000 - Train Loss: 3.5192 - Test Loss: 12.9393 - MSE: 12.9393 - MAE: 2.7871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6853/20000 - Train Loss: 3.5166 - Test Loss: 12.9341 - MSE: 12.9341 - MAE: 2.7865\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 6854/20000 - Train Loss: 3.5140 - Test Loss: 12.9288 - MSE: 12.9288 - MAE: 2.7859\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6855/20000 - Train Loss: 3.5115 - Test Loss: 12.9236 - MSE: 12.9236 - MAE: 2.7853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6856/20000 - Train Loss: 3.5089 - Test Loss: 12.9183 - MSE: 12.9183 - MAE: 2.7847\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6857/20000 - Train Loss: 3.5063 - Test Loss: 12.9130 - MSE: 12.9130 - MAE: 2.7841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6858/20000 - Train Loss: 3.5038 - Test Loss: 12.9078 - MSE: 12.9078 - MAE: 2.7835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6859/20000 - Train Loss: 3.5012 - Test Loss: 12.9026 - MSE: 12.9026 - MAE: 2.7829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6860/20000 - Train Loss: 3.4986 - Test Loss: 12.8974 - MSE: 12.8974 - MAE: 2.7824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6861/20000 - Train Loss: 3.4961 - Test Loss: 12.8922 - MSE: 12.8922 - MAE: 2.7818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6862/20000 - Train Loss: 3.4935 - Test Loss: 12.8869 - MSE: 12.8869 - MAE: 2.7812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6863/20000 - Train Loss: 3.4910 - Test Loss: 12.8817 - MSE: 12.8817 - MAE: 2.7806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6864/20000 - Train Loss: 3.4884 - Test Loss: 12.8764 - MSE: 12.8764 - MAE: 2.7800\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6865/20000 - Train Loss: 3.4859 - Test Loss: 12.8712 - MSE: 12.8712 - MAE: 2.7794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6866/20000 - Train Loss: 3.4833 - Test Loss: 12.8660 - MSE: 12.8660 - MAE: 2.7788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6867/20000 - Train Loss: 3.4808 - Test Loss: 12.8608 - MSE: 12.8608 - MAE: 2.7782\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 6868/20000 - Train Loss: 3.4782 - Test Loss: 12.8556 - MSE: 12.8556 - MAE: 2.7776\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6869/20000 - Train Loss: 3.4757 - Test Loss: 12.8504 - MSE: 12.8504 - MAE: 2.7771\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6870/20000 - Train Loss: 3.4731 - Test Loss: 12.8452 - MSE: 12.8452 - MAE: 2.7765\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6871/20000 - Train Loss: 3.4706 - Test Loss: 12.8400 - MSE: 12.8400 - MAE: 2.7759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6872/20000 - Train Loss: 3.4680 - Test Loss: 12.8348 - MSE: 12.8348 - MAE: 2.7753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6873/20000 - Train Loss: 3.4655 - Test Loss: 12.8296 - MSE: 12.8296 - MAE: 2.7747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6874/20000 - Train Loss: 3.4629 - Test Loss: 12.8244 - MSE: 12.8244 - MAE: 2.7741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6875/20000 - Train Loss: 3.4604 - Test Loss: 12.8193 - MSE: 12.8193 - MAE: 2.7735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6876/20000 - Train Loss: 3.4579 - Test Loss: 12.8141 - MSE: 12.8141 - MAE: 2.7729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6877/20000 - Train Loss: 3.4553 - Test Loss: 12.8089 - MSE: 12.8089 - MAE: 2.7723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6878/20000 - Train Loss: 3.4528 - Test Loss: 12.8038 - MSE: 12.8038 - MAE: 2.7718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6879/20000 - Train Loss: 3.4503 - Test Loss: 12.7986 - MSE: 12.7986 - MAE: 2.7712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6880/20000 - Train Loss: 3.4477 - Test Loss: 12.7934 - MSE: 12.7934 - MAE: 2.7706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6881/20000 - Train Loss: 3.4452 - Test Loss: 12.7882 - MSE: 12.7882 - MAE: 2.7700\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 6882/20000 - Train Loss: 3.4427 - Test Loss: 12.7831 - MSE: 12.7831 - MAE: 2.7694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6883/20000 - Train Loss: 3.4402 - Test Loss: 12.7779 - MSE: 12.7779 - MAE: 2.7688\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 6884/20000 - Train Loss: 3.4376 - Test Loss: 12.7728 - MSE: 12.7728 - MAE: 2.7682\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6885/20000 - Train Loss: 3.4351 - Test Loss: 12.7676 - MSE: 12.7676 - MAE: 2.7676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6886/20000 - Train Loss: 3.4326 - Test Loss: 12.7625 - MSE: 12.7625 - MAE: 2.7670\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 6887/20000 - Train Loss: 3.4301 - Test Loss: 12.7573 - MSE: 12.7573 - MAE: 2.7664\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6888/20000 - Train Loss: 3.4275 - Test Loss: 12.7521 - MSE: 12.7521 - MAE: 2.7659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6889/20000 - Train Loss: 3.4250 - Test Loss: 12.7470 - MSE: 12.7470 - MAE: 2.7653\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 6890/20000 - Train Loss: 3.4225 - Test Loss: 12.7419 - MSE: 12.7419 - MAE: 2.7647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6891/20000 - Train Loss: 3.4200 - Test Loss: 12.7368 - MSE: 12.7368 - MAE: 2.7641\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6892/20000 - Train Loss: 3.4175 - Test Loss: 12.7317 - MSE: 12.7317 - MAE: 2.7635\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6893/20000 - Train Loss: 3.4150 - Test Loss: 12.7265 - MSE: 12.7265 - MAE: 2.7629\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 6894/20000 - Train Loss: 3.4125 - Test Loss: 12.7214 - MSE: 12.7214 - MAE: 2.7623\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 6895/20000 - Train Loss: 3.4100 - Test Loss: 12.7162 - MSE: 12.7162 - MAE: 2.7617\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6896/20000 - Train Loss: 3.4075 - Test Loss: 12.7111 - MSE: 12.7111 - MAE: 2.7611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6897/20000 - Train Loss: 3.4050 - Test Loss: 12.7060 - MSE: 12.7060 - MAE: 2.7606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6898/20000 - Train Loss: 3.4024 - Test Loss: 12.7009 - MSE: 12.7009 - MAE: 2.7600\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6899/20000 - Train Loss: 3.3999 - Test Loss: 12.6958 - MSE: 12.6958 - MAE: 2.7594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6900/20000 - Train Loss: 3.3974 - Test Loss: 12.6908 - MSE: 12.6908 - MAE: 2.7588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6901/20000 - Train Loss: 3.3949 - Test Loss: 12.6857 - MSE: 12.6857 - MAE: 2.7582\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6902/20000 - Train Loss: 3.3925 - Test Loss: 12.6806 - MSE: 12.6806 - MAE: 2.7576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6903/20000 - Train Loss: 3.3900 - Test Loss: 12.6755 - MSE: 12.6755 - MAE: 2.7570\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6904/20000 - Train Loss: 3.3875 - Test Loss: 12.6703 - MSE: 12.6703 - MAE: 2.7564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6905/20000 - Train Loss: 3.3850 - Test Loss: 12.6652 - MSE: 12.6652 - MAE: 2.7558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6906/20000 - Train Loss: 3.3825 - Test Loss: 12.6601 - MSE: 12.6601 - MAE: 2.7552\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 6907/20000 - Train Loss: 3.3800 - Test Loss: 12.6551 - MSE: 12.6551 - MAE: 2.7547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6908/20000 - Train Loss: 3.3775 - Test Loss: 12.6500 - MSE: 12.6500 - MAE: 2.7541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6909/20000 - Train Loss: 3.3750 - Test Loss: 12.6450 - MSE: 12.6450 - MAE: 2.7535\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6910/20000 - Train Loss: 3.3725 - Test Loss: 12.6399 - MSE: 12.6399 - MAE: 2.7529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6911/20000 - Train Loss: 3.3700 - Test Loss: 12.6348 - MSE: 12.6348 - MAE: 2.7523\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6912/20000 - Train Loss: 3.3676 - Test Loss: 12.6298 - MSE: 12.6298 - MAE: 2.7517\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6913/20000 - Train Loss: 3.3651 - Test Loss: 12.6247 - MSE: 12.6247 - MAE: 2.7511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6914/20000 - Train Loss: 3.3626 - Test Loss: 12.6196 - MSE: 12.6196 - MAE: 2.7505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6915/20000 - Train Loss: 3.3601 - Test Loss: 12.6146 - MSE: 12.6146 - MAE: 2.7500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6916/20000 - Train Loss: 3.3577 - Test Loss: 12.6095 - MSE: 12.6095 - MAE: 2.7494\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6917/20000 - Train Loss: 3.3552 - Test Loss: 12.6045 - MSE: 12.6045 - MAE: 2.7488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6918/20000 - Train Loss: 3.3527 - Test Loss: 12.5995 - MSE: 12.5995 - MAE: 2.7482\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 6919/20000 - Train Loss: 3.3502 - Test Loss: 12.5945 - MSE: 12.5945 - MAE: 2.7476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6920/20000 - Train Loss: 3.3478 - Test Loss: 12.5894 - MSE: 12.5894 - MAE: 2.7470\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6921/20000 - Train Loss: 3.3453 - Test Loss: 12.5843 - MSE: 12.5843 - MAE: 2.7464\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6922/20000 - Train Loss: 3.3428 - Test Loss: 12.5793 - MSE: 12.5793 - MAE: 2.7458\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6923/20000 - Train Loss: 3.3404 - Test Loss: 12.5742 - MSE: 12.5742 - MAE: 2.7452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6924/20000 - Train Loss: 3.3379 - Test Loss: 12.5692 - MSE: 12.5692 - MAE: 2.7447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6925/20000 - Train Loss: 3.3354 - Test Loss: 12.5643 - MSE: 12.5643 - MAE: 2.7441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6926/20000 - Train Loss: 3.3330 - Test Loss: 12.5593 - MSE: 12.5593 - MAE: 2.7435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6927/20000 - Train Loss: 3.3305 - Test Loss: 12.5542 - MSE: 12.5542 - MAE: 2.7429\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 6928/20000 - Train Loss: 3.3281 - Test Loss: 12.5492 - MSE: 12.5492 - MAE: 2.7423\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 6929/20000 - Train Loss: 3.3256 - Test Loss: 12.5442 - MSE: 12.5442 - MAE: 2.7417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6930/20000 - Train Loss: 3.3232 - Test Loss: 12.5392 - MSE: 12.5392 - MAE: 2.7411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6931/20000 - Train Loss: 3.3207 - Test Loss: 12.5342 - MSE: 12.5342 - MAE: 2.7405\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6932/20000 - Train Loss: 3.3182 - Test Loss: 12.5292 - MSE: 12.5292 - MAE: 2.7400\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6933/20000 - Train Loss: 3.3158 - Test Loss: 12.5242 - MSE: 12.5242 - MAE: 2.7394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6934/20000 - Train Loss: 3.3134 - Test Loss: 12.5192 - MSE: 12.5192 - MAE: 2.7388\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6935/20000 - Train Loss: 3.3109 - Test Loss: 12.5143 - MSE: 12.5143 - MAE: 2.7382\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6936/20000 - Train Loss: 3.3085 - Test Loss: 12.5092 - MSE: 12.5092 - MAE: 2.7376\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 6937/20000 - Train Loss: 3.3060 - Test Loss: 12.5043 - MSE: 12.5043 - MAE: 2.7370\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6938/20000 - Train Loss: 3.3036 - Test Loss: 12.4993 - MSE: 12.4993 - MAE: 2.7364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6939/20000 - Train Loss: 3.3011 - Test Loss: 12.4943 - MSE: 12.4943 - MAE: 2.7358\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 6940/20000 - Train Loss: 3.2987 - Test Loss: 12.4894 - MSE: 12.4894 - MAE: 2.7353\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6941/20000 - Train Loss: 3.2963 - Test Loss: 12.4844 - MSE: 12.4844 - MAE: 2.7347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6942/20000 - Train Loss: 3.2938 - Test Loss: 12.4794 - MSE: 12.4794 - MAE: 2.7341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6943/20000 - Train Loss: 3.2914 - Test Loss: 12.4745 - MSE: 12.4745 - MAE: 2.7335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6944/20000 - Train Loss: 3.2890 - Test Loss: 12.4695 - MSE: 12.4695 - MAE: 2.7329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6945/20000 - Train Loss: 3.2865 - Test Loss: 12.4645 - MSE: 12.4645 - MAE: 2.7323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6946/20000 - Train Loss: 3.2841 - Test Loss: 12.4596 - MSE: 12.4596 - MAE: 2.7317\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 6947/20000 - Train Loss: 3.2817 - Test Loss: 12.4546 - MSE: 12.4546 - MAE: 2.7311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6948/20000 - Train Loss: 3.2792 - Test Loss: 12.4497 - MSE: 12.4497 - MAE: 2.7306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6949/20000 - Train Loss: 3.2768 - Test Loss: 12.4448 - MSE: 12.4448 - MAE: 2.7300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6950/20000 - Train Loss: 3.2744 - Test Loss: 12.4399 - MSE: 12.4399 - MAE: 2.7294\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6951/20000 - Train Loss: 3.2720 - Test Loss: 12.4349 - MSE: 12.4349 - MAE: 2.7288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6952/20000 - Train Loss: 3.2695 - Test Loss: 12.4299 - MSE: 12.4299 - MAE: 2.7282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6953/20000 - Train Loss: 3.2671 - Test Loss: 12.4250 - MSE: 12.4250 - MAE: 2.7276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6954/20000 - Train Loss: 3.2647 - Test Loss: 12.4201 - MSE: 12.4201 - MAE: 2.7270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6955/20000 - Train Loss: 3.2623 - Test Loss: 12.4152 - MSE: 12.4152 - MAE: 2.7264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6956/20000 - Train Loss: 3.2599 - Test Loss: 12.4103 - MSE: 12.4103 - MAE: 2.7259\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6957/20000 - Train Loss: 3.2575 - Test Loss: 12.4054 - MSE: 12.4054 - MAE: 2.7253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6958/20000 - Train Loss: 3.2551 - Test Loss: 12.4005 - MSE: 12.4005 - MAE: 2.7247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6959/20000 - Train Loss: 3.2526 - Test Loss: 12.3956 - MSE: 12.3956 - MAE: 2.7241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6960/20000 - Train Loss: 3.2502 - Test Loss: 12.3906 - MSE: 12.3906 - MAE: 2.7235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6961/20000 - Train Loss: 3.2478 - Test Loss: 12.3857 - MSE: 12.3857 - MAE: 2.7229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6962/20000 - Train Loss: 3.2454 - Test Loss: 12.3808 - MSE: 12.3808 - MAE: 2.7223\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6963/20000 - Train Loss: 3.2430 - Test Loss: 12.3759 - MSE: 12.3759 - MAE: 2.7217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6964/20000 - Train Loss: 3.2406 - Test Loss: 12.3711 - MSE: 12.3711 - MAE: 2.7212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6965/20000 - Train Loss: 3.2382 - Test Loss: 12.3662 - MSE: 12.3662 - MAE: 2.7206\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 6966/20000 - Train Loss: 3.2358 - Test Loss: 12.3613 - MSE: 12.3613 - MAE: 2.7200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6967/20000 - Train Loss: 3.2334 - Test Loss: 12.3564 - MSE: 12.3564 - MAE: 2.7194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6968/20000 - Train Loss: 3.2310 - Test Loss: 12.3515 - MSE: 12.3515 - MAE: 2.7188\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 6969/20000 - Train Loss: 3.2286 - Test Loss: 12.3466 - MSE: 12.3466 - MAE: 2.7182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6970/20000 - Train Loss: 3.2262 - Test Loss: 12.3418 - MSE: 12.3418 - MAE: 2.7176\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 6971/20000 - Train Loss: 3.2239 - Test Loss: 12.3370 - MSE: 12.3370 - MAE: 2.7170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6972/20000 - Train Loss: 3.2215 - Test Loss: 12.3321 - MSE: 12.3321 - MAE: 2.7165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6973/20000 - Train Loss: 3.2191 - Test Loss: 12.3272 - MSE: 12.3272 - MAE: 2.7159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6974/20000 - Train Loss: 3.2167 - Test Loss: 12.3223 - MSE: 12.3223 - MAE: 2.7153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6975/20000 - Train Loss: 3.2143 - Test Loss: 12.3174 - MSE: 12.3174 - MAE: 2.7147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6976/20000 - Train Loss: 3.2119 - Test Loss: 12.3126 - MSE: 12.3126 - MAE: 2.7141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6977/20000 - Train Loss: 3.2095 - Test Loss: 12.3078 - MSE: 12.3078 - MAE: 2.7135\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6978/20000 - Train Loss: 3.2072 - Test Loss: 12.3029 - MSE: 12.3029 - MAE: 2.7129\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 6979/20000 - Train Loss: 3.2048 - Test Loss: 12.2981 - MSE: 12.2981 - MAE: 2.7124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6980/20000 - Train Loss: 3.2024 - Test Loss: 12.2933 - MSE: 12.2933 - MAE: 2.7118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6981/20000 - Train Loss: 3.2000 - Test Loss: 12.2885 - MSE: 12.2885 - MAE: 2.7112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6982/20000 - Train Loss: 3.1977 - Test Loss: 12.2836 - MSE: 12.2836 - MAE: 2.7106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6983/20000 - Train Loss: 3.1953 - Test Loss: 12.2788 - MSE: 12.2788 - MAE: 2.7100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6984/20000 - Train Loss: 3.1929 - Test Loss: 12.2739 - MSE: 12.2739 - MAE: 2.7094\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6985/20000 - Train Loss: 3.1905 - Test Loss: 12.2691 - MSE: 12.2691 - MAE: 2.7088\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6986/20000 - Train Loss: 3.1882 - Test Loss: 12.2643 - MSE: 12.2643 - MAE: 2.7082\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 6987/20000 - Train Loss: 3.1858 - Test Loss: 12.2595 - MSE: 12.2595 - MAE: 2.7077\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6988/20000 - Train Loss: 3.1834 - Test Loss: 12.2547 - MSE: 12.2547 - MAE: 2.7071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6989/20000 - Train Loss: 3.1811 - Test Loss: 12.2499 - MSE: 12.2499 - MAE: 2.7065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6990/20000 - Train Loss: 3.1787 - Test Loss: 12.2451 - MSE: 12.2451 - MAE: 2.7059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6991/20000 - Train Loss: 3.1764 - Test Loss: 12.2403 - MSE: 12.2403 - MAE: 2.7053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6992/20000 - Train Loss: 3.1740 - Test Loss: 12.2354 - MSE: 12.2354 - MAE: 2.7047\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6993/20000 - Train Loss: 3.1716 - Test Loss: 12.2307 - MSE: 12.2307 - MAE: 2.7041\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6994/20000 - Train Loss: 3.1693 - Test Loss: 12.2259 - MSE: 12.2259 - MAE: 2.7036\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 6995/20000 - Train Loss: 3.1669 - Test Loss: 12.2211 - MSE: 12.2211 - MAE: 2.7030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6996/20000 - Train Loss: 3.1646 - Test Loss: 12.2163 - MSE: 12.2163 - MAE: 2.7024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6997/20000 - Train Loss: 3.1622 - Test Loss: 12.2115 - MSE: 12.2115 - MAE: 2.7018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6998/20000 - Train Loss: 3.1599 - Test Loss: 12.2068 - MSE: 12.2068 - MAE: 2.7012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 6999/20000 - Train Loss: 3.1575 - Test Loss: 12.2020 - MSE: 12.2020 - MAE: 2.7006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7000/20000 - Train Loss: 3.1552 - Test Loss: 12.1972 - MSE: 12.1972 - MAE: 2.7000\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7001/20000 - Train Loss: 3.1528 - Test Loss: 12.1924 - MSE: 12.1924 - MAE: 2.6995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7002/20000 - Train Loss: 3.1505 - Test Loss: 12.1877 - MSE: 12.1877 - MAE: 2.6989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7003/20000 - Train Loss: 3.1482 - Test Loss: 12.1829 - MSE: 12.1829 - MAE: 2.6983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7004/20000 - Train Loss: 3.1458 - Test Loss: 12.1781 - MSE: 12.1781 - MAE: 2.6977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7005/20000 - Train Loss: 3.1435 - Test Loss: 12.1734 - MSE: 12.1734 - MAE: 2.6971\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7006/20000 - Train Loss: 3.1411 - Test Loss: 12.1686 - MSE: 12.1686 - MAE: 2.6965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7007/20000 - Train Loss: 3.1388 - Test Loss: 12.1639 - MSE: 12.1639 - MAE: 2.6959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7008/20000 - Train Loss: 3.1365 - Test Loss: 12.1591 - MSE: 12.1591 - MAE: 2.6954\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7009/20000 - Train Loss: 3.1341 - Test Loss: 12.1544 - MSE: 12.1544 - MAE: 2.6948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7010/20000 - Train Loss: 3.1318 - Test Loss: 12.1496 - MSE: 12.1496 - MAE: 2.6942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7011/20000 - Train Loss: 3.1295 - Test Loss: 12.1449 - MSE: 12.1449 - MAE: 2.6936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7012/20000 - Train Loss: 3.1272 - Test Loss: 12.1402 - MSE: 12.1402 - MAE: 2.6930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7013/20000 - Train Loss: 3.1248 - Test Loss: 12.1355 - MSE: 12.1355 - MAE: 2.6924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7014/20000 - Train Loss: 3.1225 - Test Loss: 12.1308 - MSE: 12.1308 - MAE: 2.6918\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7015/20000 - Train Loss: 3.1202 - Test Loss: 12.1260 - MSE: 12.1260 - MAE: 2.6913\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7016/20000 - Train Loss: 3.1179 - Test Loss: 12.1213 - MSE: 12.1213 - MAE: 2.6907\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7017/20000 - Train Loss: 3.1155 - Test Loss: 12.1166 - MSE: 12.1166 - MAE: 2.6901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7018/20000 - Train Loss: 3.1132 - Test Loss: 12.1119 - MSE: 12.1119 - MAE: 2.6895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7019/20000 - Train Loss: 3.1109 - Test Loss: 12.1072 - MSE: 12.1072 - MAE: 2.6889\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7020/20000 - Train Loss: 3.1086 - Test Loss: 12.1025 - MSE: 12.1025 - MAE: 2.6883\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7021/20000 - Train Loss: 3.1063 - Test Loss: 12.0977 - MSE: 12.0977 - MAE: 2.6877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7022/20000 - Train Loss: 3.1040 - Test Loss: 12.0931 - MSE: 12.0931 - MAE: 2.6872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7023/20000 - Train Loss: 3.1016 - Test Loss: 12.0884 - MSE: 12.0884 - MAE: 2.6866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7024/20000 - Train Loss: 3.0993 - Test Loss: 12.0837 - MSE: 12.0837 - MAE: 2.6860\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7025/20000 - Train Loss: 3.0970 - Test Loss: 12.0790 - MSE: 12.0790 - MAE: 2.6854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7026/20000 - Train Loss: 3.0947 - Test Loss: 12.0743 - MSE: 12.0743 - MAE: 2.6848\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7027/20000 - Train Loss: 3.0924 - Test Loss: 12.0696 - MSE: 12.0696 - MAE: 2.6842\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7028/20000 - Train Loss: 3.0901 - Test Loss: 12.0649 - MSE: 12.0649 - MAE: 2.6836\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7029/20000 - Train Loss: 3.0878 - Test Loss: 12.0603 - MSE: 12.0603 - MAE: 2.6831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7030/20000 - Train Loss: 3.0855 - Test Loss: 12.0556 - MSE: 12.0556 - MAE: 2.6825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7031/20000 - Train Loss: 3.0832 - Test Loss: 12.0509 - MSE: 12.0509 - MAE: 2.6819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7032/20000 - Train Loss: 3.0809 - Test Loss: 12.0463 - MSE: 12.0463 - MAE: 2.6813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7033/20000 - Train Loss: 3.0786 - Test Loss: 12.0416 - MSE: 12.0416 - MAE: 2.6807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7034/20000 - Train Loss: 3.0763 - Test Loss: 12.0369 - MSE: 12.0369 - MAE: 2.6801\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7035/20000 - Train Loss: 3.0740 - Test Loss: 12.0323 - MSE: 12.0323 - MAE: 2.6796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7036/20000 - Train Loss: 3.0718 - Test Loss: 12.0276 - MSE: 12.0276 - MAE: 2.6790\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7037/20000 - Train Loss: 3.0695 - Test Loss: 12.0229 - MSE: 12.0229 - MAE: 2.6784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7038/20000 - Train Loss: 3.0672 - Test Loss: 12.0183 - MSE: 12.0183 - MAE: 2.6778\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7039/20000 - Train Loss: 3.0649 - Test Loss: 12.0137 - MSE: 12.0137 - MAE: 2.6772\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7040/20000 - Train Loss: 3.0626 - Test Loss: 12.0091 - MSE: 12.0091 - MAE: 2.6766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7041/20000 - Train Loss: 3.0603 - Test Loss: 12.0044 - MSE: 12.0044 - MAE: 2.6761\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7042/20000 - Train Loss: 3.0580 - Test Loss: 11.9998 - MSE: 11.9998 - MAE: 2.6755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7043/20000 - Train Loss: 3.0558 - Test Loss: 11.9952 - MSE: 11.9952 - MAE: 2.6749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7044/20000 - Train Loss: 3.0535 - Test Loss: 11.9905 - MSE: 11.9905 - MAE: 2.6743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7045/20000 - Train Loss: 3.0512 - Test Loss: 11.9859 - MSE: 11.9859 - MAE: 2.6737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7046/20000 - Train Loss: 3.0489 - Test Loss: 11.9813 - MSE: 11.9813 - MAE: 2.6731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7047/20000 - Train Loss: 3.0467 - Test Loss: 11.9767 - MSE: 11.9767 - MAE: 2.6725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7048/20000 - Train Loss: 3.0444 - Test Loss: 11.9720 - MSE: 11.9720 - MAE: 2.6720\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7049/20000 - Train Loss: 3.0421 - Test Loss: 11.9674 - MSE: 11.9674 - MAE: 2.6714\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7050/20000 - Train Loss: 3.0399 - Test Loss: 11.9629 - MSE: 11.9629 - MAE: 2.6708\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7051/20000 - Train Loss: 3.0376 - Test Loss: 11.9582 - MSE: 11.9582 - MAE: 2.6702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7052/20000 - Train Loss: 3.0353 - Test Loss: 11.9536 - MSE: 11.9536 - MAE: 2.6696\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 7053/20000 - Train Loss: 3.0331 - Test Loss: 11.9490 - MSE: 11.9490 - MAE: 2.6690\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7054/20000 - Train Loss: 3.0308 - Test Loss: 11.9444 - MSE: 11.9444 - MAE: 2.6685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7055/20000 - Train Loss: 3.0285 - Test Loss: 11.9399 - MSE: 11.9399 - MAE: 2.6679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7056/20000 - Train Loss: 3.0263 - Test Loss: 11.9353 - MSE: 11.9353 - MAE: 2.6673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7057/20000 - Train Loss: 3.0240 - Test Loss: 11.9307 - MSE: 11.9307 - MAE: 2.6667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7058/20000 - Train Loss: 3.0218 - Test Loss: 11.9261 - MSE: 11.9261 - MAE: 2.6661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7059/20000 - Train Loss: 3.0195 - Test Loss: 11.9215 - MSE: 11.9215 - MAE: 2.6655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7060/20000 - Train Loss: 3.0173 - Test Loss: 11.9169 - MSE: 11.9169 - MAE: 2.6650\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7061/20000 - Train Loss: 3.0150 - Test Loss: 11.9124 - MSE: 11.9124 - MAE: 2.6644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7062/20000 - Train Loss: 3.0128 - Test Loss: 11.9078 - MSE: 11.9078 - MAE: 2.6638\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7063/20000 - Train Loss: 3.0105 - Test Loss: 11.9033 - MSE: 11.9033 - MAE: 2.6632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7064/20000 - Train Loss: 3.0083 - Test Loss: 11.8987 - MSE: 11.8987 - MAE: 2.6626\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7065/20000 - Train Loss: 3.0060 - Test Loss: 11.8941 - MSE: 11.8941 - MAE: 2.6620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7066/20000 - Train Loss: 3.0038 - Test Loss: 11.8896 - MSE: 11.8896 - MAE: 2.6615\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7067/20000 - Train Loss: 3.0015 - Test Loss: 11.8850 - MSE: 11.8850 - MAE: 2.6609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7068/20000 - Train Loss: 2.9993 - Test Loss: 11.8805 - MSE: 11.8805 - MAE: 2.6603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7069/20000 - Train Loss: 2.9970 - Test Loss: 11.8760 - MSE: 11.8760 - MAE: 2.6597\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 7070/20000 - Train Loss: 2.9948 - Test Loss: 11.8714 - MSE: 11.8714 - MAE: 2.6591\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7071/20000 - Train Loss: 2.9926 - Test Loss: 11.8669 - MSE: 11.8669 - MAE: 2.6585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7072/20000 - Train Loss: 2.9903 - Test Loss: 11.8623 - MSE: 11.8623 - MAE: 2.6580\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 7073/20000 - Train Loss: 2.9881 - Test Loss: 11.8578 - MSE: 11.8578 - MAE: 2.6574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7074/20000 - Train Loss: 2.9859 - Test Loss: 11.8532 - MSE: 11.8532 - MAE: 2.6568\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7075/20000 - Train Loss: 2.9836 - Test Loss: 11.8487 - MSE: 11.8487 - MAE: 2.6562\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7076/20000 - Train Loss: 2.9814 - Test Loss: 11.8442 - MSE: 11.8442 - MAE: 2.6556\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 7077/20000 - Train Loss: 2.9792 - Test Loss: 11.8397 - MSE: 11.8397 - MAE: 2.6551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7078/20000 - Train Loss: 2.9770 - Test Loss: 11.8352 - MSE: 11.8352 - MAE: 2.6546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7079/20000 - Train Loss: 2.9747 - Test Loss: 11.8307 - MSE: 11.8307 - MAE: 2.6541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7080/20000 - Train Loss: 2.9725 - Test Loss: 11.8262 - MSE: 11.8262 - MAE: 2.6535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7081/20000 - Train Loss: 2.9703 - Test Loss: 11.8217 - MSE: 11.8217 - MAE: 2.6530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7082/20000 - Train Loss: 2.9681 - Test Loss: 11.8171 - MSE: 11.8171 - MAE: 2.6525\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7083/20000 - Train Loss: 2.9659 - Test Loss: 11.8126 - MSE: 11.8126 - MAE: 2.6519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7084/20000 - Train Loss: 2.9637 - Test Loss: 11.8082 - MSE: 11.8082 - MAE: 2.6514\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7085/20000 - Train Loss: 2.9614 - Test Loss: 11.8037 - MSE: 11.8037 - MAE: 2.6509\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 7086/20000 - Train Loss: 2.9592 - Test Loss: 11.7992 - MSE: 11.7992 - MAE: 2.6503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7087/20000 - Train Loss: 2.9570 - Test Loss: 11.7947 - MSE: 11.7947 - MAE: 2.6498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7088/20000 - Train Loss: 2.9548 - Test Loss: 11.7903 - MSE: 11.7903 - MAE: 2.6493\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7089/20000 - Train Loss: 2.9526 - Test Loss: 11.7857 - MSE: 11.7857 - MAE: 2.6487\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7090/20000 - Train Loss: 2.9504 - Test Loss: 11.7813 - MSE: 11.7813 - MAE: 2.6482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7091/20000 - Train Loss: 2.9482 - Test Loss: 11.7768 - MSE: 11.7768 - MAE: 2.6477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7092/20000 - Train Loss: 2.9460 - Test Loss: 11.7724 - MSE: 11.7724 - MAE: 2.6472\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7093/20000 - Train Loss: 2.9438 - Test Loss: 11.7679 - MSE: 11.7679 - MAE: 2.6466\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7094/20000 - Train Loss: 2.9416 - Test Loss: 11.7634 - MSE: 11.7634 - MAE: 2.6461\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 7095/20000 - Train Loss: 2.9394 - Test Loss: 11.7590 - MSE: 11.7590 - MAE: 2.6456\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 7096/20000 - Train Loss: 2.9372 - Test Loss: 11.7545 - MSE: 11.7545 - MAE: 2.6450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7097/20000 - Train Loss: 2.9350 - Test Loss: 11.7500 - MSE: 11.7500 - MAE: 2.6445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7098/20000 - Train Loss: 2.9328 - Test Loss: 11.7456 - MSE: 11.7456 - MAE: 2.6440\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7099/20000 - Train Loss: 2.9306 - Test Loss: 11.7412 - MSE: 11.7412 - MAE: 2.6434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7100/20000 - Train Loss: 2.9284 - Test Loss: 11.7367 - MSE: 11.7367 - MAE: 2.6429\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7101/20000 - Train Loss: 2.9262 - Test Loss: 11.7323 - MSE: 11.7323 - MAE: 2.6424\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7102/20000 - Train Loss: 2.9240 - Test Loss: 11.7278 - MSE: 11.7278 - MAE: 2.6419\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7103/20000 - Train Loss: 2.9219 - Test Loss: 11.7234 - MSE: 11.7234 - MAE: 2.6413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7104/20000 - Train Loss: 2.9197 - Test Loss: 11.7190 - MSE: 11.7190 - MAE: 2.6408\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7105/20000 - Train Loss: 2.9175 - Test Loss: 11.7146 - MSE: 11.7146 - MAE: 2.6403\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7106/20000 - Train Loss: 2.9153 - Test Loss: 11.7101 - MSE: 11.7101 - MAE: 2.6397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7107/20000 - Train Loss: 2.9131 - Test Loss: 11.7057 - MSE: 11.7057 - MAE: 2.6392\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7108/20000 - Train Loss: 2.9109 - Test Loss: 11.7013 - MSE: 11.7013 - MAE: 2.6387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7109/20000 - Train Loss: 2.9088 - Test Loss: 11.6969 - MSE: 11.6969 - MAE: 2.6381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7110/20000 - Train Loss: 2.9066 - Test Loss: 11.6925 - MSE: 11.6925 - MAE: 2.6376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7111/20000 - Train Loss: 2.9044 - Test Loss: 11.6881 - MSE: 11.6881 - MAE: 2.6371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7112/20000 - Train Loss: 2.9023 - Test Loss: 11.6837 - MSE: 11.6837 - MAE: 2.6366\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7113/20000 - Train Loss: 2.9001 - Test Loss: 11.6793 - MSE: 11.6793 - MAE: 2.6361\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 7114/20000 - Train Loss: 2.8979 - Test Loss: 11.6749 - MSE: 11.6749 - MAE: 2.6357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7115/20000 - Train Loss: 2.8957 - Test Loss: 11.6705 - MSE: 11.6705 - MAE: 2.6353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7116/20000 - Train Loss: 2.8936 - Test Loss: 11.6661 - MSE: 11.6661 - MAE: 2.6348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7117/20000 - Train Loss: 2.8914 - Test Loss: 11.6617 - MSE: 11.6617 - MAE: 2.6344\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7118/20000 - Train Loss: 2.8893 - Test Loss: 11.6573 - MSE: 11.6573 - MAE: 2.6339\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7119/20000 - Train Loss: 2.8871 - Test Loss: 11.6529 - MSE: 11.6529 - MAE: 2.6335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7120/20000 - Train Loss: 2.8849 - Test Loss: 11.6486 - MSE: 11.6486 - MAE: 2.6331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7121/20000 - Train Loss: 2.8828 - Test Loss: 11.6442 - MSE: 11.6442 - MAE: 2.6326\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7122/20000 - Train Loss: 2.8806 - Test Loss: 11.6399 - MSE: 11.6399 - MAE: 2.6322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7123/20000 - Train Loss: 2.8785 - Test Loss: 11.6355 - MSE: 11.6355 - MAE: 2.6318\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7124/20000 - Train Loss: 2.8763 - Test Loss: 11.6311 - MSE: 11.6311 - MAE: 2.6313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7125/20000 - Train Loss: 2.8742 - Test Loss: 11.6268 - MSE: 11.6268 - MAE: 2.6309\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7126/20000 - Train Loss: 2.8720 - Test Loss: 11.6224 - MSE: 11.6224 - MAE: 2.6304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7127/20000 - Train Loss: 2.8699 - Test Loss: 11.6180 - MSE: 11.6180 - MAE: 2.6300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7128/20000 - Train Loss: 2.8677 - Test Loss: 11.6137 - MSE: 11.6137 - MAE: 2.6296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7129/20000 - Train Loss: 2.8656 - Test Loss: 11.6094 - MSE: 11.6094 - MAE: 2.6291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7130/20000 - Train Loss: 2.8634 - Test Loss: 11.6050 - MSE: 11.6050 - MAE: 2.6287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7131/20000 - Train Loss: 2.8613 - Test Loss: 11.6007 - MSE: 11.6007 - MAE: 2.6282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7132/20000 - Train Loss: 2.8591 - Test Loss: 11.5963 - MSE: 11.5963 - MAE: 2.6278\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7133/20000 - Train Loss: 2.8570 - Test Loss: 11.5920 - MSE: 11.5920 - MAE: 2.6274\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7134/20000 - Train Loss: 2.8549 - Test Loss: 11.5877 - MSE: 11.5877 - MAE: 2.6269\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7135/20000 - Train Loss: 2.8527 - Test Loss: 11.5833 - MSE: 11.5833 - MAE: 2.6265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7136/20000 - Train Loss: 2.8506 - Test Loss: 11.5790 - MSE: 11.5790 - MAE: 2.6260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7137/20000 - Train Loss: 2.8485 - Test Loss: 11.5747 - MSE: 11.5747 - MAE: 2.6256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7138/20000 - Train Loss: 2.8463 - Test Loss: 11.5704 - MSE: 11.5704 - MAE: 2.6252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7139/20000 - Train Loss: 2.8442 - Test Loss: 11.5661 - MSE: 11.5661 - MAE: 2.6247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7140/20000 - Train Loss: 2.8421 - Test Loss: 11.5618 - MSE: 11.5618 - MAE: 2.6243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7141/20000 - Train Loss: 2.8400 - Test Loss: 11.5575 - MSE: 11.5575 - MAE: 2.6239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7142/20000 - Train Loss: 2.8378 - Test Loss: 11.5531 - MSE: 11.5531 - MAE: 2.6234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7143/20000 - Train Loss: 2.8357 - Test Loss: 11.5488 - MSE: 11.5488 - MAE: 2.6230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7144/20000 - Train Loss: 2.8336 - Test Loss: 11.5446 - MSE: 11.5446 - MAE: 2.6225\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7145/20000 - Train Loss: 2.8315 - Test Loss: 11.5403 - MSE: 11.5403 - MAE: 2.6221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7146/20000 - Train Loss: 2.8293 - Test Loss: 11.5360 - MSE: 11.5360 - MAE: 2.6217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7147/20000 - Train Loss: 2.8272 - Test Loss: 11.5317 - MSE: 11.5317 - MAE: 2.6212\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7148/20000 - Train Loss: 2.8251 - Test Loss: 11.5274 - MSE: 11.5274 - MAE: 2.6208\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7149/20000 - Train Loss: 2.8230 - Test Loss: 11.5231 - MSE: 11.5231 - MAE: 2.6204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7150/20000 - Train Loss: 2.8209 - Test Loss: 11.5188 - MSE: 11.5188 - MAE: 2.6199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7151/20000 - Train Loss: 2.8188 - Test Loss: 11.5146 - MSE: 11.5146 - MAE: 2.6195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7152/20000 - Train Loss: 2.8167 - Test Loss: 11.5103 - MSE: 11.5103 - MAE: 2.6190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7153/20000 - Train Loss: 2.8146 - Test Loss: 11.5061 - MSE: 11.5061 - MAE: 2.6186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7154/20000 - Train Loss: 2.8125 - Test Loss: 11.5018 - MSE: 11.5018 - MAE: 2.6182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7155/20000 - Train Loss: 2.8103 - Test Loss: 11.4975 - MSE: 11.4975 - MAE: 2.6177\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7156/20000 - Train Loss: 2.8082 - Test Loss: 11.4932 - MSE: 11.4932 - MAE: 2.6173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7157/20000 - Train Loss: 2.8061 - Test Loss: 11.4890 - MSE: 11.4890 - MAE: 2.6169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7158/20000 - Train Loss: 2.8040 - Test Loss: 11.4848 - MSE: 11.4848 - MAE: 2.6164\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 7159/20000 - Train Loss: 2.8019 - Test Loss: 11.4805 - MSE: 11.4805 - MAE: 2.6160\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 7160/20000 - Train Loss: 2.7998 - Test Loss: 11.4763 - MSE: 11.4763 - MAE: 2.6156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7161/20000 - Train Loss: 2.7978 - Test Loss: 11.4720 - MSE: 11.4720 - MAE: 2.6151\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7162/20000 - Train Loss: 2.7957 - Test Loss: 11.4678 - MSE: 11.4678 - MAE: 2.6147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7163/20000 - Train Loss: 2.7936 - Test Loss: 11.4635 - MSE: 11.4635 - MAE: 2.6142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7164/20000 - Train Loss: 2.7915 - Test Loss: 11.4593 - MSE: 11.4593 - MAE: 2.6138\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7165/20000 - Train Loss: 2.7894 - Test Loss: 11.4550 - MSE: 11.4550 - MAE: 2.6134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7166/20000 - Train Loss: 2.7873 - Test Loss: 11.4509 - MSE: 11.4509 - MAE: 2.6129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7167/20000 - Train Loss: 2.7852 - Test Loss: 11.4467 - MSE: 11.4467 - MAE: 2.6125\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7168/20000 - Train Loss: 2.7831 - Test Loss: 11.4425 - MSE: 11.4425 - MAE: 2.6121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7169/20000 - Train Loss: 2.7810 - Test Loss: 11.4382 - MSE: 11.4382 - MAE: 2.6116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7170/20000 - Train Loss: 2.7790 - Test Loss: 11.4340 - MSE: 11.4340 - MAE: 2.6112\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 7171/20000 - Train Loss: 2.7769 - Test Loss: 11.4297 - MSE: 11.4297 - MAE: 2.6107\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 7172/20000 - Train Loss: 2.7748 - Test Loss: 11.4255 - MSE: 11.4255 - MAE: 2.6103\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7173/20000 - Train Loss: 2.7727 - Test Loss: 11.4214 - MSE: 11.4214 - MAE: 2.6099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7174/20000 - Train Loss: 2.7707 - Test Loss: 11.4172 - MSE: 11.4172 - MAE: 2.6094\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7175/20000 - Train Loss: 2.7686 - Test Loss: 11.4130 - MSE: 11.4130 - MAE: 2.6090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7176/20000 - Train Loss: 2.7665 - Test Loss: 11.4088 - MSE: 11.4088 - MAE: 2.6086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7177/20000 - Train Loss: 2.7644 - Test Loss: 11.4046 - MSE: 11.4046 - MAE: 2.6081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7178/20000 - Train Loss: 2.7624 - Test Loss: 11.4004 - MSE: 11.4004 - MAE: 2.6077\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 7179/20000 - Train Loss: 2.7603 - Test Loss: 11.3962 - MSE: 11.3962 - MAE: 2.6072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7180/20000 - Train Loss: 2.7582 - Test Loss: 11.3920 - MSE: 11.3920 - MAE: 2.6068\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7181/20000 - Train Loss: 2.7562 - Test Loss: 11.3879 - MSE: 11.3879 - MAE: 2.6064\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7182/20000 - Train Loss: 2.7541 - Test Loss: 11.3837 - MSE: 11.3837 - MAE: 2.6059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7183/20000 - Train Loss: 2.7521 - Test Loss: 11.3795 - MSE: 11.3795 - MAE: 2.6055\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7184/20000 - Train Loss: 2.7500 - Test Loss: 11.3754 - MSE: 11.3754 - MAE: 2.6051\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7185/20000 - Train Loss: 2.7479 - Test Loss: 11.3712 - MSE: 11.3712 - MAE: 2.6046\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7186/20000 - Train Loss: 2.7459 - Test Loss: 11.3671 - MSE: 11.3671 - MAE: 2.6042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7187/20000 - Train Loss: 2.7438 - Test Loss: 11.3629 - MSE: 11.3629 - MAE: 2.6037\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7188/20000 - Train Loss: 2.7418 - Test Loss: 11.3587 - MSE: 11.3587 - MAE: 2.6033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7189/20000 - Train Loss: 2.7397 - Test Loss: 11.3546 - MSE: 11.3546 - MAE: 2.6029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7190/20000 - Train Loss: 2.7377 - Test Loss: 11.3505 - MSE: 11.3505 - MAE: 2.6024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7191/20000 - Train Loss: 2.7356 - Test Loss: 11.3463 - MSE: 11.3463 - MAE: 2.6020\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7192/20000 - Train Loss: 2.7336 - Test Loss: 11.3422 - MSE: 11.3422 - MAE: 2.6016\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7193/20000 - Train Loss: 2.7315 - Test Loss: 11.3380 - MSE: 11.3380 - MAE: 2.6011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7194/20000 - Train Loss: 2.7295 - Test Loss: 11.3339 - MSE: 11.3339 - MAE: 2.6007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7195/20000 - Train Loss: 2.7274 - Test Loss: 11.3298 - MSE: 11.3298 - MAE: 2.6003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7196/20000 - Train Loss: 2.7254 - Test Loss: 11.3257 - MSE: 11.3257 - MAE: 2.5998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7197/20000 - Train Loss: 2.7234 - Test Loss: 11.3215 - MSE: 11.3215 - MAE: 2.5994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7198/20000 - Train Loss: 2.7213 - Test Loss: 11.3174 - MSE: 11.3174 - MAE: 2.5989\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7199/20000 - Train Loss: 2.7193 - Test Loss: 11.3133 - MSE: 11.3133 - MAE: 2.5985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7200/20000 - Train Loss: 2.7173 - Test Loss: 11.3092 - MSE: 11.3092 - MAE: 2.5981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7201/20000 - Train Loss: 2.7152 - Test Loss: 11.3051 - MSE: 11.3051 - MAE: 2.5976\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 7202/20000 - Train Loss: 2.7132 - Test Loss: 11.3010 - MSE: 11.3010 - MAE: 2.5972\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7203/20000 - Train Loss: 2.7112 - Test Loss: 11.2969 - MSE: 11.2969 - MAE: 2.5968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7204/20000 - Train Loss: 2.7091 - Test Loss: 11.2927 - MSE: 11.2927 - MAE: 2.5963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7205/20000 - Train Loss: 2.7071 - Test Loss: 11.2886 - MSE: 11.2886 - MAE: 2.5959\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7206/20000 - Train Loss: 2.7051 - Test Loss: 11.2845 - MSE: 11.2845 - MAE: 2.5955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7207/20000 - Train Loss: 2.7031 - Test Loss: 11.2804 - MSE: 11.2804 - MAE: 2.5950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7208/20000 - Train Loss: 2.7010 - Test Loss: 11.2764 - MSE: 11.2764 - MAE: 2.5946\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7209/20000 - Train Loss: 2.6990 - Test Loss: 11.2723 - MSE: 11.2723 - MAE: 2.5942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7210/20000 - Train Loss: 2.6970 - Test Loss: 11.2682 - MSE: 11.2682 - MAE: 2.5937\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7211/20000 - Train Loss: 2.6950 - Test Loss: 11.2641 - MSE: 11.2641 - MAE: 2.5933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7212/20000 - Train Loss: 2.6930 - Test Loss: 11.2600 - MSE: 11.2600 - MAE: 2.5928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7213/20000 - Train Loss: 2.6910 - Test Loss: 11.2560 - MSE: 11.2560 - MAE: 2.5924\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7214/20000 - Train Loss: 2.6889 - Test Loss: 11.2519 - MSE: 11.2519 - MAE: 2.5920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7215/20000 - Train Loss: 2.6869 - Test Loss: 11.2478 - MSE: 11.2478 - MAE: 2.5915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7216/20000 - Train Loss: 2.6849 - Test Loss: 11.2438 - MSE: 11.2438 - MAE: 2.5911\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7217/20000 - Train Loss: 2.6829 - Test Loss: 11.2398 - MSE: 11.2398 - MAE: 2.5907\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7218/20000 - Train Loss: 2.6809 - Test Loss: 11.2357 - MSE: 11.2357 - MAE: 2.5902\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 7219/20000 - Train Loss: 2.6789 - Test Loss: 11.2316 - MSE: 11.2316 - MAE: 2.5898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7220/20000 - Train Loss: 2.6769 - Test Loss: 11.2275 - MSE: 11.2275 - MAE: 2.5894\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7221/20000 - Train Loss: 2.6749 - Test Loss: 11.2235 - MSE: 11.2235 - MAE: 2.5889\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7222/20000 - Train Loss: 2.6729 - Test Loss: 11.2194 - MSE: 11.2194 - MAE: 2.5885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7223/20000 - Train Loss: 2.6709 - Test Loss: 11.2154 - MSE: 11.2154 - MAE: 2.5881\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7224/20000 - Train Loss: 2.6689 - Test Loss: 11.2114 - MSE: 11.2114 - MAE: 2.5876\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 7225/20000 - Train Loss: 2.6669 - Test Loss: 11.2074 - MSE: 11.2074 - MAE: 2.5872\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 7226/20000 - Train Loss: 2.6649 - Test Loss: 11.2034 - MSE: 11.2034 - MAE: 2.5868\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7227/20000 - Train Loss: 2.6629 - Test Loss: 11.1993 - MSE: 11.1993 - MAE: 2.5863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7228/20000 - Train Loss: 2.6609 - Test Loss: 11.1953 - MSE: 11.1953 - MAE: 2.5859\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 7229/20000 - Train Loss: 2.6589 - Test Loss: 11.1912 - MSE: 11.1912 - MAE: 2.5854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7230/20000 - Train Loss: 2.6570 - Test Loss: 11.1872 - MSE: 11.1872 - MAE: 2.5850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7231/20000 - Train Loss: 2.6550 - Test Loss: 11.1832 - MSE: 11.1832 - MAE: 2.5846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7232/20000 - Train Loss: 2.6530 - Test Loss: 11.1793 - MSE: 11.1793 - MAE: 2.5841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7233/20000 - Train Loss: 2.6510 - Test Loss: 11.1753 - MSE: 11.1753 - MAE: 2.5837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7234/20000 - Train Loss: 2.6490 - Test Loss: 11.1712 - MSE: 11.1712 - MAE: 2.5833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7235/20000 - Train Loss: 2.6470 - Test Loss: 11.1672 - MSE: 11.1672 - MAE: 2.5828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7236/20000 - Train Loss: 2.6451 - Test Loss: 11.1632 - MSE: 11.1632 - MAE: 2.5824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7237/20000 - Train Loss: 2.6431 - Test Loss: 11.1592 - MSE: 11.1592 - MAE: 2.5820\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 7238/20000 - Train Loss: 2.6411 - Test Loss: 11.1552 - MSE: 11.1552 - MAE: 2.5815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7239/20000 - Train Loss: 2.6391 - Test Loss: 11.1513 - MSE: 11.1513 - MAE: 2.5811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7240/20000 - Train Loss: 2.6372 - Test Loss: 11.1473 - MSE: 11.1473 - MAE: 2.5807\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7241/20000 - Train Loss: 2.6352 - Test Loss: 11.1433 - MSE: 11.1433 - MAE: 2.5802\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7242/20000 - Train Loss: 2.6332 - Test Loss: 11.1393 - MSE: 11.1393 - MAE: 2.5798\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7243/20000 - Train Loss: 2.6313 - Test Loss: 11.1353 - MSE: 11.1353 - MAE: 2.5794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7244/20000 - Train Loss: 2.6293 - Test Loss: 11.1313 - MSE: 11.1313 - MAE: 2.5789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7245/20000 - Train Loss: 2.6273 - Test Loss: 11.1273 - MSE: 11.1273 - MAE: 2.5785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7246/20000 - Train Loss: 2.6254 - Test Loss: 11.1234 - MSE: 11.1234 - MAE: 2.5781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7247/20000 - Train Loss: 2.6234 - Test Loss: 11.1195 - MSE: 11.1195 - MAE: 2.5776\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7248/20000 - Train Loss: 2.6214 - Test Loss: 11.1156 - MSE: 11.1156 - MAE: 2.5772\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 7249/20000 - Train Loss: 2.6195 - Test Loss: 11.1116 - MSE: 11.1116 - MAE: 2.5768\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7250/20000 - Train Loss: 2.6175 - Test Loss: 11.1076 - MSE: 11.1076 - MAE: 2.5763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7251/20000 - Train Loss: 2.6156 - Test Loss: 11.1036 - MSE: 11.1036 - MAE: 2.5759\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 7252/20000 - Train Loss: 2.6136 - Test Loss: 11.0997 - MSE: 11.0997 - MAE: 2.5754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7253/20000 - Train Loss: 2.6117 - Test Loss: 11.0958 - MSE: 11.0958 - MAE: 2.5750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7254/20000 - Train Loss: 2.6097 - Test Loss: 11.0918 - MSE: 11.0918 - MAE: 2.5746\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7255/20000 - Train Loss: 2.6078 - Test Loss: 11.0879 - MSE: 11.0879 - MAE: 2.5741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7256/20000 - Train Loss: 2.6058 - Test Loss: 11.0840 - MSE: 11.0840 - MAE: 2.5737\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7257/20000 - Train Loss: 2.6039 - Test Loss: 11.0800 - MSE: 11.0800 - MAE: 2.5733\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 7258/20000 - Train Loss: 2.6019 - Test Loss: 11.0761 - MSE: 11.0761 - MAE: 2.5728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7259/20000 - Train Loss: 2.6000 - Test Loss: 11.0722 - MSE: 11.0722 - MAE: 2.5724\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7260/20000 - Train Loss: 2.5980 - Test Loss: 11.0683 - MSE: 11.0683 - MAE: 2.5720\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7261/20000 - Train Loss: 2.5961 - Test Loss: 11.0643 - MSE: 11.0643 - MAE: 2.5715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7262/20000 - Train Loss: 2.5942 - Test Loss: 11.0604 - MSE: 11.0604 - MAE: 2.5711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7263/20000 - Train Loss: 2.5922 - Test Loss: 11.0565 - MSE: 11.0565 - MAE: 2.5707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7264/20000 - Train Loss: 2.5903 - Test Loss: 11.0526 - MSE: 11.0526 - MAE: 2.5702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7265/20000 - Train Loss: 2.5884 - Test Loss: 11.0487 - MSE: 11.0487 - MAE: 2.5698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7266/20000 - Train Loss: 2.5864 - Test Loss: 11.0448 - MSE: 11.0448 - MAE: 2.5694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7267/20000 - Train Loss: 2.5845 - Test Loss: 11.0409 - MSE: 11.0409 - MAE: 2.5690\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7268/20000 - Train Loss: 2.5826 - Test Loss: 11.0370 - MSE: 11.0370 - MAE: 2.5685\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7269/20000 - Train Loss: 2.5806 - Test Loss: 11.0331 - MSE: 11.0331 - MAE: 2.5681\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7270/20000 - Train Loss: 2.5787 - Test Loss: 11.0292 - MSE: 11.0292 - MAE: 2.5676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7271/20000 - Train Loss: 2.5768 - Test Loss: 11.0253 - MSE: 11.0253 - MAE: 2.5672\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7272/20000 - Train Loss: 2.5749 - Test Loss: 11.0215 - MSE: 11.0215 - MAE: 2.5668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7273/20000 - Train Loss: 2.5729 - Test Loss: 11.0176 - MSE: 11.0176 - MAE: 2.5664\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7274/20000 - Train Loss: 2.5710 - Test Loss: 11.0138 - MSE: 11.0138 - MAE: 2.5659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7275/20000 - Train Loss: 2.5691 - Test Loss: 11.0098 - MSE: 11.0098 - MAE: 2.5655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7276/20000 - Train Loss: 2.5672 - Test Loss: 11.0059 - MSE: 11.0059 - MAE: 2.5650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7277/20000 - Train Loss: 2.5653 - Test Loss: 11.0021 - MSE: 11.0021 - MAE: 2.5646\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7278/20000 - Train Loss: 2.5634 - Test Loss: 10.9982 - MSE: 10.9982 - MAE: 2.5642\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7279/20000 - Train Loss: 2.5615 - Test Loss: 10.9944 - MSE: 10.9944 - MAE: 2.5638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7280/20000 - Train Loss: 2.5595 - Test Loss: 10.9906 - MSE: 10.9906 - MAE: 2.5633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7281/20000 - Train Loss: 2.5576 - Test Loss: 10.9867 - MSE: 10.9867 - MAE: 2.5629\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7282/20000 - Train Loss: 2.5557 - Test Loss: 10.9828 - MSE: 10.9828 - MAE: 2.5624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7283/20000 - Train Loss: 2.5538 - Test Loss: 10.9789 - MSE: 10.9789 - MAE: 2.5620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7284/20000 - Train Loss: 2.5519 - Test Loss: 10.9751 - MSE: 10.9751 - MAE: 2.5616\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 7285/20000 - Train Loss: 2.5500 - Test Loss: 10.9713 - MSE: 10.9713 - MAE: 2.5612\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7286/20000 - Train Loss: 2.5481 - Test Loss: 10.9675 - MSE: 10.9675 - MAE: 2.5607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7287/20000 - Train Loss: 2.5462 - Test Loss: 10.9636 - MSE: 10.9636 - MAE: 2.5603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7288/20000 - Train Loss: 2.5443 - Test Loss: 10.9598 - MSE: 10.9598 - MAE: 2.5599\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 7289/20000 - Train Loss: 2.5424 - Test Loss: 10.9560 - MSE: 10.9560 - MAE: 2.5594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7290/20000 - Train Loss: 2.5405 - Test Loss: 10.9521 - MSE: 10.9521 - MAE: 2.5590\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7291/20000 - Train Loss: 2.5386 - Test Loss: 10.9483 - MSE: 10.9483 - MAE: 2.5586\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7292/20000 - Train Loss: 2.5367 - Test Loss: 10.9445 - MSE: 10.9445 - MAE: 2.5581\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7293/20000 - Train Loss: 2.5349 - Test Loss: 10.9407 - MSE: 10.9407 - MAE: 2.5577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7294/20000 - Train Loss: 2.5330 - Test Loss: 10.9369 - MSE: 10.9369 - MAE: 2.5573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7295/20000 - Train Loss: 2.5311 - Test Loss: 10.9331 - MSE: 10.9331 - MAE: 2.5568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7296/20000 - Train Loss: 2.5292 - Test Loss: 10.9292 - MSE: 10.9292 - MAE: 2.5564\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7297/20000 - Train Loss: 2.5273 - Test Loss: 10.9255 - MSE: 10.9255 - MAE: 2.5560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7298/20000 - Train Loss: 2.5254 - Test Loss: 10.9216 - MSE: 10.9216 - MAE: 2.5555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7299/20000 - Train Loss: 2.5235 - Test Loss: 10.9178 - MSE: 10.9178 - MAE: 2.5551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7300/20000 - Train Loss: 2.5217 - Test Loss: 10.9141 - MSE: 10.9141 - MAE: 2.5547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7301/20000 - Train Loss: 2.5198 - Test Loss: 10.9103 - MSE: 10.9103 - MAE: 2.5542\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 7302/20000 - Train Loss: 2.5179 - Test Loss: 10.9065 - MSE: 10.9065 - MAE: 2.5538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7303/20000 - Train Loss: 2.5160 - Test Loss: 10.9027 - MSE: 10.9027 - MAE: 2.5534\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 7304/20000 - Train Loss: 2.5142 - Test Loss: 10.8989 - MSE: 10.8989 - MAE: 2.5529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7305/20000 - Train Loss: 2.5123 - Test Loss: 10.8951 - MSE: 10.8951 - MAE: 2.5525\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7306/20000 - Train Loss: 2.5104 - Test Loss: 10.8914 - MSE: 10.8914 - MAE: 2.5521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7307/20000 - Train Loss: 2.5086 - Test Loss: 10.8876 - MSE: 10.8876 - MAE: 2.5516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7308/20000 - Train Loss: 2.5067 - Test Loss: 10.8839 - MSE: 10.8839 - MAE: 2.5512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7309/20000 - Train Loss: 2.5048 - Test Loss: 10.8801 - MSE: 10.8801 - MAE: 2.5508\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7310/20000 - Train Loss: 2.5030 - Test Loss: 10.8763 - MSE: 10.8763 - MAE: 2.5503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7311/20000 - Train Loss: 2.5011 - Test Loss: 10.8725 - MSE: 10.8725 - MAE: 2.5499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7312/20000 - Train Loss: 2.4992 - Test Loss: 10.8688 - MSE: 10.8688 - MAE: 2.5495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7313/20000 - Train Loss: 2.4974 - Test Loss: 10.8651 - MSE: 10.8651 - MAE: 2.5491\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7314/20000 - Train Loss: 2.4955 - Test Loss: 10.8613 - MSE: 10.8613 - MAE: 2.5486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7315/20000 - Train Loss: 2.4937 - Test Loss: 10.8576 - MSE: 10.8576 - MAE: 2.5482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7316/20000 - Train Loss: 2.4918 - Test Loss: 10.8538 - MSE: 10.8538 - MAE: 2.5478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7317/20000 - Train Loss: 2.4900 - Test Loss: 10.8500 - MSE: 10.8500 - MAE: 2.5473\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7318/20000 - Train Loss: 2.4881 - Test Loss: 10.8463 - MSE: 10.8463 - MAE: 2.5469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7319/20000 - Train Loss: 2.4863 - Test Loss: 10.8426 - MSE: 10.8426 - MAE: 2.5465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7320/20000 - Train Loss: 2.4844 - Test Loss: 10.8389 - MSE: 10.8389 - MAE: 2.5460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7321/20000 - Train Loss: 2.4826 - Test Loss: 10.8352 - MSE: 10.8352 - MAE: 2.5456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7322/20000 - Train Loss: 2.4807 - Test Loss: 10.8314 - MSE: 10.8314 - MAE: 2.5452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7323/20000 - Train Loss: 2.4789 - Test Loss: 10.8277 - MSE: 10.8277 - MAE: 2.5447\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7324/20000 - Train Loss: 2.4770 - Test Loss: 10.8239 - MSE: 10.8239 - MAE: 2.5443\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7325/20000 - Train Loss: 2.4752 - Test Loss: 10.8203 - MSE: 10.8203 - MAE: 2.5439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7326/20000 - Train Loss: 2.4733 - Test Loss: 10.8166 - MSE: 10.8166 - MAE: 2.5435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7327/20000 - Train Loss: 2.4715 - Test Loss: 10.8129 - MSE: 10.8129 - MAE: 2.5430\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7328/20000 - Train Loss: 2.4697 - Test Loss: 10.8092 - MSE: 10.8092 - MAE: 2.5426\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7329/20000 - Train Loss: 2.4678 - Test Loss: 10.8055 - MSE: 10.8055 - MAE: 2.5422\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7330/20000 - Train Loss: 2.4660 - Test Loss: 10.8017 - MSE: 10.8017 - MAE: 2.5417\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7331/20000 - Train Loss: 2.4642 - Test Loss: 10.7980 - MSE: 10.7980 - MAE: 2.5413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7332/20000 - Train Loss: 2.4623 - Test Loss: 10.7944 - MSE: 10.7944 - MAE: 2.5409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7333/20000 - Train Loss: 2.4605 - Test Loss: 10.7907 - MSE: 10.7907 - MAE: 2.5404\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7334/20000 - Train Loss: 2.4587 - Test Loss: 10.7870 - MSE: 10.7870 - MAE: 2.5400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7335/20000 - Train Loss: 2.4569 - Test Loss: 10.7833 - MSE: 10.7833 - MAE: 2.5396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7336/20000 - Train Loss: 2.4550 - Test Loss: 10.7796 - MSE: 10.7796 - MAE: 2.5391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7337/20000 - Train Loss: 2.4532 - Test Loss: 10.7759 - MSE: 10.7759 - MAE: 2.5387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7338/20000 - Train Loss: 2.4514 - Test Loss: 10.7722 - MSE: 10.7722 - MAE: 2.5383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7339/20000 - Train Loss: 2.4496 - Test Loss: 10.7687 - MSE: 10.7687 - MAE: 2.5379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7340/20000 - Train Loss: 2.4478 - Test Loss: 10.7650 - MSE: 10.7650 - MAE: 2.5374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7341/20000 - Train Loss: 2.4459 - Test Loss: 10.7613 - MSE: 10.7613 - MAE: 2.5370\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 7342/20000 - Train Loss: 2.4441 - Test Loss: 10.7576 - MSE: 10.7576 - MAE: 2.5366\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7343/20000 - Train Loss: 2.4423 - Test Loss: 10.7539 - MSE: 10.7539 - MAE: 2.5361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7344/20000 - Train Loss: 2.4405 - Test Loss: 10.7503 - MSE: 10.7503 - MAE: 2.5357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7345/20000 - Train Loss: 2.4387 - Test Loss: 10.7467 - MSE: 10.7467 - MAE: 2.5353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7346/20000 - Train Loss: 2.4369 - Test Loss: 10.7430 - MSE: 10.7430 - MAE: 2.5349\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7347/20000 - Train Loss: 2.4351 - Test Loss: 10.7394 - MSE: 10.7394 - MAE: 2.5344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7348/20000 - Train Loss: 2.4333 - Test Loss: 10.7358 - MSE: 10.7358 - MAE: 2.5340\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7349/20000 - Train Loss: 2.4315 - Test Loss: 10.7321 - MSE: 10.7321 - MAE: 2.5336\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7350/20000 - Train Loss: 2.4297 - Test Loss: 10.7284 - MSE: 10.7284 - MAE: 2.5331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7351/20000 - Train Loss: 2.4279 - Test Loss: 10.7248 - MSE: 10.7248 - MAE: 2.5327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7352/20000 - Train Loss: 2.4261 - Test Loss: 10.7212 - MSE: 10.7212 - MAE: 2.5323\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7353/20000 - Train Loss: 2.4243 - Test Loss: 10.7176 - MSE: 10.7176 - MAE: 2.5318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7354/20000 - Train Loss: 2.4225 - Test Loss: 10.7140 - MSE: 10.7140 - MAE: 2.5314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7355/20000 - Train Loss: 2.4207 - Test Loss: 10.7104 - MSE: 10.7104 - MAE: 2.5310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7356/20000 - Train Loss: 2.4189 - Test Loss: 10.7067 - MSE: 10.7067 - MAE: 2.5306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7357/20000 - Train Loss: 2.4171 - Test Loss: 10.7031 - MSE: 10.7031 - MAE: 2.5301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7358/20000 - Train Loss: 2.4153 - Test Loss: 10.6994 - MSE: 10.6994 - MAE: 2.5297\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 7359/20000 - Train Loss: 2.4135 - Test Loss: 10.6959 - MSE: 10.6959 - MAE: 2.5293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7360/20000 - Train Loss: 2.4117 - Test Loss: 10.6923 - MSE: 10.6923 - MAE: 2.5288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7361/20000 - Train Loss: 2.4099 - Test Loss: 10.6887 - MSE: 10.6887 - MAE: 2.5284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7362/20000 - Train Loss: 2.4082 - Test Loss: 10.6851 - MSE: 10.6851 - MAE: 2.5280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7363/20000 - Train Loss: 2.4064 - Test Loss: 10.6815 - MSE: 10.6815 - MAE: 2.5276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7364/20000 - Train Loss: 2.4046 - Test Loss: 10.6779 - MSE: 10.6779 - MAE: 2.5271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7365/20000 - Train Loss: 2.4028 - Test Loss: 10.6743 - MSE: 10.6743 - MAE: 2.5267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7366/20000 - Train Loss: 2.4010 - Test Loss: 10.6707 - MSE: 10.6707 - MAE: 2.5263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7367/20000 - Train Loss: 2.3993 - Test Loss: 10.6672 - MSE: 10.6672 - MAE: 2.5258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7368/20000 - Train Loss: 2.3975 - Test Loss: 10.6636 - MSE: 10.6636 - MAE: 2.5254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7369/20000 - Train Loss: 2.3957 - Test Loss: 10.6600 - MSE: 10.6600 - MAE: 2.5250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7370/20000 - Train Loss: 2.3939 - Test Loss: 10.6564 - MSE: 10.6564 - MAE: 2.5246\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7371/20000 - Train Loss: 2.3922 - Test Loss: 10.6528 - MSE: 10.6528 - MAE: 2.5241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7372/20000 - Train Loss: 2.3904 - Test Loss: 10.6493 - MSE: 10.6493 - MAE: 2.5237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7373/20000 - Train Loss: 2.3886 - Test Loss: 10.6457 - MSE: 10.6457 - MAE: 2.5233\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7374/20000 - Train Loss: 2.3869 - Test Loss: 10.6422 - MSE: 10.6422 - MAE: 2.5228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7375/20000 - Train Loss: 2.3851 - Test Loss: 10.6386 - MSE: 10.6386 - MAE: 2.5224\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 7376/20000 - Train Loss: 2.3833 - Test Loss: 10.6350 - MSE: 10.6350 - MAE: 2.5220\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7377/20000 - Train Loss: 2.3816 - Test Loss: 10.6315 - MSE: 10.6315 - MAE: 2.5216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7378/20000 - Train Loss: 2.3798 - Test Loss: 10.6279 - MSE: 10.6279 - MAE: 2.5211\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7379/20000 - Train Loss: 2.3781 - Test Loss: 10.6244 - MSE: 10.6244 - MAE: 2.5207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7380/20000 - Train Loss: 2.3763 - Test Loss: 10.6208 - MSE: 10.6208 - MAE: 2.5203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7381/20000 - Train Loss: 2.3745 - Test Loss: 10.6173 - MSE: 10.6173 - MAE: 2.5199\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7382/20000 - Train Loss: 2.3728 - Test Loss: 10.6138 - MSE: 10.6138 - MAE: 2.5194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7383/20000 - Train Loss: 2.3710 - Test Loss: 10.6103 - MSE: 10.6103 - MAE: 2.5190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7384/20000 - Train Loss: 2.3693 - Test Loss: 10.6067 - MSE: 10.6067 - MAE: 2.5186\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7385/20000 - Train Loss: 2.3675 - Test Loss: 10.6032 - MSE: 10.6032 - MAE: 2.5181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7386/20000 - Train Loss: 2.3658 - Test Loss: 10.5996 - MSE: 10.5996 - MAE: 2.5177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7387/20000 - Train Loss: 2.3640 - Test Loss: 10.5961 - MSE: 10.5961 - MAE: 2.5173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7388/20000 - Train Loss: 2.3623 - Test Loss: 10.5927 - MSE: 10.5927 - MAE: 2.5169\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7389/20000 - Train Loss: 2.3606 - Test Loss: 10.5891 - MSE: 10.5891 - MAE: 2.5164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7390/20000 - Train Loss: 2.3588 - Test Loss: 10.5856 - MSE: 10.5856 - MAE: 2.5160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7391/20000 - Train Loss: 2.3571 - Test Loss: 10.5821 - MSE: 10.5821 - MAE: 2.5156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7392/20000 - Train Loss: 2.3553 - Test Loss: 10.5786 - MSE: 10.5786 - MAE: 2.5151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7393/20000 - Train Loss: 2.3536 - Test Loss: 10.5751 - MSE: 10.5751 - MAE: 2.5147\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7394/20000 - Train Loss: 2.3519 - Test Loss: 10.5716 - MSE: 10.5716 - MAE: 2.5143\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7395/20000 - Train Loss: 2.3501 - Test Loss: 10.5681 - MSE: 10.5681 - MAE: 2.5139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7396/20000 - Train Loss: 2.3484 - Test Loss: 10.5646 - MSE: 10.5646 - MAE: 2.5134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7397/20000 - Train Loss: 2.3467 - Test Loss: 10.5611 - MSE: 10.5611 - MAE: 2.5130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7398/20000 - Train Loss: 2.3449 - Test Loss: 10.5576 - MSE: 10.5576 - MAE: 2.5126\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7399/20000 - Train Loss: 2.3432 - Test Loss: 10.5541 - MSE: 10.5541 - MAE: 2.5122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7400/20000 - Train Loss: 2.3415 - Test Loss: 10.5506 - MSE: 10.5506 - MAE: 2.5117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7401/20000 - Train Loss: 2.3398 - Test Loss: 10.5472 - MSE: 10.5472 - MAE: 2.5113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7402/20000 - Train Loss: 2.3380 - Test Loss: 10.5437 - MSE: 10.5437 - MAE: 2.5109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7403/20000 - Train Loss: 2.3363 - Test Loss: 10.5402 - MSE: 10.5402 - MAE: 2.5104\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7404/20000 - Train Loss: 2.3346 - Test Loss: 10.5367 - MSE: 10.5367 - MAE: 2.5100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7405/20000 - Train Loss: 2.3329 - Test Loss: 10.5333 - MSE: 10.5333 - MAE: 2.5096\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7406/20000 - Train Loss: 2.3312 - Test Loss: 10.5298 - MSE: 10.5298 - MAE: 2.5092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7407/20000 - Train Loss: 2.3294 - Test Loss: 10.5264 - MSE: 10.5264 - MAE: 2.5088\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7408/20000 - Train Loss: 2.3277 - Test Loss: 10.5229 - MSE: 10.5229 - MAE: 2.5083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7409/20000 - Train Loss: 2.3260 - Test Loss: 10.5195 - MSE: 10.5195 - MAE: 2.5079\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7410/20000 - Train Loss: 2.3243 - Test Loss: 10.5160 - MSE: 10.5160 - MAE: 2.5075\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7411/20000 - Train Loss: 2.3226 - Test Loss: 10.5125 - MSE: 10.5125 - MAE: 2.5070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7412/20000 - Train Loss: 2.3209 - Test Loss: 10.5091 - MSE: 10.5091 - MAE: 2.5066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7413/20000 - Train Loss: 2.3192 - Test Loss: 10.5057 - MSE: 10.5057 - MAE: 2.5062\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7414/20000 - Train Loss: 2.3175 - Test Loss: 10.5022 - MSE: 10.5022 - MAE: 2.5058\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7415/20000 - Train Loss: 2.3158 - Test Loss: 10.4988 - MSE: 10.4988 - MAE: 2.5053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7416/20000 - Train Loss: 2.3141 - Test Loss: 10.4954 - MSE: 10.4954 - MAE: 2.5049\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7417/20000 - Train Loss: 2.3124 - Test Loss: 10.4920 - MSE: 10.4920 - MAE: 2.5045\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7418/20000 - Train Loss: 2.3107 - Test Loss: 10.4885 - MSE: 10.4885 - MAE: 2.5041\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7419/20000 - Train Loss: 2.3090 - Test Loss: 10.4851 - MSE: 10.4851 - MAE: 2.5036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7420/20000 - Train Loss: 2.3073 - Test Loss: 10.4817 - MSE: 10.4817 - MAE: 2.5032\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7421/20000 - Train Loss: 2.3056 - Test Loss: 10.4782 - MSE: 10.4782 - MAE: 2.5028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7422/20000 - Train Loss: 2.3039 - Test Loss: 10.4748 - MSE: 10.4748 - MAE: 2.5024\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7423/20000 - Train Loss: 2.3022 - Test Loss: 10.4715 - MSE: 10.4715 - MAE: 2.5019\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7424/20000 - Train Loss: 2.3005 - Test Loss: 10.4681 - MSE: 10.4681 - MAE: 2.5015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7425/20000 - Train Loss: 2.2988 - Test Loss: 10.4647 - MSE: 10.4647 - MAE: 2.5011\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7426/20000 - Train Loss: 2.2971 - Test Loss: 10.4612 - MSE: 10.4612 - MAE: 2.5007\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7427/20000 - Train Loss: 2.2954 - Test Loss: 10.4578 - MSE: 10.4578 - MAE: 2.5002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7428/20000 - Train Loss: 2.2938 - Test Loss: 10.4544 - MSE: 10.4544 - MAE: 2.4998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7429/20000 - Train Loss: 2.2921 - Test Loss: 10.4510 - MSE: 10.4510 - MAE: 2.4994\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7430/20000 - Train Loss: 2.2904 - Test Loss: 10.4477 - MSE: 10.4477 - MAE: 2.4990\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7431/20000 - Train Loss: 2.2887 - Test Loss: 10.4443 - MSE: 10.4443 - MAE: 2.4985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7432/20000 - Train Loss: 2.2870 - Test Loss: 10.4409 - MSE: 10.4409 - MAE: 2.4981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7433/20000 - Train Loss: 2.2853 - Test Loss: 10.4375 - MSE: 10.4375 - MAE: 2.4977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7434/20000 - Train Loss: 2.2837 - Test Loss: 10.4341 - MSE: 10.4341 - MAE: 2.4973\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7435/20000 - Train Loss: 2.2820 - Test Loss: 10.4307 - MSE: 10.4307 - MAE: 2.4968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7436/20000 - Train Loss: 2.2803 - Test Loss: 10.4274 - MSE: 10.4274 - MAE: 2.4964\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7437/20000 - Train Loss: 2.2787 - Test Loss: 10.4240 - MSE: 10.4240 - MAE: 2.4960\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7438/20000 - Train Loss: 2.2770 - Test Loss: 10.4207 - MSE: 10.4207 - MAE: 2.4956\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7439/20000 - Train Loss: 2.2753 - Test Loss: 10.4173 - MSE: 10.4173 - MAE: 2.4951\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7440/20000 - Train Loss: 2.2737 - Test Loss: 10.4139 - MSE: 10.4139 - MAE: 2.4947\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7441/20000 - Train Loss: 2.2720 - Test Loss: 10.4105 - MSE: 10.4105 - MAE: 2.4943\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7442/20000 - Train Loss: 2.2703 - Test Loss: 10.4072 - MSE: 10.4072 - MAE: 2.4939\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7443/20000 - Train Loss: 2.2687 - Test Loss: 10.4039 - MSE: 10.4039 - MAE: 2.4934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7444/20000 - Train Loss: 2.2670 - Test Loss: 10.4005 - MSE: 10.4005 - MAE: 2.4930\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7445/20000 - Train Loss: 2.2653 - Test Loss: 10.3972 - MSE: 10.3972 - MAE: 2.4926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7446/20000 - Train Loss: 2.2637 - Test Loss: 10.3939 - MSE: 10.3939 - MAE: 2.4922\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7447/20000 - Train Loss: 2.2620 - Test Loss: 10.3905 - MSE: 10.3905 - MAE: 2.4917\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7448/20000 - Train Loss: 2.2604 - Test Loss: 10.3871 - MSE: 10.3871 - MAE: 2.4913\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7449/20000 - Train Loss: 2.2587 - Test Loss: 10.3838 - MSE: 10.3838 - MAE: 2.4909\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7450/20000 - Train Loss: 2.2571 - Test Loss: 10.3805 - MSE: 10.3805 - MAE: 2.4905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7451/20000 - Train Loss: 2.2554 - Test Loss: 10.3772 - MSE: 10.3772 - MAE: 2.4900\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7452/20000 - Train Loss: 2.2538 - Test Loss: 10.3739 - MSE: 10.3739 - MAE: 2.4896\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7453/20000 - Train Loss: 2.2521 - Test Loss: 10.3705 - MSE: 10.3705 - MAE: 2.4892\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7454/20000 - Train Loss: 2.2505 - Test Loss: 10.3672 - MSE: 10.3672 - MAE: 2.4888\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7455/20000 - Train Loss: 2.2488 - Test Loss: 10.3639 - MSE: 10.3639 - MAE: 2.4884\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7456/20000 - Train Loss: 2.2472 - Test Loss: 10.3606 - MSE: 10.3606 - MAE: 2.4879\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7457/20000 - Train Loss: 2.2456 - Test Loss: 10.3573 - MSE: 10.3573 - MAE: 2.4875\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 7458/20000 - Train Loss: 2.2439 - Test Loss: 10.3540 - MSE: 10.3540 - MAE: 2.4871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7459/20000 - Train Loss: 2.2423 - Test Loss: 10.3507 - MSE: 10.3507 - MAE: 2.4867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7460/20000 - Train Loss: 2.2406 - Test Loss: 10.3474 - MSE: 10.3474 - MAE: 2.4862\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7461/20000 - Train Loss: 2.2390 - Test Loss: 10.3441 - MSE: 10.3441 - MAE: 2.4858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7462/20000 - Train Loss: 2.2374 - Test Loss: 10.3408 - MSE: 10.3408 - MAE: 2.4854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7463/20000 - Train Loss: 2.2357 - Test Loss: 10.3375 - MSE: 10.3375 - MAE: 2.4850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7464/20000 - Train Loss: 2.2341 - Test Loss: 10.3342 - MSE: 10.3342 - MAE: 2.4845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7465/20000 - Train Loss: 2.2325 - Test Loss: 10.3309 - MSE: 10.3309 - MAE: 2.4841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7466/20000 - Train Loss: 2.2308 - Test Loss: 10.3276 - MSE: 10.3276 - MAE: 2.4837\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7467/20000 - Train Loss: 2.2292 - Test Loss: 10.3244 - MSE: 10.3244 - MAE: 2.4833\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7468/20000 - Train Loss: 2.2276 - Test Loss: 10.3211 - MSE: 10.3211 - MAE: 2.4829\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7469/20000 - Train Loss: 2.2260 - Test Loss: 10.3178 - MSE: 10.3178 - MAE: 2.4824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7470/20000 - Train Loss: 2.2244 - Test Loss: 10.3145 - MSE: 10.3145 - MAE: 2.4820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7471/20000 - Train Loss: 2.2227 - Test Loss: 10.3113 - MSE: 10.3113 - MAE: 2.4816\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7472/20000 - Train Loss: 2.2211 - Test Loss: 10.3080 - MSE: 10.3080 - MAE: 2.4812\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7473/20000 - Train Loss: 2.2195 - Test Loss: 10.3047 - MSE: 10.3047 - MAE: 2.4807\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7474/20000 - Train Loss: 2.2179 - Test Loss: 10.3015 - MSE: 10.3015 - MAE: 2.4803\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7475/20000 - Train Loss: 2.2163 - Test Loss: 10.2983 - MSE: 10.2983 - MAE: 2.4799\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7476/20000 - Train Loss: 2.2147 - Test Loss: 10.2950 - MSE: 10.2950 - MAE: 2.4795\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7477/20000 - Train Loss: 2.2130 - Test Loss: 10.2917 - MSE: 10.2917 - MAE: 2.4791\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7478/20000 - Train Loss: 2.2114 - Test Loss: 10.2885 - MSE: 10.2885 - MAE: 2.4786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7479/20000 - Train Loss: 2.2098 - Test Loss: 10.2852 - MSE: 10.2852 - MAE: 2.4782\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7480/20000 - Train Loss: 2.2082 - Test Loss: 10.2820 - MSE: 10.2820 - MAE: 2.4778\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7481/20000 - Train Loss: 2.2066 - Test Loss: 10.2788 - MSE: 10.2788 - MAE: 2.4774\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7482/20000 - Train Loss: 2.2050 - Test Loss: 10.2756 - MSE: 10.2756 - MAE: 2.4769\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7483/20000 - Train Loss: 2.2034 - Test Loss: 10.2723 - MSE: 10.2723 - MAE: 2.4765\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7484/20000 - Train Loss: 2.2018 - Test Loss: 10.2691 - MSE: 10.2691 - MAE: 2.4761\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7485/20000 - Train Loss: 2.2002 - Test Loss: 10.2659 - MSE: 10.2659 - MAE: 2.4757\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7486/20000 - Train Loss: 2.1986 - Test Loss: 10.2626 - MSE: 10.2626 - MAE: 2.4753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7487/20000 - Train Loss: 2.1970 - Test Loss: 10.2594 - MSE: 10.2594 - MAE: 2.4748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7488/20000 - Train Loss: 2.1954 - Test Loss: 10.2562 - MSE: 10.2562 - MAE: 2.4744\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7489/20000 - Train Loss: 2.1938 - Test Loss: 10.2530 - MSE: 10.2530 - MAE: 2.4740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7490/20000 - Train Loss: 2.1922 - Test Loss: 10.2498 - MSE: 10.2498 - MAE: 2.4736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7491/20000 - Train Loss: 2.1906 - Test Loss: 10.2466 - MSE: 10.2466 - MAE: 2.4732\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7492/20000 - Train Loss: 2.1890 - Test Loss: 10.2434 - MSE: 10.2434 - MAE: 2.4727\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7493/20000 - Train Loss: 2.1875 - Test Loss: 10.2401 - MSE: 10.2401 - MAE: 2.4723\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7494/20000 - Train Loss: 2.1859 - Test Loss: 10.2370 - MSE: 10.2370 - MAE: 2.4719\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7495/20000 - Train Loss: 2.1843 - Test Loss: 10.2338 - MSE: 10.2338 - MAE: 2.4715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7496/20000 - Train Loss: 2.1827 - Test Loss: 10.2306 - MSE: 10.2306 - MAE: 2.4710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7497/20000 - Train Loss: 2.1811 - Test Loss: 10.2274 - MSE: 10.2274 - MAE: 2.4706\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7498/20000 - Train Loss: 2.1795 - Test Loss: 10.2242 - MSE: 10.2242 - MAE: 2.4702\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7499/20000 - Train Loss: 2.1780 - Test Loss: 10.2210 - MSE: 10.2210 - MAE: 2.4698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7500/20000 - Train Loss: 2.1764 - Test Loss: 10.2178 - MSE: 10.2178 - MAE: 2.4694\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7501/20000 - Train Loss: 2.1748 - Test Loss: 10.2147 - MSE: 10.2147 - MAE: 2.4689\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7502/20000 - Train Loss: 2.1732 - Test Loss: 10.2115 - MSE: 10.2115 - MAE: 2.4685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7503/20000 - Train Loss: 2.1717 - Test Loss: 10.2083 - MSE: 10.2083 - MAE: 2.4681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7504/20000 - Train Loss: 2.1701 - Test Loss: 10.2052 - MSE: 10.2052 - MAE: 2.4677\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 7505/20000 - Train Loss: 2.1685 - Test Loss: 10.2020 - MSE: 10.2020 - MAE: 2.4673\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7506/20000 - Train Loss: 2.1670 - Test Loss: 10.1988 - MSE: 10.1988 - MAE: 2.4668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7507/20000 - Train Loss: 2.1654 - Test Loss: 10.1957 - MSE: 10.1957 - MAE: 2.4664\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7508/20000 - Train Loss: 2.1638 - Test Loss: 10.1925 - MSE: 10.1925 - MAE: 2.4660\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7509/20000 - Train Loss: 2.1623 - Test Loss: 10.1893 - MSE: 10.1893 - MAE: 2.4656\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7510/20000 - Train Loss: 2.1607 - Test Loss: 10.1862 - MSE: 10.1862 - MAE: 2.4652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7511/20000 - Train Loss: 2.1591 - Test Loss: 10.1831 - MSE: 10.1831 - MAE: 2.4647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7512/20000 - Train Loss: 2.1576 - Test Loss: 10.1799 - MSE: 10.1799 - MAE: 2.4643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7513/20000 - Train Loss: 2.1560 - Test Loss: 10.1767 - MSE: 10.1767 - MAE: 2.4639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7514/20000 - Train Loss: 2.1545 - Test Loss: 10.1736 - MSE: 10.1736 - MAE: 2.4635\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7515/20000 - Train Loss: 2.1529 - Test Loss: 10.1705 - MSE: 10.1705 - MAE: 2.4631\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7516/20000 - Train Loss: 2.1513 - Test Loss: 10.1673 - MSE: 10.1673 - MAE: 2.4626\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7517/20000 - Train Loss: 2.1498 - Test Loss: 10.1642 - MSE: 10.1642 - MAE: 2.4622\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 7518/20000 - Train Loss: 2.1482 - Test Loss: 10.1611 - MSE: 10.1611 - MAE: 2.4618\n",
      "2/2 [==============================] - 0s 975us/step\n",
      "Epoch 7519/20000 - Train Loss: 2.1467 - Test Loss: 10.1580 - MSE: 10.1580 - MAE: 2.4614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7520/20000 - Train Loss: 2.1451 - Test Loss: 10.1549 - MSE: 10.1549 - MAE: 2.4610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7521/20000 - Train Loss: 2.1436 - Test Loss: 10.1517 - MSE: 10.1517 - MAE: 2.4605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7522/20000 - Train Loss: 2.1420 - Test Loss: 10.1486 - MSE: 10.1486 - MAE: 2.4601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7523/20000 - Train Loss: 2.1405 - Test Loss: 10.1455 - MSE: 10.1455 - MAE: 2.4597\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7524/20000 - Train Loss: 2.1390 - Test Loss: 10.1424 - MSE: 10.1424 - MAE: 2.4593\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 7525/20000 - Train Loss: 2.1374 - Test Loss: 10.1393 - MSE: 10.1393 - MAE: 2.4589\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7526/20000 - Train Loss: 2.1359 - Test Loss: 10.1362 - MSE: 10.1362 - MAE: 2.4585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7527/20000 - Train Loss: 2.1343 - Test Loss: 10.1331 - MSE: 10.1331 - MAE: 2.4580\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7528/20000 - Train Loss: 2.1328 - Test Loss: 10.1299 - MSE: 10.1299 - MAE: 2.4576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7529/20000 - Train Loss: 2.1313 - Test Loss: 10.1269 - MSE: 10.1269 - MAE: 2.4572\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7530/20000 - Train Loss: 2.1297 - Test Loss: 10.1238 - MSE: 10.1238 - MAE: 2.4568\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7531/20000 - Train Loss: 2.1282 - Test Loss: 10.1207 - MSE: 10.1207 - MAE: 2.4564\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7532/20000 - Train Loss: 2.1267 - Test Loss: 10.1176 - MSE: 10.1176 - MAE: 2.4559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7533/20000 - Train Loss: 2.1251 - Test Loss: 10.1145 - MSE: 10.1145 - MAE: 2.4555\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7534/20000 - Train Loss: 2.1236 - Test Loss: 10.1114 - MSE: 10.1114 - MAE: 2.4551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7535/20000 - Train Loss: 2.1221 - Test Loss: 10.1084 - MSE: 10.1084 - MAE: 2.4547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7536/20000 - Train Loss: 2.1206 - Test Loss: 10.1053 - MSE: 10.1053 - MAE: 2.4543\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7537/20000 - Train Loss: 2.1190 - Test Loss: 10.1022 - MSE: 10.1022 - MAE: 2.4539\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7538/20000 - Train Loss: 2.1175 - Test Loss: 10.0991 - MSE: 10.0991 - MAE: 2.4534\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7539/20000 - Train Loss: 2.1160 - Test Loss: 10.0960 - MSE: 10.0960 - MAE: 2.4530\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7540/20000 - Train Loss: 2.1145 - Test Loss: 10.0930 - MSE: 10.0930 - MAE: 2.4526\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7541/20000 - Train Loss: 2.1130 - Test Loss: 10.0899 - MSE: 10.0899 - MAE: 2.4522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7542/20000 - Train Loss: 2.1114 - Test Loss: 10.0869 - MSE: 10.0869 - MAE: 2.4518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7543/20000 - Train Loss: 2.1099 - Test Loss: 10.0839 - MSE: 10.0839 - MAE: 2.4514\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7544/20000 - Train Loss: 2.1084 - Test Loss: 10.0808 - MSE: 10.0808 - MAE: 2.4509\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7545/20000 - Train Loss: 2.1069 - Test Loss: 10.0777 - MSE: 10.0777 - MAE: 2.4505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7546/20000 - Train Loss: 2.1054 - Test Loss: 10.0746 - MSE: 10.0746 - MAE: 2.4501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7547/20000 - Train Loss: 2.1039 - Test Loss: 10.0716 - MSE: 10.0716 - MAE: 2.4498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7548/20000 - Train Loss: 2.1024 - Test Loss: 10.0686 - MSE: 10.0686 - MAE: 2.4494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7549/20000 - Train Loss: 2.1009 - Test Loss: 10.0656 - MSE: 10.0656 - MAE: 2.4490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7550/20000 - Train Loss: 2.0994 - Test Loss: 10.0625 - MSE: 10.0625 - MAE: 2.4486\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 7551/20000 - Train Loss: 2.0979 - Test Loss: 10.0594 - MSE: 10.0594 - MAE: 2.4482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7552/20000 - Train Loss: 2.0964 - Test Loss: 10.0564 - MSE: 10.0564 - MAE: 2.4478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7553/20000 - Train Loss: 2.0949 - Test Loss: 10.0534 - MSE: 10.0534 - MAE: 2.4475\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7554/20000 - Train Loss: 2.0934 - Test Loss: 10.0504 - MSE: 10.0504 - MAE: 2.4471\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7555/20000 - Train Loss: 2.0919 - Test Loss: 10.0473 - MSE: 10.0473 - MAE: 2.4467\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7556/20000 - Train Loss: 2.0904 - Test Loss: 10.0444 - MSE: 10.0444 - MAE: 2.4463\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7557/20000 - Train Loss: 2.0889 - Test Loss: 10.0413 - MSE: 10.0413 - MAE: 2.4459\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7558/20000 - Train Loss: 2.0874 - Test Loss: 10.0383 - MSE: 10.0383 - MAE: 2.4455\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7559/20000 - Train Loss: 2.0859 - Test Loss: 10.0353 - MSE: 10.0353 - MAE: 2.4452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7560/20000 - Train Loss: 2.0844 - Test Loss: 10.0323 - MSE: 10.0323 - MAE: 2.4448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7561/20000 - Train Loss: 2.0829 - Test Loss: 10.0293 - MSE: 10.0293 - MAE: 2.4444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7562/20000 - Train Loss: 2.0814 - Test Loss: 10.0263 - MSE: 10.0263 - MAE: 2.4440\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7563/20000 - Train Loss: 2.0799 - Test Loss: 10.0233 - MSE: 10.0233 - MAE: 2.4436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7564/20000 - Train Loss: 2.0784 - Test Loss: 10.0203 - MSE: 10.0203 - MAE: 2.4432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7565/20000 - Train Loss: 2.0770 - Test Loss: 10.0173 - MSE: 10.0173 - MAE: 2.4429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7566/20000 - Train Loss: 2.0755 - Test Loss: 10.0143 - MSE: 10.0143 - MAE: 2.4425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7567/20000 - Train Loss: 2.0740 - Test Loss: 10.0113 - MSE: 10.0113 - MAE: 2.4421\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7568/20000 - Train Loss: 2.0725 - Test Loss: 10.0083 - MSE: 10.0083 - MAE: 2.4417\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7569/20000 - Train Loss: 2.0710 - Test Loss: 10.0053 - MSE: 10.0053 - MAE: 2.4413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7570/20000 - Train Loss: 2.0696 - Test Loss: 10.0024 - MSE: 10.0024 - MAE: 2.4409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7571/20000 - Train Loss: 2.0681 - Test Loss: 9.9994 - MSE: 9.9994 - MAE: 2.4406\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7572/20000 - Train Loss: 2.0666 - Test Loss: 9.9964 - MSE: 9.9964 - MAE: 2.4402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7573/20000 - Train Loss: 2.0651 - Test Loss: 9.9934 - MSE: 9.9934 - MAE: 2.4398\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 7574/20000 - Train Loss: 2.0637 - Test Loss: 9.9905 - MSE: 9.9905 - MAE: 2.4394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7575/20000 - Train Loss: 2.0622 - Test Loss: 9.9875 - MSE: 9.9875 - MAE: 2.4390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7576/20000 - Train Loss: 2.0607 - Test Loss: 9.9846 - MSE: 9.9846 - MAE: 2.4386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7577/20000 - Train Loss: 2.0593 - Test Loss: 9.9816 - MSE: 9.9816 - MAE: 2.4383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7578/20000 - Train Loss: 2.0578 - Test Loss: 9.9786 - MSE: 9.9786 - MAE: 2.4379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7579/20000 - Train Loss: 2.0563 - Test Loss: 9.9757 - MSE: 9.9757 - MAE: 2.4375\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7580/20000 - Train Loss: 2.0549 - Test Loss: 9.9727 - MSE: 9.9727 - MAE: 2.4371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7581/20000 - Train Loss: 2.0534 - Test Loss: 9.9698 - MSE: 9.9698 - MAE: 2.4367\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7582/20000 - Train Loss: 2.0520 - Test Loss: 9.9669 - MSE: 9.9669 - MAE: 2.4363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7583/20000 - Train Loss: 2.0505 - Test Loss: 9.9639 - MSE: 9.9639 - MAE: 2.4360\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7584/20000 - Train Loss: 2.0490 - Test Loss: 9.9609 - MSE: 9.9609 - MAE: 2.4356\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7585/20000 - Train Loss: 2.0476 - Test Loss: 9.9580 - MSE: 9.9580 - MAE: 2.4352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7586/20000 - Train Loss: 2.0461 - Test Loss: 9.9550 - MSE: 9.9550 - MAE: 2.4348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7587/20000 - Train Loss: 2.0447 - Test Loss: 9.9522 - MSE: 9.9522 - MAE: 2.4344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7588/20000 - Train Loss: 2.0432 - Test Loss: 9.9492 - MSE: 9.9492 - MAE: 2.4340\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7589/20000 - Train Loss: 2.0418 - Test Loss: 9.9463 - MSE: 9.9463 - MAE: 2.4337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7590/20000 - Train Loss: 2.0403 - Test Loss: 9.9434 - MSE: 9.9434 - MAE: 2.4333\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7591/20000 - Train Loss: 2.0389 - Test Loss: 9.9404 - MSE: 9.9404 - MAE: 2.4329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7592/20000 - Train Loss: 2.0374 - Test Loss: 9.9375 - MSE: 9.9375 - MAE: 2.4325\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7593/20000 - Train Loss: 2.0360 - Test Loss: 9.9346 - MSE: 9.9346 - MAE: 2.4321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7594/20000 - Train Loss: 2.0346 - Test Loss: 9.9317 - MSE: 9.9317 - MAE: 2.4318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7595/20000 - Train Loss: 2.0331 - Test Loss: 9.9288 - MSE: 9.9288 - MAE: 2.4314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7596/20000 - Train Loss: 2.0317 - Test Loss: 9.9259 - MSE: 9.9259 - MAE: 2.4310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7597/20000 - Train Loss: 2.0302 - Test Loss: 9.9230 - MSE: 9.9230 - MAE: 2.4306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7598/20000 - Train Loss: 2.0288 - Test Loss: 9.9201 - MSE: 9.9201 - MAE: 2.4302\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 7599/20000 - Train Loss: 2.0274 - Test Loss: 9.9172 - MSE: 9.9172 - MAE: 2.4298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7600/20000 - Train Loss: 2.0259 - Test Loss: 9.9143 - MSE: 9.9143 - MAE: 2.4295\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 7601/20000 - Train Loss: 2.0245 - Test Loss: 9.9114 - MSE: 9.9114 - MAE: 2.4291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7602/20000 - Train Loss: 2.0231 - Test Loss: 9.9085 - MSE: 9.9085 - MAE: 2.4287\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7603/20000 - Train Loss: 2.0216 - Test Loss: 9.9056 - MSE: 9.9056 - MAE: 2.4283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7604/20000 - Train Loss: 2.0202 - Test Loss: 9.9027 - MSE: 9.9027 - MAE: 2.4279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7605/20000 - Train Loss: 2.0188 - Test Loss: 9.8999 - MSE: 9.8999 - MAE: 2.4276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7606/20000 - Train Loss: 2.0174 - Test Loss: 9.8970 - MSE: 9.8970 - MAE: 2.4272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7607/20000 - Train Loss: 2.0159 - Test Loss: 9.8941 - MSE: 9.8941 - MAE: 2.4268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7608/20000 - Train Loss: 2.0145 - Test Loss: 9.8912 - MSE: 9.8912 - MAE: 2.4264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7609/20000 - Train Loss: 2.0131 - Test Loss: 9.8883 - MSE: 9.8883 - MAE: 2.4260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7610/20000 - Train Loss: 2.0117 - Test Loss: 9.8855 - MSE: 9.8855 - MAE: 2.4256\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7611/20000 - Train Loss: 2.0103 - Test Loss: 9.8826 - MSE: 9.8826 - MAE: 2.4253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7612/20000 - Train Loss: 2.0088 - Test Loss: 9.8797 - MSE: 9.8797 - MAE: 2.4249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7613/20000 - Train Loss: 2.0074 - Test Loss: 9.8769 - MSE: 9.8769 - MAE: 2.4245\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7614/20000 - Train Loss: 2.0060 - Test Loss: 9.8740 - MSE: 9.8740 - MAE: 2.4241\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7615/20000 - Train Loss: 2.0046 - Test Loss: 9.8712 - MSE: 9.8712 - MAE: 2.4237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7616/20000 - Train Loss: 2.0032 - Test Loss: 9.8683 - MSE: 9.8683 - MAE: 2.4234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7617/20000 - Train Loss: 2.0018 - Test Loss: 9.8655 - MSE: 9.8655 - MAE: 2.4230\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7618/20000 - Train Loss: 2.0004 - Test Loss: 9.8626 - MSE: 9.8626 - MAE: 2.4226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7619/20000 - Train Loss: 1.9990 - Test Loss: 9.8598 - MSE: 9.8598 - MAE: 2.4222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7620/20000 - Train Loss: 1.9976 - Test Loss: 9.8569 - MSE: 9.8569 - MAE: 2.4218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7621/20000 - Train Loss: 1.9962 - Test Loss: 9.8541 - MSE: 9.8541 - MAE: 2.4215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7622/20000 - Train Loss: 1.9948 - Test Loss: 9.8513 - MSE: 9.8513 - MAE: 2.4211\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7623/20000 - Train Loss: 1.9934 - Test Loss: 9.8485 - MSE: 9.8485 - MAE: 2.4207\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7624/20000 - Train Loss: 1.9920 - Test Loss: 9.8456 - MSE: 9.8456 - MAE: 2.4203\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7625/20000 - Train Loss: 1.9906 - Test Loss: 9.8428 - MSE: 9.8428 - MAE: 2.4199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7626/20000 - Train Loss: 1.9892 - Test Loss: 9.8399 - MSE: 9.8399 - MAE: 2.4196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7627/20000 - Train Loss: 1.9878 - Test Loss: 9.8371 - MSE: 9.8371 - MAE: 2.4192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7628/20000 - Train Loss: 1.9864 - Test Loss: 9.8343 - MSE: 9.8343 - MAE: 2.4188\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7629/20000 - Train Loss: 1.9850 - Test Loss: 9.8315 - MSE: 9.8315 - MAE: 2.4184\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7630/20000 - Train Loss: 1.9836 - Test Loss: 9.8287 - MSE: 9.8287 - MAE: 2.4180\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 7631/20000 - Train Loss: 1.9822 - Test Loss: 9.8259 - MSE: 9.8259 - MAE: 2.4177\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7632/20000 - Train Loss: 1.9808 - Test Loss: 9.8230 - MSE: 9.8230 - MAE: 2.4173\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7633/20000 - Train Loss: 1.9794 - Test Loss: 9.8202 - MSE: 9.8202 - MAE: 2.4169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7634/20000 - Train Loss: 1.9780 - Test Loss: 9.8175 - MSE: 9.8175 - MAE: 2.4165\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7635/20000 - Train Loss: 1.9766 - Test Loss: 9.8146 - MSE: 9.8146 - MAE: 2.4161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7636/20000 - Train Loss: 1.9753 - Test Loss: 9.8118 - MSE: 9.8118 - MAE: 2.4158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7637/20000 - Train Loss: 1.9739 - Test Loss: 9.8091 - MSE: 9.8091 - MAE: 2.4154\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7638/20000 - Train Loss: 1.9725 - Test Loss: 9.8062 - MSE: 9.8062 - MAE: 2.4150\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7639/20000 - Train Loss: 1.9711 - Test Loss: 9.8035 - MSE: 9.8035 - MAE: 2.4146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7640/20000 - Train Loss: 1.9697 - Test Loss: 9.8007 - MSE: 9.8007 - MAE: 2.4142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7641/20000 - Train Loss: 1.9684 - Test Loss: 9.7979 - MSE: 9.7979 - MAE: 2.4139\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 7642/20000 - Train Loss: 1.9670 - Test Loss: 9.7951 - MSE: 9.7951 - MAE: 2.4135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7643/20000 - Train Loss: 1.9656 - Test Loss: 9.7924 - MSE: 9.7924 - MAE: 2.4131\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 7644/20000 - Train Loss: 1.9642 - Test Loss: 9.7896 - MSE: 9.7896 - MAE: 2.4127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7645/20000 - Train Loss: 1.9629 - Test Loss: 9.7868 - MSE: 9.7868 - MAE: 2.4123\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7646/20000 - Train Loss: 1.9615 - Test Loss: 9.7840 - MSE: 9.7840 - MAE: 2.4120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7647/20000 - Train Loss: 1.9601 - Test Loss: 9.7812 - MSE: 9.7812 - MAE: 2.4116\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7648/20000 - Train Loss: 1.9588 - Test Loss: 9.7785 - MSE: 9.7785 - MAE: 2.4112\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7649/20000 - Train Loss: 1.9574 - Test Loss: 9.7757 - MSE: 9.7757 - MAE: 2.4108\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7650/20000 - Train Loss: 1.9560 - Test Loss: 9.7730 - MSE: 9.7730 - MAE: 2.4104\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7651/20000 - Train Loss: 1.9547 - Test Loss: 9.7702 - MSE: 9.7702 - MAE: 2.4101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7652/20000 - Train Loss: 1.9533 - Test Loss: 9.7675 - MSE: 9.7675 - MAE: 2.4097\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7653/20000 - Train Loss: 1.9520 - Test Loss: 9.7647 - MSE: 9.7647 - MAE: 2.4093\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7654/20000 - Train Loss: 1.9506 - Test Loss: 9.7619 - MSE: 9.7619 - MAE: 2.4089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7655/20000 - Train Loss: 1.9492 - Test Loss: 9.7592 - MSE: 9.7592 - MAE: 2.4085\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7656/20000 - Train Loss: 1.9479 - Test Loss: 9.7565 - MSE: 9.7565 - MAE: 2.4082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7657/20000 - Train Loss: 1.9465 - Test Loss: 9.7537 - MSE: 9.7537 - MAE: 2.4078\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7658/20000 - Train Loss: 1.9452 - Test Loss: 9.7510 - MSE: 9.7510 - MAE: 2.4074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7659/20000 - Train Loss: 1.9438 - Test Loss: 9.7483 - MSE: 9.7483 - MAE: 2.4070\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7660/20000 - Train Loss: 1.9425 - Test Loss: 9.7456 - MSE: 9.7456 - MAE: 2.4067\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7661/20000 - Train Loss: 1.9411 - Test Loss: 9.7428 - MSE: 9.7428 - MAE: 2.4063\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7662/20000 - Train Loss: 1.9398 - Test Loss: 9.7400 - MSE: 9.7400 - MAE: 2.4059\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7663/20000 - Train Loss: 1.9384 - Test Loss: 9.7373 - MSE: 9.7373 - MAE: 2.4055\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7664/20000 - Train Loss: 1.9371 - Test Loss: 9.7346 - MSE: 9.7346 - MAE: 2.4051\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7665/20000 - Train Loss: 1.9357 - Test Loss: 9.7319 - MSE: 9.7319 - MAE: 2.4048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7666/20000 - Train Loss: 1.9344 - Test Loss: 9.7292 - MSE: 9.7292 - MAE: 2.4044\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7667/20000 - Train Loss: 1.9331 - Test Loss: 9.7264 - MSE: 9.7264 - MAE: 2.4040\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7668/20000 - Train Loss: 1.9317 - Test Loss: 9.7237 - MSE: 9.7237 - MAE: 2.4036\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7669/20000 - Train Loss: 1.9304 - Test Loss: 9.7211 - MSE: 9.7211 - MAE: 2.4033\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7670/20000 - Train Loss: 1.9291 - Test Loss: 9.7184 - MSE: 9.7184 - MAE: 2.4029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7671/20000 - Train Loss: 1.9277 - Test Loss: 9.7156 - MSE: 9.7156 - MAE: 2.4025\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7672/20000 - Train Loss: 1.9264 - Test Loss: 9.7129 - MSE: 9.7129 - MAE: 2.4021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7673/20000 - Train Loss: 1.9250 - Test Loss: 9.7102 - MSE: 9.7102 - MAE: 2.4017\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7674/20000 - Train Loss: 1.9237 - Test Loss: 9.7075 - MSE: 9.7075 - MAE: 2.4014\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7675/20000 - Train Loss: 1.9224 - Test Loss: 9.7049 - MSE: 9.7049 - MAE: 2.4010\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7676/20000 - Train Loss: 1.9211 - Test Loss: 9.7022 - MSE: 9.7022 - MAE: 2.4006\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 7677/20000 - Train Loss: 1.9197 - Test Loss: 9.6995 - MSE: 9.6995 - MAE: 2.4002\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7678/20000 - Train Loss: 1.9184 - Test Loss: 9.6968 - MSE: 9.6968 - MAE: 2.3999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7679/20000 - Train Loss: 1.9171 - Test Loss: 9.6940 - MSE: 9.6940 - MAE: 2.3995\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7680/20000 - Train Loss: 1.9158 - Test Loss: 9.6914 - MSE: 9.6914 - MAE: 2.3991\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7681/20000 - Train Loss: 1.9144 - Test Loss: 9.6888 - MSE: 9.6888 - MAE: 2.3987\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7682/20000 - Train Loss: 1.9131 - Test Loss: 9.6861 - MSE: 9.6861 - MAE: 2.3983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7683/20000 - Train Loss: 1.9118 - Test Loss: 9.6834 - MSE: 9.6834 - MAE: 2.3980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7684/20000 - Train Loss: 1.9105 - Test Loss: 9.6807 - MSE: 9.6807 - MAE: 2.3976\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7685/20000 - Train Loss: 1.9092 - Test Loss: 9.6780 - MSE: 9.6780 - MAE: 2.3972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7686/20000 - Train Loss: 1.9079 - Test Loss: 9.6753 - MSE: 9.6753 - MAE: 2.3968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7687/20000 - Train Loss: 1.9065 - Test Loss: 9.6727 - MSE: 9.6727 - MAE: 2.3965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7688/20000 - Train Loss: 1.9052 - Test Loss: 9.6701 - MSE: 9.6701 - MAE: 2.3961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7689/20000 - Train Loss: 1.9039 - Test Loss: 9.6675 - MSE: 9.6675 - MAE: 2.3957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7690/20000 - Train Loss: 1.9026 - Test Loss: 9.6648 - MSE: 9.6648 - MAE: 2.3953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7691/20000 - Train Loss: 1.9013 - Test Loss: 9.6621 - MSE: 9.6621 - MAE: 2.3950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7692/20000 - Train Loss: 1.9000 - Test Loss: 9.6594 - MSE: 9.6594 - MAE: 2.3946\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7693/20000 - Train Loss: 1.8987 - Test Loss: 9.6567 - MSE: 9.6567 - MAE: 2.3942\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7694/20000 - Train Loss: 1.8974 - Test Loss: 9.6541 - MSE: 9.6541 - MAE: 2.3938\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7695/20000 - Train Loss: 1.8961 - Test Loss: 9.6515 - MSE: 9.6515 - MAE: 2.3935\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7696/20000 - Train Loss: 1.8948 - Test Loss: 9.6489 - MSE: 9.6489 - MAE: 2.3931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7697/20000 - Train Loss: 1.8935 - Test Loss: 9.6463 - MSE: 9.6463 - MAE: 2.3927\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7698/20000 - Train Loss: 1.8922 - Test Loss: 9.6436 - MSE: 9.6436 - MAE: 2.3923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7699/20000 - Train Loss: 1.8909 - Test Loss: 9.6409 - MSE: 9.6409 - MAE: 2.3919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7700/20000 - Train Loss: 1.8896 - Test Loss: 9.6383 - MSE: 9.6383 - MAE: 2.3916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7701/20000 - Train Loss: 1.8883 - Test Loss: 9.6357 - MSE: 9.6357 - MAE: 2.3912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7702/20000 - Train Loss: 1.8870 - Test Loss: 9.6331 - MSE: 9.6331 - MAE: 2.3908\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7703/20000 - Train Loss: 1.8857 - Test Loss: 9.6305 - MSE: 9.6305 - MAE: 2.3904\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7704/20000 - Train Loss: 1.8844 - Test Loss: 9.6279 - MSE: 9.6279 - MAE: 2.3901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7705/20000 - Train Loss: 1.8831 - Test Loss: 9.6252 - MSE: 9.6252 - MAE: 2.3897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7706/20000 - Train Loss: 1.8818 - Test Loss: 9.6226 - MSE: 9.6226 - MAE: 2.3893\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7707/20000 - Train Loss: 1.8806 - Test Loss: 9.6200 - MSE: 9.6200 - MAE: 2.3889\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7708/20000 - Train Loss: 1.8793 - Test Loss: 9.6174 - MSE: 9.6175 - MAE: 2.3886\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7709/20000 - Train Loss: 1.8780 - Test Loss: 9.6148 - MSE: 9.6148 - MAE: 2.3882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7710/20000 - Train Loss: 1.8767 - Test Loss: 9.6122 - MSE: 9.6122 - MAE: 2.3878\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7711/20000 - Train Loss: 1.8754 - Test Loss: 9.6096 - MSE: 9.6096 - MAE: 2.3874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7712/20000 - Train Loss: 1.8741 - Test Loss: 9.6070 - MSE: 9.6070 - MAE: 2.3871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7713/20000 - Train Loss: 1.8729 - Test Loss: 9.6044 - MSE: 9.6044 - MAE: 2.3867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7714/20000 - Train Loss: 1.8716 - Test Loss: 9.6018 - MSE: 9.6018 - MAE: 2.3863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7715/20000 - Train Loss: 1.8703 - Test Loss: 9.5992 - MSE: 9.5992 - MAE: 2.3859\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7716/20000 - Train Loss: 1.8690 - Test Loss: 9.5966 - MSE: 9.5966 - MAE: 2.3856\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7717/20000 - Train Loss: 1.8678 - Test Loss: 9.5941 - MSE: 9.5941 - MAE: 2.3852\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7718/20000 - Train Loss: 1.8665 - Test Loss: 9.5915 - MSE: 9.5915 - MAE: 2.3848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7719/20000 - Train Loss: 1.8652 - Test Loss: 9.5889 - MSE: 9.5889 - MAE: 2.3844\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7720/20000 - Train Loss: 1.8639 - Test Loss: 9.5863 - MSE: 9.5863 - MAE: 2.3841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7721/20000 - Train Loss: 1.8627 - Test Loss: 9.5838 - MSE: 9.5838 - MAE: 2.3837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7722/20000 - Train Loss: 1.8614 - Test Loss: 9.5812 - MSE: 9.5812 - MAE: 2.3833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7723/20000 - Train Loss: 1.8601 - Test Loss: 9.5786 - MSE: 9.5786 - MAE: 2.3829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7724/20000 - Train Loss: 1.8589 - Test Loss: 9.5760 - MSE: 9.5760 - MAE: 2.3826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7725/20000 - Train Loss: 1.8576 - Test Loss: 9.5734 - MSE: 9.5734 - MAE: 2.3822\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 7726/20000 - Train Loss: 1.8564 - Test Loss: 9.5709 - MSE: 9.5709 - MAE: 2.3818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7727/20000 - Train Loss: 1.8551 - Test Loss: 9.5684 - MSE: 9.5684 - MAE: 2.3814\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7728/20000 - Train Loss: 1.8538 - Test Loss: 9.5658 - MSE: 9.5658 - MAE: 2.3811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7729/20000 - Train Loss: 1.8526 - Test Loss: 9.5633 - MSE: 9.5633 - MAE: 2.3807\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7730/20000 - Train Loss: 1.8513 - Test Loss: 9.5607 - MSE: 9.5607 - MAE: 2.3803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7731/20000 - Train Loss: 1.8501 - Test Loss: 9.5581 - MSE: 9.5581 - MAE: 2.3799\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7732/20000 - Train Loss: 1.8488 - Test Loss: 9.5555 - MSE: 9.5555 - MAE: 2.3796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7733/20000 - Train Loss: 1.8476 - Test Loss: 9.5530 - MSE: 9.5530 - MAE: 2.3792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7734/20000 - Train Loss: 1.8463 - Test Loss: 9.5505 - MSE: 9.5505 - MAE: 2.3788\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7735/20000 - Train Loss: 1.8451 - Test Loss: 9.5480 - MSE: 9.5480 - MAE: 2.3785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7736/20000 - Train Loss: 1.8438 - Test Loss: 9.5455 - MSE: 9.5455 - MAE: 2.3781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7737/20000 - Train Loss: 1.8426 - Test Loss: 9.5429 - MSE: 9.5429 - MAE: 2.3777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7738/20000 - Train Loss: 1.8413 - Test Loss: 9.5403 - MSE: 9.5403 - MAE: 2.3773\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7739/20000 - Train Loss: 1.8401 - Test Loss: 9.5378 - MSE: 9.5378 - MAE: 2.3769\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7740/20000 - Train Loss: 1.8388 - Test Loss: 9.5353 - MSE: 9.5353 - MAE: 2.3766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7741/20000 - Train Loss: 1.8376 - Test Loss: 9.5328 - MSE: 9.5328 - MAE: 2.3762\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7742/20000 - Train Loss: 1.8364 - Test Loss: 9.5303 - MSE: 9.5303 - MAE: 2.3758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7743/20000 - Train Loss: 1.8351 - Test Loss: 9.5277 - MSE: 9.5277 - MAE: 2.3755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7744/20000 - Train Loss: 1.8339 - Test Loss: 9.5252 - MSE: 9.5252 - MAE: 2.3751\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7745/20000 - Train Loss: 1.8327 - Test Loss: 9.5226 - MSE: 9.5226 - MAE: 2.3747\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7746/20000 - Train Loss: 1.8314 - Test Loss: 9.5202 - MSE: 9.5202 - MAE: 2.3743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7747/20000 - Train Loss: 1.8302 - Test Loss: 9.5177 - MSE: 9.5177 - MAE: 2.3740\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7748/20000 - Train Loss: 1.8289 - Test Loss: 9.5152 - MSE: 9.5152 - MAE: 2.3736\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7749/20000 - Train Loss: 1.8277 - Test Loss: 9.5127 - MSE: 9.5127 - MAE: 2.3732\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7750/20000 - Train Loss: 1.8265 - Test Loss: 9.5102 - MSE: 9.5102 - MAE: 2.3728\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7751/20000 - Train Loss: 1.8253 - Test Loss: 9.5076 - MSE: 9.5076 - MAE: 2.3725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7752/20000 - Train Loss: 1.8240 - Test Loss: 9.5051 - MSE: 9.5051 - MAE: 2.3721\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7753/20000 - Train Loss: 1.8228 - Test Loss: 9.5027 - MSE: 9.5027 - MAE: 2.3717\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7754/20000 - Train Loss: 1.8216 - Test Loss: 9.5002 - MSE: 9.5002 - MAE: 2.3714\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7755/20000 - Train Loss: 1.8204 - Test Loss: 9.4977 - MSE: 9.4977 - MAE: 2.3710\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7756/20000 - Train Loss: 1.8191 - Test Loss: 9.4952 - MSE: 9.4952 - MAE: 2.3706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7757/20000 - Train Loss: 1.8179 - Test Loss: 9.4927 - MSE: 9.4927 - MAE: 2.3702\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 7758/20000 - Train Loss: 1.8167 - Test Loss: 9.4902 - MSE: 9.4902 - MAE: 2.3699\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7759/20000 - Train Loss: 1.8155 - Test Loss: 9.4878 - MSE: 9.4878 - MAE: 2.3695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7760/20000 - Train Loss: 1.8143 - Test Loss: 9.4853 - MSE: 9.4853 - MAE: 2.3691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7761/20000 - Train Loss: 1.8130 - Test Loss: 9.4828 - MSE: 9.4828 - MAE: 2.3687\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7762/20000 - Train Loss: 1.8118 - Test Loss: 9.4803 - MSE: 9.4803 - MAE: 2.3684\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7763/20000 - Train Loss: 1.8106 - Test Loss: 9.4778 - MSE: 9.4778 - MAE: 2.3680\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7764/20000 - Train Loss: 1.8094 - Test Loss: 9.4754 - MSE: 9.4754 - MAE: 2.3676\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7765/20000 - Train Loss: 1.8082 - Test Loss: 9.4730 - MSE: 9.4730 - MAE: 2.3673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7766/20000 - Train Loss: 1.8070 - Test Loss: 9.4705 - MSE: 9.4705 - MAE: 2.3669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7767/20000 - Train Loss: 1.8058 - Test Loss: 9.4680 - MSE: 9.4680 - MAE: 2.3665\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7768/20000 - Train Loss: 1.8046 - Test Loss: 9.4655 - MSE: 9.4655 - MAE: 2.3661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7769/20000 - Train Loss: 1.8034 - Test Loss: 9.4631 - MSE: 9.4631 - MAE: 2.3658\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7770/20000 - Train Loss: 1.8022 - Test Loss: 9.4606 - MSE: 9.4606 - MAE: 2.3654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7771/20000 - Train Loss: 1.8010 - Test Loss: 9.4582 - MSE: 9.4582 - MAE: 2.3650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7772/20000 - Train Loss: 1.7998 - Test Loss: 9.4558 - MSE: 9.4558 - MAE: 2.3647\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7773/20000 - Train Loss: 1.7986 - Test Loss: 9.4533 - MSE: 9.4533 - MAE: 2.3643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7774/20000 - Train Loss: 1.7974 - Test Loss: 9.4508 - MSE: 9.4508 - MAE: 2.3639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7775/20000 - Train Loss: 1.7962 - Test Loss: 9.4484 - MSE: 9.4484 - MAE: 2.3635\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7776/20000 - Train Loss: 1.7950 - Test Loss: 9.4460 - MSE: 9.4460 - MAE: 2.3632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7777/20000 - Train Loss: 1.7938 - Test Loss: 9.4436 - MSE: 9.4436 - MAE: 2.3628\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7778/20000 - Train Loss: 1.7926 - Test Loss: 9.4411 - MSE: 9.4411 - MAE: 2.3624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7779/20000 - Train Loss: 1.7914 - Test Loss: 9.4387 - MSE: 9.4387 - MAE: 2.3621\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7780/20000 - Train Loss: 1.7902 - Test Loss: 9.4362 - MSE: 9.4362 - MAE: 2.3617\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7781/20000 - Train Loss: 1.7890 - Test Loss: 9.4338 - MSE: 9.4338 - MAE: 2.3613\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7782/20000 - Train Loss: 1.7878 - Test Loss: 9.4314 - MSE: 9.4314 - MAE: 2.3609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7783/20000 - Train Loss: 1.7866 - Test Loss: 9.4290 - MSE: 9.4290 - MAE: 2.3606\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7784/20000 - Train Loss: 1.7855 - Test Loss: 9.4266 - MSE: 9.4266 - MAE: 2.3602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7785/20000 - Train Loss: 1.7843 - Test Loss: 9.4242 - MSE: 9.4242 - MAE: 2.3598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7786/20000 - Train Loss: 1.7831 - Test Loss: 9.4217 - MSE: 9.4217 - MAE: 2.3595\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7787/20000 - Train Loss: 1.7819 - Test Loss: 9.4193 - MSE: 9.4193 - MAE: 2.3591\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 7788/20000 - Train Loss: 1.7807 - Test Loss: 9.4169 - MSE: 9.4169 - MAE: 2.3587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7789/20000 - Train Loss: 1.7795 - Test Loss: 9.4145 - MSE: 9.4145 - MAE: 2.3584\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7790/20000 - Train Loss: 1.7784 - Test Loss: 9.4121 - MSE: 9.4121 - MAE: 2.3580\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7791/20000 - Train Loss: 1.7772 - Test Loss: 9.4097 - MSE: 9.4097 - MAE: 2.3576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7792/20000 - Train Loss: 1.7760 - Test Loss: 9.4073 - MSE: 9.4073 - MAE: 2.3572\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7793/20000 - Train Loss: 1.7748 - Test Loss: 9.4049 - MSE: 9.4049 - MAE: 2.3569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7794/20000 - Train Loss: 1.7737 - Test Loss: 9.4025 - MSE: 9.4025 - MAE: 2.3565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7795/20000 - Train Loss: 1.7725 - Test Loss: 9.4001 - MSE: 9.4001 - MAE: 2.3561\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7796/20000 - Train Loss: 1.7713 - Test Loss: 9.3977 - MSE: 9.3977 - MAE: 2.3558\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7797/20000 - Train Loss: 1.7702 - Test Loss: 9.3953 - MSE: 9.3953 - MAE: 2.3554\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7798/20000 - Train Loss: 1.7690 - Test Loss: 9.3930 - MSE: 9.3930 - MAE: 2.3550\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7799/20000 - Train Loss: 1.7678 - Test Loss: 9.3906 - MSE: 9.3906 - MAE: 2.3547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7800/20000 - Train Loss: 1.7667 - Test Loss: 9.3882 - MSE: 9.3882 - MAE: 2.3543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7801/20000 - Train Loss: 1.7655 - Test Loss: 9.3858 - MSE: 9.3858 - MAE: 2.3539\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7802/20000 - Train Loss: 1.7643 - Test Loss: 9.3834 - MSE: 9.3834 - MAE: 2.3535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7803/20000 - Train Loss: 1.7632 - Test Loss: 9.3811 - MSE: 9.3811 - MAE: 2.3532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7804/20000 - Train Loss: 1.7620 - Test Loss: 9.3788 - MSE: 9.3788 - MAE: 2.3528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7805/20000 - Train Loss: 1.7608 - Test Loss: 9.3764 - MSE: 9.3764 - MAE: 2.3524\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7806/20000 - Train Loss: 1.7597 - Test Loss: 9.3740 - MSE: 9.3740 - MAE: 2.3521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7807/20000 - Train Loss: 1.7585 - Test Loss: 9.3716 - MSE: 9.3716 - MAE: 2.3517\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7808/20000 - Train Loss: 1.7574 - Test Loss: 9.3692 - MSE: 9.3692 - MAE: 2.3513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7809/20000 - Train Loss: 1.7562 - Test Loss: 9.3669 - MSE: 9.3669 - MAE: 2.3510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7810/20000 - Train Loss: 1.7551 - Test Loss: 9.3646 - MSE: 9.3646 - MAE: 2.3506\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 7811/20000 - Train Loss: 1.7539 - Test Loss: 9.3622 - MSE: 9.3622 - MAE: 2.3502\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7812/20000 - Train Loss: 1.7528 - Test Loss: 9.3598 - MSE: 9.3598 - MAE: 2.3499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7813/20000 - Train Loss: 1.7516 - Test Loss: 9.3575 - MSE: 9.3575 - MAE: 2.3495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7814/20000 - Train Loss: 1.7505 - Test Loss: 9.3551 - MSE: 9.3551 - MAE: 2.3491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7815/20000 - Train Loss: 1.7493 - Test Loss: 9.3528 - MSE: 9.3528 - MAE: 2.3488\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7816/20000 - Train Loss: 1.7482 - Test Loss: 9.3505 - MSE: 9.3505 - MAE: 2.3484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7817/20000 - Train Loss: 1.7470 - Test Loss: 9.3481 - MSE: 9.3481 - MAE: 2.3480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7818/20000 - Train Loss: 1.7459 - Test Loss: 9.3458 - MSE: 9.3458 - MAE: 2.3476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7819/20000 - Train Loss: 1.7448 - Test Loss: 9.3434 - MSE: 9.3434 - MAE: 2.3473\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7820/20000 - Train Loss: 1.7436 - Test Loss: 9.3411 - MSE: 9.3411 - MAE: 2.3469\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7821/20000 - Train Loss: 1.7425 - Test Loss: 9.3388 - MSE: 9.3388 - MAE: 2.3465\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7822/20000 - Train Loss: 1.7413 - Test Loss: 9.3365 - MSE: 9.3365 - MAE: 2.3462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7823/20000 - Train Loss: 1.7402 - Test Loss: 9.3341 - MSE: 9.3341 - MAE: 2.3458\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 7824/20000 - Train Loss: 1.7391 - Test Loss: 9.3318 - MSE: 9.3318 - MAE: 2.3454\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7825/20000 - Train Loss: 1.7379 - Test Loss: 9.3295 - MSE: 9.3295 - MAE: 2.3451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7826/20000 - Train Loss: 1.7368 - Test Loss: 9.3271 - MSE: 9.3271 - MAE: 2.3447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7827/20000 - Train Loss: 1.7357 - Test Loss: 9.3248 - MSE: 9.3248 - MAE: 2.3443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7828/20000 - Train Loss: 1.7345 - Test Loss: 9.3225 - MSE: 9.3225 - MAE: 2.3440\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7829/20000 - Train Loss: 1.7334 - Test Loss: 9.3202 - MSE: 9.3202 - MAE: 2.3436\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7830/20000 - Train Loss: 1.7323 - Test Loss: 9.3179 - MSE: 9.3179 - MAE: 2.3432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7831/20000 - Train Loss: 1.7312 - Test Loss: 9.3156 - MSE: 9.3156 - MAE: 2.3429\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 7832/20000 - Train Loss: 1.7300 - Test Loss: 9.3133 - MSE: 9.3133 - MAE: 2.3425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7833/20000 - Train Loss: 1.7289 - Test Loss: 9.3110 - MSE: 9.3110 - MAE: 2.3421\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7834/20000 - Train Loss: 1.7278 - Test Loss: 9.3087 - MSE: 9.3087 - MAE: 2.3418\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7835/20000 - Train Loss: 1.7267 - Test Loss: 9.3064 - MSE: 9.3064 - MAE: 2.3414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7836/20000 - Train Loss: 1.7255 - Test Loss: 9.3041 - MSE: 9.3041 - MAE: 2.3410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7837/20000 - Train Loss: 1.7244 - Test Loss: 9.3018 - MSE: 9.3018 - MAE: 2.3407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7838/20000 - Train Loss: 1.7233 - Test Loss: 9.2995 - MSE: 9.2995 - MAE: 2.3403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7839/20000 - Train Loss: 1.7222 - Test Loss: 9.2972 - MSE: 9.2972 - MAE: 2.3399\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7840/20000 - Train Loss: 1.7211 - Test Loss: 9.2949 - MSE: 9.2949 - MAE: 2.3396\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7841/20000 - Train Loss: 1.7200 - Test Loss: 9.2927 - MSE: 9.2927 - MAE: 2.3393\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7842/20000 - Train Loss: 1.7188 - Test Loss: 9.2904 - MSE: 9.2904 - MAE: 2.3389\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7843/20000 - Train Loss: 1.7177 - Test Loss: 9.2881 - MSE: 9.2881 - MAE: 2.3386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7844/20000 - Train Loss: 1.7166 - Test Loss: 9.2858 - MSE: 9.2858 - MAE: 2.3383\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7845/20000 - Train Loss: 1.7155 - Test Loss: 9.2836 - MSE: 9.2836 - MAE: 2.3380\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7846/20000 - Train Loss: 1.7144 - Test Loss: 9.2813 - MSE: 9.2813 - MAE: 2.3377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7847/20000 - Train Loss: 1.7133 - Test Loss: 9.2790 - MSE: 9.2790 - MAE: 2.3374\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7848/20000 - Train Loss: 1.7122 - Test Loss: 9.2767 - MSE: 9.2767 - MAE: 2.3370\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7849/20000 - Train Loss: 1.7111 - Test Loss: 9.2744 - MSE: 9.2744 - MAE: 2.3367\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7850/20000 - Train Loss: 1.7100 - Test Loss: 9.2722 - MSE: 9.2722 - MAE: 2.3364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7851/20000 - Train Loss: 1.7089 - Test Loss: 9.2700 - MSE: 9.2700 - MAE: 2.3361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7852/20000 - Train Loss: 1.7078 - Test Loss: 9.2677 - MSE: 9.2677 - MAE: 2.3358\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 7853/20000 - Train Loss: 1.7067 - Test Loss: 9.2654 - MSE: 9.2655 - MAE: 2.3354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7854/20000 - Train Loss: 1.7056 - Test Loss: 9.2631 - MSE: 9.2631 - MAE: 2.3351\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 7855/20000 - Train Loss: 1.7045 - Test Loss: 9.2608 - MSE: 9.2608 - MAE: 2.3348\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7856/20000 - Train Loss: 1.7034 - Test Loss: 9.2586 - MSE: 9.2586 - MAE: 2.3345\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7857/20000 - Train Loss: 1.7023 - Test Loss: 9.2564 - MSE: 9.2564 - MAE: 2.3342\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7858/20000 - Train Loss: 1.7012 - Test Loss: 9.2542 - MSE: 9.2542 - MAE: 2.3339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7859/20000 - Train Loss: 1.7001 - Test Loss: 9.2520 - MSE: 9.2520 - MAE: 2.3335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7860/20000 - Train Loss: 1.6990 - Test Loss: 9.2497 - MSE: 9.2497 - MAE: 2.3332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7861/20000 - Train Loss: 1.6979 - Test Loss: 9.2474 - MSE: 9.2474 - MAE: 2.3329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7862/20000 - Train Loss: 1.6968 - Test Loss: 9.2452 - MSE: 9.2452 - MAE: 2.3326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7863/20000 - Train Loss: 1.6958 - Test Loss: 9.2430 - MSE: 9.2430 - MAE: 2.3323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7864/20000 - Train Loss: 1.6947 - Test Loss: 9.2407 - MSE: 9.2407 - MAE: 2.3319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7865/20000 - Train Loss: 1.6936 - Test Loss: 9.2385 - MSE: 9.2385 - MAE: 2.3316\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7866/20000 - Train Loss: 1.6925 - Test Loss: 9.2363 - MSE: 9.2363 - MAE: 2.3313\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7867/20000 - Train Loss: 1.6914 - Test Loss: 9.2340 - MSE: 9.2340 - MAE: 2.3310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7868/20000 - Train Loss: 1.6903 - Test Loss: 9.2318 - MSE: 9.2318 - MAE: 2.3307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7869/20000 - Train Loss: 1.6893 - Test Loss: 9.2296 - MSE: 9.2296 - MAE: 2.3303\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7870/20000 - Train Loss: 1.6882 - Test Loss: 9.2274 - MSE: 9.2274 - MAE: 2.3300\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7871/20000 - Train Loss: 1.6871 - Test Loss: 9.2252 - MSE: 9.2252 - MAE: 2.3297\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7872/20000 - Train Loss: 1.6860 - Test Loss: 9.2230 - MSE: 9.2230 - MAE: 2.3294\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7873/20000 - Train Loss: 1.6850 - Test Loss: 9.2207 - MSE: 9.2207 - MAE: 2.3291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7874/20000 - Train Loss: 1.6839 - Test Loss: 9.2185 - MSE: 9.2185 - MAE: 2.3288\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7875/20000 - Train Loss: 1.6828 - Test Loss: 9.2163 - MSE: 9.2163 - MAE: 2.3284\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7876/20000 - Train Loss: 1.6817 - Test Loss: 9.2141 - MSE: 9.2141 - MAE: 2.3281\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7877/20000 - Train Loss: 1.6807 - Test Loss: 9.2120 - MSE: 9.2120 - MAE: 2.3278\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7878/20000 - Train Loss: 1.6796 - Test Loss: 9.2098 - MSE: 9.2098 - MAE: 2.3275\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7879/20000 - Train Loss: 1.6785 - Test Loss: 9.2075 - MSE: 9.2075 - MAE: 2.3272\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7880/20000 - Train Loss: 1.6775 - Test Loss: 9.2053 - MSE: 9.2053 - MAE: 2.3268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7881/20000 - Train Loss: 1.6764 - Test Loss: 9.2031 - MSE: 9.2031 - MAE: 2.3265\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7882/20000 - Train Loss: 1.6753 - Test Loss: 9.2009 - MSE: 9.2009 - MAE: 2.3262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7883/20000 - Train Loss: 1.6743 - Test Loss: 9.1988 - MSE: 9.1988 - MAE: 2.3259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7884/20000 - Train Loss: 1.6732 - Test Loss: 9.1966 - MSE: 9.1966 - MAE: 2.3256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7885/20000 - Train Loss: 1.6722 - Test Loss: 9.1944 - MSE: 9.1944 - MAE: 2.3253\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7886/20000 - Train Loss: 1.6711 - Test Loss: 9.1922 - MSE: 9.1922 - MAE: 2.3249\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7887/20000 - Train Loss: 1.6700 - Test Loss: 9.1900 - MSE: 9.1900 - MAE: 2.3246\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 7888/20000 - Train Loss: 1.6690 - Test Loss: 9.1878 - MSE: 9.1878 - MAE: 2.3243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7889/20000 - Train Loss: 1.6679 - Test Loss: 9.1856 - MSE: 9.1856 - MAE: 2.3240\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 7890/20000 - Train Loss: 1.6669 - Test Loss: 9.1835 - MSE: 9.1835 - MAE: 2.3237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7891/20000 - Train Loss: 1.6658 - Test Loss: 9.1813 - MSE: 9.1813 - MAE: 2.3234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7892/20000 - Train Loss: 1.6648 - Test Loss: 9.1792 - MSE: 9.1792 - MAE: 2.3231\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 7893/20000 - Train Loss: 1.6637 - Test Loss: 9.1770 - MSE: 9.1770 - MAE: 2.3227\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7894/20000 - Train Loss: 1.6627 - Test Loss: 9.1748 - MSE: 9.1748 - MAE: 2.3224\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7895/20000 - Train Loss: 1.6616 - Test Loss: 9.1726 - MSE: 9.1726 - MAE: 2.3221\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7896/20000 - Train Loss: 1.6606 - Test Loss: 9.1705 - MSE: 9.1705 - MAE: 2.3218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7897/20000 - Train Loss: 1.6595 - Test Loss: 9.1683 - MSE: 9.1683 - MAE: 2.3215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7898/20000 - Train Loss: 1.6585 - Test Loss: 9.1662 - MSE: 9.1662 - MAE: 2.3211\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7899/20000 - Train Loss: 1.6574 - Test Loss: 9.1640 - MSE: 9.1640 - MAE: 2.3208\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7900/20000 - Train Loss: 1.6564 - Test Loss: 9.1618 - MSE: 9.1618 - MAE: 2.3205\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 7901/20000 - Train Loss: 1.6553 - Test Loss: 9.1597 - MSE: 9.1597 - MAE: 2.3202\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7902/20000 - Train Loss: 1.6543 - Test Loss: 9.1576 - MSE: 9.1576 - MAE: 2.3199\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7903/20000 - Train Loss: 1.6533 - Test Loss: 9.1554 - MSE: 9.1554 - MAE: 2.3196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7904/20000 - Train Loss: 1.6522 - Test Loss: 9.1532 - MSE: 9.1532 - MAE: 2.3192\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7905/20000 - Train Loss: 1.6512 - Test Loss: 9.1511 - MSE: 9.1511 - MAE: 2.3189\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7906/20000 - Train Loss: 1.6502 - Test Loss: 9.1490 - MSE: 9.1490 - MAE: 2.3186\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7907/20000 - Train Loss: 1.6491 - Test Loss: 9.1469 - MSE: 9.1469 - MAE: 2.3183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7908/20000 - Train Loss: 1.6481 - Test Loss: 9.1447 - MSE: 9.1447 - MAE: 2.3180\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7909/20000 - Train Loss: 1.6471 - Test Loss: 9.1426 - MSE: 9.1426 - MAE: 2.3177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7910/20000 - Train Loss: 1.6460 - Test Loss: 9.1404 - MSE: 9.1404 - MAE: 2.3173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7911/20000 - Train Loss: 1.6450 - Test Loss: 9.1383 - MSE: 9.1383 - MAE: 2.3170\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7912/20000 - Train Loss: 1.6440 - Test Loss: 9.1362 - MSE: 9.1362 - MAE: 2.3167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7913/20000 - Train Loss: 1.6429 - Test Loss: 9.1341 - MSE: 9.1341 - MAE: 2.3164\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7914/20000 - Train Loss: 1.6419 - Test Loss: 9.1320 - MSE: 9.1320 - MAE: 2.3161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7915/20000 - Train Loss: 1.6409 - Test Loss: 9.1298 - MSE: 9.1298 - MAE: 2.3158\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 7916/20000 - Train Loss: 1.6399 - Test Loss: 9.1277 - MSE: 9.1277 - MAE: 2.3154\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7917/20000 - Train Loss: 1.6388 - Test Loss: 9.1256 - MSE: 9.1256 - MAE: 2.3151\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7918/20000 - Train Loss: 1.6378 - Test Loss: 9.1235 - MSE: 9.1235 - MAE: 2.3148\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7919/20000 - Train Loss: 1.6368 - Test Loss: 9.1214 - MSE: 9.1214 - MAE: 2.3145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7920/20000 - Train Loss: 1.6358 - Test Loss: 9.1193 - MSE: 9.1193 - MAE: 2.3142\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7921/20000 - Train Loss: 1.6348 - Test Loss: 9.1172 - MSE: 9.1172 - MAE: 2.3139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7922/20000 - Train Loss: 1.6337 - Test Loss: 9.1150 - MSE: 9.1150 - MAE: 2.3135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7923/20000 - Train Loss: 1.6327 - Test Loss: 9.1129 - MSE: 9.1129 - MAE: 2.3132\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7924/20000 - Train Loss: 1.6317 - Test Loss: 9.1108 - MSE: 9.1108 - MAE: 2.3129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7925/20000 - Train Loss: 1.6307 - Test Loss: 9.1088 - MSE: 9.1088 - MAE: 2.3126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7926/20000 - Train Loss: 1.6297 - Test Loss: 9.1067 - MSE: 9.1067 - MAE: 2.3123\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7927/20000 - Train Loss: 1.6287 - Test Loss: 9.1046 - MSE: 9.1046 - MAE: 2.3120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7928/20000 - Train Loss: 1.6277 - Test Loss: 9.1024 - MSE: 9.1024 - MAE: 2.3117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7929/20000 - Train Loss: 1.6267 - Test Loss: 9.1003 - MSE: 9.1003 - MAE: 2.3113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7930/20000 - Train Loss: 1.6257 - Test Loss: 9.0983 - MSE: 9.0983 - MAE: 2.3110\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7931/20000 - Train Loss: 1.6246 - Test Loss: 9.0962 - MSE: 9.0962 - MAE: 2.3107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7932/20000 - Train Loss: 1.6236 - Test Loss: 9.0941 - MSE: 9.0941 - MAE: 2.3104\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7933/20000 - Train Loss: 1.6226 - Test Loss: 9.0920 - MSE: 9.0920 - MAE: 2.3101\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7934/20000 - Train Loss: 1.6216 - Test Loss: 9.0899 - MSE: 9.0899 - MAE: 2.3098\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7935/20000 - Train Loss: 1.6206 - Test Loss: 9.0879 - MSE: 9.0879 - MAE: 2.3094\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7936/20000 - Train Loss: 1.6196 - Test Loss: 9.0858 - MSE: 9.0858 - MAE: 2.3091\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7937/20000 - Train Loss: 1.6186 - Test Loss: 9.0837 - MSE: 9.0837 - MAE: 2.3088\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 7938/20000 - Train Loss: 1.6176 - Test Loss: 9.0817 - MSE: 9.0817 - MAE: 2.3085\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7939/20000 - Train Loss: 1.6166 - Test Loss: 9.0796 - MSE: 9.0796 - MAE: 2.3082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7940/20000 - Train Loss: 1.6156 - Test Loss: 9.0775 - MSE: 9.0775 - MAE: 2.3079\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7941/20000 - Train Loss: 1.6146 - Test Loss: 9.0754 - MSE: 9.0754 - MAE: 2.3076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7942/20000 - Train Loss: 1.6136 - Test Loss: 9.0734 - MSE: 9.0734 - MAE: 2.3072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7943/20000 - Train Loss: 1.6127 - Test Loss: 9.0713 - MSE: 9.0713 - MAE: 2.3069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7944/20000 - Train Loss: 1.6117 - Test Loss: 9.0693 - MSE: 9.0693 - MAE: 2.3066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7945/20000 - Train Loss: 1.6107 - Test Loss: 9.0672 - MSE: 9.0672 - MAE: 2.3063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7946/20000 - Train Loss: 1.6097 - Test Loss: 9.0651 - MSE: 9.0651 - MAE: 2.3060\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 7947/20000 - Train Loss: 1.6087 - Test Loss: 9.0631 - MSE: 9.0631 - MAE: 2.3057\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7948/20000 - Train Loss: 1.6077 - Test Loss: 9.0610 - MSE: 9.0610 - MAE: 2.3054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7949/20000 - Train Loss: 1.6067 - Test Loss: 9.0590 - MSE: 9.0590 - MAE: 2.3050\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7950/20000 - Train Loss: 1.6057 - Test Loss: 9.0570 - MSE: 9.0570 - MAE: 2.3047\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7951/20000 - Train Loss: 1.6048 - Test Loss: 9.0549 - MSE: 9.0549 - MAE: 2.3044\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7952/20000 - Train Loss: 1.6038 - Test Loss: 9.0529 - MSE: 9.0529 - MAE: 2.3041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7953/20000 - Train Loss: 1.6028 - Test Loss: 9.0508 - MSE: 9.0508 - MAE: 2.3038\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Epoch 7954/20000 - Train Loss: 1.6018 - Test Loss: 9.0488 - MSE: 9.0488 - MAE: 2.3035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7955/20000 - Train Loss: 1.6008 - Test Loss: 9.0468 - MSE: 9.0468 - MAE: 2.3032\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 7956/20000 - Train Loss: 1.5999 - Test Loss: 9.0448 - MSE: 9.0448 - MAE: 2.3028\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 7957/20000 - Train Loss: 1.5989 - Test Loss: 9.0427 - MSE: 9.0427 - MAE: 2.3025\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7958/20000 - Train Loss: 1.5979 - Test Loss: 9.0406 - MSE: 9.0406 - MAE: 2.3022\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7959/20000 - Train Loss: 1.5969 - Test Loss: 9.0386 - MSE: 9.0386 - MAE: 2.3019\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7960/20000 - Train Loss: 1.5960 - Test Loss: 9.0366 - MSE: 9.0366 - MAE: 2.3016\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7961/20000 - Train Loss: 1.5950 - Test Loss: 9.0346 - MSE: 9.0346 - MAE: 2.3013\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7962/20000 - Train Loss: 1.5940 - Test Loss: 9.0325 - MSE: 9.0325 - MAE: 2.3010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7963/20000 - Train Loss: 1.5930 - Test Loss: 9.0305 - MSE: 9.0305 - MAE: 2.3006\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7964/20000 - Train Loss: 1.5921 - Test Loss: 9.0285 - MSE: 9.0285 - MAE: 2.3003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7965/20000 - Train Loss: 1.5911 - Test Loss: 9.0265 - MSE: 9.0265 - MAE: 2.3000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7966/20000 - Train Loss: 1.5901 - Test Loss: 9.0245 - MSE: 9.0245 - MAE: 2.2997\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 7967/20000 - Train Loss: 1.5892 - Test Loss: 9.0225 - MSE: 9.0225 - MAE: 2.2994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7968/20000 - Train Loss: 1.5882 - Test Loss: 9.0205 - MSE: 9.0205 - MAE: 2.2991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7969/20000 - Train Loss: 1.5872 - Test Loss: 9.0184 - MSE: 9.0184 - MAE: 2.2988\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7970/20000 - Train Loss: 1.5863 - Test Loss: 9.0164 - MSE: 9.0164 - MAE: 2.2984\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7971/20000 - Train Loss: 1.5853 - Test Loss: 9.0144 - MSE: 9.0144 - MAE: 2.2981\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7972/20000 - Train Loss: 1.5844 - Test Loss: 9.0124 - MSE: 9.0124 - MAE: 2.2978\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7973/20000 - Train Loss: 1.5834 - Test Loss: 9.0104 - MSE: 9.0104 - MAE: 2.2975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7974/20000 - Train Loss: 1.5824 - Test Loss: 9.0085 - MSE: 9.0085 - MAE: 2.2972\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 7975/20000 - Train Loss: 1.5815 - Test Loss: 9.0064 - MSE: 9.0064 - MAE: 2.2969\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7976/20000 - Train Loss: 1.5805 - Test Loss: 9.0044 - MSE: 9.0044 - MAE: 2.2966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7977/20000 - Train Loss: 1.5796 - Test Loss: 9.0024 - MSE: 9.0024 - MAE: 2.2962\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7978/20000 - Train Loss: 1.5786 - Test Loss: 9.0004 - MSE: 9.0004 - MAE: 2.2959\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7979/20000 - Train Loss: 1.5777 - Test Loss: 8.9985 - MSE: 8.9985 - MAE: 2.2956\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 7980/20000 - Train Loss: 1.5767 - Test Loss: 8.9965 - MSE: 8.9965 - MAE: 2.2953\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7981/20000 - Train Loss: 1.5758 - Test Loss: 8.9945 - MSE: 8.9945 - MAE: 2.2950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7982/20000 - Train Loss: 1.5748 - Test Loss: 8.9925 - MSE: 8.9925 - MAE: 2.2947\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7983/20000 - Train Loss: 1.5739 - Test Loss: 8.9905 - MSE: 8.9905 - MAE: 2.2944\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 7984/20000 - Train Loss: 1.5729 - Test Loss: 8.9886 - MSE: 8.9886 - MAE: 2.2941\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 7985/20000 - Train Loss: 1.5720 - Test Loss: 8.9866 - MSE: 8.9866 - MAE: 2.2937\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7986/20000 - Train Loss: 1.5710 - Test Loss: 8.9846 - MSE: 8.9846 - MAE: 2.2934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7987/20000 - Train Loss: 1.5701 - Test Loss: 8.9826 - MSE: 8.9826 - MAE: 2.2931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7988/20000 - Train Loss: 1.5692 - Test Loss: 8.9807 - MSE: 8.9807 - MAE: 2.2928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7989/20000 - Train Loss: 1.5682 - Test Loss: 8.9787 - MSE: 8.9787 - MAE: 2.2925\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7990/20000 - Train Loss: 1.5673 - Test Loss: 8.9767 - MSE: 8.9767 - MAE: 2.2922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7991/20000 - Train Loss: 1.5663 - Test Loss: 8.9747 - MSE: 8.9747 - MAE: 2.2919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7992/20000 - Train Loss: 1.5654 - Test Loss: 8.9728 - MSE: 8.9728 - MAE: 2.2915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7993/20000 - Train Loss: 1.5645 - Test Loss: 8.9709 - MSE: 8.9709 - MAE: 2.2912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7994/20000 - Train Loss: 1.5635 - Test Loss: 8.9689 - MSE: 8.9689 - MAE: 2.2909\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 7995/20000 - Train Loss: 1.5626 - Test Loss: 8.9669 - MSE: 8.9669 - MAE: 2.2906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7996/20000 - Train Loss: 1.5617 - Test Loss: 8.9650 - MSE: 8.9650 - MAE: 2.2903\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 7997/20000 - Train Loss: 1.5607 - Test Loss: 8.9630 - MSE: 8.9630 - MAE: 2.2900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7998/20000 - Train Loss: 1.5598 - Test Loss: 8.9611 - MSE: 8.9611 - MAE: 2.2897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 7999/20000 - Train Loss: 1.5589 - Test Loss: 8.9591 - MSE: 8.9591 - MAE: 2.2894\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8000/20000 - Train Loss: 1.5579 - Test Loss: 8.9571 - MSE: 8.9571 - MAE: 2.2890\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 8001/20000 - Train Loss: 1.5570 - Test Loss: 8.9552 - MSE: 8.9552 - MAE: 2.2887\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8002/20000 - Train Loss: 1.5561 - Test Loss: 8.9533 - MSE: 8.9533 - MAE: 2.2884\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8003/20000 - Train Loss: 1.5552 - Test Loss: 8.9514 - MSE: 8.9514 - MAE: 2.2881\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8004/20000 - Train Loss: 1.5542 - Test Loss: 8.9494 - MSE: 8.9494 - MAE: 2.2878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8005/20000 - Train Loss: 1.5533 - Test Loss: 8.9474 - MSE: 8.9474 - MAE: 2.2875\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8006/20000 - Train Loss: 1.5524 - Test Loss: 8.9455 - MSE: 8.9455 - MAE: 2.2872\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8007/20000 - Train Loss: 1.5515 - Test Loss: 8.9436 - MSE: 8.9436 - MAE: 2.2869\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8008/20000 - Train Loss: 1.5505 - Test Loss: 8.9416 - MSE: 8.9416 - MAE: 2.2865\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8009/20000 - Train Loss: 1.5496 - Test Loss: 8.9397 - MSE: 8.9397 - MAE: 2.2862\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8010/20000 - Train Loss: 1.5487 - Test Loss: 8.9378 - MSE: 8.9378 - MAE: 2.2859\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8011/20000 - Train Loss: 1.5478 - Test Loss: 8.9359 - MSE: 8.9359 - MAE: 2.2856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8012/20000 - Train Loss: 1.5469 - Test Loss: 8.9339 - MSE: 8.9339 - MAE: 2.2853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8013/20000 - Train Loss: 1.5460 - Test Loss: 8.9320 - MSE: 8.9320 - MAE: 2.2850\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8014/20000 - Train Loss: 1.5451 - Test Loss: 8.9301 - MSE: 8.9301 - MAE: 2.2847\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8015/20000 - Train Loss: 1.5441 - Test Loss: 8.9282 - MSE: 8.9282 - MAE: 2.2845\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8016/20000 - Train Loss: 1.5432 - Test Loss: 8.9263 - MSE: 8.9263 - MAE: 2.2842\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8017/20000 - Train Loss: 1.5423 - Test Loss: 8.9244 - MSE: 8.9244 - MAE: 2.2840\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8018/20000 - Train Loss: 1.5414 - Test Loss: 8.9225 - MSE: 8.9225 - MAE: 2.2837\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8019/20000 - Train Loss: 1.5405 - Test Loss: 8.9205 - MSE: 8.9205 - MAE: 2.2834\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8020/20000 - Train Loss: 1.5396 - Test Loss: 8.9186 - MSE: 8.9186 - MAE: 2.2831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8021/20000 - Train Loss: 1.5387 - Test Loss: 8.9167 - MSE: 8.9167 - MAE: 2.2829\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 8022/20000 - Train Loss: 1.5378 - Test Loss: 8.9148 - MSE: 8.9148 - MAE: 2.2826\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8023/20000 - Train Loss: 1.5369 - Test Loss: 8.9129 - MSE: 8.9129 - MAE: 2.2823\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8024/20000 - Train Loss: 1.5360 - Test Loss: 8.9110 - MSE: 8.9110 - MAE: 2.2821\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8025/20000 - Train Loss: 1.5351 - Test Loss: 8.9091 - MSE: 8.9091 - MAE: 2.2818\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8026/20000 - Train Loss: 1.5342 - Test Loss: 8.9072 - MSE: 8.9072 - MAE: 2.2815\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8027/20000 - Train Loss: 1.5333 - Test Loss: 8.9053 - MSE: 8.9053 - MAE: 2.2813\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8028/20000 - Train Loss: 1.5324 - Test Loss: 8.9034 - MSE: 8.9034 - MAE: 2.2810\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8029/20000 - Train Loss: 1.5315 - Test Loss: 8.9015 - MSE: 8.9015 - MAE: 2.2807\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8030/20000 - Train Loss: 1.5306 - Test Loss: 8.8996 - MSE: 8.8996 - MAE: 2.2805\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8031/20000 - Train Loss: 1.5297 - Test Loss: 8.8978 - MSE: 8.8978 - MAE: 2.2802\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8032/20000 - Train Loss: 1.5288 - Test Loss: 8.8959 - MSE: 8.8959 - MAE: 2.2799\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8033/20000 - Train Loss: 1.5279 - Test Loss: 8.8940 - MSE: 8.8940 - MAE: 2.2797\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8034/20000 - Train Loss: 1.5270 - Test Loss: 8.8921 - MSE: 8.8921 - MAE: 2.2794\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8035/20000 - Train Loss: 1.5261 - Test Loss: 8.8902 - MSE: 8.8902 - MAE: 2.2791\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8036/20000 - Train Loss: 1.5252 - Test Loss: 8.8883 - MSE: 8.8883 - MAE: 2.2789\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8037/20000 - Train Loss: 1.5243 - Test Loss: 8.8865 - MSE: 8.8865 - MAE: 2.2786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8038/20000 - Train Loss: 1.5234 - Test Loss: 8.8846 - MSE: 8.8846 - MAE: 2.2783\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8039/20000 - Train Loss: 1.5226 - Test Loss: 8.8827 - MSE: 8.8827 - MAE: 2.2781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8040/20000 - Train Loss: 1.5217 - Test Loss: 8.8809 - MSE: 8.8809 - MAE: 2.2778\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8041/20000 - Train Loss: 1.5208 - Test Loss: 8.8790 - MSE: 8.8790 - MAE: 2.2775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8042/20000 - Train Loss: 1.5199 - Test Loss: 8.8771 - MSE: 8.8771 - MAE: 2.2773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8043/20000 - Train Loss: 1.5190 - Test Loss: 8.8753 - MSE: 8.8753 - MAE: 2.2770\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8044/20000 - Train Loss: 1.5181 - Test Loss: 8.8734 - MSE: 8.8734 - MAE: 2.2767\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8045/20000 - Train Loss: 1.5173 - Test Loss: 8.8715 - MSE: 8.8715 - MAE: 2.2764\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8046/20000 - Train Loss: 1.5164 - Test Loss: 8.8696 - MSE: 8.8696 - MAE: 2.2762\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8047/20000 - Train Loss: 1.5155 - Test Loss: 8.8678 - MSE: 8.8678 - MAE: 2.2759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8048/20000 - Train Loss: 1.5146 - Test Loss: 8.8660 - MSE: 8.8660 - MAE: 2.2756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8049/20000 - Train Loss: 1.5137 - Test Loss: 8.8641 - MSE: 8.8641 - MAE: 2.2754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8050/20000 - Train Loss: 1.5129 - Test Loss: 8.8622 - MSE: 8.8622 - MAE: 2.2751\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8051/20000 - Train Loss: 1.5120 - Test Loss: 8.8604 - MSE: 8.8604 - MAE: 2.2748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8052/20000 - Train Loss: 1.5111 - Test Loss: 8.8585 - MSE: 8.8585 - MAE: 2.2746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8053/20000 - Train Loss: 1.5103 - Test Loss: 8.8567 - MSE: 8.8567 - MAE: 2.2743\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8054/20000 - Train Loss: 1.5094 - Test Loss: 8.8549 - MSE: 8.8549 - MAE: 2.2740\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8055/20000 - Train Loss: 1.5085 - Test Loss: 8.8530 - MSE: 8.8530 - MAE: 2.2738\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8056/20000 - Train Loss: 1.5076 - Test Loss: 8.8512 - MSE: 8.8512 - MAE: 2.2735\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8057/20000 - Train Loss: 1.5068 - Test Loss: 8.8493 - MSE: 8.8493 - MAE: 2.2732\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8058/20000 - Train Loss: 1.5059 - Test Loss: 8.8475 - MSE: 8.8475 - MAE: 2.2730\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8059/20000 - Train Loss: 1.5050 - Test Loss: 8.8457 - MSE: 8.8457 - MAE: 2.2727\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8060/20000 - Train Loss: 1.5042 - Test Loss: 8.8438 - MSE: 8.8438 - MAE: 2.2724\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8061/20000 - Train Loss: 1.5033 - Test Loss: 8.8420 - MSE: 8.8420 - MAE: 2.2722\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 8062/20000 - Train Loss: 1.5025 - Test Loss: 8.8402 - MSE: 8.8402 - MAE: 2.2719\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8063/20000 - Train Loss: 1.5016 - Test Loss: 8.8383 - MSE: 8.8383 - MAE: 2.2716\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8064/20000 - Train Loss: 1.5007 - Test Loss: 8.8365 - MSE: 8.8365 - MAE: 2.2713\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8065/20000 - Train Loss: 1.4999 - Test Loss: 8.8347 - MSE: 8.8347 - MAE: 2.2711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8066/20000 - Train Loss: 1.4990 - Test Loss: 8.8328 - MSE: 8.8328 - MAE: 2.2708\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8067/20000 - Train Loss: 1.4982 - Test Loss: 8.8310 - MSE: 8.8310 - MAE: 2.2706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8068/20000 - Train Loss: 1.4973 - Test Loss: 8.8292 - MSE: 8.8292 - MAE: 2.2703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8069/20000 - Train Loss: 1.4964 - Test Loss: 8.8274 - MSE: 8.8274 - MAE: 2.2700\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8070/20000 - Train Loss: 1.4956 - Test Loss: 8.8256 - MSE: 8.8256 - MAE: 2.2697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8071/20000 - Train Loss: 1.4947 - Test Loss: 8.8238 - MSE: 8.8238 - MAE: 2.2695\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8072/20000 - Train Loss: 1.4939 - Test Loss: 8.8219 - MSE: 8.8219 - MAE: 2.2692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8073/20000 - Train Loss: 1.4930 - Test Loss: 8.8201 - MSE: 8.8201 - MAE: 2.2689\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8074/20000 - Train Loss: 1.4922 - Test Loss: 8.8184 - MSE: 8.8184 - MAE: 2.2687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8075/20000 - Train Loss: 1.4913 - Test Loss: 8.8165 - MSE: 8.8165 - MAE: 2.2684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8076/20000 - Train Loss: 1.4905 - Test Loss: 8.8147 - MSE: 8.8147 - MAE: 2.2681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8077/20000 - Train Loss: 1.4896 - Test Loss: 8.8129 - MSE: 8.8129 - MAE: 2.2679\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8078/20000 - Train Loss: 1.4888 - Test Loss: 8.8111 - MSE: 8.8111 - MAE: 2.2676\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8079/20000 - Train Loss: 1.4879 - Test Loss: 8.8093 - MSE: 8.8093 - MAE: 2.2673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8080/20000 - Train Loss: 1.4871 - Test Loss: 8.8075 - MSE: 8.8075 - MAE: 2.2671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8081/20000 - Train Loss: 1.4863 - Test Loss: 8.8057 - MSE: 8.8057 - MAE: 2.2668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8082/20000 - Train Loss: 1.4854 - Test Loss: 8.8039 - MSE: 8.8039 - MAE: 2.2665\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8083/20000 - Train Loss: 1.4846 - Test Loss: 8.8021 - MSE: 8.8021 - MAE: 2.2663\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8084/20000 - Train Loss: 1.4837 - Test Loss: 8.8004 - MSE: 8.8004 - MAE: 2.2660\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8085/20000 - Train Loss: 1.4829 - Test Loss: 8.7985 - MSE: 8.7985 - MAE: 2.2657\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8086/20000 - Train Loss: 1.4821 - Test Loss: 8.7968 - MSE: 8.7968 - MAE: 2.2655\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8087/20000 - Train Loss: 1.4812 - Test Loss: 8.7950 - MSE: 8.7950 - MAE: 2.2652\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8088/20000 - Train Loss: 1.4804 - Test Loss: 8.7932 - MSE: 8.7932 - MAE: 2.2649\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8089/20000 - Train Loss: 1.4795 - Test Loss: 8.7914 - MSE: 8.7914 - MAE: 2.2647\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8090/20000 - Train Loss: 1.4787 - Test Loss: 8.7896 - MSE: 8.7896 - MAE: 2.2644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8091/20000 - Train Loss: 1.4779 - Test Loss: 8.7878 - MSE: 8.7878 - MAE: 2.2641\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8092/20000 - Train Loss: 1.4770 - Test Loss: 8.7861 - MSE: 8.7861 - MAE: 2.2638\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8093/20000 - Train Loss: 1.4762 - Test Loss: 8.7843 - MSE: 8.7843 - MAE: 2.2636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8094/20000 - Train Loss: 1.4754 - Test Loss: 8.7825 - MSE: 8.7825 - MAE: 2.2633\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8095/20000 - Train Loss: 1.4746 - Test Loss: 8.7808 - MSE: 8.7808 - MAE: 2.2630\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8096/20000 - Train Loss: 1.4737 - Test Loss: 8.7790 - MSE: 8.7790 - MAE: 2.2628\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8097/20000 - Train Loss: 1.4729 - Test Loss: 8.7772 - MSE: 8.7772 - MAE: 2.2625\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8098/20000 - Train Loss: 1.4721 - Test Loss: 8.7754 - MSE: 8.7754 - MAE: 2.2622\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8099/20000 - Train Loss: 1.4712 - Test Loss: 8.7737 - MSE: 8.7737 - MAE: 2.2620\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8100/20000 - Train Loss: 1.4704 - Test Loss: 8.7719 - MSE: 8.7719 - MAE: 2.2617\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8101/20000 - Train Loss: 1.4696 - Test Loss: 8.7701 - MSE: 8.7701 - MAE: 2.2614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8102/20000 - Train Loss: 1.4688 - Test Loss: 8.7684 - MSE: 8.7684 - MAE: 2.2612\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8103/20000 - Train Loss: 1.4680 - Test Loss: 8.7666 - MSE: 8.7666 - MAE: 2.2609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8104/20000 - Train Loss: 1.4671 - Test Loss: 8.7649 - MSE: 8.7649 - MAE: 2.2606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8105/20000 - Train Loss: 1.4663 - Test Loss: 8.7631 - MSE: 8.7631 - MAE: 2.2604\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8106/20000 - Train Loss: 1.4655 - Test Loss: 8.7613 - MSE: 8.7613 - MAE: 2.2601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8107/20000 - Train Loss: 1.4647 - Test Loss: 8.7596 - MSE: 8.7596 - MAE: 2.2598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8108/20000 - Train Loss: 1.4639 - Test Loss: 8.7579 - MSE: 8.7579 - MAE: 2.2596\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8109/20000 - Train Loss: 1.4630 - Test Loss: 8.7561 - MSE: 8.7561 - MAE: 2.2593\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8110/20000 - Train Loss: 1.4622 - Test Loss: 8.7544 - MSE: 8.7544 - MAE: 2.2590\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8111/20000 - Train Loss: 1.4614 - Test Loss: 8.7526 - MSE: 8.7526 - MAE: 2.2588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8112/20000 - Train Loss: 1.4606 - Test Loss: 8.7509 - MSE: 8.7509 - MAE: 2.2585\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8113/20000 - Train Loss: 1.4598 - Test Loss: 8.7491 - MSE: 8.7491 - MAE: 2.2582\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8114/20000 - Train Loss: 1.4590 - Test Loss: 8.7474 - MSE: 8.7474 - MAE: 2.2579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8115/20000 - Train Loss: 1.4582 - Test Loss: 8.7457 - MSE: 8.7457 - MAE: 2.2577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8116/20000 - Train Loss: 1.4574 - Test Loss: 8.7439 - MSE: 8.7439 - MAE: 2.2574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8117/20000 - Train Loss: 1.4566 - Test Loss: 8.7422 - MSE: 8.7422 - MAE: 2.2571\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8118/20000 - Train Loss: 1.4558 - Test Loss: 8.7404 - MSE: 8.7404 - MAE: 2.2569\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8119/20000 - Train Loss: 1.4550 - Test Loss: 8.7387 - MSE: 8.7387 - MAE: 2.2566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8120/20000 - Train Loss: 1.4541 - Test Loss: 8.7370 - MSE: 8.7370 - MAE: 2.2563\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8121/20000 - Train Loss: 1.4533 - Test Loss: 8.7353 - MSE: 8.7353 - MAE: 2.2561\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8122/20000 - Train Loss: 1.4525 - Test Loss: 8.7336 - MSE: 8.7336 - MAE: 2.2558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8123/20000 - Train Loss: 1.4517 - Test Loss: 8.7318 - MSE: 8.7318 - MAE: 2.2555\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8124/20000 - Train Loss: 1.4509 - Test Loss: 8.7301 - MSE: 8.7301 - MAE: 2.2553\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8125/20000 - Train Loss: 1.4501 - Test Loss: 8.7283 - MSE: 8.7283 - MAE: 2.2550\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 8126/20000 - Train Loss: 1.4493 - Test Loss: 8.7266 - MSE: 8.7266 - MAE: 2.2547\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8127/20000 - Train Loss: 1.4485 - Test Loss: 8.7249 - MSE: 8.7249 - MAE: 2.2545\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8128/20000 - Train Loss: 1.4477 - Test Loss: 8.7232 - MSE: 8.7232 - MAE: 2.2542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8129/20000 - Train Loss: 1.4470 - Test Loss: 8.7215 - MSE: 8.7215 - MAE: 2.2539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8130/20000 - Train Loss: 1.4462 - Test Loss: 8.7198 - MSE: 8.7198 - MAE: 2.2537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8131/20000 - Train Loss: 1.4454 - Test Loss: 8.7181 - MSE: 8.7181 - MAE: 2.2534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8132/20000 - Train Loss: 1.4446 - Test Loss: 8.7164 - MSE: 8.7164 - MAE: 2.2531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8133/20000 - Train Loss: 1.4438 - Test Loss: 8.7146 - MSE: 8.7146 - MAE: 2.2528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8134/20000 - Train Loss: 1.4430 - Test Loss: 8.7129 - MSE: 8.7129 - MAE: 2.2526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8135/20000 - Train Loss: 1.4422 - Test Loss: 8.7112 - MSE: 8.7112 - MAE: 2.2523\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8136/20000 - Train Loss: 1.4414 - Test Loss: 8.7095 - MSE: 8.7095 - MAE: 2.2521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8137/20000 - Train Loss: 1.4406 - Test Loss: 8.7078 - MSE: 8.7078 - MAE: 2.2518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8138/20000 - Train Loss: 1.4398 - Test Loss: 8.7061 - MSE: 8.7061 - MAE: 2.2515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8139/20000 - Train Loss: 1.4391 - Test Loss: 8.7044 - MSE: 8.7044 - MAE: 2.2512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8140/20000 - Train Loss: 1.4383 - Test Loss: 8.7028 - MSE: 8.7028 - MAE: 2.2510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8141/20000 - Train Loss: 1.4375 - Test Loss: 8.7011 - MSE: 8.7011 - MAE: 2.2507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8142/20000 - Train Loss: 1.4367 - Test Loss: 8.6994 - MSE: 8.6994 - MAE: 2.2504\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8143/20000 - Train Loss: 1.4359 - Test Loss: 8.6976 - MSE: 8.6976 - MAE: 2.2502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8144/20000 - Train Loss: 1.4351 - Test Loss: 8.6959 - MSE: 8.6959 - MAE: 2.2499\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8145/20000 - Train Loss: 1.4344 - Test Loss: 8.6943 - MSE: 8.6943 - MAE: 2.2496\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8146/20000 - Train Loss: 1.4336 - Test Loss: 8.6926 - MSE: 8.6926 - MAE: 2.2494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8147/20000 - Train Loss: 1.4328 - Test Loss: 8.6909 - MSE: 8.6909 - MAE: 2.2491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8148/20000 - Train Loss: 1.4320 - Test Loss: 8.6892 - MSE: 8.6892 - MAE: 2.2488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8149/20000 - Train Loss: 1.4312 - Test Loss: 8.6875 - MSE: 8.6875 - MAE: 2.2486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8150/20000 - Train Loss: 1.4305 - Test Loss: 8.6858 - MSE: 8.6858 - MAE: 2.2483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8151/20000 - Train Loss: 1.4297 - Test Loss: 8.6842 - MSE: 8.6842 - MAE: 2.2480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8152/20000 - Train Loss: 1.4289 - Test Loss: 8.6825 - MSE: 8.6825 - MAE: 2.2478\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8153/20000 - Train Loss: 1.4282 - Test Loss: 8.6808 - MSE: 8.6808 - MAE: 2.2475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8154/20000 - Train Loss: 1.4274 - Test Loss: 8.6791 - MSE: 8.6791 - MAE: 2.2472\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8155/20000 - Train Loss: 1.4266 - Test Loss: 8.6775 - MSE: 8.6775 - MAE: 2.2469\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8156/20000 - Train Loss: 1.4258 - Test Loss: 8.6758 - MSE: 8.6758 - MAE: 2.2467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8157/20000 - Train Loss: 1.4251 - Test Loss: 8.6742 - MSE: 8.6742 - MAE: 2.2464\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8158/20000 - Train Loss: 1.4243 - Test Loss: 8.6725 - MSE: 8.6725 - MAE: 2.2462\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8159/20000 - Train Loss: 1.4235 - Test Loss: 8.6708 - MSE: 8.6708 - MAE: 2.2459\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8160/20000 - Train Loss: 1.4228 - Test Loss: 8.6691 - MSE: 8.6691 - MAE: 2.2456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8161/20000 - Train Loss: 1.4220 - Test Loss: 8.6675 - MSE: 8.6675 - MAE: 2.2453\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8162/20000 - Train Loss: 1.4212 - Test Loss: 8.6658 - MSE: 8.6658 - MAE: 2.2451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8163/20000 - Train Loss: 1.4205 - Test Loss: 8.6642 - MSE: 8.6642 - MAE: 2.2448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8164/20000 - Train Loss: 1.4197 - Test Loss: 8.6625 - MSE: 8.6625 - MAE: 2.2445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8165/20000 - Train Loss: 1.4190 - Test Loss: 8.6608 - MSE: 8.6608 - MAE: 2.2443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8166/20000 - Train Loss: 1.4182 - Test Loss: 8.6592 - MSE: 8.6592 - MAE: 2.2440\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8167/20000 - Train Loss: 1.4174 - Test Loss: 8.6575 - MSE: 8.6575 - MAE: 2.2437\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 8168/20000 - Train Loss: 1.4167 - Test Loss: 8.6559 - MSE: 8.6559 - MAE: 2.2435\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 8169/20000 - Train Loss: 1.4159 - Test Loss: 8.6543 - MSE: 8.6543 - MAE: 2.2432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8170/20000 - Train Loss: 1.4152 - Test Loss: 8.6526 - MSE: 8.6526 - MAE: 2.2429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8171/20000 - Train Loss: 1.4144 - Test Loss: 8.6509 - MSE: 8.6509 - MAE: 2.2427\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8172/20000 - Train Loss: 1.4137 - Test Loss: 8.6493 - MSE: 8.6493 - MAE: 2.2424\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8173/20000 - Train Loss: 1.4129 - Test Loss: 8.6476 - MSE: 8.6476 - MAE: 2.2421\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8174/20000 - Train Loss: 1.4121 - Test Loss: 8.6460 - MSE: 8.6460 - MAE: 2.2419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8175/20000 - Train Loss: 1.4114 - Test Loss: 8.6444 - MSE: 8.6444 - MAE: 2.2416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8176/20000 - Train Loss: 1.4106 - Test Loss: 8.6427 - MSE: 8.6427 - MAE: 2.2413\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 8177/20000 - Train Loss: 1.4099 - Test Loss: 8.6411 - MSE: 8.6411 - MAE: 2.2410\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8178/20000 - Train Loss: 1.4091 - Test Loss: 8.6394 - MSE: 8.6394 - MAE: 2.2408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8179/20000 - Train Loss: 1.4084 - Test Loss: 8.6378 - MSE: 8.6378 - MAE: 2.2405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8180/20000 - Train Loss: 1.4077 - Test Loss: 8.6362 - MSE: 8.6362 - MAE: 2.2402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8181/20000 - Train Loss: 1.4069 - Test Loss: 8.6345 - MSE: 8.6345 - MAE: 2.2400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8182/20000 - Train Loss: 1.4062 - Test Loss: 8.6329 - MSE: 8.6329 - MAE: 2.2397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8183/20000 - Train Loss: 1.4054 - Test Loss: 8.6313 - MSE: 8.6313 - MAE: 2.2394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8184/20000 - Train Loss: 1.4047 - Test Loss: 8.6297 - MSE: 8.6297 - MAE: 2.2392\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8185/20000 - Train Loss: 1.4039 - Test Loss: 8.6281 - MSE: 8.6281 - MAE: 2.2389\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8186/20000 - Train Loss: 1.4032 - Test Loss: 8.6264 - MSE: 8.6264 - MAE: 2.2386\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8187/20000 - Train Loss: 1.4024 - Test Loss: 8.6248 - MSE: 8.6248 - MAE: 2.2384\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8188/20000 - Train Loss: 1.4017 - Test Loss: 8.6231 - MSE: 8.6231 - MAE: 2.2381\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 8189/20000 - Train Loss: 1.4010 - Test Loss: 8.6216 - MSE: 8.6216 - MAE: 2.2378\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8190/20000 - Train Loss: 1.4002 - Test Loss: 8.6200 - MSE: 8.6200 - MAE: 2.2376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8191/20000 - Train Loss: 1.3995 - Test Loss: 8.6183 - MSE: 8.6183 - MAE: 2.2373\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8192/20000 - Train Loss: 1.3988 - Test Loss: 8.6166 - MSE: 8.6167 - MAE: 2.2370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8193/20000 - Train Loss: 1.3980 - Test Loss: 8.6150 - MSE: 8.6150 - MAE: 2.2367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8194/20000 - Train Loss: 1.3973 - Test Loss: 8.6135 - MSE: 8.6135 - MAE: 2.2365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8195/20000 - Train Loss: 1.3966 - Test Loss: 8.6119 - MSE: 8.6119 - MAE: 2.2362\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8196/20000 - Train Loss: 1.3958 - Test Loss: 8.6102 - MSE: 8.6102 - MAE: 2.2360\n",
      "2/2 [==============================] - 0s 982us/step\n",
      "Epoch 8197/20000 - Train Loss: 1.3951 - Test Loss: 8.6086 - MSE: 8.6086 - MAE: 2.2357\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8198/20000 - Train Loss: 1.3944 - Test Loss: 8.6070 - MSE: 8.6070 - MAE: 2.2354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8199/20000 - Train Loss: 1.3936 - Test Loss: 8.6054 - MSE: 8.6054 - MAE: 2.2351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8200/20000 - Train Loss: 1.3929 - Test Loss: 8.6038 - MSE: 8.6038 - MAE: 2.2349\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8201/20000 - Train Loss: 1.3922 - Test Loss: 8.6023 - MSE: 8.6023 - MAE: 2.2346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8202/20000 - Train Loss: 1.3914 - Test Loss: 8.6006 - MSE: 8.6006 - MAE: 2.2343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8203/20000 - Train Loss: 1.3907 - Test Loss: 8.5990 - MSE: 8.5990 - MAE: 2.2341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8204/20000 - Train Loss: 1.3900 - Test Loss: 8.5974 - MSE: 8.5974 - MAE: 2.2338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8205/20000 - Train Loss: 1.3893 - Test Loss: 8.5958 - MSE: 8.5958 - MAE: 2.2335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8206/20000 - Train Loss: 1.3885 - Test Loss: 8.5943 - MSE: 8.5943 - MAE: 2.2333\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8207/20000 - Train Loss: 1.3878 - Test Loss: 8.5927 - MSE: 8.5927 - MAE: 2.2330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8208/20000 - Train Loss: 1.3871 - Test Loss: 8.5911 - MSE: 8.5911 - MAE: 2.2327\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8209/20000 - Train Loss: 1.3864 - Test Loss: 8.5894 - MSE: 8.5894 - MAE: 2.2325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8210/20000 - Train Loss: 1.3857 - Test Loss: 8.5878 - MSE: 8.5878 - MAE: 2.2322\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8211/20000 - Train Loss: 1.3849 - Test Loss: 8.5863 - MSE: 8.5863 - MAE: 2.2319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8212/20000 - Train Loss: 1.3842 - Test Loss: 8.5847 - MSE: 8.5847 - MAE: 2.2317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8213/20000 - Train Loss: 1.3835 - Test Loss: 8.5832 - MSE: 8.5832 - MAE: 2.2314\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8214/20000 - Train Loss: 1.3828 - Test Loss: 8.5816 - MSE: 8.5816 - MAE: 2.2311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8215/20000 - Train Loss: 1.3821 - Test Loss: 8.5799 - MSE: 8.5799 - MAE: 2.2308\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8216/20000 - Train Loss: 1.3814 - Test Loss: 8.5783 - MSE: 8.5783 - MAE: 2.2306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8217/20000 - Train Loss: 1.3806 - Test Loss: 8.5768 - MSE: 8.5768 - MAE: 2.2303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8218/20000 - Train Loss: 1.3799 - Test Loss: 8.5753 - MSE: 8.5753 - MAE: 2.2301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8219/20000 - Train Loss: 1.3792 - Test Loss: 8.5737 - MSE: 8.5737 - MAE: 2.2298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8220/20000 - Train Loss: 1.3785 - Test Loss: 8.5721 - MSE: 8.5721 - MAE: 2.2295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8221/20000 - Train Loss: 1.3778 - Test Loss: 8.5705 - MSE: 8.5705 - MAE: 2.2292\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8222/20000 - Train Loss: 1.3771 - Test Loss: 8.5689 - MSE: 8.5689 - MAE: 2.2290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8223/20000 - Train Loss: 1.3764 - Test Loss: 8.5674 - MSE: 8.5674 - MAE: 2.2287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8224/20000 - Train Loss: 1.3757 - Test Loss: 8.5658 - MSE: 8.5658 - MAE: 2.2284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8225/20000 - Train Loss: 1.3750 - Test Loss: 8.5643 - MSE: 8.5643 - MAE: 2.2282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8226/20000 - Train Loss: 1.3743 - Test Loss: 8.5626 - MSE: 8.5626 - MAE: 2.2279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8227/20000 - Train Loss: 1.3736 - Test Loss: 8.5610 - MSE: 8.5610 - MAE: 2.2276\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8228/20000 - Train Loss: 1.3729 - Test Loss: 8.5595 - MSE: 8.5595 - MAE: 2.2274\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8229/20000 - Train Loss: 1.3722 - Test Loss: 8.5580 - MSE: 8.5580 - MAE: 2.2271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8230/20000 - Train Loss: 1.3715 - Test Loss: 8.5565 - MSE: 8.5565 - MAE: 2.2268\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8231/20000 - Train Loss: 1.3708 - Test Loss: 8.5549 - MSE: 8.5549 - MAE: 2.2266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8232/20000 - Train Loss: 1.3701 - Test Loss: 8.5532 - MSE: 8.5532 - MAE: 2.2263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8233/20000 - Train Loss: 1.3694 - Test Loss: 8.5517 - MSE: 8.5517 - MAE: 2.2260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8234/20000 - Train Loss: 1.3687 - Test Loss: 8.5502 - MSE: 8.5502 - MAE: 2.2258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8235/20000 - Train Loss: 1.3680 - Test Loss: 8.5487 - MSE: 8.5487 - MAE: 2.2255\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 8236/20000 - Train Loss: 1.3673 - Test Loss: 8.5471 - MSE: 8.5471 - MAE: 2.2252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8237/20000 - Train Loss: 1.3666 - Test Loss: 8.5455 - MSE: 8.5455 - MAE: 2.2249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8238/20000 - Train Loss: 1.3659 - Test Loss: 8.5440 - MSE: 8.5440 - MAE: 2.2247\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 8239/20000 - Train Loss: 1.3652 - Test Loss: 8.5424 - MSE: 8.5424 - MAE: 2.2244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8240/20000 - Train Loss: 1.3645 - Test Loss: 8.5409 - MSE: 8.5409 - MAE: 2.2241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8241/20000 - Train Loss: 1.3638 - Test Loss: 8.5394 - MSE: 8.5394 - MAE: 2.2239\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8242/20000 - Train Loss: 1.3631 - Test Loss: 8.5378 - MSE: 8.5378 - MAE: 2.2236\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8243/20000 - Train Loss: 1.3624 - Test Loss: 8.5363 - MSE: 8.5363 - MAE: 2.2233\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8244/20000 - Train Loss: 1.3617 - Test Loss: 8.5347 - MSE: 8.5347 - MAE: 2.2231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8245/20000 - Train Loss: 1.3610 - Test Loss: 8.5332 - MSE: 8.5332 - MAE: 2.2228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8246/20000 - Train Loss: 1.3603 - Test Loss: 8.5317 - MSE: 8.5317 - MAE: 2.2225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8247/20000 - Train Loss: 1.3596 - Test Loss: 8.5301 - MSE: 8.5301 - MAE: 2.2223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8248/20000 - Train Loss: 1.3590 - Test Loss: 8.5286 - MSE: 8.5286 - MAE: 2.2220\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 8249/20000 - Train Loss: 1.3583 - Test Loss: 8.5271 - MSE: 8.5271 - MAE: 2.2217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8250/20000 - Train Loss: 1.3576 - Test Loss: 8.5255 - MSE: 8.5255 - MAE: 2.2215\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8251/20000 - Train Loss: 1.3569 - Test Loss: 8.5240 - MSE: 8.5240 - MAE: 2.2212\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8252/20000 - Train Loss: 1.3562 - Test Loss: 8.5225 - MSE: 8.5225 - MAE: 2.2209\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8253/20000 - Train Loss: 1.3555 - Test Loss: 8.5210 - MSE: 8.5210 - MAE: 2.2207\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8254/20000 - Train Loss: 1.3549 - Test Loss: 8.5194 - MSE: 8.5194 - MAE: 2.2204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8255/20000 - Train Loss: 1.3542 - Test Loss: 8.5179 - MSE: 8.5179 - MAE: 2.2201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8256/20000 - Train Loss: 1.3535 - Test Loss: 8.5163 - MSE: 8.5163 - MAE: 2.2198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8257/20000 - Train Loss: 1.3528 - Test Loss: 8.5149 - MSE: 8.5149 - MAE: 2.2196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8258/20000 - Train Loss: 1.3521 - Test Loss: 8.5134 - MSE: 8.5134 - MAE: 2.2193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8259/20000 - Train Loss: 1.3515 - Test Loss: 8.5118 - MSE: 8.5118 - MAE: 2.2190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8260/20000 - Train Loss: 1.3508 - Test Loss: 8.5103 - MSE: 8.5103 - MAE: 2.2188\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8261/20000 - Train Loss: 1.3501 - Test Loss: 8.5088 - MSE: 8.5088 - MAE: 2.2185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8262/20000 - Train Loss: 1.3494 - Test Loss: 8.5073 - MSE: 8.5073 - MAE: 2.2182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8263/20000 - Train Loss: 1.3488 - Test Loss: 8.5057 - MSE: 8.5057 - MAE: 2.2180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8264/20000 - Train Loss: 1.3481 - Test Loss: 8.5043 - MSE: 8.5043 - MAE: 2.2177\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8265/20000 - Train Loss: 1.3474 - Test Loss: 8.5027 - MSE: 8.5027 - MAE: 2.2174\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8266/20000 - Train Loss: 1.3468 - Test Loss: 8.5012 - MSE: 8.5012 - MAE: 2.2172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8267/20000 - Train Loss: 1.3461 - Test Loss: 8.4997 - MSE: 8.4997 - MAE: 2.2169\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8268/20000 - Train Loss: 1.3454 - Test Loss: 8.4982 - MSE: 8.4982 - MAE: 2.2166\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8269/20000 - Train Loss: 1.3447 - Test Loss: 8.4967 - MSE: 8.4967 - MAE: 2.2164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8270/20000 - Train Loss: 1.3441 - Test Loss: 8.4952 - MSE: 8.4952 - MAE: 2.2161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8271/20000 - Train Loss: 1.3434 - Test Loss: 8.4937 - MSE: 8.4937 - MAE: 2.2158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8272/20000 - Train Loss: 1.3427 - Test Loss: 8.4922 - MSE: 8.4922 - MAE: 2.2156\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8273/20000 - Train Loss: 1.3421 - Test Loss: 8.4907 - MSE: 8.4907 - MAE: 2.2153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8274/20000 - Train Loss: 1.3414 - Test Loss: 8.4892 - MSE: 8.4892 - MAE: 2.2150\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8275/20000 - Train Loss: 1.3407 - Test Loss: 8.4877 - MSE: 8.4877 - MAE: 2.2147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8276/20000 - Train Loss: 1.3401 - Test Loss: 8.4862 - MSE: 8.4862 - MAE: 2.2145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8277/20000 - Train Loss: 1.3394 - Test Loss: 8.4847 - MSE: 8.4847 - MAE: 2.2142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8278/20000 - Train Loss: 1.3388 - Test Loss: 8.4832 - MSE: 8.4832 - MAE: 2.2140\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8279/20000 - Train Loss: 1.3381 - Test Loss: 8.4817 - MSE: 8.4817 - MAE: 2.2137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8280/20000 - Train Loss: 1.3374 - Test Loss: 8.4802 - MSE: 8.4802 - MAE: 2.2134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8281/20000 - Train Loss: 1.3368 - Test Loss: 8.4787 - MSE: 8.4787 - MAE: 2.2131\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8282/20000 - Train Loss: 1.3361 - Test Loss: 8.4773 - MSE: 8.4773 - MAE: 2.2129\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8283/20000 - Train Loss: 1.3355 - Test Loss: 8.4758 - MSE: 8.4758 - MAE: 2.2126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8284/20000 - Train Loss: 1.3348 - Test Loss: 8.4743 - MSE: 8.4743 - MAE: 2.2123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8285/20000 - Train Loss: 1.3342 - Test Loss: 8.4728 - MSE: 8.4728 - MAE: 2.2121\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8286/20000 - Train Loss: 1.3335 - Test Loss: 8.4713 - MSE: 8.4713 - MAE: 2.2118\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8287/20000 - Train Loss: 1.3329 - Test Loss: 8.4698 - MSE: 8.4698 - MAE: 2.2115\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8288/20000 - Train Loss: 1.3322 - Test Loss: 8.4684 - MSE: 8.4684 - MAE: 2.2113\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8289/20000 - Train Loss: 1.3315 - Test Loss: 8.4669 - MSE: 8.4669 - MAE: 2.2110\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8290/20000 - Train Loss: 1.3309 - Test Loss: 8.4654 - MSE: 8.4654 - MAE: 2.2107\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8291/20000 - Train Loss: 1.3302 - Test Loss: 8.4639 - MSE: 8.4639 - MAE: 2.2105\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8292/20000 - Train Loss: 1.3296 - Test Loss: 8.4624 - MSE: 8.4624 - MAE: 2.2102\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8293/20000 - Train Loss: 1.3289 - Test Loss: 8.4610 - MSE: 8.4610 - MAE: 2.2099\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8294/20000 - Train Loss: 1.3283 - Test Loss: 8.4595 - MSE: 8.4595 - MAE: 2.2097\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8295/20000 - Train Loss: 1.3276 - Test Loss: 8.4580 - MSE: 8.4580 - MAE: 2.2094\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8296/20000 - Train Loss: 1.3270 - Test Loss: 8.4566 - MSE: 8.4566 - MAE: 2.2091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8297/20000 - Train Loss: 1.3264 - Test Loss: 8.4551 - MSE: 8.4551 - MAE: 2.2088\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8298/20000 - Train Loss: 1.3257 - Test Loss: 8.4536 - MSE: 8.4536 - MAE: 2.2086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8299/20000 - Train Loss: 1.3251 - Test Loss: 8.4522 - MSE: 8.4522 - MAE: 2.2083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8300/20000 - Train Loss: 1.3244 - Test Loss: 8.4507 - MSE: 8.4507 - MAE: 2.2080\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 8301/20000 - Train Loss: 1.3238 - Test Loss: 8.4493 - MSE: 8.4493 - MAE: 2.2078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8302/20000 - Train Loss: 1.3231 - Test Loss: 8.4478 - MSE: 8.4478 - MAE: 2.2075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8303/20000 - Train Loss: 1.3225 - Test Loss: 8.4463 - MSE: 8.4463 - MAE: 2.2072\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8304/20000 - Train Loss: 1.3219 - Test Loss: 8.4448 - MSE: 8.4448 - MAE: 2.2070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8305/20000 - Train Loss: 1.3212 - Test Loss: 8.4434 - MSE: 8.4434 - MAE: 2.2067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8306/20000 - Train Loss: 1.3206 - Test Loss: 8.4420 - MSE: 8.4420 - MAE: 2.2064\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8307/20000 - Train Loss: 1.3199 - Test Loss: 8.4405 - MSE: 8.4405 - MAE: 2.2062\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8308/20000 - Train Loss: 1.3193 - Test Loss: 8.4390 - MSE: 8.4390 - MAE: 2.2059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8309/20000 - Train Loss: 1.3187 - Test Loss: 8.4375 - MSE: 8.4375 - MAE: 2.2056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8310/20000 - Train Loss: 1.3180 - Test Loss: 8.4361 - MSE: 8.4361 - MAE: 2.2054\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 8311/20000 - Train Loss: 1.3174 - Test Loss: 8.4347 - MSE: 8.4347 - MAE: 2.2051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8312/20000 - Train Loss: 1.3168 - Test Loss: 8.4332 - MSE: 8.4332 - MAE: 2.2048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8313/20000 - Train Loss: 1.3161 - Test Loss: 8.4318 - MSE: 8.4318 - MAE: 2.2046\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8314/20000 - Train Loss: 1.3155 - Test Loss: 8.4303 - MSE: 8.4303 - MAE: 2.2043\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8315/20000 - Train Loss: 1.3149 - Test Loss: 8.4288 - MSE: 8.4288 - MAE: 2.2040\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8316/20000 - Train Loss: 1.3142 - Test Loss: 8.4274 - MSE: 8.4274 - MAE: 2.2037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8317/20000 - Train Loss: 1.3136 - Test Loss: 8.4260 - MSE: 8.4260 - MAE: 2.2035\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8318/20000 - Train Loss: 1.3130 - Test Loss: 8.4246 - MSE: 8.4246 - MAE: 2.2032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8319/20000 - Train Loss: 1.3124 - Test Loss: 8.4232 - MSE: 8.4232 - MAE: 2.2030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8320/20000 - Train Loss: 1.3117 - Test Loss: 8.4217 - MSE: 8.4217 - MAE: 2.2027\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8321/20000 - Train Loss: 1.3111 - Test Loss: 8.4202 - MSE: 8.4202 - MAE: 2.2024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8322/20000 - Train Loss: 1.3105 - Test Loss: 8.4188 - MSE: 8.4188 - MAE: 2.2021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8323/20000 - Train Loss: 1.3099 - Test Loss: 8.4174 - MSE: 8.4174 - MAE: 2.2019\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8324/20000 - Train Loss: 1.3092 - Test Loss: 8.4160 - MSE: 8.4160 - MAE: 2.2016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8325/20000 - Train Loss: 1.3086 - Test Loss: 8.4145 - MSE: 8.4145 - MAE: 2.2013\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8326/20000 - Train Loss: 1.3080 - Test Loss: 8.4130 - MSE: 8.4130 - MAE: 2.2011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8327/20000 - Train Loss: 1.3074 - Test Loss: 8.4116 - MSE: 8.4116 - MAE: 2.2008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8328/20000 - Train Loss: 1.3067 - Test Loss: 8.4102 - MSE: 8.4102 - MAE: 2.2005\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8329/20000 - Train Loss: 1.3061 - Test Loss: 8.4088 - MSE: 8.4088 - MAE: 2.2003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8330/20000 - Train Loss: 1.3055 - Test Loss: 8.4074 - MSE: 8.4074 - MAE: 2.2000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8331/20000 - Train Loss: 1.3049 - Test Loss: 8.4059 - MSE: 8.4059 - MAE: 2.1997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8332/20000 - Train Loss: 1.3043 - Test Loss: 8.4045 - MSE: 8.4045 - MAE: 2.1995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8333/20000 - Train Loss: 1.3037 - Test Loss: 8.4031 - MSE: 8.4031 - MAE: 2.1992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8334/20000 - Train Loss: 1.3030 - Test Loss: 8.4017 - MSE: 8.4017 - MAE: 2.1989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8335/20000 - Train Loss: 1.3024 - Test Loss: 8.4002 - MSE: 8.4002 - MAE: 2.1987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8336/20000 - Train Loss: 1.3018 - Test Loss: 8.3988 - MSE: 8.3988 - MAE: 2.1984\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8337/20000 - Train Loss: 1.3012 - Test Loss: 8.3974 - MSE: 8.3974 - MAE: 2.1981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8338/20000 - Train Loss: 1.3006 - Test Loss: 8.3960 - MSE: 8.3960 - MAE: 2.1979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8339/20000 - Train Loss: 1.3000 - Test Loss: 8.3945 - MSE: 8.3945 - MAE: 2.1976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8340/20000 - Train Loss: 1.2994 - Test Loss: 8.3931 - MSE: 8.3931 - MAE: 2.1973\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8341/20000 - Train Loss: 1.2987 - Test Loss: 8.3917 - MSE: 8.3917 - MAE: 2.1971\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8342/20000 - Train Loss: 1.2981 - Test Loss: 8.3903 - MSE: 8.3903 - MAE: 2.1968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8343/20000 - Train Loss: 1.2975 - Test Loss: 8.3889 - MSE: 8.3889 - MAE: 2.1965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8344/20000 - Train Loss: 1.2969 - Test Loss: 8.3875 - MSE: 8.3875 - MAE: 2.1962\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8345/20000 - Train Loss: 1.2963 - Test Loss: 8.3861 - MSE: 8.3861 - MAE: 2.1960\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8346/20000 - Train Loss: 1.2957 - Test Loss: 8.3846 - MSE: 8.3846 - MAE: 2.1957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8347/20000 - Train Loss: 1.2951 - Test Loss: 8.3833 - MSE: 8.3833 - MAE: 2.1954\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8348/20000 - Train Loss: 1.2945 - Test Loss: 8.3819 - MSE: 8.3819 - MAE: 2.1952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8349/20000 - Train Loss: 1.2939 - Test Loss: 8.3805 - MSE: 8.3805 - MAE: 2.1949\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8350/20000 - Train Loss: 1.2933 - Test Loss: 8.3790 - MSE: 8.3790 - MAE: 2.1946\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8351/20000 - Train Loss: 1.2927 - Test Loss: 8.3776 - MSE: 8.3776 - MAE: 2.1944\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8352/20000 - Train Loss: 1.2921 - Test Loss: 8.3762 - MSE: 8.3762 - MAE: 2.1941\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8353/20000 - Train Loss: 1.2915 - Test Loss: 8.3749 - MSE: 8.3749 - MAE: 2.1938\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8354/20000 - Train Loss: 1.2909 - Test Loss: 8.3735 - MSE: 8.3735 - MAE: 2.1936\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8355/20000 - Train Loss: 1.2903 - Test Loss: 8.3721 - MSE: 8.3721 - MAE: 2.1933\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8356/20000 - Train Loss: 1.2897 - Test Loss: 8.3706 - MSE: 8.3706 - MAE: 2.1930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8357/20000 - Train Loss: 1.2891 - Test Loss: 8.3693 - MSE: 8.3693 - MAE: 2.1928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8358/20000 - Train Loss: 1.2885 - Test Loss: 8.3679 - MSE: 8.3678 - MAE: 2.1925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8359/20000 - Train Loss: 1.2879 - Test Loss: 8.3665 - MSE: 8.3665 - MAE: 2.1922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8360/20000 - Train Loss: 1.2873 - Test Loss: 8.3651 - MSE: 8.3651 - MAE: 2.1920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8361/20000 - Train Loss: 1.2867 - Test Loss: 8.3637 - MSE: 8.3637 - MAE: 2.1917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8362/20000 - Train Loss: 1.2861 - Test Loss: 8.3623 - MSE: 8.3623 - MAE: 2.1914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8363/20000 - Train Loss: 1.2855 - Test Loss: 8.3609 - MSE: 8.3609 - MAE: 2.1912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8364/20000 - Train Loss: 1.2849 - Test Loss: 8.3595 - MSE: 8.3595 - MAE: 2.1909\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 8365/20000 - Train Loss: 1.2843 - Test Loss: 8.3581 - MSE: 8.3581 - MAE: 2.1906\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8366/20000 - Train Loss: 1.2837 - Test Loss: 8.3568 - MSE: 8.3568 - MAE: 2.1904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8367/20000 - Train Loss: 1.2831 - Test Loss: 8.3554 - MSE: 8.3554 - MAE: 2.1901\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8368/20000 - Train Loss: 1.2825 - Test Loss: 8.3540 - MSE: 8.3540 - MAE: 2.1898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8369/20000 - Train Loss: 1.2820 - Test Loss: 8.3526 - MSE: 8.3526 - MAE: 2.1895\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8370/20000 - Train Loss: 1.2814 - Test Loss: 8.3512 - MSE: 8.3512 - MAE: 2.1893\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8371/20000 - Train Loss: 1.2808 - Test Loss: 8.3498 - MSE: 8.3498 - MAE: 2.1890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8372/20000 - Train Loss: 1.2802 - Test Loss: 8.3485 - MSE: 8.3485 - MAE: 2.1887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8373/20000 - Train Loss: 1.2796 - Test Loss: 8.3471 - MSE: 8.3471 - MAE: 2.1885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8374/20000 - Train Loss: 1.2790 - Test Loss: 8.3457 - MSE: 8.3457 - MAE: 2.1882\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8375/20000 - Train Loss: 1.2784 - Test Loss: 8.3443 - MSE: 8.3443 - MAE: 2.1879\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8376/20000 - Train Loss: 1.2779 - Test Loss: 8.3430 - MSE: 8.3430 - MAE: 2.1877\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8377/20000 - Train Loss: 1.2773 - Test Loss: 8.3416 - MSE: 8.3416 - MAE: 2.1874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8378/20000 - Train Loss: 1.2767 - Test Loss: 8.3402 - MSE: 8.3402 - MAE: 2.1871\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8379/20000 - Train Loss: 1.2761 - Test Loss: 8.3389 - MSE: 8.3389 - MAE: 2.1869\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8380/20000 - Train Loss: 1.2755 - Test Loss: 8.3375 - MSE: 8.3375 - MAE: 2.1866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8381/20000 - Train Loss: 1.2749 - Test Loss: 8.3361 - MSE: 8.3361 - MAE: 2.1863\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 8382/20000 - Train Loss: 1.2744 - Test Loss: 8.3348 - MSE: 8.3348 - MAE: 2.1861\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8383/20000 - Train Loss: 1.2738 - Test Loss: 8.3334 - MSE: 8.3334 - MAE: 2.1858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8384/20000 - Train Loss: 1.2732 - Test Loss: 8.3321 - MSE: 8.3321 - MAE: 2.1855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8385/20000 - Train Loss: 1.2726 - Test Loss: 8.3306 - MSE: 8.3306 - MAE: 2.1853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8386/20000 - Train Loss: 1.2721 - Test Loss: 8.3293 - MSE: 8.3293 - MAE: 2.1850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8387/20000 - Train Loss: 1.2715 - Test Loss: 8.3280 - MSE: 8.3280 - MAE: 2.1847\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 8388/20000 - Train Loss: 1.2709 - Test Loss: 8.3266 - MSE: 8.3266 - MAE: 2.1845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8389/20000 - Train Loss: 1.2703 - Test Loss: 8.3253 - MSE: 8.3253 - MAE: 2.1842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8390/20000 - Train Loss: 1.2698 - Test Loss: 8.3238 - MSE: 8.3238 - MAE: 2.1839\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8391/20000 - Train Loss: 1.2692 - Test Loss: 8.3225 - MSE: 8.3225 - MAE: 2.1836\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8392/20000 - Train Loss: 1.2686 - Test Loss: 8.3212 - MSE: 8.3212 - MAE: 2.1834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8393/20000 - Train Loss: 1.2680 - Test Loss: 8.3198 - MSE: 8.3198 - MAE: 2.1831\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 8394/20000 - Train Loss: 1.2675 - Test Loss: 8.3185 - MSE: 8.3185 - MAE: 2.1829\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8395/20000 - Train Loss: 1.2669 - Test Loss: 8.3171 - MSE: 8.3171 - MAE: 2.1826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8396/20000 - Train Loss: 1.2663 - Test Loss: 8.3157 - MSE: 8.3157 - MAE: 2.1823\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8397/20000 - Train Loss: 1.2658 - Test Loss: 8.3144 - MSE: 8.3144 - MAE: 2.1820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8398/20000 - Train Loss: 1.2652 - Test Loss: 8.3131 - MSE: 8.3131 - MAE: 2.1818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8399/20000 - Train Loss: 1.2646 - Test Loss: 8.3117 - MSE: 8.3117 - MAE: 2.1815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8400/20000 - Train Loss: 1.2641 - Test Loss: 8.3103 - MSE: 8.3103 - MAE: 2.1812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8401/20000 - Train Loss: 1.2635 - Test Loss: 8.3090 - MSE: 8.3090 - MAE: 2.1810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8402/20000 - Train Loss: 1.2629 - Test Loss: 8.3076 - MSE: 8.3076 - MAE: 2.1807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8403/20000 - Train Loss: 1.2624 - Test Loss: 8.3063 - MSE: 8.3063 - MAE: 2.1804\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8404/20000 - Train Loss: 1.2618 - Test Loss: 8.3050 - MSE: 8.3050 - MAE: 2.1802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8405/20000 - Train Loss: 1.2612 - Test Loss: 8.3036 - MSE: 8.3036 - MAE: 2.1799\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8406/20000 - Train Loss: 1.2607 - Test Loss: 8.3023 - MSE: 8.3023 - MAE: 2.1796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8407/20000 - Train Loss: 1.2601 - Test Loss: 8.3010 - MSE: 8.3010 - MAE: 2.1794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8408/20000 - Train Loss: 1.2595 - Test Loss: 8.2996 - MSE: 8.2996 - MAE: 2.1791\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8409/20000 - Train Loss: 1.2590 - Test Loss: 8.2983 - MSE: 8.2983 - MAE: 2.1788\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8410/20000 - Train Loss: 1.2584 - Test Loss: 8.2969 - MSE: 8.2969 - MAE: 2.1786\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8411/20000 - Train Loss: 1.2579 - Test Loss: 8.2956 - MSE: 8.2956 - MAE: 2.1783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8412/20000 - Train Loss: 1.2573 - Test Loss: 8.2943 - MSE: 8.2943 - MAE: 2.1780\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 8413/20000 - Train Loss: 1.2567 - Test Loss: 8.2929 - MSE: 8.2929 - MAE: 2.1778\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8414/20000 - Train Loss: 1.2562 - Test Loss: 8.2916 - MSE: 8.2916 - MAE: 2.1775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8415/20000 - Train Loss: 1.2556 - Test Loss: 8.2903 - MSE: 8.2903 - MAE: 2.1772\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8416/20000 - Train Loss: 1.2551 - Test Loss: 8.2890 - MSE: 8.2890 - MAE: 2.1770\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8417/20000 - Train Loss: 1.2545 - Test Loss: 8.2876 - MSE: 8.2876 - MAE: 2.1767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8418/20000 - Train Loss: 1.2540 - Test Loss: 8.2863 - MSE: 8.2863 - MAE: 2.1764\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 8419/20000 - Train Loss: 1.2534 - Test Loss: 8.2850 - MSE: 8.2850 - MAE: 2.1762\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8420/20000 - Train Loss: 1.2529 - Test Loss: 8.2836 - MSE: 8.2836 - MAE: 2.1759\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8421/20000 - Train Loss: 1.2523 - Test Loss: 8.2823 - MSE: 8.2823 - MAE: 2.1756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8422/20000 - Train Loss: 1.2518 - Test Loss: 8.2810 - MSE: 8.2810 - MAE: 2.1753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8423/20000 - Train Loss: 1.2512 - Test Loss: 8.2796 - MSE: 8.2796 - MAE: 2.1751\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8424/20000 - Train Loss: 1.2507 - Test Loss: 8.2783 - MSE: 8.2783 - MAE: 2.1748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8425/20000 - Train Loss: 1.2501 - Test Loss: 8.2770 - MSE: 8.2770 - MAE: 2.1746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8426/20000 - Train Loss: 1.2496 - Test Loss: 8.2757 - MSE: 8.2757 - MAE: 2.1743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8427/20000 - Train Loss: 1.2490 - Test Loss: 8.2744 - MSE: 8.2744 - MAE: 2.1740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8428/20000 - Train Loss: 1.2485 - Test Loss: 8.2730 - MSE: 8.2730 - MAE: 2.1737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8429/20000 - Train Loss: 1.2479 - Test Loss: 8.2717 - MSE: 8.2717 - MAE: 2.1735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8430/20000 - Train Loss: 1.2474 - Test Loss: 8.2704 - MSE: 8.2704 - MAE: 2.1732\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8431/20000 - Train Loss: 1.2468 - Test Loss: 8.2691 - MSE: 8.2691 - MAE: 2.1729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8432/20000 - Train Loss: 1.2463 - Test Loss: 8.2678 - MSE: 8.2678 - MAE: 2.1727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8433/20000 - Train Loss: 1.2457 - Test Loss: 8.2665 - MSE: 8.2665 - MAE: 2.1724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8434/20000 - Train Loss: 1.2452 - Test Loss: 8.2652 - MSE: 8.2652 - MAE: 2.1721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8435/20000 - Train Loss: 1.2447 - Test Loss: 8.2639 - MSE: 8.2639 - MAE: 2.1719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8436/20000 - Train Loss: 1.2441 - Test Loss: 8.2626 - MSE: 8.2626 - MAE: 2.1716\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8437/20000 - Train Loss: 1.2436 - Test Loss: 8.2612 - MSE: 8.2612 - MAE: 2.1713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8438/20000 - Train Loss: 1.2430 - Test Loss: 8.2599 - MSE: 8.2599 - MAE: 2.1711\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8439/20000 - Train Loss: 1.2425 - Test Loss: 8.2586 - MSE: 8.2586 - MAE: 2.1708\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8440/20000 - Train Loss: 1.2420 - Test Loss: 8.2574 - MSE: 8.2574 - MAE: 2.1705\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8441/20000 - Train Loss: 1.2414 - Test Loss: 8.2561 - MSE: 8.2561 - MAE: 2.1703\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8442/20000 - Train Loss: 1.2409 - Test Loss: 8.2547 - MSE: 8.2547 - MAE: 2.1700\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8443/20000 - Train Loss: 1.2403 - Test Loss: 8.2534 - MSE: 8.2534 - MAE: 2.1697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8444/20000 - Train Loss: 1.2398 - Test Loss: 8.2521 - MSE: 8.2521 - MAE: 2.1695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8445/20000 - Train Loss: 1.2393 - Test Loss: 8.2509 - MSE: 8.2509 - MAE: 2.1692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8446/20000 - Train Loss: 1.2387 - Test Loss: 8.2496 - MSE: 8.2495 - MAE: 2.1689\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8447/20000 - Train Loss: 1.2382 - Test Loss: 8.2482 - MSE: 8.2482 - MAE: 2.1687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8448/20000 - Train Loss: 1.2377 - Test Loss: 8.2469 - MSE: 8.2469 - MAE: 2.1684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8449/20000 - Train Loss: 1.2371 - Test Loss: 8.2456 - MSE: 8.2456 - MAE: 2.1681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8450/20000 - Train Loss: 1.2366 - Test Loss: 8.2443 - MSE: 8.2443 - MAE: 2.1679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8451/20000 - Train Loss: 1.2361 - Test Loss: 8.2431 - MSE: 8.2431 - MAE: 2.1676\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8452/20000 - Train Loss: 1.2355 - Test Loss: 8.2417 - MSE: 8.2417 - MAE: 2.1673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8453/20000 - Train Loss: 1.2350 - Test Loss: 8.2404 - MSE: 8.2404 - MAE: 2.1670\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8454/20000 - Train Loss: 1.2345 - Test Loss: 8.2391 - MSE: 8.2391 - MAE: 2.1668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8455/20000 - Train Loss: 1.2340 - Test Loss: 8.2379 - MSE: 8.2379 - MAE: 2.1665\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8456/20000 - Train Loss: 1.2334 - Test Loss: 8.2366 - MSE: 8.2366 - MAE: 2.1663\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8457/20000 - Train Loss: 1.2329 - Test Loss: 8.2353 - MSE: 8.2353 - MAE: 2.1660\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8458/20000 - Train Loss: 1.2324 - Test Loss: 8.2340 - MSE: 8.2340 - MAE: 2.1657\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8459/20000 - Train Loss: 1.2319 - Test Loss: 8.2327 - MSE: 8.2327 - MAE: 2.1654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8460/20000 - Train Loss: 1.2313 - Test Loss: 8.2314 - MSE: 8.2314 - MAE: 2.1652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8461/20000 - Train Loss: 1.2308 - Test Loss: 8.2301 - MSE: 8.2301 - MAE: 2.1649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8462/20000 - Train Loss: 1.2303 - Test Loss: 8.2288 - MSE: 8.2288 - MAE: 2.1646\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 8463/20000 - Train Loss: 1.2298 - Test Loss: 8.2276 - MSE: 8.2276 - MAE: 2.1644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8464/20000 - Train Loss: 1.2292 - Test Loss: 8.2263 - MSE: 8.2263 - MAE: 2.1641\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8465/20000 - Train Loss: 1.2287 - Test Loss: 8.2250 - MSE: 8.2250 - MAE: 2.1639\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8466/20000 - Train Loss: 1.2282 - Test Loss: 8.2237 - MSE: 8.2237 - MAE: 2.1636\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8467/20000 - Train Loss: 1.2277 - Test Loss: 8.2224 - MSE: 8.2224 - MAE: 2.1633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8468/20000 - Train Loss: 1.2271 - Test Loss: 8.2212 - MSE: 8.2212 - MAE: 2.1630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8469/20000 - Train Loss: 1.2266 - Test Loss: 8.2199 - MSE: 8.2199 - MAE: 2.1628\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8470/20000 - Train Loss: 1.2261 - Test Loss: 8.2186 - MSE: 8.2186 - MAE: 2.1625\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8471/20000 - Train Loss: 1.2256 - Test Loss: 8.2173 - MSE: 8.2173 - MAE: 2.1622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8472/20000 - Train Loss: 1.2251 - Test Loss: 8.2161 - MSE: 8.2161 - MAE: 2.1620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8473/20000 - Train Loss: 1.2246 - Test Loss: 8.2148 - MSE: 8.2148 - MAE: 2.1617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8474/20000 - Train Loss: 1.2240 - Test Loss: 8.2135 - MSE: 8.2135 - MAE: 2.1614\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 8475/20000 - Train Loss: 1.2235 - Test Loss: 8.2122 - MSE: 8.2122 - MAE: 2.1612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8476/20000 - Train Loss: 1.2230 - Test Loss: 8.2110 - MSE: 8.2110 - MAE: 2.1609\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8477/20000 - Train Loss: 1.2225 - Test Loss: 8.2097 - MSE: 8.2097 - MAE: 2.1606\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8478/20000 - Train Loss: 1.2220 - Test Loss: 8.2084 - MSE: 8.2084 - MAE: 2.1604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8479/20000 - Train Loss: 1.2215 - Test Loss: 8.2072 - MSE: 8.2072 - MAE: 2.1601\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8480/20000 - Train Loss: 1.2210 - Test Loss: 8.2059 - MSE: 8.2059 - MAE: 2.1598\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 8481/20000 - Train Loss: 1.2204 - Test Loss: 8.2046 - MSE: 8.2046 - MAE: 2.1596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8482/20000 - Train Loss: 1.2199 - Test Loss: 8.2033 - MSE: 8.2033 - MAE: 2.1593\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8483/20000 - Train Loss: 1.2194 - Test Loss: 8.2021 - MSE: 8.2021 - MAE: 2.1590\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8484/20000 - Train Loss: 1.2189 - Test Loss: 8.2008 - MSE: 8.2008 - MAE: 2.1588\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8485/20000 - Train Loss: 1.2184 - Test Loss: 8.1996 - MSE: 8.1996 - MAE: 2.1585\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8486/20000 - Train Loss: 1.2179 - Test Loss: 8.1983 - MSE: 8.1983 - MAE: 2.1582\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 8487/20000 - Train Loss: 1.2174 - Test Loss: 8.1970 - MSE: 8.1970 - MAE: 2.1580\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8488/20000 - Train Loss: 1.2169 - Test Loss: 8.1958 - MSE: 8.1958 - MAE: 2.1577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8489/20000 - Train Loss: 1.2164 - Test Loss: 8.1945 - MSE: 8.1945 - MAE: 2.1574\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8490/20000 - Train Loss: 1.2159 - Test Loss: 8.1933 - MSE: 8.1933 - MAE: 2.1572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8491/20000 - Train Loss: 1.2154 - Test Loss: 8.1920 - MSE: 8.1920 - MAE: 2.1569\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 8492/20000 - Train Loss: 1.2149 - Test Loss: 8.1907 - MSE: 8.1907 - MAE: 2.1566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8493/20000 - Train Loss: 1.2144 - Test Loss: 8.1895 - MSE: 8.1895 - MAE: 2.1564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8494/20000 - Train Loss: 1.2139 - Test Loss: 8.1883 - MSE: 8.1883 - MAE: 2.1561\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8495/20000 - Train Loss: 1.2134 - Test Loss: 8.1870 - MSE: 8.1870 - MAE: 2.1558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8496/20000 - Train Loss: 1.2128 - Test Loss: 8.1857 - MSE: 8.1857 - MAE: 2.1556\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8497/20000 - Train Loss: 1.2123 - Test Loss: 8.1845 - MSE: 8.1845 - MAE: 2.1553\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 8498/20000 - Train Loss: 1.2118 - Test Loss: 8.1832 - MSE: 8.1832 - MAE: 2.1551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8499/20000 - Train Loss: 1.2113 - Test Loss: 8.1820 - MSE: 8.1820 - MAE: 2.1549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8500/20000 - Train Loss: 1.2108 - Test Loss: 8.1808 - MSE: 8.1808 - MAE: 2.1547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8501/20000 - Train Loss: 1.2103 - Test Loss: 8.1795 - MSE: 8.1795 - MAE: 2.1546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8502/20000 - Train Loss: 1.2098 - Test Loss: 8.1782 - MSE: 8.1782 - MAE: 2.1544\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8503/20000 - Train Loss: 1.2094 - Test Loss: 8.1770 - MSE: 8.1770 - MAE: 2.1542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8504/20000 - Train Loss: 1.2089 - Test Loss: 8.1758 - MSE: 8.1758 - MAE: 2.1541\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8505/20000 - Train Loss: 1.2084 - Test Loss: 8.1745 - MSE: 8.1745 - MAE: 2.1539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8506/20000 - Train Loss: 1.2079 - Test Loss: 8.1732 - MSE: 8.1732 - MAE: 2.1537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8507/20000 - Train Loss: 1.2074 - Test Loss: 8.1720 - MSE: 8.1720 - MAE: 2.1535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8508/20000 - Train Loss: 1.2069 - Test Loss: 8.1708 - MSE: 8.1708 - MAE: 2.1534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8509/20000 - Train Loss: 1.2064 - Test Loss: 8.1696 - MSE: 8.1696 - MAE: 2.1532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8510/20000 - Train Loss: 1.2059 - Test Loss: 8.1683 - MSE: 8.1683 - MAE: 2.1530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8511/20000 - Train Loss: 1.2054 - Test Loss: 8.1670 - MSE: 8.1670 - MAE: 2.1529\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8512/20000 - Train Loss: 1.2049 - Test Loss: 8.1658 - MSE: 8.1658 - MAE: 2.1527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8513/20000 - Train Loss: 1.2044 - Test Loss: 8.1646 - MSE: 8.1646 - MAE: 2.1525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8514/20000 - Train Loss: 1.2039 - Test Loss: 8.1633 - MSE: 8.1633 - MAE: 2.1523\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 8515/20000 - Train Loss: 1.2034 - Test Loss: 8.1621 - MSE: 8.1621 - MAE: 2.1522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8516/20000 - Train Loss: 1.2029 - Test Loss: 8.1608 - MSE: 8.1608 - MAE: 2.1520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8517/20000 - Train Loss: 1.2025 - Test Loss: 8.1596 - MSE: 8.1596 - MAE: 2.1518\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8518/20000 - Train Loss: 1.2020 - Test Loss: 8.1584 - MSE: 8.1584 - MAE: 2.1517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8519/20000 - Train Loss: 1.2015 - Test Loss: 8.1572 - MSE: 8.1572 - MAE: 2.1515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8520/20000 - Train Loss: 1.2010 - Test Loss: 8.1559 - MSE: 8.1559 - MAE: 2.1513\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8521/20000 - Train Loss: 1.2005 - Test Loss: 8.1547 - MSE: 8.1547 - MAE: 2.1511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8522/20000 - Train Loss: 1.2000 - Test Loss: 8.1535 - MSE: 8.1535 - MAE: 2.1510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8523/20000 - Train Loss: 1.1995 - Test Loss: 8.1523 - MSE: 8.1523 - MAE: 2.1508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8524/20000 - Train Loss: 1.1990 - Test Loss: 8.1510 - MSE: 8.1510 - MAE: 2.1506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8525/20000 - Train Loss: 1.1986 - Test Loss: 8.1498 - MSE: 8.1498 - MAE: 2.1504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8526/20000 - Train Loss: 1.1981 - Test Loss: 8.1485 - MSE: 8.1485 - MAE: 2.1503\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8527/20000 - Train Loss: 1.1976 - Test Loss: 8.1473 - MSE: 8.1473 - MAE: 2.1501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8528/20000 - Train Loss: 1.1971 - Test Loss: 8.1461 - MSE: 8.1461 - MAE: 2.1499\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8529/20000 - Train Loss: 1.1966 - Test Loss: 8.1449 - MSE: 8.1449 - MAE: 2.1498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8530/20000 - Train Loss: 1.1961 - Test Loss: 8.1436 - MSE: 8.1436 - MAE: 2.1496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8531/20000 - Train Loss: 1.1957 - Test Loss: 8.1424 - MSE: 8.1424 - MAE: 2.1494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8532/20000 - Train Loss: 1.1952 - Test Loss: 8.1412 - MSE: 8.1412 - MAE: 2.1492\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8533/20000 - Train Loss: 1.1947 - Test Loss: 8.1400 - MSE: 8.1400 - MAE: 2.1491\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8534/20000 - Train Loss: 1.1942 - Test Loss: 8.1388 - MSE: 8.1388 - MAE: 2.1489\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8535/20000 - Train Loss: 1.1938 - Test Loss: 8.1375 - MSE: 8.1375 - MAE: 2.1487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8536/20000 - Train Loss: 1.1933 - Test Loss: 8.1363 - MSE: 8.1363 - MAE: 2.1486\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 8537/20000 - Train Loss: 1.1928 - Test Loss: 8.1351 - MSE: 8.1351 - MAE: 2.1484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8538/20000 - Train Loss: 1.1923 - Test Loss: 8.1339 - MSE: 8.1339 - MAE: 2.1482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8539/20000 - Train Loss: 1.1918 - Test Loss: 8.1327 - MSE: 8.1327 - MAE: 2.1481\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8540/20000 - Train Loss: 1.1914 - Test Loss: 8.1315 - MSE: 8.1315 - MAE: 2.1479\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8541/20000 - Train Loss: 1.1909 - Test Loss: 8.1302 - MSE: 8.1302 - MAE: 2.1477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8542/20000 - Train Loss: 1.1904 - Test Loss: 8.1290 - MSE: 8.1290 - MAE: 2.1475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8543/20000 - Train Loss: 1.1899 - Test Loss: 8.1279 - MSE: 8.1279 - MAE: 2.1474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8544/20000 - Train Loss: 1.1895 - Test Loss: 8.1266 - MSE: 8.1266 - MAE: 2.1472\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8545/20000 - Train Loss: 1.1890 - Test Loss: 8.1254 - MSE: 8.1254 - MAE: 2.1470\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8546/20000 - Train Loss: 1.1885 - Test Loss: 8.1241 - MSE: 8.1241 - MAE: 2.1468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8547/20000 - Train Loss: 1.1881 - Test Loss: 8.1230 - MSE: 8.1230 - MAE: 2.1467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8548/20000 - Train Loss: 1.1876 - Test Loss: 8.1218 - MSE: 8.1218 - MAE: 2.1465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8549/20000 - Train Loss: 1.1871 - Test Loss: 8.1206 - MSE: 8.1206 - MAE: 2.1463\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8550/20000 - Train Loss: 1.1867 - Test Loss: 8.1194 - MSE: 8.1194 - MAE: 2.1461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8551/20000 - Train Loss: 1.1862 - Test Loss: 8.1181 - MSE: 8.1181 - MAE: 2.1460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8552/20000 - Train Loss: 1.1857 - Test Loss: 8.1169 - MSE: 8.1169 - MAE: 2.1458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8553/20000 - Train Loss: 1.1852 - Test Loss: 8.1157 - MSE: 8.1157 - MAE: 2.1456\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 8554/20000 - Train Loss: 1.1848 - Test Loss: 8.1145 - MSE: 8.1145 - MAE: 2.1455\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8555/20000 - Train Loss: 1.1843 - Test Loss: 8.1133 - MSE: 8.1133 - MAE: 2.1453\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8556/20000 - Train Loss: 1.1839 - Test Loss: 8.1121 - MSE: 8.1121 - MAE: 2.1451\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 8557/20000 - Train Loss: 1.1834 - Test Loss: 8.1109 - MSE: 8.1109 - MAE: 2.1449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8558/20000 - Train Loss: 1.1829 - Test Loss: 8.1097 - MSE: 8.1097 - MAE: 2.1448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8559/20000 - Train Loss: 1.1825 - Test Loss: 8.1085 - MSE: 8.1085 - MAE: 2.1446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8560/20000 - Train Loss: 1.1820 - Test Loss: 8.1073 - MSE: 8.1073 - MAE: 2.1444\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8561/20000 - Train Loss: 1.1815 - Test Loss: 8.1061 - MSE: 8.1061 - MAE: 2.1442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8562/20000 - Train Loss: 1.1811 - Test Loss: 8.1050 - MSE: 8.1050 - MAE: 2.1441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8563/20000 - Train Loss: 1.1806 - Test Loss: 8.1037 - MSE: 8.1037 - MAE: 2.1439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8564/20000 - Train Loss: 1.1801 - Test Loss: 8.1025 - MSE: 8.1025 - MAE: 2.1437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8565/20000 - Train Loss: 1.1797 - Test Loss: 8.1013 - MSE: 8.1013 - MAE: 2.1436\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 8566/20000 - Train Loss: 1.1792 - Test Loss: 8.1002 - MSE: 8.1002 - MAE: 2.1434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8567/20000 - Train Loss: 1.1788 - Test Loss: 8.0990 - MSE: 8.0990 - MAE: 2.1432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8568/20000 - Train Loss: 1.1783 - Test Loss: 8.0977 - MSE: 8.0977 - MAE: 2.1430\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8569/20000 - Train Loss: 1.1778 - Test Loss: 8.0965 - MSE: 8.0965 - MAE: 2.1429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8570/20000 - Train Loss: 1.1774 - Test Loss: 8.0954 - MSE: 8.0954 - MAE: 2.1427\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8571/20000 - Train Loss: 1.1769 - Test Loss: 8.0942 - MSE: 8.0942 - MAE: 2.1425\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8572/20000 - Train Loss: 1.1765 - Test Loss: 8.0930 - MSE: 8.0930 - MAE: 2.1423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8573/20000 - Train Loss: 1.1760 - Test Loss: 8.0918 - MSE: 8.0918 - MAE: 2.1422\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8574/20000 - Train Loss: 1.1756 - Test Loss: 8.0906 - MSE: 8.0906 - MAE: 2.1420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8575/20000 - Train Loss: 1.1751 - Test Loss: 8.0894 - MSE: 8.0894 - MAE: 2.1418\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8576/20000 - Train Loss: 1.1747 - Test Loss: 8.0883 - MSE: 8.0883 - MAE: 2.1417\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8577/20000 - Train Loss: 1.1742 - Test Loss: 8.0870 - MSE: 8.0870 - MAE: 2.1415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8578/20000 - Train Loss: 1.1738 - Test Loss: 8.0858 - MSE: 8.0858 - MAE: 2.1413\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8579/20000 - Train Loss: 1.1733 - Test Loss: 8.0846 - MSE: 8.0846 - MAE: 2.1411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8580/20000 - Train Loss: 1.1728 - Test Loss: 8.0835 - MSE: 8.0835 - MAE: 2.1410\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8581/20000 - Train Loss: 1.1724 - Test Loss: 8.0823 - MSE: 8.0823 - MAE: 2.1408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8582/20000 - Train Loss: 1.1719 - Test Loss: 8.0811 - MSE: 8.0811 - MAE: 2.1406\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8583/20000 - Train Loss: 1.1715 - Test Loss: 8.0799 - MSE: 8.0799 - MAE: 2.1404\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 8584/20000 - Train Loss: 1.1710 - Test Loss: 8.0788 - MSE: 8.0788 - MAE: 2.1403\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8585/20000 - Train Loss: 1.1706 - Test Loss: 8.0776 - MSE: 8.0776 - MAE: 2.1401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8586/20000 - Train Loss: 1.1701 - Test Loss: 8.0764 - MSE: 8.0764 - MAE: 2.1399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8587/20000 - Train Loss: 1.1697 - Test Loss: 8.0752 - MSE: 8.0752 - MAE: 2.1397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8588/20000 - Train Loss: 1.1692 - Test Loss: 8.0740 - MSE: 8.0740 - MAE: 2.1396\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8589/20000 - Train Loss: 1.1688 - Test Loss: 8.0729 - MSE: 8.0729 - MAE: 2.1394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8590/20000 - Train Loss: 1.1684 - Test Loss: 8.0717 - MSE: 8.0717 - MAE: 2.1392\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8591/20000 - Train Loss: 1.1679 - Test Loss: 8.0705 - MSE: 8.0705 - MAE: 2.1391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8592/20000 - Train Loss: 1.1675 - Test Loss: 8.0693 - MSE: 8.0693 - MAE: 2.1389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8593/20000 - Train Loss: 1.1670 - Test Loss: 8.0681 - MSE: 8.0681 - MAE: 2.1387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8594/20000 - Train Loss: 1.1666 - Test Loss: 8.0670 - MSE: 8.0670 - MAE: 2.1385\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8595/20000 - Train Loss: 1.1661 - Test Loss: 8.0658 - MSE: 8.0658 - MAE: 2.1384\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8596/20000 - Train Loss: 1.1657 - Test Loss: 8.0646 - MSE: 8.0646 - MAE: 2.1382\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8597/20000 - Train Loss: 1.1652 - Test Loss: 8.0634 - MSE: 8.0634 - MAE: 2.1380\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8598/20000 - Train Loss: 1.1648 - Test Loss: 8.0623 - MSE: 8.0623 - MAE: 2.1378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8599/20000 - Train Loss: 1.1644 - Test Loss: 8.0611 - MSE: 8.0611 - MAE: 2.1377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8600/20000 - Train Loss: 1.1639 - Test Loss: 8.0599 - MSE: 8.0599 - MAE: 2.1375\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8601/20000 - Train Loss: 1.1635 - Test Loss: 8.0587 - MSE: 8.0587 - MAE: 2.1373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8602/20000 - Train Loss: 1.1630 - Test Loss: 8.0576 - MSE: 8.0576 - MAE: 2.1371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8603/20000 - Train Loss: 1.1626 - Test Loss: 8.0565 - MSE: 8.0565 - MAE: 2.1370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8604/20000 - Train Loss: 1.1622 - Test Loss: 8.0553 - MSE: 8.0553 - MAE: 2.1368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8605/20000 - Train Loss: 1.1617 - Test Loss: 8.0541 - MSE: 8.0541 - MAE: 2.1366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8606/20000 - Train Loss: 1.1613 - Test Loss: 8.0529 - MSE: 8.0529 - MAE: 2.1364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8607/20000 - Train Loss: 1.1609 - Test Loss: 8.0518 - MSE: 8.0518 - MAE: 2.1363\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8608/20000 - Train Loss: 1.1604 - Test Loss: 8.0506 - MSE: 8.0506 - MAE: 2.1361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8609/20000 - Train Loss: 1.1600 - Test Loss: 8.0494 - MSE: 8.0494 - MAE: 2.1359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8610/20000 - Train Loss: 1.1595 - Test Loss: 8.0483 - MSE: 8.0483 - MAE: 2.1358\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8611/20000 - Train Loss: 1.1591 - Test Loss: 8.0471 - MSE: 8.0471 - MAE: 2.1356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8612/20000 - Train Loss: 1.1587 - Test Loss: 8.0460 - MSE: 8.0460 - MAE: 2.1354\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8613/20000 - Train Loss: 1.1582 - Test Loss: 8.0448 - MSE: 8.0448 - MAE: 2.1352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8614/20000 - Train Loss: 1.1578 - Test Loss: 8.0436 - MSE: 8.0436 - MAE: 2.1351\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8615/20000 - Train Loss: 1.1574 - Test Loss: 8.0425 - MSE: 8.0425 - MAE: 2.1349\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8616/20000 - Train Loss: 1.1569 - Test Loss: 8.0413 - MSE: 8.0413 - MAE: 2.1347\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8617/20000 - Train Loss: 1.1565 - Test Loss: 8.0402 - MSE: 8.0402 - MAE: 2.1345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8618/20000 - Train Loss: 1.1561 - Test Loss: 8.0390 - MSE: 8.0390 - MAE: 2.1344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8619/20000 - Train Loss: 1.1556 - Test Loss: 8.0379 - MSE: 8.0379 - MAE: 2.1342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8620/20000 - Train Loss: 1.1552 - Test Loss: 8.0367 - MSE: 8.0367 - MAE: 2.1340\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8621/20000 - Train Loss: 1.1548 - Test Loss: 8.0355 - MSE: 8.0355 - MAE: 2.1338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8622/20000 - Train Loss: 1.1544 - Test Loss: 8.0344 - MSE: 8.0344 - MAE: 2.1337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8623/20000 - Train Loss: 1.1539 - Test Loss: 8.0333 - MSE: 8.0333 - MAE: 2.1335\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8624/20000 - Train Loss: 1.1535 - Test Loss: 8.0321 - MSE: 8.0321 - MAE: 2.1333\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8625/20000 - Train Loss: 1.1531 - Test Loss: 8.0308 - MSE: 8.0308 - MAE: 2.1331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8626/20000 - Train Loss: 1.1526 - Test Loss: 8.0297 - MSE: 8.0297 - MAE: 2.1330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8627/20000 - Train Loss: 1.1522 - Test Loss: 8.0286 - MSE: 8.0286 - MAE: 2.1328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8628/20000 - Train Loss: 1.1518 - Test Loss: 8.0275 - MSE: 8.0275 - MAE: 2.1326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8629/20000 - Train Loss: 1.1514 - Test Loss: 8.0263 - MSE: 8.0263 - MAE: 2.1324\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8630/20000 - Train Loss: 1.1509 - Test Loss: 8.0251 - MSE: 8.0251 - MAE: 2.1323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8631/20000 - Train Loss: 1.1505 - Test Loss: 8.0240 - MSE: 8.0240 - MAE: 2.1321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8632/20000 - Train Loss: 1.1501 - Test Loss: 8.0229 - MSE: 8.0229 - MAE: 2.1319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8633/20000 - Train Loss: 1.1497 - Test Loss: 8.0217 - MSE: 8.0217 - MAE: 2.1318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8634/20000 - Train Loss: 1.1492 - Test Loss: 8.0206 - MSE: 8.0206 - MAE: 2.1316\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8635/20000 - Train Loss: 1.1488 - Test Loss: 8.0194 - MSE: 8.0194 - MAE: 2.1314\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 8636/20000 - Train Loss: 1.1484 - Test Loss: 8.0183 - MSE: 8.0183 - MAE: 2.1312\n",
      "2/2 [==============================] - 0s 986us/step\n",
      "Epoch 8637/20000 - Train Loss: 1.1480 - Test Loss: 8.0172 - MSE: 8.0172 - MAE: 2.1311\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8638/20000 - Train Loss: 1.1476 - Test Loss: 8.0160 - MSE: 8.0160 - MAE: 2.1309\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8639/20000 - Train Loss: 1.1471 - Test Loss: 8.0148 - MSE: 8.0148 - MAE: 2.1307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8640/20000 - Train Loss: 1.1467 - Test Loss: 8.0137 - MSE: 8.0137 - MAE: 2.1305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8641/20000 - Train Loss: 1.1463 - Test Loss: 8.0126 - MSE: 8.0126 - MAE: 2.1303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8642/20000 - Train Loss: 1.1459 - Test Loss: 8.0115 - MSE: 8.0115 - MAE: 2.1302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8643/20000 - Train Loss: 1.1455 - Test Loss: 8.0103 - MSE: 8.0103 - MAE: 2.1300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8644/20000 - Train Loss: 1.1450 - Test Loss: 8.0091 - MSE: 8.0091 - MAE: 2.1298\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 8645/20000 - Train Loss: 1.1446 - Test Loss: 8.0080 - MSE: 8.0080 - MAE: 2.1296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8646/20000 - Train Loss: 1.1442 - Test Loss: 8.0069 - MSE: 8.0069 - MAE: 2.1295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8647/20000 - Train Loss: 1.1438 - Test Loss: 8.0058 - MSE: 8.0058 - MAE: 2.1293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8648/20000 - Train Loss: 1.1434 - Test Loss: 8.0046 - MSE: 8.0046 - MAE: 2.1291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8649/20000 - Train Loss: 1.1430 - Test Loss: 8.0034 - MSE: 8.0034 - MAE: 2.1289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8650/20000 - Train Loss: 1.1426 - Test Loss: 8.0023 - MSE: 8.0023 - MAE: 2.1288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8651/20000 - Train Loss: 1.1421 - Test Loss: 8.0012 - MSE: 8.0012 - MAE: 2.1286\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8652/20000 - Train Loss: 1.1417 - Test Loss: 8.0001 - MSE: 8.0001 - MAE: 2.1284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8653/20000 - Train Loss: 1.1413 - Test Loss: 7.9989 - MSE: 7.9989 - MAE: 2.1283\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8654/20000 - Train Loss: 1.1409 - Test Loss: 7.9978 - MSE: 7.9978 - MAE: 2.1281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8655/20000 - Train Loss: 1.1405 - Test Loss: 7.9966 - MSE: 7.9966 - MAE: 2.1279\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8656/20000 - Train Loss: 1.1401 - Test Loss: 7.9955 - MSE: 7.9955 - MAE: 2.1277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8657/20000 - Train Loss: 1.1397 - Test Loss: 7.9944 - MSE: 7.9944 - MAE: 2.1276\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 8658/20000 - Train Loss: 1.1393 - Test Loss: 7.9933 - MSE: 7.9933 - MAE: 2.1274\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 8659/20000 - Train Loss: 1.1388 - Test Loss: 7.9921 - MSE: 7.9921 - MAE: 2.1272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8660/20000 - Train Loss: 1.1384 - Test Loss: 7.9910 - MSE: 7.9910 - MAE: 2.1270\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 8661/20000 - Train Loss: 1.1380 - Test Loss: 7.9899 - MSE: 7.9899 - MAE: 2.1269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8662/20000 - Train Loss: 1.1376 - Test Loss: 7.9887 - MSE: 7.9887 - MAE: 2.1267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8663/20000 - Train Loss: 1.1372 - Test Loss: 7.9876 - MSE: 7.9876 - MAE: 2.1265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8664/20000 - Train Loss: 1.1368 - Test Loss: 7.9864 - MSE: 7.9864 - MAE: 2.1263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8665/20000 - Train Loss: 1.1364 - Test Loss: 7.9853 - MSE: 7.9853 - MAE: 2.1262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8666/20000 - Train Loss: 1.1360 - Test Loss: 7.9842 - MSE: 7.9842 - MAE: 2.1260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8667/20000 - Train Loss: 1.1356 - Test Loss: 7.9831 - MSE: 7.9831 - MAE: 2.1258\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8668/20000 - Train Loss: 1.1352 - Test Loss: 7.9820 - MSE: 7.9820 - MAE: 2.1256\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8669/20000 - Train Loss: 1.1348 - Test Loss: 7.9808 - MSE: 7.9808 - MAE: 2.1254\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 8670/20000 - Train Loss: 1.1344 - Test Loss: 7.9797 - MSE: 7.9797 - MAE: 2.1253\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8671/20000 - Train Loss: 1.1340 - Test Loss: 7.9786 - MSE: 7.9786 - MAE: 2.1251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8672/20000 - Train Loss: 1.1336 - Test Loss: 7.9775 - MSE: 7.9775 - MAE: 2.1249\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8673/20000 - Train Loss: 1.1331 - Test Loss: 7.9763 - MSE: 7.9763 - MAE: 2.1247\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8674/20000 - Train Loss: 1.1327 - Test Loss: 7.9752 - MSE: 7.9752 - MAE: 2.1246\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8675/20000 - Train Loss: 1.1323 - Test Loss: 7.9741 - MSE: 7.9741 - MAE: 2.1244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8676/20000 - Train Loss: 1.1319 - Test Loss: 7.9730 - MSE: 7.9730 - MAE: 2.1242\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8677/20000 - Train Loss: 1.1315 - Test Loss: 7.9719 - MSE: 7.9719 - MAE: 2.1240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8678/20000 - Train Loss: 1.1311 - Test Loss: 7.9707 - MSE: 7.9707 - MAE: 2.1239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8679/20000 - Train Loss: 1.1307 - Test Loss: 7.9696 - MSE: 7.9696 - MAE: 2.1237\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8680/20000 - Train Loss: 1.1303 - Test Loss: 7.9685 - MSE: 7.9685 - MAE: 2.1235\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8681/20000 - Train Loss: 1.1299 - Test Loss: 7.9674 - MSE: 7.9674 - MAE: 2.1234\n",
      "2/2 [==============================] - 0s 985us/step\n",
      "Epoch 8682/20000 - Train Loss: 1.1295 - Test Loss: 7.9663 - MSE: 7.9663 - MAE: 2.1232\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8683/20000 - Train Loss: 1.1291 - Test Loss: 7.9651 - MSE: 7.9651 - MAE: 2.1230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8684/20000 - Train Loss: 1.1287 - Test Loss: 7.9640 - MSE: 7.9640 - MAE: 2.1228\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8685/20000 - Train Loss: 1.1283 - Test Loss: 7.9630 - MSE: 7.9630 - MAE: 2.1227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8686/20000 - Train Loss: 1.1279 - Test Loss: 7.9619 - MSE: 7.9619 - MAE: 2.1225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8687/20000 - Train Loss: 1.1276 - Test Loss: 7.9606 - MSE: 7.9606 - MAE: 2.1223\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8688/20000 - Train Loss: 1.1272 - Test Loss: 7.9595 - MSE: 7.9595 - MAE: 2.1221\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8689/20000 - Train Loss: 1.1268 - Test Loss: 7.9585 - MSE: 7.9585 - MAE: 2.1219\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8690/20000 - Train Loss: 1.1264 - Test Loss: 7.9574 - MSE: 7.9574 - MAE: 2.1218\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8691/20000 - Train Loss: 1.1260 - Test Loss: 7.9563 - MSE: 7.9563 - MAE: 2.1216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8692/20000 - Train Loss: 1.1256 - Test Loss: 7.9551 - MSE: 7.9551 - MAE: 2.1214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8693/20000 - Train Loss: 1.1252 - Test Loss: 7.9540 - MSE: 7.9540 - MAE: 2.1212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8694/20000 - Train Loss: 1.1248 - Test Loss: 7.9529 - MSE: 7.9529 - MAE: 2.1211\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8695/20000 - Train Loss: 1.1244 - Test Loss: 7.9518 - MSE: 7.9518 - MAE: 2.1209\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8696/20000 - Train Loss: 1.1240 - Test Loss: 7.9507 - MSE: 7.9507 - MAE: 2.1207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8697/20000 - Train Loss: 1.1236 - Test Loss: 7.9496 - MSE: 7.9496 - MAE: 2.1205\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8698/20000 - Train Loss: 1.1232 - Test Loss: 7.9484 - MSE: 7.9484 - MAE: 2.1203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8699/20000 - Train Loss: 1.1228 - Test Loss: 7.9473 - MSE: 7.9473 - MAE: 2.1202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8700/20000 - Train Loss: 1.1224 - Test Loss: 7.9463 - MSE: 7.9463 - MAE: 2.1200\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8701/20000 - Train Loss: 1.1220 - Test Loss: 7.9452 - MSE: 7.9452 - MAE: 2.1198\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8702/20000 - Train Loss: 1.1217 - Test Loss: 7.9440 - MSE: 7.9440 - MAE: 2.1196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8703/20000 - Train Loss: 1.1213 - Test Loss: 7.9429 - MSE: 7.9429 - MAE: 2.1195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8704/20000 - Train Loss: 1.1209 - Test Loss: 7.9418 - MSE: 7.9418 - MAE: 2.1193\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch 8705/20000 - Train Loss: 1.1205 - Test Loss: 7.9407 - MSE: 7.9407 - MAE: 2.1191\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8706/20000 - Train Loss: 1.1201 - Test Loss: 7.9396 - MSE: 7.9396 - MAE: 2.1190\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8707/20000 - Train Loss: 1.1197 - Test Loss: 7.9385 - MSE: 7.9385 - MAE: 2.1188\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8708/20000 - Train Loss: 1.1193 - Test Loss: 7.9374 - MSE: 7.9374 - MAE: 2.1186\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8709/20000 - Train Loss: 1.1189 - Test Loss: 7.9363 - MSE: 7.9363 - MAE: 2.1184\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8710/20000 - Train Loss: 1.1186 - Test Loss: 7.9352 - MSE: 7.9352 - MAE: 2.1182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8711/20000 - Train Loss: 1.1182 - Test Loss: 7.9342 - MSE: 7.9342 - MAE: 2.1181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8712/20000 - Train Loss: 1.1178 - Test Loss: 7.9330 - MSE: 7.9330 - MAE: 2.1179\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 8713/20000 - Train Loss: 1.1174 - Test Loss: 7.9319 - MSE: 7.9319 - MAE: 2.1177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8714/20000 - Train Loss: 1.1170 - Test Loss: 7.9308 - MSE: 7.9308 - MAE: 2.1175\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8715/20000 - Train Loss: 1.1166 - Test Loss: 7.9298 - MSE: 7.9298 - MAE: 2.1174\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8716/20000 - Train Loss: 1.1163 - Test Loss: 7.9286 - MSE: 7.9286 - MAE: 2.1172\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8717/20000 - Train Loss: 1.1159 - Test Loss: 7.9275 - MSE: 7.9275 - MAE: 2.1170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8718/20000 - Train Loss: 1.1155 - Test Loss: 7.9264 - MSE: 7.9264 - MAE: 2.1168\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8719/20000 - Train Loss: 1.1151 - Test Loss: 7.9253 - MSE: 7.9253 - MAE: 2.1167\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8720/20000 - Train Loss: 1.1147 - Test Loss: 7.9242 - MSE: 7.9242 - MAE: 2.1165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8721/20000 - Train Loss: 1.1143 - Test Loss: 7.9231 - MSE: 7.9231 - MAE: 2.1163\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 8722/20000 - Train Loss: 1.1140 - Test Loss: 7.9221 - MSE: 7.9221 - MAE: 2.1161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8723/20000 - Train Loss: 1.1136 - Test Loss: 7.9209 - MSE: 7.9209 - MAE: 2.1159\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8724/20000 - Train Loss: 1.1132 - Test Loss: 7.9199 - MSE: 7.9199 - MAE: 2.1158\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8725/20000 - Train Loss: 1.1128 - Test Loss: 7.9188 - MSE: 7.9188 - MAE: 2.1156\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8726/20000 - Train Loss: 1.1124 - Test Loss: 7.9177 - MSE: 7.9177 - MAE: 2.1154\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8727/20000 - Train Loss: 1.1121 - Test Loss: 7.9166 - MSE: 7.9166 - MAE: 2.1152\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8728/20000 - Train Loss: 1.1117 - Test Loss: 7.9155 - MSE: 7.9155 - MAE: 2.1151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8729/20000 - Train Loss: 1.1113 - Test Loss: 7.9144 - MSE: 7.9144 - MAE: 2.1149\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8730/20000 - Train Loss: 1.1109 - Test Loss: 7.9133 - MSE: 7.9133 - MAE: 2.1147\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8731/20000 - Train Loss: 1.1106 - Test Loss: 7.9122 - MSE: 7.9122 - MAE: 2.1145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8732/20000 - Train Loss: 1.1102 - Test Loss: 7.9111 - MSE: 7.9111 - MAE: 2.1144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8733/20000 - Train Loss: 1.1098 - Test Loss: 7.9100 - MSE: 7.9100 - MAE: 2.1142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8734/20000 - Train Loss: 1.1094 - Test Loss: 7.9089 - MSE: 7.9089 - MAE: 2.1140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8735/20000 - Train Loss: 1.1091 - Test Loss: 7.9079 - MSE: 7.9079 - MAE: 2.1138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8736/20000 - Train Loss: 1.1087 - Test Loss: 7.9068 - MSE: 7.9068 - MAE: 2.1137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8737/20000 - Train Loss: 1.1083 - Test Loss: 7.9056 - MSE: 7.9056 - MAE: 2.1135\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8738/20000 - Train Loss: 1.1079 - Test Loss: 7.9046 - MSE: 7.9046 - MAE: 2.1133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8739/20000 - Train Loss: 1.1076 - Test Loss: 7.9035 - MSE: 7.9035 - MAE: 2.1131\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8740/20000 - Train Loss: 1.1072 - Test Loss: 7.9024 - MSE: 7.9024 - MAE: 2.1129\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8741/20000 - Train Loss: 1.1068 - Test Loss: 7.9013 - MSE: 7.9013 - MAE: 2.1128\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8742/20000 - Train Loss: 1.1065 - Test Loss: 7.9003 - MSE: 7.9003 - MAE: 2.1126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8743/20000 - Train Loss: 1.1061 - Test Loss: 7.8992 - MSE: 7.8992 - MAE: 2.1124\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8744/20000 - Train Loss: 1.1057 - Test Loss: 7.8981 - MSE: 7.8981 - MAE: 2.1122\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8745/20000 - Train Loss: 1.1053 - Test Loss: 7.8970 - MSE: 7.8970 - MAE: 2.1121\n",
      "2/2 [==============================] - 0s 965us/step\n",
      "Epoch 8746/20000 - Train Loss: 1.1050 - Test Loss: 7.8959 - MSE: 7.8959 - MAE: 2.1119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8747/20000 - Train Loss: 1.1046 - Test Loss: 7.8948 - MSE: 7.8948 - MAE: 2.1117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8748/20000 - Train Loss: 1.1042 - Test Loss: 7.8937 - MSE: 7.8937 - MAE: 2.1115\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8749/20000 - Train Loss: 1.1039 - Test Loss: 7.8926 - MSE: 7.8926 - MAE: 2.1113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8750/20000 - Train Loss: 1.1035 - Test Loss: 7.8916 - MSE: 7.8916 - MAE: 2.1112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8751/20000 - Train Loss: 1.1031 - Test Loss: 7.8906 - MSE: 7.8906 - MAE: 2.1110\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8752/20000 - Train Loss: 1.1028 - Test Loss: 7.8894 - MSE: 7.8894 - MAE: 2.1108\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 8753/20000 - Train Loss: 1.1024 - Test Loss: 7.8883 - MSE: 7.8883 - MAE: 2.1106\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8754/20000 - Train Loss: 1.1020 - Test Loss: 7.8873 - MSE: 7.8873 - MAE: 2.1105\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8755/20000 - Train Loss: 1.1017 - Test Loss: 7.8862 - MSE: 7.8862 - MAE: 2.1103\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8756/20000 - Train Loss: 1.1013 - Test Loss: 7.8852 - MSE: 7.8852 - MAE: 2.1101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8757/20000 - Train Loss: 1.1009 - Test Loss: 7.8841 - MSE: 7.8841 - MAE: 2.1099\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8758/20000 - Train Loss: 1.1006 - Test Loss: 7.8829 - MSE: 7.8829 - MAE: 2.1098\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8759/20000 - Train Loss: 1.1002 - Test Loss: 7.8819 - MSE: 7.8819 - MAE: 2.1096\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8760/20000 - Train Loss: 1.0998 - Test Loss: 7.8808 - MSE: 7.8808 - MAE: 2.1094\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8761/20000 - Train Loss: 1.0995 - Test Loss: 7.8798 - MSE: 7.8798 - MAE: 2.1092\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8762/20000 - Train Loss: 1.0991 - Test Loss: 7.8787 - MSE: 7.8787 - MAE: 2.1090\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8763/20000 - Train Loss: 1.0987 - Test Loss: 7.8775 - MSE: 7.8776 - MAE: 2.1089\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8764/20000 - Train Loss: 1.0984 - Test Loss: 7.8765 - MSE: 7.8765 - MAE: 2.1087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8765/20000 - Train Loss: 1.0980 - Test Loss: 7.8755 - MSE: 7.8755 - MAE: 2.1085\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8766/20000 - Train Loss: 1.0977 - Test Loss: 7.8744 - MSE: 7.8744 - MAE: 2.1083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8767/20000 - Train Loss: 1.0973 - Test Loss: 7.8733 - MSE: 7.8733 - MAE: 2.1082\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8768/20000 - Train Loss: 1.0969 - Test Loss: 7.8722 - MSE: 7.8722 - MAE: 2.1080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8769/20000 - Train Loss: 1.0966 - Test Loss: 7.8711 - MSE: 7.8711 - MAE: 2.1078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8770/20000 - Train Loss: 1.0962 - Test Loss: 7.8701 - MSE: 7.8701 - MAE: 2.1076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8771/20000 - Train Loss: 1.0959 - Test Loss: 7.8690 - MSE: 7.8690 - MAE: 2.1075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8772/20000 - Train Loss: 1.0955 - Test Loss: 7.8679 - MSE: 7.8679 - MAE: 2.1073\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8773/20000 - Train Loss: 1.0951 - Test Loss: 7.8669 - MSE: 7.8669 - MAE: 2.1071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8774/20000 - Train Loss: 1.0948 - Test Loss: 7.8658 - MSE: 7.8658 - MAE: 2.1069\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8775/20000 - Train Loss: 1.0944 - Test Loss: 7.8647 - MSE: 7.8647 - MAE: 2.1067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8776/20000 - Train Loss: 1.0941 - Test Loss: 7.8637 - MSE: 7.8637 - MAE: 2.1066\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8777/20000 - Train Loss: 1.0937 - Test Loss: 7.8626 - MSE: 7.8626 - MAE: 2.1064\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8778/20000 - Train Loss: 1.0934 - Test Loss: 7.8615 - MSE: 7.8615 - MAE: 2.1062\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8779/20000 - Train Loss: 1.0930 - Test Loss: 7.8604 - MSE: 7.8604 - MAE: 2.1060\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8780/20000 - Train Loss: 1.0926 - Test Loss: 7.8594 - MSE: 7.8594 - MAE: 2.1059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8781/20000 - Train Loss: 1.0923 - Test Loss: 7.8583 - MSE: 7.8583 - MAE: 2.1057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8782/20000 - Train Loss: 1.0919 - Test Loss: 7.8573 - MSE: 7.8573 - MAE: 2.1055\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8783/20000 - Train Loss: 1.0916 - Test Loss: 7.8562 - MSE: 7.8562 - MAE: 2.1053\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 8784/20000 - Train Loss: 1.0912 - Test Loss: 7.8551 - MSE: 7.8551 - MAE: 2.1051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8785/20000 - Train Loss: 1.0909 - Test Loss: 7.8541 - MSE: 7.8541 - MAE: 2.1050\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8786/20000 - Train Loss: 1.0905 - Test Loss: 7.8530 - MSE: 7.8530 - MAE: 2.1048\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8787/20000 - Train Loss: 1.0902 - Test Loss: 7.8519 - MSE: 7.8519 - MAE: 2.1046\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8788/20000 - Train Loss: 1.0898 - Test Loss: 7.8509 - MSE: 7.8509 - MAE: 2.1044\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8789/20000 - Train Loss: 1.0895 - Test Loss: 7.8498 - MSE: 7.8498 - MAE: 2.1043\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 8790/20000 - Train Loss: 1.0891 - Test Loss: 7.8487 - MSE: 7.8487 - MAE: 2.1041\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8791/20000 - Train Loss: 1.0888 - Test Loss: 7.8477 - MSE: 7.8477 - MAE: 2.1039\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8792/20000 - Train Loss: 1.0884 - Test Loss: 7.8466 - MSE: 7.8466 - MAE: 2.1037\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8793/20000 - Train Loss: 1.0881 - Test Loss: 7.8456 - MSE: 7.8456 - MAE: 2.1035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8794/20000 - Train Loss: 1.0877 - Test Loss: 7.8445 - MSE: 7.8445 - MAE: 2.1034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8795/20000 - Train Loss: 1.0874 - Test Loss: 7.8434 - MSE: 7.8434 - MAE: 2.1032\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8796/20000 - Train Loss: 1.0870 - Test Loss: 7.8424 - MSE: 7.8424 - MAE: 2.1030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8797/20000 - Train Loss: 1.0867 - Test Loss: 7.8413 - MSE: 7.8413 - MAE: 2.1028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8798/20000 - Train Loss: 1.0863 - Test Loss: 7.8403 - MSE: 7.8403 - MAE: 2.1026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8799/20000 - Train Loss: 1.0860 - Test Loss: 7.8392 - MSE: 7.8392 - MAE: 2.1025\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8800/20000 - Train Loss: 1.0856 - Test Loss: 7.8382 - MSE: 7.8382 - MAE: 2.1023\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8801/20000 - Train Loss: 1.0853 - Test Loss: 7.8371 - MSE: 7.8371 - MAE: 2.1021\n",
      "2/2 [==============================] - 0s 976us/step\n",
      "Epoch 8802/20000 - Train Loss: 1.0849 - Test Loss: 7.8360 - MSE: 7.8360 - MAE: 2.1019\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8803/20000 - Train Loss: 1.0846 - Test Loss: 7.8350 - MSE: 7.8350 - MAE: 2.1018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8804/20000 - Train Loss: 1.0842 - Test Loss: 7.8339 - MSE: 7.8339 - MAE: 2.1016\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8805/20000 - Train Loss: 1.0839 - Test Loss: 7.8328 - MSE: 7.8328 - MAE: 2.1014\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8806/20000 - Train Loss: 1.0835 - Test Loss: 7.8318 - MSE: 7.8318 - MAE: 2.1012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8807/20000 - Train Loss: 1.0832 - Test Loss: 7.8308 - MSE: 7.8308 - MAE: 2.1010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8808/20000 - Train Loss: 1.0829 - Test Loss: 7.8297 - MSE: 7.8297 - MAE: 2.1009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8809/20000 - Train Loss: 1.0825 - Test Loss: 7.8286 - MSE: 7.8286 - MAE: 2.1007\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8810/20000 - Train Loss: 1.0822 - Test Loss: 7.8276 - MSE: 7.8276 - MAE: 2.1005\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8811/20000 - Train Loss: 1.0818 - Test Loss: 7.8265 - MSE: 7.8265 - MAE: 2.1003\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8812/20000 - Train Loss: 1.0815 - Test Loss: 7.8255 - MSE: 7.8255 - MAE: 2.1002\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8813/20000 - Train Loss: 1.0811 - Test Loss: 7.8245 - MSE: 7.8245 - MAE: 2.1000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8814/20000 - Train Loss: 1.0808 - Test Loss: 7.8234 - MSE: 7.8234 - MAE: 2.0998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8815/20000 - Train Loss: 1.0805 - Test Loss: 7.8223 - MSE: 7.8223 - MAE: 2.0996\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8816/20000 - Train Loss: 1.0801 - Test Loss: 7.8213 - MSE: 7.8213 - MAE: 2.0994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8817/20000 - Train Loss: 1.0798 - Test Loss: 7.8202 - MSE: 7.8202 - MAE: 2.0993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8818/20000 - Train Loss: 1.0794 - Test Loss: 7.8192 - MSE: 7.8192 - MAE: 2.0991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8819/20000 - Train Loss: 1.0791 - Test Loss: 7.8181 - MSE: 7.8181 - MAE: 2.0989\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8820/20000 - Train Loss: 1.0788 - Test Loss: 7.8171 - MSE: 7.8171 - MAE: 2.0987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8821/20000 - Train Loss: 1.0784 - Test Loss: 7.8160 - MSE: 7.8160 - MAE: 2.0986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8822/20000 - Train Loss: 1.0781 - Test Loss: 7.8150 - MSE: 7.8150 - MAE: 2.0984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8823/20000 - Train Loss: 1.0777 - Test Loss: 7.8139 - MSE: 7.8139 - MAE: 2.0982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8824/20000 - Train Loss: 1.0774 - Test Loss: 7.8129 - MSE: 7.8129 - MAE: 2.0980\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 8825/20000 - Train Loss: 1.0771 - Test Loss: 7.8119 - MSE: 7.8119 - MAE: 2.0978\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8826/20000 - Train Loss: 1.0767 - Test Loss: 7.8108 - MSE: 7.8108 - MAE: 2.0977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8827/20000 - Train Loss: 1.0764 - Test Loss: 7.8097 - MSE: 7.8097 - MAE: 2.0975\n",
      "2/2 [==============================] - 0s 985us/step\n",
      "Epoch 8828/20000 - Train Loss: 1.0761 - Test Loss: 7.8087 - MSE: 7.8087 - MAE: 2.0973\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8829/20000 - Train Loss: 1.0757 - Test Loss: 7.8077 - MSE: 7.8077 - MAE: 2.0971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8830/20000 - Train Loss: 1.0754 - Test Loss: 7.8066 - MSE: 7.8066 - MAE: 2.0969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8831/20000 - Train Loss: 1.0750 - Test Loss: 7.8056 - MSE: 7.8056 - MAE: 2.0968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8832/20000 - Train Loss: 1.0747 - Test Loss: 7.8045 - MSE: 7.8045 - MAE: 2.0966\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8833/20000 - Train Loss: 1.0744 - Test Loss: 7.8034 - MSE: 7.8034 - MAE: 2.0964\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 8834/20000 - Train Loss: 1.0740 - Test Loss: 7.8024 - MSE: 7.8024 - MAE: 2.0962\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8835/20000 - Train Loss: 1.0737 - Test Loss: 7.8014 - MSE: 7.8014 - MAE: 2.0961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8836/20000 - Train Loss: 1.0734 - Test Loss: 7.8003 - MSE: 7.8003 - MAE: 2.0959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8837/20000 - Train Loss: 1.0730 - Test Loss: 7.7993 - MSE: 7.7993 - MAE: 2.0957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8838/20000 - Train Loss: 1.0727 - Test Loss: 7.7983 - MSE: 7.7983 - MAE: 2.0955\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 8839/20000 - Train Loss: 1.0724 - Test Loss: 7.7972 - MSE: 7.7972 - MAE: 2.0953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8840/20000 - Train Loss: 1.0720 - Test Loss: 7.7962 - MSE: 7.7962 - MAE: 2.0951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8841/20000 - Train Loss: 1.0717 - Test Loss: 7.7951 - MSE: 7.7951 - MAE: 2.0950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8842/20000 - Train Loss: 1.0714 - Test Loss: 7.7941 - MSE: 7.7941 - MAE: 2.0948\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8843/20000 - Train Loss: 1.0711 - Test Loss: 7.7931 - MSE: 7.7931 - MAE: 2.0946\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8844/20000 - Train Loss: 1.0707 - Test Loss: 7.7920 - MSE: 7.7920 - MAE: 2.0944\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8845/20000 - Train Loss: 1.0704 - Test Loss: 7.7910 - MSE: 7.7910 - MAE: 2.0943\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8846/20000 - Train Loss: 1.0701 - Test Loss: 7.7900 - MSE: 7.7900 - MAE: 2.0941\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 8847/20000 - Train Loss: 1.0697 - Test Loss: 7.7889 - MSE: 7.7889 - MAE: 2.0939\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 8848/20000 - Train Loss: 1.0694 - Test Loss: 7.7878 - MSE: 7.7878 - MAE: 2.0937\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8849/20000 - Train Loss: 1.0691 - Test Loss: 7.7868 - MSE: 7.7868 - MAE: 2.0935\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8850/20000 - Train Loss: 1.0687 - Test Loss: 7.7858 - MSE: 7.7858 - MAE: 2.0934\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8851/20000 - Train Loss: 1.0684 - Test Loss: 7.7847 - MSE: 7.7847 - MAE: 2.0932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8852/20000 - Train Loss: 1.0681 - Test Loss: 7.7837 - MSE: 7.7837 - MAE: 2.0930\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8853/20000 - Train Loss: 1.0678 - Test Loss: 7.7827 - MSE: 7.7827 - MAE: 2.0928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8854/20000 - Train Loss: 1.0674 - Test Loss: 7.7816 - MSE: 7.7816 - MAE: 2.0926\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8855/20000 - Train Loss: 1.0671 - Test Loss: 7.7806 - MSE: 7.7806 - MAE: 2.0925\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8856/20000 - Train Loss: 1.0668 - Test Loss: 7.7796 - MSE: 7.7796 - MAE: 2.0923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8857/20000 - Train Loss: 1.0665 - Test Loss: 7.7785 - MSE: 7.7785 - MAE: 2.0921\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8858/20000 - Train Loss: 1.0661 - Test Loss: 7.7775 - MSE: 7.7775 - MAE: 2.0919\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8859/20000 - Train Loss: 1.0658 - Test Loss: 7.7765 - MSE: 7.7765 - MAE: 2.0918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8860/20000 - Train Loss: 1.0655 - Test Loss: 7.7754 - MSE: 7.7754 - MAE: 2.0916\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8861/20000 - Train Loss: 1.0652 - Test Loss: 7.7744 - MSE: 7.7744 - MAE: 2.0914\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8862/20000 - Train Loss: 1.0648 - Test Loss: 7.7733 - MSE: 7.7733 - MAE: 2.0912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8863/20000 - Train Loss: 1.0645 - Test Loss: 7.7724 - MSE: 7.7724 - MAE: 2.0910\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8864/20000 - Train Loss: 1.0642 - Test Loss: 7.7713 - MSE: 7.7713 - MAE: 2.0909\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8865/20000 - Train Loss: 1.0639 - Test Loss: 7.7702 - MSE: 7.7702 - MAE: 2.0907\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8866/20000 - Train Loss: 1.0635 - Test Loss: 7.7692 - MSE: 7.7692 - MAE: 2.0905\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8867/20000 - Train Loss: 1.0632 - Test Loss: 7.7682 - MSE: 7.7682 - MAE: 2.0903\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8868/20000 - Train Loss: 1.0629 - Test Loss: 7.7672 - MSE: 7.7672 - MAE: 2.0901\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8869/20000 - Train Loss: 1.0626 - Test Loss: 7.7661 - MSE: 7.7661 - MAE: 2.0900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8870/20000 - Train Loss: 1.0622 - Test Loss: 7.7650 - MSE: 7.7650 - MAE: 2.0898\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8871/20000 - Train Loss: 1.0619 - Test Loss: 7.7641 - MSE: 7.7641 - MAE: 2.0896\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8872/20000 - Train Loss: 1.0616 - Test Loss: 7.7631 - MSE: 7.7631 - MAE: 2.0894\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8873/20000 - Train Loss: 1.0613 - Test Loss: 7.7620 - MSE: 7.7620 - MAE: 2.0892\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8874/20000 - Train Loss: 1.0610 - Test Loss: 7.7610 - MSE: 7.7610 - MAE: 2.0891\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8875/20000 - Train Loss: 1.0606 - Test Loss: 7.7599 - MSE: 7.7599 - MAE: 2.0889\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8876/20000 - Train Loss: 1.0603 - Test Loss: 7.7589 - MSE: 7.7589 - MAE: 2.0887\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8877/20000 - Train Loss: 1.0600 - Test Loss: 7.7579 - MSE: 7.7579 - MAE: 2.0885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8878/20000 - Train Loss: 1.0597 - Test Loss: 7.7569 - MSE: 7.7569 - MAE: 2.0883\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8879/20000 - Train Loss: 1.0594 - Test Loss: 7.7558 - MSE: 7.7558 - MAE: 2.0882\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8880/20000 - Train Loss: 1.0591 - Test Loss: 7.7548 - MSE: 7.7548 - MAE: 2.0880\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8881/20000 - Train Loss: 1.0587 - Test Loss: 7.7538 - MSE: 7.7538 - MAE: 2.0878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8882/20000 - Train Loss: 1.0584 - Test Loss: 7.7528 - MSE: 7.7528 - MAE: 2.0876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8883/20000 - Train Loss: 1.0581 - Test Loss: 7.7517 - MSE: 7.7517 - MAE: 2.0874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8884/20000 - Train Loss: 1.0578 - Test Loss: 7.7507 - MSE: 7.7507 - MAE: 2.0873\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8885/20000 - Train Loss: 1.0575 - Test Loss: 7.7497 - MSE: 7.7497 - MAE: 2.0871\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8886/20000 - Train Loss: 1.0572 - Test Loss: 7.7487 - MSE: 7.7487 - MAE: 2.0869\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8887/20000 - Train Loss: 1.0568 - Test Loss: 7.7477 - MSE: 7.7477 - MAE: 2.0867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8888/20000 - Train Loss: 1.0565 - Test Loss: 7.7466 - MSE: 7.7466 - MAE: 2.0865\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8889/20000 - Train Loss: 1.0562 - Test Loss: 7.7456 - MSE: 7.7456 - MAE: 2.0864\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8890/20000 - Train Loss: 1.0559 - Test Loss: 7.7446 - MSE: 7.7446 - MAE: 2.0862\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8891/20000 - Train Loss: 1.0556 - Test Loss: 7.7436 - MSE: 7.7436 - MAE: 2.0860\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8892/20000 - Train Loss: 1.0553 - Test Loss: 7.7425 - MSE: 7.7425 - MAE: 2.0858\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8893/20000 - Train Loss: 1.0550 - Test Loss: 7.7415 - MSE: 7.7415 - MAE: 2.0856\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8894/20000 - Train Loss: 1.0546 - Test Loss: 7.7405 - MSE: 7.7405 - MAE: 2.0855\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8895/20000 - Train Loss: 1.0543 - Test Loss: 7.7395 - MSE: 7.7395 - MAE: 2.0853\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8896/20000 - Train Loss: 1.0540 - Test Loss: 7.7384 - MSE: 7.7384 - MAE: 2.0851\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8897/20000 - Train Loss: 1.0537 - Test Loss: 7.7374 - MSE: 7.7374 - MAE: 2.0849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8898/20000 - Train Loss: 1.0534 - Test Loss: 7.7364 - MSE: 7.7364 - MAE: 2.0847\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8899/20000 - Train Loss: 1.0531 - Test Loss: 7.7353 - MSE: 7.7353 - MAE: 2.0846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8900/20000 - Train Loss: 1.0528 - Test Loss: 7.7344 - MSE: 7.7344 - MAE: 2.0844\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8901/20000 - Train Loss: 1.0525 - Test Loss: 7.7333 - MSE: 7.7333 - MAE: 2.0842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8902/20000 - Train Loss: 1.0522 - Test Loss: 7.7323 - MSE: 7.7323 - MAE: 2.0840\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8903/20000 - Train Loss: 1.0518 - Test Loss: 7.7313 - MSE: 7.7313 - MAE: 2.0838\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8904/20000 - Train Loss: 1.0515 - Test Loss: 7.7303 - MSE: 7.7303 - MAE: 2.0837\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8905/20000 - Train Loss: 1.0512 - Test Loss: 7.7293 - MSE: 7.7293 - MAE: 2.0835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8906/20000 - Train Loss: 1.0509 - Test Loss: 7.7282 - MSE: 7.7282 - MAE: 2.0833\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8907/20000 - Train Loss: 1.0506 - Test Loss: 7.7272 - MSE: 7.7272 - MAE: 2.0831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8908/20000 - Train Loss: 1.0503 - Test Loss: 7.7262 - MSE: 7.7262 - MAE: 2.0830\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8909/20000 - Train Loss: 1.0500 - Test Loss: 7.7252 - MSE: 7.7252 - MAE: 2.0828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8910/20000 - Train Loss: 1.0497 - Test Loss: 7.7242 - MSE: 7.7242 - MAE: 2.0826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8911/20000 - Train Loss: 1.0494 - Test Loss: 7.7231 - MSE: 7.7231 - MAE: 2.0824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8912/20000 - Train Loss: 1.0491 - Test Loss: 7.7221 - MSE: 7.7221 - MAE: 2.0822\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8913/20000 - Train Loss: 1.0488 - Test Loss: 7.7211 - MSE: 7.7211 - MAE: 2.0820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8914/20000 - Train Loss: 1.0485 - Test Loss: 7.7201 - MSE: 7.7201 - MAE: 2.0819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8915/20000 - Train Loss: 1.0481 - Test Loss: 7.7191 - MSE: 7.7191 - MAE: 2.0817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8916/20000 - Train Loss: 1.0478 - Test Loss: 7.7181 - MSE: 7.7181 - MAE: 2.0815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8917/20000 - Train Loss: 1.0475 - Test Loss: 7.7170 - MSE: 7.7170 - MAE: 2.0813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8918/20000 - Train Loss: 1.0472 - Test Loss: 7.7160 - MSE: 7.7160 - MAE: 2.0811\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8919/20000 - Train Loss: 1.0469 - Test Loss: 7.7150 - MSE: 7.7150 - MAE: 2.0810\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8920/20000 - Train Loss: 1.0466 - Test Loss: 7.7140 - MSE: 7.7140 - MAE: 2.0808\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8921/20000 - Train Loss: 1.0463 - Test Loss: 7.7130 - MSE: 7.7130 - MAE: 2.0806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8922/20000 - Train Loss: 1.0460 - Test Loss: 7.7119 - MSE: 7.7119 - MAE: 2.0804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8923/20000 - Train Loss: 1.0457 - Test Loss: 7.7109 - MSE: 7.7109 - MAE: 2.0802\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8924/20000 - Train Loss: 1.0454 - Test Loss: 7.7099 - MSE: 7.7099 - MAE: 2.0801\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8925/20000 - Train Loss: 1.0451 - Test Loss: 7.7090 - MSE: 7.7090 - MAE: 2.0799\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8926/20000 - Train Loss: 1.0448 - Test Loss: 7.7079 - MSE: 7.7079 - MAE: 2.0797\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8927/20000 - Train Loss: 1.0445 - Test Loss: 7.7068 - MSE: 7.7068 - MAE: 2.0795\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8928/20000 - Train Loss: 1.0442 - Test Loss: 7.7059 - MSE: 7.7059 - MAE: 2.0793\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 8929/20000 - Train Loss: 1.0439 - Test Loss: 7.7049 - MSE: 7.7049 - MAE: 2.0792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8930/20000 - Train Loss: 1.0436 - Test Loss: 7.7039 - MSE: 7.7039 - MAE: 2.0790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8931/20000 - Train Loss: 1.0433 - Test Loss: 7.7029 - MSE: 7.7029 - MAE: 2.0788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8932/20000 - Train Loss: 1.0430 - Test Loss: 7.7018 - MSE: 7.7018 - MAE: 2.0786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8933/20000 - Train Loss: 1.0427 - Test Loss: 7.7008 - MSE: 7.7008 - MAE: 2.0784\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 8934/20000 - Train Loss: 1.0424 - Test Loss: 7.6999 - MSE: 7.6999 - MAE: 2.0783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8935/20000 - Train Loss: 1.0421 - Test Loss: 7.6989 - MSE: 7.6989 - MAE: 2.0781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8936/20000 - Train Loss: 1.0418 - Test Loss: 7.6978 - MSE: 7.6978 - MAE: 2.0779\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8937/20000 - Train Loss: 1.0415 - Test Loss: 7.6968 - MSE: 7.6968 - MAE: 2.0777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8938/20000 - Train Loss: 1.0412 - Test Loss: 7.6958 - MSE: 7.6958 - MAE: 2.0775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8939/20000 - Train Loss: 1.0409 - Test Loss: 7.6948 - MSE: 7.6948 - MAE: 2.0774\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8940/20000 - Train Loss: 1.0406 - Test Loss: 7.6938 - MSE: 7.6938 - MAE: 2.0772\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8941/20000 - Train Loss: 1.0403 - Test Loss: 7.6927 - MSE: 7.6927 - MAE: 2.0770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8942/20000 - Train Loss: 1.0400 - Test Loss: 7.6917 - MSE: 7.6917 - MAE: 2.0768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8943/20000 - Train Loss: 1.0397 - Test Loss: 7.6908 - MSE: 7.6908 - MAE: 2.0766\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8944/20000 - Train Loss: 1.0394 - Test Loss: 7.6898 - MSE: 7.6898 - MAE: 2.0765\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8945/20000 - Train Loss: 1.0391 - Test Loss: 7.6887 - MSE: 7.6887 - MAE: 2.0763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8946/20000 - Train Loss: 1.0388 - Test Loss: 7.6877 - MSE: 7.6877 - MAE: 2.0761\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8947/20000 - Train Loss: 1.0385 - Test Loss: 7.6867 - MSE: 7.6867 - MAE: 2.0759\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 8948/20000 - Train Loss: 1.0382 - Test Loss: 7.6857 - MSE: 7.6857 - MAE: 2.0757\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8949/20000 - Train Loss: 1.0379 - Test Loss: 7.6847 - MSE: 7.6847 - MAE: 2.0756\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8950/20000 - Train Loss: 1.0376 - Test Loss: 7.6837 - MSE: 7.6837 - MAE: 2.0754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8951/20000 - Train Loss: 1.0373 - Test Loss: 7.6827 - MSE: 7.6827 - MAE: 2.0752\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8952/20000 - Train Loss: 1.0370 - Test Loss: 7.6817 - MSE: 7.6817 - MAE: 2.0750\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8953/20000 - Train Loss: 1.0367 - Test Loss: 7.6807 - MSE: 7.6807 - MAE: 2.0748\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8954/20000 - Train Loss: 1.0365 - Test Loss: 7.6797 - MSE: 7.6797 - MAE: 2.0746\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8955/20000 - Train Loss: 1.0362 - Test Loss: 7.6786 - MSE: 7.6786 - MAE: 2.0745\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 8956/20000 - Train Loss: 1.0359 - Test Loss: 7.6777 - MSE: 7.6777 - MAE: 2.0743\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8957/20000 - Train Loss: 1.0356 - Test Loss: 7.6767 - MSE: 7.6767 - MAE: 2.0741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8958/20000 - Train Loss: 1.0353 - Test Loss: 7.6757 - MSE: 7.6757 - MAE: 2.0739\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8959/20000 - Train Loss: 1.0350 - Test Loss: 7.6746 - MSE: 7.6746 - MAE: 2.0737\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8960/20000 - Train Loss: 1.0347 - Test Loss: 7.6736 - MSE: 7.6736 - MAE: 2.0736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8961/20000 - Train Loss: 1.0344 - Test Loss: 7.6726 - MSE: 7.6726 - MAE: 2.0734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8962/20000 - Train Loss: 1.0341 - Test Loss: 7.6717 - MSE: 7.6717 - MAE: 2.0732\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8963/20000 - Train Loss: 1.0338 - Test Loss: 7.6707 - MSE: 7.6707 - MAE: 2.0730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8964/20000 - Train Loss: 1.0335 - Test Loss: 7.6696 - MSE: 7.6696 - MAE: 2.0728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8965/20000 - Train Loss: 1.0332 - Test Loss: 7.6686 - MSE: 7.6686 - MAE: 2.0727\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 8966/20000 - Train Loss: 1.0330 - Test Loss: 7.6677 - MSE: 7.6677 - MAE: 2.0725\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8967/20000 - Train Loss: 1.0327 - Test Loss: 7.6667 - MSE: 7.6667 - MAE: 2.0723\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 8968/20000 - Train Loss: 1.0324 - Test Loss: 7.6656 - MSE: 7.6656 - MAE: 2.0721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8969/20000 - Train Loss: 1.0321 - Test Loss: 7.6646 - MSE: 7.6646 - MAE: 2.0719\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 8970/20000 - Train Loss: 1.0318 - Test Loss: 7.6636 - MSE: 7.6636 - MAE: 2.0718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8971/20000 - Train Loss: 1.0315 - Test Loss: 7.6627 - MSE: 7.6627 - MAE: 2.0716\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8972/20000 - Train Loss: 1.0312 - Test Loss: 7.6616 - MSE: 7.6616 - MAE: 2.0714\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8973/20000 - Train Loss: 1.0309 - Test Loss: 7.6606 - MSE: 7.6606 - MAE: 2.0712\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8974/20000 - Train Loss: 1.0306 - Test Loss: 7.6596 - MSE: 7.6596 - MAE: 2.0710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8975/20000 - Train Loss: 1.0304 - Test Loss: 7.6586 - MSE: 7.6586 - MAE: 2.0708\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8976/20000 - Train Loss: 1.0301 - Test Loss: 7.6577 - MSE: 7.6577 - MAE: 2.0707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8977/20000 - Train Loss: 1.0298 - Test Loss: 7.6566 - MSE: 7.6566 - MAE: 2.0705\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8978/20000 - Train Loss: 1.0295 - Test Loss: 7.6556 - MSE: 7.6556 - MAE: 2.0703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8979/20000 - Train Loss: 1.0292 - Test Loss: 7.6546 - MSE: 7.6546 - MAE: 2.0701\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 8980/20000 - Train Loss: 1.0289 - Test Loss: 7.6537 - MSE: 7.6537 - MAE: 2.0699\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8981/20000 - Train Loss: 1.0286 - Test Loss: 7.6527 - MSE: 7.6527 - MAE: 2.0698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8982/20000 - Train Loss: 1.0283 - Test Loss: 7.6517 - MSE: 7.6517 - MAE: 2.0696\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 8983/20000 - Train Loss: 1.0281 - Test Loss: 7.6506 - MSE: 7.6506 - MAE: 2.0694\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 8984/20000 - Train Loss: 1.0278 - Test Loss: 7.6497 - MSE: 7.6497 - MAE: 2.0692\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8985/20000 - Train Loss: 1.0275 - Test Loss: 7.6487 - MSE: 7.6487 - MAE: 2.0690\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8986/20000 - Train Loss: 1.0272 - Test Loss: 7.6477 - MSE: 7.6477 - MAE: 2.0689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8987/20000 - Train Loss: 1.0269 - Test Loss: 7.6466 - MSE: 7.6466 - MAE: 2.0687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8988/20000 - Train Loss: 1.0266 - Test Loss: 7.6457 - MSE: 7.6457 - MAE: 2.0685\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8989/20000 - Train Loss: 1.0264 - Test Loss: 7.6447 - MSE: 7.6447 - MAE: 2.0683\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 8990/20000 - Train Loss: 1.0261 - Test Loss: 7.6437 - MSE: 7.6437 - MAE: 2.0681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8991/20000 - Train Loss: 1.0258 - Test Loss: 7.6427 - MSE: 7.6427 - MAE: 2.0679\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 8992/20000 - Train Loss: 1.0255 - Test Loss: 7.6416 - MSE: 7.6416 - MAE: 2.0678\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8993/20000 - Train Loss: 1.0252 - Test Loss: 7.6407 - MSE: 7.6407 - MAE: 2.0676\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 8994/20000 - Train Loss: 1.0249 - Test Loss: 7.6398 - MSE: 7.6398 - MAE: 2.0674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8995/20000 - Train Loss: 1.0247 - Test Loss: 7.6388 - MSE: 7.6388 - MAE: 2.0672\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 8996/20000 - Train Loss: 1.0244 - Test Loss: 7.6377 - MSE: 7.6377 - MAE: 2.0670\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8997/20000 - Train Loss: 1.0241 - Test Loss: 7.6367 - MSE: 7.6367 - MAE: 2.0668\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 8998/20000 - Train Loss: 1.0238 - Test Loss: 7.6358 - MSE: 7.6358 - MAE: 2.0667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 8999/20000 - Train Loss: 1.0235 - Test Loss: 7.6348 - MSE: 7.6348 - MAE: 2.0665\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9000/20000 - Train Loss: 1.0233 - Test Loss: 7.6337 - MSE: 7.6337 - MAE: 2.0663\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9001/20000 - Train Loss: 1.0230 - Test Loss: 7.6327 - MSE: 7.6327 - MAE: 2.0661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9002/20000 - Train Loss: 1.0227 - Test Loss: 7.6318 - MSE: 7.6318 - MAE: 2.0660\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9003/20000 - Train Loss: 1.0224 - Test Loss: 7.6308 - MSE: 7.6308 - MAE: 2.0658\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9004/20000 - Train Loss: 1.0221 - Test Loss: 7.6298 - MSE: 7.6298 - MAE: 2.0656\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9005/20000 - Train Loss: 1.0219 - Test Loss: 7.6287 - MSE: 7.6287 - MAE: 2.0654\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9006/20000 - Train Loss: 1.0216 - Test Loss: 7.6278 - MSE: 7.6278 - MAE: 2.0652\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9007/20000 - Train Loss: 1.0213 - Test Loss: 7.6268 - MSE: 7.6268 - MAE: 2.0650\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9008/20000 - Train Loss: 1.0210 - Test Loss: 7.6258 - MSE: 7.6258 - MAE: 2.0649\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9009/20000 - Train Loss: 1.0207 - Test Loss: 7.6248 - MSE: 7.6248 - MAE: 2.0647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9010/20000 - Train Loss: 1.0205 - Test Loss: 7.6238 - MSE: 7.6238 - MAE: 2.0645\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9011/20000 - Train Loss: 1.0202 - Test Loss: 7.6228 - MSE: 7.6228 - MAE: 2.0643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9012/20000 - Train Loss: 1.0199 - Test Loss: 7.6218 - MSE: 7.6219 - MAE: 2.0641\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9013/20000 - Train Loss: 1.0196 - Test Loss: 7.6208 - MSE: 7.6208 - MAE: 2.0639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9014/20000 - Train Loss: 1.0194 - Test Loss: 7.6198 - MSE: 7.6198 - MAE: 2.0638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9015/20000 - Train Loss: 1.0191 - Test Loss: 7.6189 - MSE: 7.6189 - MAE: 2.0636\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9016/20000 - Train Loss: 1.0188 - Test Loss: 7.6179 - MSE: 7.6179 - MAE: 2.0634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9017/20000 - Train Loss: 1.0185 - Test Loss: 7.6169 - MSE: 7.6169 - MAE: 2.0632\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9018/20000 - Train Loss: 1.0183 - Test Loss: 7.6159 - MSE: 7.6159 - MAE: 2.0630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9019/20000 - Train Loss: 1.0180 - Test Loss: 7.6149 - MSE: 7.6149 - MAE: 2.0629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9020/20000 - Train Loss: 1.0177 - Test Loss: 7.6139 - MSE: 7.6139 - MAE: 2.0627\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 9021/20000 - Train Loss: 1.0174 - Test Loss: 7.6129 - MSE: 7.6129 - MAE: 2.0625\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9022/20000 - Train Loss: 1.0172 - Test Loss: 7.6119 - MSE: 7.6119 - MAE: 2.0623\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9023/20000 - Train Loss: 1.0169 - Test Loss: 7.6110 - MSE: 7.6110 - MAE: 2.0621\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9024/20000 - Train Loss: 1.0166 - Test Loss: 7.6100 - MSE: 7.6100 - MAE: 2.0620\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9025/20000 - Train Loss: 1.0163 - Test Loss: 7.6090 - MSE: 7.6090 - MAE: 2.0618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9026/20000 - Train Loss: 1.0161 - Test Loss: 7.6080 - MSE: 7.6080 - MAE: 2.0616\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9027/20000 - Train Loss: 1.0158 - Test Loss: 7.6070 - MSE: 7.6070 - MAE: 2.0614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9028/20000 - Train Loss: 1.0155 - Test Loss: 7.6060 - MSE: 7.6060 - MAE: 2.0612\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9029/20000 - Train Loss: 1.0152 - Test Loss: 7.6050 - MSE: 7.6050 - MAE: 2.0610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9030/20000 - Train Loss: 1.0150 - Test Loss: 7.6040 - MSE: 7.6040 - MAE: 2.0609\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 9031/20000 - Train Loss: 1.0147 - Test Loss: 7.6031 - MSE: 7.6031 - MAE: 2.0607\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9032/20000 - Train Loss: 1.0144 - Test Loss: 7.6021 - MSE: 7.6021 - MAE: 2.0605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9033/20000 - Train Loss: 1.0142 - Test Loss: 7.6011 - MSE: 7.6011 - MAE: 2.0603\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9034/20000 - Train Loss: 1.0139 - Test Loss: 7.6001 - MSE: 7.6001 - MAE: 2.0601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9035/20000 - Train Loss: 1.0136 - Test Loss: 7.5991 - MSE: 7.5991 - MAE: 2.0600\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9036/20000 - Train Loss: 1.0133 - Test Loss: 7.5982 - MSE: 7.5982 - MAE: 2.0598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9037/20000 - Train Loss: 1.0131 - Test Loss: 7.5972 - MSE: 7.5972 - MAE: 2.0596\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9038/20000 - Train Loss: 1.0128 - Test Loss: 7.5961 - MSE: 7.5961 - MAE: 2.0594\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9039/20000 - Train Loss: 1.0125 - Test Loss: 7.5952 - MSE: 7.5952 - MAE: 2.0592\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9040/20000 - Train Loss: 1.0123 - Test Loss: 7.5942 - MSE: 7.5942 - MAE: 2.0590\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9041/20000 - Train Loss: 1.0120 - Test Loss: 7.5933 - MSE: 7.5933 - MAE: 2.0589\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9042/20000 - Train Loss: 1.0117 - Test Loss: 7.5922 - MSE: 7.5922 - MAE: 2.0587\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9043/20000 - Train Loss: 1.0114 - Test Loss: 7.5912 - MSE: 7.5912 - MAE: 2.0585\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9044/20000 - Train Loss: 1.0112 - Test Loss: 7.5903 - MSE: 7.5903 - MAE: 2.0583\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 9045/20000 - Train Loss: 1.0109 - Test Loss: 7.5893 - MSE: 7.5893 - MAE: 2.0581\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9046/20000 - Train Loss: 1.0106 - Test Loss: 7.5883 - MSE: 7.5883 - MAE: 2.0579\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9047/20000 - Train Loss: 1.0104 - Test Loss: 7.5873 - MSE: 7.5873 - MAE: 2.0578\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9048/20000 - Train Loss: 1.0101 - Test Loss: 7.5863 - MSE: 7.5863 - MAE: 2.0576\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9049/20000 - Train Loss: 1.0098 - Test Loss: 7.5854 - MSE: 7.5854 - MAE: 2.0574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9050/20000 - Train Loss: 1.0096 - Test Loss: 7.5844 - MSE: 7.5844 - MAE: 2.0572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9051/20000 - Train Loss: 1.0093 - Test Loss: 7.5834 - MSE: 7.5834 - MAE: 2.0570\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 9052/20000 - Train Loss: 1.0090 - Test Loss: 7.5824 - MSE: 7.5824 - MAE: 2.0569\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9053/20000 - Train Loss: 1.0088 - Test Loss: 7.5814 - MSE: 7.5814 - MAE: 2.0567\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9054/20000 - Train Loss: 1.0085 - Test Loss: 7.5804 - MSE: 7.5804 - MAE: 2.0565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9055/20000 - Train Loss: 1.0082 - Test Loss: 7.5795 - MSE: 7.5795 - MAE: 2.0563\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9056/20000 - Train Loss: 1.0080 - Test Loss: 7.5785 - MSE: 7.5785 - MAE: 2.0561\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9057/20000 - Train Loss: 1.0077 - Test Loss: 7.5775 - MSE: 7.5775 - MAE: 2.0559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9058/20000 - Train Loss: 1.0074 - Test Loss: 7.5765 - MSE: 7.5765 - MAE: 2.0558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9059/20000 - Train Loss: 1.0072 - Test Loss: 7.5755 - MSE: 7.5755 - MAE: 2.0556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9060/20000 - Train Loss: 1.0069 - Test Loss: 7.5746 - MSE: 7.5746 - MAE: 2.0555\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9061/20000 - Train Loss: 1.0067 - Test Loss: 7.5736 - MSE: 7.5736 - MAE: 2.0554\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9062/20000 - Train Loss: 1.0064 - Test Loss: 7.5726 - MSE: 7.5726 - MAE: 2.0552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9063/20000 - Train Loss: 1.0061 - Test Loss: 7.5716 - MSE: 7.5716 - MAE: 2.0551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9064/20000 - Train Loss: 1.0059 - Test Loss: 7.5706 - MSE: 7.5706 - MAE: 2.0550\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9065/20000 - Train Loss: 1.0056 - Test Loss: 7.5697 - MSE: 7.5697 - MAE: 2.0548\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch 9066/20000 - Train Loss: 1.0053 - Test Loss: 7.5687 - MSE: 7.5687 - MAE: 2.0547\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "Epoch 9067/20000 - Train Loss: 1.0051 - Test Loss: 7.5677 - MSE: 7.5677 - MAE: 2.0545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9068/20000 - Train Loss: 1.0048 - Test Loss: 7.5667 - MSE: 7.5667 - MAE: 2.0544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9069/20000 - Train Loss: 1.0045 - Test Loss: 7.5658 - MSE: 7.5658 - MAE: 2.0543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9070/20000 - Train Loss: 1.0043 - Test Loss: 7.5648 - MSE: 7.5648 - MAE: 2.0541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9071/20000 - Train Loss: 1.0040 - Test Loss: 7.5638 - MSE: 7.5638 - MAE: 2.0540\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9072/20000 - Train Loss: 1.0038 - Test Loss: 7.5628 - MSE: 7.5628 - MAE: 2.0539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9073/20000 - Train Loss: 1.0035 - Test Loss: 7.5619 - MSE: 7.5619 - MAE: 2.0537\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9074/20000 - Train Loss: 1.0032 - Test Loss: 7.5609 - MSE: 7.5609 - MAE: 2.0536\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9075/20000 - Train Loss: 1.0030 - Test Loss: 7.5599 - MSE: 7.5599 - MAE: 2.0535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9076/20000 - Train Loss: 1.0027 - Test Loss: 7.5589 - MSE: 7.5589 - MAE: 2.0533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9077/20000 - Train Loss: 1.0025 - Test Loss: 7.5580 - MSE: 7.5580 - MAE: 2.0532\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9078/20000 - Train Loss: 1.0022 - Test Loss: 7.5570 - MSE: 7.5570 - MAE: 2.0530\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9079/20000 - Train Loss: 1.0019 - Test Loss: 7.5560 - MSE: 7.5560 - MAE: 2.0529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9080/20000 - Train Loss: 1.0017 - Test Loss: 7.5550 - MSE: 7.5550 - MAE: 2.0528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9081/20000 - Train Loss: 1.0014 - Test Loss: 7.5540 - MSE: 7.5540 - MAE: 2.0526\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 9082/20000 - Train Loss: 1.0012 - Test Loss: 7.5530 - MSE: 7.5530 - MAE: 2.0525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9083/20000 - Train Loss: 1.0009 - Test Loss: 7.5521 - MSE: 7.5521 - MAE: 2.0524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9084/20000 - Train Loss: 1.0006 - Test Loss: 7.5511 - MSE: 7.5511 - MAE: 2.0522\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9085/20000 - Train Loss: 1.0004 - Test Loss: 7.5501 - MSE: 7.5501 - MAE: 2.0521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9086/20000 - Train Loss: 1.0001 - Test Loss: 7.5492 - MSE: 7.5492 - MAE: 2.0519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9087/20000 - Train Loss: 0.9999 - Test Loss: 7.5482 - MSE: 7.5482 - MAE: 2.0518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9088/20000 - Train Loss: 0.9996 - Test Loss: 7.5472 - MSE: 7.5472 - MAE: 2.0517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9089/20000 - Train Loss: 0.9993 - Test Loss: 7.5462 - MSE: 7.5462 - MAE: 2.0515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9090/20000 - Train Loss: 0.9991 - Test Loss: 7.5452 - MSE: 7.5452 - MAE: 2.0514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9091/20000 - Train Loss: 0.9988 - Test Loss: 7.5443 - MSE: 7.5443 - MAE: 2.0513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9092/20000 - Train Loss: 0.9986 - Test Loss: 7.5433 - MSE: 7.5433 - MAE: 2.0511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9093/20000 - Train Loss: 0.9983 - Test Loss: 7.5423 - MSE: 7.5423 - MAE: 2.0510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9094/20000 - Train Loss: 0.9981 - Test Loss: 7.5413 - MSE: 7.5413 - MAE: 2.0508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9095/20000 - Train Loss: 0.9978 - Test Loss: 7.5404 - MSE: 7.5404 - MAE: 2.0507\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9096/20000 - Train Loss: 0.9975 - Test Loss: 7.5394 - MSE: 7.5394 - MAE: 2.0506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9097/20000 - Train Loss: 0.9973 - Test Loss: 7.5384 - MSE: 7.5384 - MAE: 2.0504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9098/20000 - Train Loss: 0.9970 - Test Loss: 7.5375 - MSE: 7.5375 - MAE: 2.0503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9099/20000 - Train Loss: 0.9968 - Test Loss: 7.5365 - MSE: 7.5365 - MAE: 2.0502\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9100/20000 - Train Loss: 0.9965 - Test Loss: 7.5355 - MSE: 7.5355 - MAE: 2.0500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9101/20000 - Train Loss: 0.9963 - Test Loss: 7.5345 - MSE: 7.5345 - MAE: 2.0499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9102/20000 - Train Loss: 0.9960 - Test Loss: 7.5336 - MSE: 7.5336 - MAE: 2.0497\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9103/20000 - Train Loss: 0.9958 - Test Loss: 7.5326 - MSE: 7.5326 - MAE: 2.0496\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9104/20000 - Train Loss: 0.9955 - Test Loss: 7.5316 - MSE: 7.5316 - MAE: 2.0495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9105/20000 - Train Loss: 0.9953 - Test Loss: 7.5307 - MSE: 7.5307 - MAE: 2.0493\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9106/20000 - Train Loss: 0.9950 - Test Loss: 7.5297 - MSE: 7.5297 - MAE: 2.0492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9107/20000 - Train Loss: 0.9947 - Test Loss: 7.5286 - MSE: 7.5286 - MAE: 2.0490\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9108/20000 - Train Loss: 0.9945 - Test Loss: 7.5277 - MSE: 7.5277 - MAE: 2.0489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9109/20000 - Train Loss: 0.9942 - Test Loss: 7.5268 - MSE: 7.5268 - MAE: 2.0488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9110/20000 - Train Loss: 0.9940 - Test Loss: 7.5258 - MSE: 7.5258 - MAE: 2.0486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9111/20000 - Train Loss: 0.9937 - Test Loss: 7.5248 - MSE: 7.5248 - MAE: 2.0485\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9112/20000 - Train Loss: 0.9935 - Test Loss: 7.5239 - MSE: 7.5239 - MAE: 2.0484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9113/20000 - Train Loss: 0.9932 - Test Loss: 7.5229 - MSE: 7.5229 - MAE: 2.0482\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9114/20000 - Train Loss: 0.9930 - Test Loss: 7.5219 - MSE: 7.5219 - MAE: 2.0481\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9115/20000 - Train Loss: 0.9927 - Test Loss: 7.5209 - MSE: 7.5209 - MAE: 2.0479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9116/20000 - Train Loss: 0.9925 - Test Loss: 7.5199 - MSE: 7.5199 - MAE: 2.0478\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9117/20000 - Train Loss: 0.9922 - Test Loss: 7.5190 - MSE: 7.5190 - MAE: 2.0477\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9118/20000 - Train Loss: 0.9920 - Test Loss: 7.5181 - MSE: 7.5181 - MAE: 2.0475\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9119/20000 - Train Loss: 0.9917 - Test Loss: 7.5170 - MSE: 7.5170 - MAE: 2.0474\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9120/20000 - Train Loss: 0.9915 - Test Loss: 7.5160 - MSE: 7.5160 - MAE: 2.0472\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 9121/20000 - Train Loss: 0.9912 - Test Loss: 7.5151 - MSE: 7.5151 - MAE: 2.0471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9122/20000 - Train Loss: 0.9910 - Test Loss: 7.5142 - MSE: 7.5142 - MAE: 2.0470\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9123/20000 - Train Loss: 0.9907 - Test Loss: 7.5132 - MSE: 7.5132 - MAE: 2.0468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9124/20000 - Train Loss: 0.9905 - Test Loss: 7.5122 - MSE: 7.5122 - MAE: 2.0467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9125/20000 - Train Loss: 0.9902 - Test Loss: 7.5112 - MSE: 7.5112 - MAE: 2.0465\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9126/20000 - Train Loss: 0.9900 - Test Loss: 7.5103 - MSE: 7.5103 - MAE: 2.0464\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9127/20000 - Train Loss: 0.9897 - Test Loss: 7.5093 - MSE: 7.5093 - MAE: 2.0463\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9128/20000 - Train Loss: 0.9895 - Test Loss: 7.5083 - MSE: 7.5083 - MAE: 2.0461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9129/20000 - Train Loss: 0.9892 - Test Loss: 7.5073 - MSE: 7.5073 - MAE: 2.0460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9130/20000 - Train Loss: 0.9890 - Test Loss: 7.5064 - MSE: 7.5064 - MAE: 2.0458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9131/20000 - Train Loss: 0.9887 - Test Loss: 7.5055 - MSE: 7.5055 - MAE: 2.0457\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9132/20000 - Train Loss: 0.9885 - Test Loss: 7.5045 - MSE: 7.5045 - MAE: 2.0456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9133/20000 - Train Loss: 0.9882 - Test Loss: 7.5035 - MSE: 7.5035 - MAE: 2.0454\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9134/20000 - Train Loss: 0.9880 - Test Loss: 7.5025 - MSE: 7.5025 - MAE: 2.0453\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 9135/20000 - Train Loss: 0.9877 - Test Loss: 7.5016 - MSE: 7.5016 - MAE: 2.0451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9136/20000 - Train Loss: 0.9875 - Test Loss: 7.5006 - MSE: 7.5006 - MAE: 2.0450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9137/20000 - Train Loss: 0.9872 - Test Loss: 7.4996 - MSE: 7.4996 - MAE: 2.0449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9138/20000 - Train Loss: 0.9870 - Test Loss: 7.4986 - MSE: 7.4986 - MAE: 2.0447\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9139/20000 - Train Loss: 0.9868 - Test Loss: 7.4977 - MSE: 7.4977 - MAE: 2.0446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9140/20000 - Train Loss: 0.9865 - Test Loss: 7.4968 - MSE: 7.4968 - MAE: 2.0444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9141/20000 - Train Loss: 0.9863 - Test Loss: 7.4957 - MSE: 7.4957 - MAE: 2.0443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9142/20000 - Train Loss: 0.9860 - Test Loss: 7.4948 - MSE: 7.4948 - MAE: 2.0442\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9143/20000 - Train Loss: 0.9858 - Test Loss: 7.4938 - MSE: 7.4938 - MAE: 2.0440\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9144/20000 - Train Loss: 0.9855 - Test Loss: 7.4929 - MSE: 7.4929 - MAE: 2.0439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9145/20000 - Train Loss: 0.9853 - Test Loss: 7.4919 - MSE: 7.4919 - MAE: 2.0437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9146/20000 - Train Loss: 0.9850 - Test Loss: 7.4909 - MSE: 7.4909 - MAE: 2.0436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9147/20000 - Train Loss: 0.9848 - Test Loss: 7.4899 - MSE: 7.4899 - MAE: 2.0435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9148/20000 - Train Loss: 0.9845 - Test Loss: 7.4890 - MSE: 7.4890 - MAE: 2.0433\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9149/20000 - Train Loss: 0.9843 - Test Loss: 7.4881 - MSE: 7.4881 - MAE: 2.0432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9150/20000 - Train Loss: 0.9841 - Test Loss: 7.4870 - MSE: 7.4870 - MAE: 2.0430\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9151/20000 - Train Loss: 0.9838 - Test Loss: 7.4861 - MSE: 7.4861 - MAE: 2.0429\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9152/20000 - Train Loss: 0.9836 - Test Loss: 7.4851 - MSE: 7.4851 - MAE: 2.0428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9153/20000 - Train Loss: 0.9833 - Test Loss: 7.4842 - MSE: 7.4842 - MAE: 2.0426\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9154/20000 - Train Loss: 0.9831 - Test Loss: 7.4832 - MSE: 7.4832 - MAE: 2.0425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9155/20000 - Train Loss: 0.9828 - Test Loss: 7.4822 - MSE: 7.4822 - MAE: 2.0423\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9156/20000 - Train Loss: 0.9826 - Test Loss: 7.4813 - MSE: 7.4813 - MAE: 2.0422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9157/20000 - Train Loss: 0.9824 - Test Loss: 7.4803 - MSE: 7.4803 - MAE: 2.0421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9158/20000 - Train Loss: 0.9821 - Test Loss: 7.4794 - MSE: 7.4794 - MAE: 2.0419\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9159/20000 - Train Loss: 0.9819 - Test Loss: 7.4784 - MSE: 7.4784 - MAE: 2.0418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9160/20000 - Train Loss: 0.9816 - Test Loss: 7.4774 - MSE: 7.4774 - MAE: 2.0416\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9161/20000 - Train Loss: 0.9814 - Test Loss: 7.4764 - MSE: 7.4764 - MAE: 2.0415\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9162/20000 - Train Loss: 0.9811 - Test Loss: 7.4755 - MSE: 7.4755 - MAE: 2.0413\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9163/20000 - Train Loss: 0.9809 - Test Loss: 7.4746 - MSE: 7.4746 - MAE: 2.0412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9164/20000 - Train Loss: 0.9807 - Test Loss: 7.4736 - MSE: 7.4736 - MAE: 2.0411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9165/20000 - Train Loss: 0.9804 - Test Loss: 7.4726 - MSE: 7.4726 - MAE: 2.0409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9166/20000 - Train Loss: 0.9802 - Test Loss: 7.4716 - MSE: 7.4716 - MAE: 2.0408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9167/20000 - Train Loss: 0.9799 - Test Loss: 7.4707 - MSE: 7.4707 - MAE: 2.0406\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9168/20000 - Train Loss: 0.9797 - Test Loss: 7.4698 - MSE: 7.4698 - MAE: 2.0405\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9169/20000 - Train Loss: 0.9795 - Test Loss: 7.4687 - MSE: 7.4687 - MAE: 2.0403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9170/20000 - Train Loss: 0.9792 - Test Loss: 7.4678 - MSE: 7.4678 - MAE: 2.0402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9171/20000 - Train Loss: 0.9790 - Test Loss: 7.4669 - MSE: 7.4669 - MAE: 2.0401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9172/20000 - Train Loss: 0.9787 - Test Loss: 7.4659 - MSE: 7.4659 - MAE: 2.0399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9173/20000 - Train Loss: 0.9785 - Test Loss: 7.4649 - MSE: 7.4649 - MAE: 2.0398\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9174/20000 - Train Loss: 0.9783 - Test Loss: 7.4639 - MSE: 7.4639 - MAE: 2.0396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9175/20000 - Train Loss: 0.9780 - Test Loss: 7.4630 - MSE: 7.4630 - MAE: 2.0395\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9176/20000 - Train Loss: 0.9778 - Test Loss: 7.4621 - MSE: 7.4621 - MAE: 2.0394\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9177/20000 - Train Loss: 0.9776 - Test Loss: 7.4611 - MSE: 7.4611 - MAE: 2.0392\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 9178/20000 - Train Loss: 0.9773 - Test Loss: 7.4601 - MSE: 7.4601 - MAE: 2.0391\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 9179/20000 - Train Loss: 0.9771 - Test Loss: 7.4591 - MSE: 7.4591 - MAE: 2.0389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9180/20000 - Train Loss: 0.9768 - Test Loss: 7.4582 - MSE: 7.4582 - MAE: 2.0388\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9181/20000 - Train Loss: 0.9766 - Test Loss: 7.4573 - MSE: 7.4573 - MAE: 2.0386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9182/20000 - Train Loss: 0.9764 - Test Loss: 7.4562 - MSE: 7.4562 - MAE: 2.0385\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9183/20000 - Train Loss: 0.9761 - Test Loss: 7.4553 - MSE: 7.4553 - MAE: 2.0383\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9184/20000 - Train Loss: 0.9759 - Test Loss: 7.4544 - MSE: 7.4544 - MAE: 2.0382\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9185/20000 - Train Loss: 0.9756 - Test Loss: 7.4534 - MSE: 7.4534 - MAE: 2.0381\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9186/20000 - Train Loss: 0.9754 - Test Loss: 7.4524 - MSE: 7.4524 - MAE: 2.0379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9187/20000 - Train Loss: 0.9752 - Test Loss: 7.4514 - MSE: 7.4514 - MAE: 2.0378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9188/20000 - Train Loss: 0.9749 - Test Loss: 7.4505 - MSE: 7.4505 - MAE: 2.0376\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9189/20000 - Train Loss: 0.9747 - Test Loss: 7.4496 - MSE: 7.4496 - MAE: 2.0375\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9190/20000 - Train Loss: 0.9745 - Test Loss: 7.4486 - MSE: 7.4486 - MAE: 2.0373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9191/20000 - Train Loss: 0.9742 - Test Loss: 7.4476 - MSE: 7.4476 - MAE: 2.0372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9192/20000 - Train Loss: 0.9740 - Test Loss: 7.4466 - MSE: 7.4466 - MAE: 2.0371\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9193/20000 - Train Loss: 0.9738 - Test Loss: 7.4458 - MSE: 7.4458 - MAE: 2.0369\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9194/20000 - Train Loss: 0.9735 - Test Loss: 7.4448 - MSE: 7.4448 - MAE: 2.0368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9195/20000 - Train Loss: 0.9733 - Test Loss: 7.4438 - MSE: 7.4438 - MAE: 2.0366\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9196/20000 - Train Loss: 0.9731 - Test Loss: 7.4428 - MSE: 7.4428 - MAE: 2.0365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9197/20000 - Train Loss: 0.9728 - Test Loss: 7.4419 - MSE: 7.4419 - MAE: 2.0364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9198/20000 - Train Loss: 0.9726 - Test Loss: 7.4409 - MSE: 7.4409 - MAE: 2.0362\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9199/20000 - Train Loss: 0.9724 - Test Loss: 7.4399 - MSE: 7.4399 - MAE: 2.0361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9200/20000 - Train Loss: 0.9721 - Test Loss: 7.4390 - MSE: 7.4390 - MAE: 2.0359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9201/20000 - Train Loss: 0.9719 - Test Loss: 7.4381 - MSE: 7.4381 - MAE: 2.0358\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9202/20000 - Train Loss: 0.9717 - Test Loss: 7.4371 - MSE: 7.4371 - MAE: 2.0356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9203/20000 - Train Loss: 0.9714 - Test Loss: 7.4361 - MSE: 7.4361 - MAE: 2.0355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9204/20000 - Train Loss: 0.9712 - Test Loss: 7.4351 - MSE: 7.4351 - MAE: 2.0353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9205/20000 - Train Loss: 0.9710 - Test Loss: 7.4342 - MSE: 7.4342 - MAE: 2.0352\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9206/20000 - Train Loss: 0.9707 - Test Loss: 7.4333 - MSE: 7.4333 - MAE: 2.0351\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9207/20000 - Train Loss: 0.9705 - Test Loss: 7.4323 - MSE: 7.4323 - MAE: 2.0349\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9208/20000 - Train Loss: 0.9703 - Test Loss: 7.4313 - MSE: 7.4313 - MAE: 2.0348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9209/20000 - Train Loss: 0.9700 - Test Loss: 7.4304 - MSE: 7.4304 - MAE: 2.0346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9210/20000 - Train Loss: 0.9698 - Test Loss: 7.4295 - MSE: 7.4295 - MAE: 2.0345\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9211/20000 - Train Loss: 0.9696 - Test Loss: 7.4285 - MSE: 7.4285 - MAE: 2.0343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9212/20000 - Train Loss: 0.9693 - Test Loss: 7.4275 - MSE: 7.4275 - MAE: 2.0342\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9213/20000 - Train Loss: 0.9691 - Test Loss: 7.4265 - MSE: 7.4265 - MAE: 2.0340\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 9214/20000 - Train Loss: 0.9689 - Test Loss: 7.4256 - MSE: 7.4256 - MAE: 2.0339\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9215/20000 - Train Loss: 0.9686 - Test Loss: 7.4247 - MSE: 7.4247 - MAE: 2.0338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9216/20000 - Train Loss: 0.9684 - Test Loss: 7.4237 - MSE: 7.4237 - MAE: 2.0336\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9217/20000 - Train Loss: 0.9682 - Test Loss: 7.4227 - MSE: 7.4227 - MAE: 2.0335\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9218/20000 - Train Loss: 0.9679 - Test Loss: 7.4218 - MSE: 7.4218 - MAE: 2.0333\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9219/20000 - Train Loss: 0.9677 - Test Loss: 7.4208 - MSE: 7.4208 - MAE: 2.0332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9220/20000 - Train Loss: 0.9675 - Test Loss: 7.4199 - MSE: 7.4199 - MAE: 2.0330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9221/20000 - Train Loss: 0.9673 - Test Loss: 7.4189 - MSE: 7.4189 - MAE: 2.0329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9222/20000 - Train Loss: 0.9670 - Test Loss: 7.4180 - MSE: 7.4180 - MAE: 2.0327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9223/20000 - Train Loss: 0.9668 - Test Loss: 7.4170 - MSE: 7.4170 - MAE: 2.0326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9224/20000 - Train Loss: 0.9666 - Test Loss: 7.4160 - MSE: 7.4160 - MAE: 2.0324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9225/20000 - Train Loss: 0.9663 - Test Loss: 7.4150 - MSE: 7.4150 - MAE: 2.0323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9226/20000 - Train Loss: 0.9661 - Test Loss: 7.4141 - MSE: 7.4141 - MAE: 2.0322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9227/20000 - Train Loss: 0.9659 - Test Loss: 7.4132 - MSE: 7.4132 - MAE: 2.0320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9228/20000 - Train Loss: 0.9656 - Test Loss: 7.4122 - MSE: 7.4122 - MAE: 2.0319\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9229/20000 - Train Loss: 0.9654 - Test Loss: 7.4112 - MSE: 7.4112 - MAE: 2.0317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9230/20000 - Train Loss: 0.9652 - Test Loss: 7.4103 - MSE: 7.4103 - MAE: 2.0316\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9231/20000 - Train Loss: 0.9650 - Test Loss: 7.4094 - MSE: 7.4094 - MAE: 2.0314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9232/20000 - Train Loss: 0.9647 - Test Loss: 7.4084 - MSE: 7.4084 - MAE: 2.0313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9233/20000 - Train Loss: 0.9645 - Test Loss: 7.4074 - MSE: 7.4074 - MAE: 2.0311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9234/20000 - Train Loss: 0.9643 - Test Loss: 7.4065 - MSE: 7.4065 - MAE: 2.0310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9235/20000 - Train Loss: 0.9640 - Test Loss: 7.4056 - MSE: 7.4056 - MAE: 2.0309\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9236/20000 - Train Loss: 0.9638 - Test Loss: 7.4046 - MSE: 7.4046 - MAE: 2.0307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9237/20000 - Train Loss: 0.9636 - Test Loss: 7.4035 - MSE: 7.4035 - MAE: 2.0305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9238/20000 - Train Loss: 0.9634 - Test Loss: 7.4027 - MSE: 7.4027 - MAE: 2.0304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9239/20000 - Train Loss: 0.9631 - Test Loss: 7.4018 - MSE: 7.4018 - MAE: 2.0303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9240/20000 - Train Loss: 0.9629 - Test Loss: 7.4008 - MSE: 7.4008 - MAE: 2.0301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9241/20000 - Train Loss: 0.9627 - Test Loss: 7.3998 - MSE: 7.3998 - MAE: 2.0300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9242/20000 - Train Loss: 0.9625 - Test Loss: 7.3989 - MSE: 7.3989 - MAE: 2.0298\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9243/20000 - Train Loss: 0.9622 - Test Loss: 7.3980 - MSE: 7.3980 - MAE: 2.0297\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9244/20000 - Train Loss: 0.9620 - Test Loss: 7.3970 - MSE: 7.3970 - MAE: 2.0295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9245/20000 - Train Loss: 0.9618 - Test Loss: 7.3960 - MSE: 7.3960 - MAE: 2.0294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9246/20000 - Train Loss: 0.9616 - Test Loss: 7.3950 - MSE: 7.3950 - MAE: 2.0292\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9247/20000 - Train Loss: 0.9613 - Test Loss: 7.3941 - MSE: 7.3941 - MAE: 2.0291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9248/20000 - Train Loss: 0.9611 - Test Loss: 7.3932 - MSE: 7.3932 - MAE: 2.0290\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9249/20000 - Train Loss: 0.9609 - Test Loss: 7.3922 - MSE: 7.3922 - MAE: 2.0288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9250/20000 - Train Loss: 0.9607 - Test Loss: 7.3912 - MSE: 7.3912 - MAE: 2.0287\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9251/20000 - Train Loss: 0.9604 - Test Loss: 7.3903 - MSE: 7.3903 - MAE: 2.0285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9252/20000 - Train Loss: 0.9602 - Test Loss: 7.3894 - MSE: 7.3894 - MAE: 2.0284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9253/20000 - Train Loss: 0.9600 - Test Loss: 7.3884 - MSE: 7.3884 - MAE: 2.0282\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9254/20000 - Train Loss: 0.9598 - Test Loss: 7.3874 - MSE: 7.3874 - MAE: 2.0281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9255/20000 - Train Loss: 0.9595 - Test Loss: 7.3865 - MSE: 7.3865 - MAE: 2.0279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9256/20000 - Train Loss: 0.9593 - Test Loss: 7.3856 - MSE: 7.3856 - MAE: 2.0278\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9257/20000 - Train Loss: 0.9591 - Test Loss: 7.3846 - MSE: 7.3846 - MAE: 2.0276\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9258/20000 - Train Loss: 0.9589 - Test Loss: 7.3836 - MSE: 7.3836 - MAE: 2.0275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9259/20000 - Train Loss: 0.9586 - Test Loss: 7.3827 - MSE: 7.3827 - MAE: 2.0273\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9260/20000 - Train Loss: 0.9584 - Test Loss: 7.3817 - MSE: 7.3817 - MAE: 2.0272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9261/20000 - Train Loss: 0.9582 - Test Loss: 7.3808 - MSE: 7.3808 - MAE: 2.0270\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9262/20000 - Train Loss: 0.9580 - Test Loss: 7.3798 - MSE: 7.3798 - MAE: 2.0269\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9263/20000 - Train Loss: 0.9578 - Test Loss: 7.3789 - MSE: 7.3789 - MAE: 2.0268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9264/20000 - Train Loss: 0.9575 - Test Loss: 7.3779 - MSE: 7.3779 - MAE: 2.0266\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9265/20000 - Train Loss: 0.9573 - Test Loss: 7.3770 - MSE: 7.3770 - MAE: 2.0265\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9266/20000 - Train Loss: 0.9571 - Test Loss: 7.3760 - MSE: 7.3760 - MAE: 2.0263\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9267/20000 - Train Loss: 0.9569 - Test Loss: 7.3751 - MSE: 7.3751 - MAE: 2.0262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9268/20000 - Train Loss: 0.9566 - Test Loss: 7.3741 - MSE: 7.3741 - MAE: 2.0260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9269/20000 - Train Loss: 0.9564 - Test Loss: 7.3732 - MSE: 7.3732 - MAE: 2.0259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9270/20000 - Train Loss: 0.9562 - Test Loss: 7.3722 - MSE: 7.3722 - MAE: 2.0257\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9271/20000 - Train Loss: 0.9560 - Test Loss: 7.3713 - MSE: 7.3713 - MAE: 2.0256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9272/20000 - Train Loss: 0.9558 - Test Loss: 7.3703 - MSE: 7.3703 - MAE: 2.0254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9273/20000 - Train Loss: 0.9555 - Test Loss: 7.3694 - MSE: 7.3694 - MAE: 2.0253\n",
      "2/2 [==============================] - 0s 988us/step\n",
      "Epoch 9274/20000 - Train Loss: 0.9553 - Test Loss: 7.3684 - MSE: 7.3684 - MAE: 2.0251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9275/20000 - Train Loss: 0.9551 - Test Loss: 7.3674 - MSE: 7.3674 - MAE: 2.0250\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9276/20000 - Train Loss: 0.9549 - Test Loss: 7.3665 - MSE: 7.3666 - MAE: 2.0248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9277/20000 - Train Loss: 0.9547 - Test Loss: 7.3656 - MSE: 7.3656 - MAE: 2.0247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9278/20000 - Train Loss: 0.9544 - Test Loss: 7.3646 - MSE: 7.3646 - MAE: 2.0245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9279/20000 - Train Loss: 0.9542 - Test Loss: 7.3636 - MSE: 7.3636 - MAE: 2.0244\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9280/20000 - Train Loss: 0.9540 - Test Loss: 7.3628 - MSE: 7.3628 - MAE: 2.0242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9281/20000 - Train Loss: 0.9538 - Test Loss: 7.3618 - MSE: 7.3618 - MAE: 2.0241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9282/20000 - Train Loss: 0.9536 - Test Loss: 7.3609 - MSE: 7.3609 - MAE: 2.0240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9283/20000 - Train Loss: 0.9533 - Test Loss: 7.3598 - MSE: 7.3598 - MAE: 2.0238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9284/20000 - Train Loss: 0.9531 - Test Loss: 7.3589 - MSE: 7.3589 - MAE: 2.0237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9285/20000 - Train Loss: 0.9529 - Test Loss: 7.3580 - MSE: 7.3580 - MAE: 2.0235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9286/20000 - Train Loss: 0.9527 - Test Loss: 7.3571 - MSE: 7.3571 - MAE: 2.0234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9287/20000 - Train Loss: 0.9525 - Test Loss: 7.3560 - MSE: 7.3560 - MAE: 2.0232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9288/20000 - Train Loss: 0.9522 - Test Loss: 7.3551 - MSE: 7.3551 - MAE: 2.0231\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9289/20000 - Train Loss: 0.9520 - Test Loss: 7.3542 - MSE: 7.3542 - MAE: 2.0229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9290/20000 - Train Loss: 0.9518 - Test Loss: 7.3533 - MSE: 7.3533 - MAE: 2.0228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9291/20000 - Train Loss: 0.9516 - Test Loss: 7.3523 - MSE: 7.3523 - MAE: 2.0226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9292/20000 - Train Loss: 0.9514 - Test Loss: 7.3514 - MSE: 7.3514 - MAE: 2.0225\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9293/20000 - Train Loss: 0.9512 - Test Loss: 7.3504 - MSE: 7.3504 - MAE: 2.0223\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9294/20000 - Train Loss: 0.9509 - Test Loss: 7.3495 - MSE: 7.3495 - MAE: 2.0222\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9295/20000 - Train Loss: 0.9507 - Test Loss: 7.3486 - MSE: 7.3486 - MAE: 2.0220\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 9296/20000 - Train Loss: 0.9505 - Test Loss: 7.3476 - MSE: 7.3476 - MAE: 2.0219\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9297/20000 - Train Loss: 0.9503 - Test Loss: 7.3466 - MSE: 7.3466 - MAE: 2.0217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9298/20000 - Train Loss: 0.9501 - Test Loss: 7.3457 - MSE: 7.3457 - MAE: 2.0216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9299/20000 - Train Loss: 0.9499 - Test Loss: 7.3448 - MSE: 7.3448 - MAE: 2.0214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9300/20000 - Train Loss: 0.9496 - Test Loss: 7.3438 - MSE: 7.3438 - MAE: 2.0213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9301/20000 - Train Loss: 0.9494 - Test Loss: 7.3428 - MSE: 7.3428 - MAE: 2.0211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9302/20000 - Train Loss: 0.9492 - Test Loss: 7.3419 - MSE: 7.3419 - MAE: 2.0210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9303/20000 - Train Loss: 0.9490 - Test Loss: 7.3410 - MSE: 7.3410 - MAE: 2.0208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9304/20000 - Train Loss: 0.9488 - Test Loss: 7.3400 - MSE: 7.3400 - MAE: 2.0207\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9305/20000 - Train Loss: 0.9486 - Test Loss: 7.3390 - MSE: 7.3390 - MAE: 2.0205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9306/20000 - Train Loss: 0.9483 - Test Loss: 7.3381 - MSE: 7.3381 - MAE: 2.0204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9307/20000 - Train Loss: 0.9481 - Test Loss: 7.3372 - MSE: 7.3372 - MAE: 2.0202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9308/20000 - Train Loss: 0.9479 - Test Loss: 7.3362 - MSE: 7.3362 - MAE: 2.0201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9309/20000 - Train Loss: 0.9477 - Test Loss: 7.3353 - MSE: 7.3353 - MAE: 2.0199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9310/20000 - Train Loss: 0.9475 - Test Loss: 7.3343 - MSE: 7.3343 - MAE: 2.0198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9311/20000 - Train Loss: 0.9473 - Test Loss: 7.3334 - MSE: 7.3334 - MAE: 2.0196\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9312/20000 - Train Loss: 0.9471 - Test Loss: 7.3325 - MSE: 7.3325 - MAE: 2.0195\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9313/20000 - Train Loss: 0.9468 - Test Loss: 7.3315 - MSE: 7.3315 - MAE: 2.0193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9314/20000 - Train Loss: 0.9466 - Test Loss: 7.3305 - MSE: 7.3305 - MAE: 2.0192\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9315/20000 - Train Loss: 0.9464 - Test Loss: 7.3296 - MSE: 7.3296 - MAE: 2.0190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9316/20000 - Train Loss: 0.9462 - Test Loss: 7.3286 - MSE: 7.3286 - MAE: 2.0189\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9317/20000 - Train Loss: 0.9460 - Test Loss: 7.3277 - MSE: 7.3277 - MAE: 2.0187\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9318/20000 - Train Loss: 0.9458 - Test Loss: 7.3268 - MSE: 7.3268 - MAE: 2.0186\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9319/20000 - Train Loss: 0.9456 - Test Loss: 7.3258 - MSE: 7.3258 - MAE: 2.0184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9320/20000 - Train Loss: 0.9453 - Test Loss: 7.3249 - MSE: 7.3249 - MAE: 2.0183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9321/20000 - Train Loss: 0.9451 - Test Loss: 7.3240 - MSE: 7.3240 - MAE: 2.0181\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9322/20000 - Train Loss: 0.9449 - Test Loss: 7.3230 - MSE: 7.3230 - MAE: 2.0180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9323/20000 - Train Loss: 0.9447 - Test Loss: 7.3220 - MSE: 7.3220 - MAE: 2.0178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9324/20000 - Train Loss: 0.9445 - Test Loss: 7.3211 - MSE: 7.3211 - MAE: 2.0177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9325/20000 - Train Loss: 0.9443 - Test Loss: 7.3201 - MSE: 7.3201 - MAE: 2.0175\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 9326/20000 - Train Loss: 0.9441 - Test Loss: 7.3192 - MSE: 7.3192 - MAE: 2.0174\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9327/20000 - Train Loss: 0.9439 - Test Loss: 7.3182 - MSE: 7.3182 - MAE: 2.0172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9328/20000 - Train Loss: 0.9436 - Test Loss: 7.3173 - MSE: 7.3173 - MAE: 2.0171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9329/20000 - Train Loss: 0.9434 - Test Loss: 7.3164 - MSE: 7.3164 - MAE: 2.0169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9330/20000 - Train Loss: 0.9432 - Test Loss: 7.3154 - MSE: 7.3154 - MAE: 2.0168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9331/20000 - Train Loss: 0.9430 - Test Loss: 7.3145 - MSE: 7.3145 - MAE: 2.0166\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9332/20000 - Train Loss: 0.9428 - Test Loss: 7.3136 - MSE: 7.3136 - MAE: 2.0165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9333/20000 - Train Loss: 0.9426 - Test Loss: 7.3126 - MSE: 7.3126 - MAE: 2.0163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9334/20000 - Train Loss: 0.9424 - Test Loss: 7.3116 - MSE: 7.3116 - MAE: 2.0162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9335/20000 - Train Loss: 0.9422 - Test Loss: 7.3107 - MSE: 7.3107 - MAE: 2.0160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9336/20000 - Train Loss: 0.9420 - Test Loss: 7.3098 - MSE: 7.3098 - MAE: 2.0159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9337/20000 - Train Loss: 0.9417 - Test Loss: 7.3089 - MSE: 7.3089 - MAE: 2.0157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9338/20000 - Train Loss: 0.9415 - Test Loss: 7.3079 - MSE: 7.3079 - MAE: 2.0156\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9339/20000 - Train Loss: 0.9413 - Test Loss: 7.3069 - MSE: 7.3069 - MAE: 2.0154\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 9340/20000 - Train Loss: 0.9411 - Test Loss: 7.3060 - MSE: 7.3060 - MAE: 2.0153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9341/20000 - Train Loss: 0.9409 - Test Loss: 7.3051 - MSE: 7.3051 - MAE: 2.0151\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9342/20000 - Train Loss: 0.9407 - Test Loss: 7.3041 - MSE: 7.3041 - MAE: 2.0150\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9343/20000 - Train Loss: 0.9405 - Test Loss: 7.3031 - MSE: 7.3031 - MAE: 2.0148\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 9344/20000 - Train Loss: 0.9403 - Test Loss: 7.3022 - MSE: 7.3022 - MAE: 2.0147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9345/20000 - Train Loss: 0.9401 - Test Loss: 7.3013 - MSE: 7.3013 - MAE: 2.0145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9346/20000 - Train Loss: 0.9399 - Test Loss: 7.3003 - MSE: 7.3003 - MAE: 2.0144\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9347/20000 - Train Loss: 0.9396 - Test Loss: 7.2994 - MSE: 7.2994 - MAE: 2.0142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9348/20000 - Train Loss: 0.9394 - Test Loss: 7.2985 - MSE: 7.2985 - MAE: 2.0141\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9349/20000 - Train Loss: 0.9392 - Test Loss: 7.2975 - MSE: 7.2975 - MAE: 2.0139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9350/20000 - Train Loss: 0.9390 - Test Loss: 7.2966 - MSE: 7.2966 - MAE: 2.0138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9351/20000 - Train Loss: 0.9388 - Test Loss: 7.2957 - MSE: 7.2957 - MAE: 2.0136\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 9352/20000 - Train Loss: 0.9386 - Test Loss: 7.2947 - MSE: 7.2947 - MAE: 2.0135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9353/20000 - Train Loss: 0.9384 - Test Loss: 7.2937 - MSE: 7.2937 - MAE: 2.0133\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9354/20000 - Train Loss: 0.9382 - Test Loss: 7.2928 - MSE: 7.2928 - MAE: 2.0132\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9355/20000 - Train Loss: 0.9380 - Test Loss: 7.2918 - MSE: 7.2918 - MAE: 2.0130\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 9356/20000 - Train Loss: 0.9378 - Test Loss: 7.2909 - MSE: 7.2909 - MAE: 2.0129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9357/20000 - Train Loss: 0.9376 - Test Loss: 7.2900 - MSE: 7.2900 - MAE: 2.0127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9358/20000 - Train Loss: 0.9374 - Test Loss: 7.2890 - MSE: 7.2890 - MAE: 2.0126\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9359/20000 - Train Loss: 0.9371 - Test Loss: 7.2881 - MSE: 7.2881 - MAE: 2.0124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9360/20000 - Train Loss: 0.9369 - Test Loss: 7.2872 - MSE: 7.2872 - MAE: 2.0123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9361/20000 - Train Loss: 0.9367 - Test Loss: 7.2863 - MSE: 7.2863 - MAE: 2.0121\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9362/20000 - Train Loss: 0.9365 - Test Loss: 7.2852 - MSE: 7.2852 - MAE: 2.0119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9363/20000 - Train Loss: 0.9363 - Test Loss: 7.2843 - MSE: 7.2843 - MAE: 2.0118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9364/20000 - Train Loss: 0.9361 - Test Loss: 7.2834 - MSE: 7.2834 - MAE: 2.0117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9365/20000 - Train Loss: 0.9359 - Test Loss: 7.2825 - MSE: 7.2825 - MAE: 2.0115\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9366/20000 - Train Loss: 0.9357 - Test Loss: 7.2815 - MSE: 7.2815 - MAE: 2.0113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9367/20000 - Train Loss: 0.9355 - Test Loss: 7.2805 - MSE: 7.2805 - MAE: 2.0112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9368/20000 - Train Loss: 0.9353 - Test Loss: 7.2797 - MSE: 7.2797 - MAE: 2.0111\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9369/20000 - Train Loss: 0.9351 - Test Loss: 7.2788 - MSE: 7.2788 - MAE: 2.0109\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9370/20000 - Train Loss: 0.9349 - Test Loss: 7.2777 - MSE: 7.2777 - MAE: 2.0107\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9371/20000 - Train Loss: 0.9347 - Test Loss: 7.2767 - MSE: 7.2767 - MAE: 2.0106\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch 9372/20000 - Train Loss: 0.9345 - Test Loss: 7.2759 - MSE: 7.2759 - MAE: 2.0104\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9373/20000 - Train Loss: 0.9343 - Test Loss: 7.2750 - MSE: 7.2750 - MAE: 2.0103\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9374/20000 - Train Loss: 0.9341 - Test Loss: 7.2740 - MSE: 7.2740 - MAE: 2.0101\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9375/20000 - Train Loss: 0.9338 - Test Loss: 7.2730 - MSE: 7.2730 - MAE: 2.0100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9376/20000 - Train Loss: 0.9336 - Test Loss: 7.2721 - MSE: 7.2721 - MAE: 2.0098\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9377/20000 - Train Loss: 0.9334 - Test Loss: 7.2712 - MSE: 7.2712 - MAE: 2.0097\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9378/20000 - Train Loss: 0.9332 - Test Loss: 7.2702 - MSE: 7.2702 - MAE: 2.0095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9379/20000 - Train Loss: 0.9330 - Test Loss: 7.2693 - MSE: 7.2693 - MAE: 2.0094\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9380/20000 - Train Loss: 0.9328 - Test Loss: 7.2684 - MSE: 7.2684 - MAE: 2.0092\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9381/20000 - Train Loss: 0.9326 - Test Loss: 7.2674 - MSE: 7.2674 - MAE: 2.0091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9382/20000 - Train Loss: 0.9324 - Test Loss: 7.2665 - MSE: 7.2665 - MAE: 2.0089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9383/20000 - Train Loss: 0.9322 - Test Loss: 7.2656 - MSE: 7.2656 - MAE: 2.0088\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9384/20000 - Train Loss: 0.9320 - Test Loss: 7.2646 - MSE: 7.2646 - MAE: 2.0086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9385/20000 - Train Loss: 0.9318 - Test Loss: 7.2636 - MSE: 7.2636 - MAE: 2.0084\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 9386/20000 - Train Loss: 0.9316 - Test Loss: 7.2627 - MSE: 7.2627 - MAE: 2.0083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9387/20000 - Train Loss: 0.9314 - Test Loss: 7.2618 - MSE: 7.2618 - MAE: 2.0081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9388/20000 - Train Loss: 0.9312 - Test Loss: 7.2608 - MSE: 7.2608 - MAE: 2.0080\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9389/20000 - Train Loss: 0.9310 - Test Loss: 7.2599 - MSE: 7.2599 - MAE: 2.0078\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 9390/20000 - Train Loss: 0.9308 - Test Loss: 7.2589 - MSE: 7.2589 - MAE: 2.0077\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9391/20000 - Train Loss: 0.9306 - Test Loss: 7.2580 - MSE: 7.2580 - MAE: 2.0075\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9392/20000 - Train Loss: 0.9304 - Test Loss: 7.2571 - MSE: 7.2571 - MAE: 2.0074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9393/20000 - Train Loss: 0.9302 - Test Loss: 7.2561 - MSE: 7.2561 - MAE: 2.0072\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9394/20000 - Train Loss: 0.9300 - Test Loss: 7.2552 - MSE: 7.2552 - MAE: 2.0071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9395/20000 - Train Loss: 0.9298 - Test Loss: 7.2543 - MSE: 7.2543 - MAE: 2.0069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9396/20000 - Train Loss: 0.9296 - Test Loss: 7.2533 - MSE: 7.2533 - MAE: 2.0068\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 9397/20000 - Train Loss: 0.9294 - Test Loss: 7.2524 - MSE: 7.2524 - MAE: 2.0066\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9398/20000 - Train Loss: 0.9292 - Test Loss: 7.2515 - MSE: 7.2515 - MAE: 2.0065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9399/20000 - Train Loss: 0.9290 - Test Loss: 7.2505 - MSE: 7.2505 - MAE: 2.0063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9400/20000 - Train Loss: 0.9288 - Test Loss: 7.2496 - MSE: 7.2496 - MAE: 2.0061\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9401/20000 - Train Loss: 0.9286 - Test Loss: 7.2486 - MSE: 7.2486 - MAE: 2.0060\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9402/20000 - Train Loss: 0.9284 - Test Loss: 7.2477 - MSE: 7.2477 - MAE: 2.0058\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9403/20000 - Train Loss: 0.9282 - Test Loss: 7.2468 - MSE: 7.2468 - MAE: 2.0057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9404/20000 - Train Loss: 0.9280 - Test Loss: 7.2458 - MSE: 7.2458 - MAE: 2.0055\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9405/20000 - Train Loss: 0.9278 - Test Loss: 7.2449 - MSE: 7.2449 - MAE: 2.0054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9406/20000 - Train Loss: 0.9276 - Test Loss: 7.2440 - MSE: 7.2440 - MAE: 2.0052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9407/20000 - Train Loss: 0.9274 - Test Loss: 7.2431 - MSE: 7.2431 - MAE: 2.0051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9408/20000 - Train Loss: 0.9272 - Test Loss: 7.2421 - MSE: 7.2421 - MAE: 2.0049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9409/20000 - Train Loss: 0.9270 - Test Loss: 7.2411 - MSE: 7.2411 - MAE: 2.0048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9410/20000 - Train Loss: 0.9268 - Test Loss: 7.2403 - MSE: 7.2403 - MAE: 2.0046\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9411/20000 - Train Loss: 0.9266 - Test Loss: 7.2393 - MSE: 7.2393 - MAE: 2.0045\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9412/20000 - Train Loss: 0.9264 - Test Loss: 7.2383 - MSE: 7.2383 - MAE: 2.0043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9413/20000 - Train Loss: 0.9262 - Test Loss: 7.2374 - MSE: 7.2374 - MAE: 2.0042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9414/20000 - Train Loss: 0.9259 - Test Loss: 7.2365 - MSE: 7.2365 - MAE: 2.0040\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9415/20000 - Train Loss: 0.9258 - Test Loss: 7.2356 - MSE: 7.2356 - MAE: 2.0039\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 9416/20000 - Train Loss: 0.9256 - Test Loss: 7.2346 - MSE: 7.2346 - MAE: 2.0037\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9417/20000 - Train Loss: 0.9254 - Test Loss: 7.2336 - MSE: 7.2336 - MAE: 2.0035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9418/20000 - Train Loss: 0.9252 - Test Loss: 7.2328 - MSE: 7.2328 - MAE: 2.0034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9419/20000 - Train Loss: 0.9250 - Test Loss: 7.2318 - MSE: 7.2318 - MAE: 2.0032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9420/20000 - Train Loss: 0.9248 - Test Loss: 7.2308 - MSE: 7.2308 - MAE: 2.0031\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9421/20000 - Train Loss: 0.9246 - Test Loss: 7.2299 - MSE: 7.2299 - MAE: 2.0029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9422/20000 - Train Loss: 0.9244 - Test Loss: 7.2290 - MSE: 7.2290 - MAE: 2.0028\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9423/20000 - Train Loss: 0.9242 - Test Loss: 7.2281 - MSE: 7.2281 - MAE: 2.0026\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9424/20000 - Train Loss: 0.9240 - Test Loss: 7.2271 - MSE: 7.2271 - MAE: 2.0025\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9425/20000 - Train Loss: 0.9238 - Test Loss: 7.2262 - MSE: 7.2262 - MAE: 2.0023\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9426/20000 - Train Loss: 0.9236 - Test Loss: 7.2252 - MSE: 7.2252 - MAE: 2.0021\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9427/20000 - Train Loss: 0.9234 - Test Loss: 7.2243 - MSE: 7.2243 - MAE: 2.0020\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9428/20000 - Train Loss: 0.9232 - Test Loss: 7.2234 - MSE: 7.2234 - MAE: 2.0018\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9429/20000 - Train Loss: 0.9230 - Test Loss: 7.2225 - MSE: 7.2225 - MAE: 2.0017\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9430/20000 - Train Loss: 0.9228 - Test Loss: 7.2215 - MSE: 7.2215 - MAE: 2.0015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9431/20000 - Train Loss: 0.9226 - Test Loss: 7.2205 - MSE: 7.2205 - MAE: 2.0014\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9432/20000 - Train Loss: 0.9224 - Test Loss: 7.2197 - MSE: 7.2197 - MAE: 2.0012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9433/20000 - Train Loss: 0.9222 - Test Loss: 7.2188 - MSE: 7.2188 - MAE: 2.0011\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9434/20000 - Train Loss: 0.9220 - Test Loss: 7.2178 - MSE: 7.2178 - MAE: 2.0009\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9435/20000 - Train Loss: 0.9218 - Test Loss: 7.2168 - MSE: 7.2168 - MAE: 2.0007\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 9436/20000 - Train Loss: 0.9216 - Test Loss: 7.2159 - MSE: 7.2159 - MAE: 2.0006\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9437/20000 - Train Loss: 0.9214 - Test Loss: 7.2150 - MSE: 7.2150 - MAE: 2.0005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9438/20000 - Train Loss: 0.9212 - Test Loss: 7.2140 - MSE: 7.2140 - MAE: 2.0003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9439/20000 - Train Loss: 0.9210 - Test Loss: 7.2131 - MSE: 7.2131 - MAE: 2.0001\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9440/20000 - Train Loss: 0.9208 - Test Loss: 7.2122 - MSE: 7.2122 - MAE: 2.0000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9441/20000 - Train Loss: 0.9206 - Test Loss: 7.2112 - MSE: 7.2112 - MAE: 1.9998\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9442/20000 - Train Loss: 0.9204 - Test Loss: 7.2103 - MSE: 7.2103 - MAE: 1.9997\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Epoch 9443/20000 - Train Loss: 0.9202 - Test Loss: 7.2093 - MSE: 7.2093 - MAE: 1.9995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9444/20000 - Train Loss: 0.9200 - Test Loss: 7.2084 - MSE: 7.2084 - MAE: 1.9994\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9445/20000 - Train Loss: 0.9198 - Test Loss: 7.2075 - MSE: 7.2075 - MAE: 1.9992\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 9446/20000 - Train Loss: 0.9196 - Test Loss: 7.2065 - MSE: 7.2065 - MAE: 1.9990\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9447/20000 - Train Loss: 0.9194 - Test Loss: 7.2056 - MSE: 7.2056 - MAE: 1.9989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9448/20000 - Train Loss: 0.9192 - Test Loss: 7.2047 - MSE: 7.2047 - MAE: 1.9987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9449/20000 - Train Loss: 0.9190 - Test Loss: 7.2038 - MSE: 7.2038 - MAE: 1.9986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9450/20000 - Train Loss: 0.9188 - Test Loss: 7.2028 - MSE: 7.2028 - MAE: 1.9984\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9451/20000 - Train Loss: 0.9186 - Test Loss: 7.2019 - MSE: 7.2019 - MAE: 1.9983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9452/20000 - Train Loss: 0.9184 - Test Loss: 7.2010 - MSE: 7.2010 - MAE: 1.9981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9453/20000 - Train Loss: 0.9183 - Test Loss: 7.2000 - MSE: 7.2000 - MAE: 1.9980\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 9454/20000 - Train Loss: 0.9181 - Test Loss: 7.1991 - MSE: 7.1991 - MAE: 1.9978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9455/20000 - Train Loss: 0.9179 - Test Loss: 7.1982 - MSE: 7.1982 - MAE: 1.9976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9456/20000 - Train Loss: 0.9177 - Test Loss: 7.1972 - MSE: 7.1972 - MAE: 1.9975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9457/20000 - Train Loss: 0.9175 - Test Loss: 7.1963 - MSE: 7.1963 - MAE: 1.9973\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9458/20000 - Train Loss: 0.9173 - Test Loss: 7.1954 - MSE: 7.1954 - MAE: 1.9972\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9459/20000 - Train Loss: 0.9171 - Test Loss: 7.1944 - MSE: 7.1944 - MAE: 1.9970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9460/20000 - Train Loss: 0.9169 - Test Loss: 7.1935 - MSE: 7.1935 - MAE: 1.9969\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9461/20000 - Train Loss: 0.9167 - Test Loss: 7.1926 - MSE: 7.1926 - MAE: 1.9967\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9462/20000 - Train Loss: 0.9165 - Test Loss: 7.1916 - MSE: 7.1916 - MAE: 1.9965\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9463/20000 - Train Loss: 0.9163 - Test Loss: 7.1907 - MSE: 7.1907 - MAE: 1.9964\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9464/20000 - Train Loss: 0.9161 - Test Loss: 7.1898 - MSE: 7.1898 - MAE: 1.9962\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9465/20000 - Train Loss: 0.9159 - Test Loss: 7.1889 - MSE: 7.1889 - MAE: 1.9961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9466/20000 - Train Loss: 0.9157 - Test Loss: 7.1879 - MSE: 7.1879 - MAE: 1.9959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9467/20000 - Train Loss: 0.9155 - Test Loss: 7.1870 - MSE: 7.1870 - MAE: 1.9958\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9468/20000 - Train Loss: 0.9153 - Test Loss: 7.1861 - MSE: 7.1861 - MAE: 1.9956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9469/20000 - Train Loss: 0.9152 - Test Loss: 7.1851 - MSE: 7.1851 - MAE: 1.9955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9470/20000 - Train Loss: 0.9150 - Test Loss: 7.1842 - MSE: 7.1842 - MAE: 1.9953\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9471/20000 - Train Loss: 0.9148 - Test Loss: 7.1833 - MSE: 7.1833 - MAE: 1.9951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9472/20000 - Train Loss: 0.9146 - Test Loss: 7.1823 - MSE: 7.1823 - MAE: 1.9950\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 9473/20000 - Train Loss: 0.9144 - Test Loss: 7.1814 - MSE: 7.1814 - MAE: 1.9948\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 9474/20000 - Train Loss: 0.9142 - Test Loss: 7.1805 - MSE: 7.1805 - MAE: 1.9947\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9475/20000 - Train Loss: 0.9140 - Test Loss: 7.1795 - MSE: 7.1795 - MAE: 1.9945\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9476/20000 - Train Loss: 0.9138 - Test Loss: 7.1786 - MSE: 7.1786 - MAE: 1.9944\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9477/20000 - Train Loss: 0.9136 - Test Loss: 7.1777 - MSE: 7.1777 - MAE: 1.9942\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9478/20000 - Train Loss: 0.9134 - Test Loss: 7.1767 - MSE: 7.1767 - MAE: 1.9940\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 9479/20000 - Train Loss: 0.9132 - Test Loss: 7.1758 - MSE: 7.1758 - MAE: 1.9939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9480/20000 - Train Loss: 0.9130 - Test Loss: 7.1749 - MSE: 7.1749 - MAE: 1.9937\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9481/20000 - Train Loss: 0.9128 - Test Loss: 7.1739 - MSE: 7.1739 - MAE: 1.9936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9482/20000 - Train Loss: 0.9127 - Test Loss: 7.1730 - MSE: 7.1730 - MAE: 1.9934\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9483/20000 - Train Loss: 0.9125 - Test Loss: 7.1721 - MSE: 7.1721 - MAE: 1.9933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9484/20000 - Train Loss: 0.9123 - Test Loss: 7.1711 - MSE: 7.1711 - MAE: 1.9931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9485/20000 - Train Loss: 0.9121 - Test Loss: 7.1702 - MSE: 7.1702 - MAE: 1.9929\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9486/20000 - Train Loss: 0.9119 - Test Loss: 7.1693 - MSE: 7.1693 - MAE: 1.9928\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9487/20000 - Train Loss: 0.9117 - Test Loss: 7.1684 - MSE: 7.1684 - MAE: 1.9926\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9488/20000 - Train Loss: 0.9115 - Test Loss: 7.1674 - MSE: 7.1674 - MAE: 1.9925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9489/20000 - Train Loss: 0.9113 - Test Loss: 7.1665 - MSE: 7.1665 - MAE: 1.9923\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9490/20000 - Train Loss: 0.9111 - Test Loss: 7.1656 - MSE: 7.1656 - MAE: 1.9922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9491/20000 - Train Loss: 0.9109 - Test Loss: 7.1647 - MSE: 7.1647 - MAE: 1.9920\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9492/20000 - Train Loss: 0.9107 - Test Loss: 7.1637 - MSE: 7.1637 - MAE: 1.9919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9493/20000 - Train Loss: 0.9106 - Test Loss: 7.1628 - MSE: 7.1628 - MAE: 1.9917\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9494/20000 - Train Loss: 0.9104 - Test Loss: 7.1618 - MSE: 7.1618 - MAE: 1.9915\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9495/20000 - Train Loss: 0.9102 - Test Loss: 7.1610 - MSE: 7.1610 - MAE: 1.9914\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 9496/20000 - Train Loss: 0.9100 - Test Loss: 7.1600 - MSE: 7.1600 - MAE: 1.9912\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9497/20000 - Train Loss: 0.9098 - Test Loss: 7.1590 - MSE: 7.1590 - MAE: 1.9911\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9498/20000 - Train Loss: 0.9096 - Test Loss: 7.1581 - MSE: 7.1581 - MAE: 1.9910\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9499/20000 - Train Loss: 0.9094 - Test Loss: 7.1573 - MSE: 7.1573 - MAE: 1.9909\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9500/20000 - Train Loss: 0.9092 - Test Loss: 7.1563 - MSE: 7.1563 - MAE: 1.9908\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9501/20000 - Train Loss: 0.9090 - Test Loss: 7.1553 - MSE: 7.1553 - MAE: 1.9906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9502/20000 - Train Loss: 0.9088 - Test Loss: 7.1544 - MSE: 7.1544 - MAE: 1.9905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9503/20000 - Train Loss: 0.9087 - Test Loss: 7.1536 - MSE: 7.1536 - MAE: 1.9904\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9504/20000 - Train Loss: 0.9085 - Test Loss: 7.1526 - MSE: 7.1526 - MAE: 1.9903\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9505/20000 - Train Loss: 0.9083 - Test Loss: 7.1516 - MSE: 7.1516 - MAE: 1.9902\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9506/20000 - Train Loss: 0.9081 - Test Loss: 7.1507 - MSE: 7.1507 - MAE: 1.9901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9507/20000 - Train Loss: 0.9079 - Test Loss: 7.1499 - MSE: 7.1499 - MAE: 1.9900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9508/20000 - Train Loss: 0.9077 - Test Loss: 7.1488 - MSE: 7.1488 - MAE: 1.9898\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9509/20000 - Train Loss: 0.9075 - Test Loss: 7.1479 - MSE: 7.1479 - MAE: 1.9897\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9510/20000 - Train Loss: 0.9073 - Test Loss: 7.1470 - MSE: 7.1470 - MAE: 1.9896\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9511/20000 - Train Loss: 0.9071 - Test Loss: 7.1461 - MSE: 7.1461 - MAE: 1.9895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9512/20000 - Train Loss: 0.9070 - Test Loss: 7.1451 - MSE: 7.1451 - MAE: 1.9894\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9513/20000 - Train Loss: 0.9068 - Test Loss: 7.1442 - MSE: 7.1442 - MAE: 1.9893\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9514/20000 - Train Loss: 0.9066 - Test Loss: 7.1434 - MSE: 7.1434 - MAE: 1.9892\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9515/20000 - Train Loss: 0.9064 - Test Loss: 7.1424 - MSE: 7.1424 - MAE: 1.9890\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9516/20000 - Train Loss: 0.9062 - Test Loss: 7.1414 - MSE: 7.1414 - MAE: 1.9889\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9517/20000 - Train Loss: 0.9060 - Test Loss: 7.1405 - MSE: 7.1405 - MAE: 1.9888\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9518/20000 - Train Loss: 0.9058 - Test Loss: 7.1396 - MSE: 7.1396 - MAE: 1.9887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9519/20000 - Train Loss: 0.9056 - Test Loss: 7.1387 - MSE: 7.1387 - MAE: 1.9886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9520/20000 - Train Loss: 0.9055 - Test Loss: 7.1377 - MSE: 7.1377 - MAE: 1.9885\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9521/20000 - Train Loss: 0.9053 - Test Loss: 7.1368 - MSE: 7.1368 - MAE: 1.9884\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9522/20000 - Train Loss: 0.9051 - Test Loss: 7.1359 - MSE: 7.1359 - MAE: 1.9882\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9523/20000 - Train Loss: 0.9049 - Test Loss: 7.1350 - MSE: 7.1350 - MAE: 1.9881\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9524/20000 - Train Loss: 0.9047 - Test Loss: 7.1340 - MSE: 7.1340 - MAE: 1.9880\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9525/20000 - Train Loss: 0.9045 - Test Loss: 7.1331 - MSE: 7.1331 - MAE: 1.9879\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9526/20000 - Train Loss: 0.9043 - Test Loss: 7.1322 - MSE: 7.1322 - MAE: 1.9878\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9527/20000 - Train Loss: 0.9042 - Test Loss: 7.1313 - MSE: 7.1313 - MAE: 1.9877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9528/20000 - Train Loss: 0.9040 - Test Loss: 7.1303 - MSE: 7.1303 - MAE: 1.9876\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9529/20000 - Train Loss: 0.9038 - Test Loss: 7.1294 - MSE: 7.1294 - MAE: 1.9874\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9530/20000 - Train Loss: 0.9036 - Test Loss: 7.1285 - MSE: 7.1285 - MAE: 1.9873\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9531/20000 - Train Loss: 0.9034 - Test Loss: 7.1276 - MSE: 7.1276 - MAE: 1.9872\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9532/20000 - Train Loss: 0.9032 - Test Loss: 7.1266 - MSE: 7.1266 - MAE: 1.9871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9533/20000 - Train Loss: 0.9030 - Test Loss: 7.1257 - MSE: 7.1257 - MAE: 1.9870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9534/20000 - Train Loss: 0.9029 - Test Loss: 7.1248 - MSE: 7.1248 - MAE: 1.9869\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9535/20000 - Train Loss: 0.9027 - Test Loss: 7.1238 - MSE: 7.1238 - MAE: 1.9867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9536/20000 - Train Loss: 0.9025 - Test Loss: 7.1229 - MSE: 7.1229 - MAE: 1.9866\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9537/20000 - Train Loss: 0.9023 - Test Loss: 7.1220 - MSE: 7.1220 - MAE: 1.9865\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9538/20000 - Train Loss: 0.9021 - Test Loss: 7.1211 - MSE: 7.1211 - MAE: 1.9864\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9539/20000 - Train Loss: 0.9019 - Test Loss: 7.1201 - MSE: 7.1201 - MAE: 1.9863\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9540/20000 - Train Loss: 0.9017 - Test Loss: 7.1192 - MSE: 7.1192 - MAE: 1.9862\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9541/20000 - Train Loss: 0.9016 - Test Loss: 7.1183 - MSE: 7.1183 - MAE: 1.9861\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 9542/20000 - Train Loss: 0.9014 - Test Loss: 7.1174 - MSE: 7.1174 - MAE: 1.9859\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9543/20000 - Train Loss: 0.9012 - Test Loss: 7.1164 - MSE: 7.1164 - MAE: 1.9858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9544/20000 - Train Loss: 0.9010 - Test Loss: 7.1155 - MSE: 7.1155 - MAE: 1.9857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9545/20000 - Train Loss: 0.9008 - Test Loss: 7.1146 - MSE: 7.1146 - MAE: 1.9856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9546/20000 - Train Loss: 0.9006 - Test Loss: 7.1137 - MSE: 7.1137 - MAE: 1.9855\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9547/20000 - Train Loss: 0.9004 - Test Loss: 7.1127 - MSE: 7.1127 - MAE: 1.9853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9548/20000 - Train Loss: 0.9003 - Test Loss: 7.1118 - MSE: 7.1118 - MAE: 1.9852\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9549/20000 - Train Loss: 0.9001 - Test Loss: 7.1109 - MSE: 7.1109 - MAE: 1.9851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9550/20000 - Train Loss: 0.8999 - Test Loss: 7.1100 - MSE: 7.1100 - MAE: 1.9850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9551/20000 - Train Loss: 0.8997 - Test Loss: 7.1090 - MSE: 7.1090 - MAE: 1.9849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9552/20000 - Train Loss: 0.8995 - Test Loss: 7.1081 - MSE: 7.1081 - MAE: 1.9848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9553/20000 - Train Loss: 0.8993 - Test Loss: 7.1072 - MSE: 7.1072 - MAE: 1.9847\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9554/20000 - Train Loss: 0.8992 - Test Loss: 7.1063 - MSE: 7.1063 - MAE: 1.9845\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9555/20000 - Train Loss: 0.8990 - Test Loss: 7.1053 - MSE: 7.1053 - MAE: 1.9844\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9556/20000 - Train Loss: 0.8988 - Test Loss: 7.1044 - MSE: 7.1044 - MAE: 1.9843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9557/20000 - Train Loss: 0.8986 - Test Loss: 7.1035 - MSE: 7.1035 - MAE: 1.9842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9558/20000 - Train Loss: 0.8984 - Test Loss: 7.1026 - MSE: 7.1026 - MAE: 1.9841\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9559/20000 - Train Loss: 0.8982 - Test Loss: 7.1017 - MSE: 7.1017 - MAE: 1.9839\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9560/20000 - Train Loss: 0.8981 - Test Loss: 7.1007 - MSE: 7.1007 - MAE: 1.9838\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9561/20000 - Train Loss: 0.8979 - Test Loss: 7.0998 - MSE: 7.0998 - MAE: 1.9837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9562/20000 - Train Loss: 0.8977 - Test Loss: 7.0989 - MSE: 7.0989 - MAE: 1.9836\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9563/20000 - Train Loss: 0.8975 - Test Loss: 7.0980 - MSE: 7.0980 - MAE: 1.9835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9564/20000 - Train Loss: 0.8973 - Test Loss: 7.0970 - MSE: 7.0970 - MAE: 1.9834\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9565/20000 - Train Loss: 0.8971 - Test Loss: 7.0961 - MSE: 7.0961 - MAE: 1.9832\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9566/20000 - Train Loss: 0.8970 - Test Loss: 7.0952 - MSE: 7.0952 - MAE: 1.9831\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9567/20000 - Train Loss: 0.8968 - Test Loss: 7.0943 - MSE: 7.0943 - MAE: 1.9830\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9568/20000 - Train Loss: 0.8966 - Test Loss: 7.0933 - MSE: 7.0933 - MAE: 1.9829\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9569/20000 - Train Loss: 0.8964 - Test Loss: 7.0924 - MSE: 7.0924 - MAE: 1.9828\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9570/20000 - Train Loss: 0.8962 - Test Loss: 7.0916 - MSE: 7.0916 - MAE: 1.9827\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9571/20000 - Train Loss: 0.8961 - Test Loss: 7.0906 - MSE: 7.0906 - MAE: 1.9825\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9572/20000 - Train Loss: 0.8959 - Test Loss: 7.0896 - MSE: 7.0896 - MAE: 1.9824\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9573/20000 - Train Loss: 0.8957 - Test Loss: 7.0888 - MSE: 7.0888 - MAE: 1.9823\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9574/20000 - Train Loss: 0.8955 - Test Loss: 7.0879 - MSE: 7.0879 - MAE: 1.9822\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9575/20000 - Train Loss: 0.8953 - Test Loss: 7.0868 - MSE: 7.0868 - MAE: 1.9821\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9576/20000 - Train Loss: 0.8951 - Test Loss: 7.0859 - MSE: 7.0859 - MAE: 1.9819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9577/20000 - Train Loss: 0.8950 - Test Loss: 7.0852 - MSE: 7.0852 - MAE: 1.9818\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9578/20000 - Train Loss: 0.8948 - Test Loss: 7.0842 - MSE: 7.0842 - MAE: 1.9817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9579/20000 - Train Loss: 0.8946 - Test Loss: 7.0831 - MSE: 7.0831 - MAE: 1.9816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9580/20000 - Train Loss: 0.8944 - Test Loss: 7.0823 - MSE: 7.0823 - MAE: 1.9815\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9581/20000 - Train Loss: 0.8942 - Test Loss: 7.0814 - MSE: 7.0814 - MAE: 1.9814\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9582/20000 - Train Loss: 0.8941 - Test Loss: 7.0804 - MSE: 7.0804 - MAE: 1.9812\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 9583/20000 - Train Loss: 0.8939 - Test Loss: 7.0795 - MSE: 7.0795 - MAE: 1.9811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9584/20000 - Train Loss: 0.8937 - Test Loss: 7.0786 - MSE: 7.0786 - MAE: 1.9810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9585/20000 - Train Loss: 0.8935 - Test Loss: 7.0778 - MSE: 7.0778 - MAE: 1.9809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9586/20000 - Train Loss: 0.8933 - Test Loss: 7.0767 - MSE: 7.0767 - MAE: 1.9808\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9587/20000 - Train Loss: 0.8932 - Test Loss: 7.0758 - MSE: 7.0758 - MAE: 1.9806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9588/20000 - Train Loss: 0.8930 - Test Loss: 7.0750 - MSE: 7.0750 - MAE: 1.9805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9589/20000 - Train Loss: 0.8928 - Test Loss: 7.0740 - MSE: 7.0740 - MAE: 1.9804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9590/20000 - Train Loss: 0.8926 - Test Loss: 7.0730 - MSE: 7.0730 - MAE: 1.9803\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9591/20000 - Train Loss: 0.8924 - Test Loss: 7.0721 - MSE: 7.0721 - MAE: 1.9802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9592/20000 - Train Loss: 0.8923 - Test Loss: 7.0713 - MSE: 7.0713 - MAE: 1.9801\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9593/20000 - Train Loss: 0.8921 - Test Loss: 7.0703 - MSE: 7.0703 - MAE: 1.9799\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9594/20000 - Train Loss: 0.8919 - Test Loss: 7.0694 - MSE: 7.0694 - MAE: 1.9798\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9595/20000 - Train Loss: 0.8917 - Test Loss: 7.0685 - MSE: 7.0685 - MAE: 1.9797\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 9596/20000 - Train Loss: 0.8915 - Test Loss: 7.0676 - MSE: 7.0676 - MAE: 1.9796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9597/20000 - Train Loss: 0.8914 - Test Loss: 7.0667 - MSE: 7.0667 - MAE: 1.9795\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9598/20000 - Train Loss: 0.8912 - Test Loss: 7.0657 - MSE: 7.0657 - MAE: 1.9793\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9599/20000 - Train Loss: 0.8910 - Test Loss: 7.0648 - MSE: 7.0648 - MAE: 1.9792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9600/20000 - Train Loss: 0.8908 - Test Loss: 7.0639 - MSE: 7.0639 - MAE: 1.9791\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 9601/20000 - Train Loss: 0.8906 - Test Loss: 7.0630 - MSE: 7.0630 - MAE: 1.9790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9602/20000 - Train Loss: 0.8905 - Test Loss: 7.0620 - MSE: 7.0620 - MAE: 1.9788\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9603/20000 - Train Loss: 0.8903 - Test Loss: 7.0612 - MSE: 7.0612 - MAE: 1.9787\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9604/20000 - Train Loss: 0.8901 - Test Loss: 7.0602 - MSE: 7.0602 - MAE: 1.9786\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9605/20000 - Train Loss: 0.8899 - Test Loss: 7.0593 - MSE: 7.0593 - MAE: 1.9785\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 9606/20000 - Train Loss: 0.8898 - Test Loss: 7.0583 - MSE: 7.0583 - MAE: 1.9784\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9607/20000 - Train Loss: 0.8896 - Test Loss: 7.0575 - MSE: 7.0575 - MAE: 1.9783\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9608/20000 - Train Loss: 0.8894 - Test Loss: 7.0566 - MSE: 7.0566 - MAE: 1.9781\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9609/20000 - Train Loss: 0.8892 - Test Loss: 7.0556 - MSE: 7.0556 - MAE: 1.9780\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9610/20000 - Train Loss: 0.8890 - Test Loss: 7.0547 - MSE: 7.0547 - MAE: 1.9779\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9611/20000 - Train Loss: 0.8889 - Test Loss: 7.0538 - MSE: 7.0538 - MAE: 1.9778\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9612/20000 - Train Loss: 0.8887 - Test Loss: 7.0529 - MSE: 7.0529 - MAE: 1.9777\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 9613/20000 - Train Loss: 0.8885 - Test Loss: 7.0519 - MSE: 7.0519 - MAE: 1.9775\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 9614/20000 - Train Loss: 0.8883 - Test Loss: 7.0510 - MSE: 7.0510 - MAE: 1.9774\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9615/20000 - Train Loss: 0.8882 - Test Loss: 7.0501 - MSE: 7.0501 - MAE: 1.9773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9616/20000 - Train Loss: 0.8880 - Test Loss: 7.0492 - MSE: 7.0492 - MAE: 1.9772\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 9617/20000 - Train Loss: 0.8878 - Test Loss: 7.0483 - MSE: 7.0483 - MAE: 1.9770\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9618/20000 - Train Loss: 0.8876 - Test Loss: 7.0473 - MSE: 7.0473 - MAE: 1.9769\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9619/20000 - Train Loss: 0.8874 - Test Loss: 7.0464 - MSE: 7.0464 - MAE: 1.9768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9620/20000 - Train Loss: 0.8873 - Test Loss: 7.0455 - MSE: 7.0455 - MAE: 1.9767\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9621/20000 - Train Loss: 0.8871 - Test Loss: 7.0446 - MSE: 7.0446 - MAE: 1.9766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9622/20000 - Train Loss: 0.8869 - Test Loss: 7.0437 - MSE: 7.0437 - MAE: 1.9764\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 9623/20000 - Train Loss: 0.8867 - Test Loss: 7.0428 - MSE: 7.0428 - MAE: 1.9763\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9624/20000 - Train Loss: 0.8866 - Test Loss: 7.0418 - MSE: 7.0418 - MAE: 1.9762\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9625/20000 - Train Loss: 0.8864 - Test Loss: 7.0409 - MSE: 7.0409 - MAE: 1.9761\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9626/20000 - Train Loss: 0.8862 - Test Loss: 7.0400 - MSE: 7.0400 - MAE: 1.9760\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 9627/20000 - Train Loss: 0.8860 - Test Loss: 7.0391 - MSE: 7.0391 - MAE: 1.9758\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9628/20000 - Train Loss: 0.8859 - Test Loss: 7.0381 - MSE: 7.0381 - MAE: 1.9757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9629/20000 - Train Loss: 0.8857 - Test Loss: 7.0373 - MSE: 7.0373 - MAE: 1.9756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9630/20000 - Train Loss: 0.8855 - Test Loss: 7.0364 - MSE: 7.0364 - MAE: 1.9755\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9631/20000 - Train Loss: 0.8853 - Test Loss: 7.0354 - MSE: 7.0354 - MAE: 1.9753\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9632/20000 - Train Loss: 0.8852 - Test Loss: 7.0345 - MSE: 7.0345 - MAE: 1.9752\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9633/20000 - Train Loss: 0.8850 - Test Loss: 7.0336 - MSE: 7.0336 - MAE: 1.9751\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9634/20000 - Train Loss: 0.8848 - Test Loss: 7.0327 - MSE: 7.0327 - MAE: 1.9750\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9635/20000 - Train Loss: 0.8846 - Test Loss: 7.0317 - MSE: 7.0317 - MAE: 1.9749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9636/20000 - Train Loss: 0.8844 - Test Loss: 7.0309 - MSE: 7.0309 - MAE: 1.9747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9637/20000 - Train Loss: 0.8843 - Test Loss: 7.0300 - MSE: 7.0300 - MAE: 1.9746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9638/20000 - Train Loss: 0.8841 - Test Loss: 7.0290 - MSE: 7.0290 - MAE: 1.9745\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9639/20000 - Train Loss: 0.8839 - Test Loss: 7.0281 - MSE: 7.0281 - MAE: 1.9744\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9640/20000 - Train Loss: 0.8837 - Test Loss: 7.0272 - MSE: 7.0272 - MAE: 1.9743\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9641/20000 - Train Loss: 0.8836 - Test Loss: 7.0263 - MSE: 7.0263 - MAE: 1.9741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9642/20000 - Train Loss: 0.8834 - Test Loss: 7.0253 - MSE: 7.0253 - MAE: 1.9740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9643/20000 - Train Loss: 0.8832 - Test Loss: 7.0244 - MSE: 7.0244 - MAE: 1.9739\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9644/20000 - Train Loss: 0.8830 - Test Loss: 7.0236 - MSE: 7.0236 - MAE: 1.9738\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 9645/20000 - Train Loss: 0.8829 - Test Loss: 7.0226 - MSE: 7.0226 - MAE: 1.9736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9646/20000 - Train Loss: 0.8827 - Test Loss: 7.0216 - MSE: 7.0216 - MAE: 1.9735\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9647/20000 - Train Loss: 0.8825 - Test Loss: 7.0208 - MSE: 7.0208 - MAE: 1.9734\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9648/20000 - Train Loss: 0.8823 - Test Loss: 7.0199 - MSE: 7.0199 - MAE: 1.9733\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9649/20000 - Train Loss: 0.8822 - Test Loss: 7.0189 - MSE: 7.0189 - MAE: 1.9731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9650/20000 - Train Loss: 0.8820 - Test Loss: 7.0180 - MSE: 7.0180 - MAE: 1.9730\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9651/20000 - Train Loss: 0.8818 - Test Loss: 7.0172 - MSE: 7.0172 - MAE: 1.9729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9652/20000 - Train Loss: 0.8817 - Test Loss: 7.0162 - MSE: 7.0162 - MAE: 1.9728\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9653/20000 - Train Loss: 0.8815 - Test Loss: 7.0153 - MSE: 7.0153 - MAE: 1.9726\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9654/20000 - Train Loss: 0.8813 - Test Loss: 7.0144 - MSE: 7.0144 - MAE: 1.9725\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9655/20000 - Train Loss: 0.8811 - Test Loss: 7.0135 - MSE: 7.0135 - MAE: 1.9724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9656/20000 - Train Loss: 0.8810 - Test Loss: 7.0126 - MSE: 7.0126 - MAE: 1.9723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9657/20000 - Train Loss: 0.8808 - Test Loss: 7.0116 - MSE: 7.0116 - MAE: 1.9722\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9658/20000 - Train Loss: 0.8806 - Test Loss: 7.0108 - MSE: 7.0108 - MAE: 1.9720\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9659/20000 - Train Loss: 0.8804 - Test Loss: 7.0098 - MSE: 7.0098 - MAE: 1.9719\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9660/20000 - Train Loss: 0.8803 - Test Loss: 7.0089 - MSE: 7.0089 - MAE: 1.9718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9661/20000 - Train Loss: 0.8801 - Test Loss: 7.0080 - MSE: 7.0080 - MAE: 1.9717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9662/20000 - Train Loss: 0.8799 - Test Loss: 7.0071 - MSE: 7.0071 - MAE: 1.9715\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9663/20000 - Train Loss: 0.8797 - Test Loss: 7.0062 - MSE: 7.0062 - MAE: 1.9714\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9664/20000 - Train Loss: 0.8796 - Test Loss: 7.0052 - MSE: 7.0052 - MAE: 1.9713\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9665/20000 - Train Loss: 0.8794 - Test Loss: 7.0043 - MSE: 7.0043 - MAE: 1.9712\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9666/20000 - Train Loss: 0.8792 - Test Loss: 7.0035 - MSE: 7.0035 - MAE: 1.9711\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9667/20000 - Train Loss: 0.8791 - Test Loss: 7.0025 - MSE: 7.0025 - MAE: 1.9709\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 9668/20000 - Train Loss: 0.8789 - Test Loss: 7.0016 - MSE: 7.0016 - MAE: 1.9708\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9669/20000 - Train Loss: 0.8787 - Test Loss: 7.0007 - MSE: 7.0007 - MAE: 1.9707\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9670/20000 - Train Loss: 0.8785 - Test Loss: 6.9998 - MSE: 6.9998 - MAE: 1.9706\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9671/20000 - Train Loss: 0.8784 - Test Loss: 6.9989 - MSE: 6.9989 - MAE: 1.9704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9672/20000 - Train Loss: 0.8782 - Test Loss: 6.9979 - MSE: 6.9979 - MAE: 1.9703\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9673/20000 - Train Loss: 0.8780 - Test Loss: 6.9970 - MSE: 6.9970 - MAE: 1.9702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9674/20000 - Train Loss: 0.8778 - Test Loss: 6.9962 - MSE: 6.9962 - MAE: 1.9701\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9675/20000 - Train Loss: 0.8777 - Test Loss: 6.9952 - MSE: 6.9952 - MAE: 1.9699\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9676/20000 - Train Loss: 0.8775 - Test Loss: 6.9943 - MSE: 6.9943 - MAE: 1.9698\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9677/20000 - Train Loss: 0.8773 - Test Loss: 6.9934 - MSE: 6.9934 - MAE: 1.9697\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9678/20000 - Train Loss: 0.8772 - Test Loss: 6.9925 - MSE: 6.9925 - MAE: 1.9696\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9679/20000 - Train Loss: 0.8770 - Test Loss: 6.9915 - MSE: 6.9915 - MAE: 1.9694\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9680/20000 - Train Loss: 0.8768 - Test Loss: 6.9907 - MSE: 6.9907 - MAE: 1.9693\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9681/20000 - Train Loss: 0.8766 - Test Loss: 6.9898 - MSE: 6.9898 - MAE: 1.9692\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9682/20000 - Train Loss: 0.8765 - Test Loss: 6.9888 - MSE: 6.9888 - MAE: 1.9691\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9683/20000 - Train Loss: 0.8763 - Test Loss: 6.9879 - MSE: 6.9879 - MAE: 1.9689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9684/20000 - Train Loss: 0.8761 - Test Loss: 6.9870 - MSE: 6.9870 - MAE: 1.9688\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9685/20000 - Train Loss: 0.8760 - Test Loss: 6.9861 - MSE: 6.9861 - MAE: 1.9687\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9686/20000 - Train Loss: 0.8758 - Test Loss: 6.9852 - MSE: 6.9852 - MAE: 1.9686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9687/20000 - Train Loss: 0.8756 - Test Loss: 6.9843 - MSE: 6.9843 - MAE: 1.9684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9688/20000 - Train Loss: 0.8754 - Test Loss: 6.9834 - MSE: 6.9834 - MAE: 1.9683\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9689/20000 - Train Loss: 0.8753 - Test Loss: 6.9825 - MSE: 6.9825 - MAE: 1.9682\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9690/20000 - Train Loss: 0.8751 - Test Loss: 6.9816 - MSE: 6.9816 - MAE: 1.9681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9691/20000 - Train Loss: 0.8749 - Test Loss: 6.9807 - MSE: 6.9807 - MAE: 1.9679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9692/20000 - Train Loss: 0.8748 - Test Loss: 6.9797 - MSE: 6.9797 - MAE: 1.9678\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9693/20000 - Train Loss: 0.8746 - Test Loss: 6.9788 - MSE: 6.9788 - MAE: 1.9677\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9694/20000 - Train Loss: 0.8744 - Test Loss: 6.9779 - MSE: 6.9779 - MAE: 1.9676\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9695/20000 - Train Loss: 0.8743 - Test Loss: 6.9770 - MSE: 6.9770 - MAE: 1.9674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9696/20000 - Train Loss: 0.8741 - Test Loss: 6.9761 - MSE: 6.9761 - MAE: 1.9673\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9697/20000 - Train Loss: 0.8739 - Test Loss: 6.9752 - MSE: 6.9752 - MAE: 1.9672\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9698/20000 - Train Loss: 0.8737 - Test Loss: 6.9743 - MSE: 6.9743 - MAE: 1.9671\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9699/20000 - Train Loss: 0.8736 - Test Loss: 6.9734 - MSE: 6.9734 - MAE: 1.9669\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9700/20000 - Train Loss: 0.8734 - Test Loss: 6.9725 - MSE: 6.9725 - MAE: 1.9668\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9701/20000 - Train Loss: 0.8732 - Test Loss: 6.9716 - MSE: 6.9716 - MAE: 1.9667\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9702/20000 - Train Loss: 0.8731 - Test Loss: 6.9706 - MSE: 6.9706 - MAE: 1.9666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9703/20000 - Train Loss: 0.8729 - Test Loss: 6.9697 - MSE: 6.9697 - MAE: 1.9664\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9704/20000 - Train Loss: 0.8727 - Test Loss: 6.9688 - MSE: 6.9688 - MAE: 1.9663\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9705/20000 - Train Loss: 0.8726 - Test Loss: 6.9679 - MSE: 6.9679 - MAE: 1.9662\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9706/20000 - Train Loss: 0.8724 - Test Loss: 6.9670 - MSE: 6.9670 - MAE: 1.9660\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9707/20000 - Train Loss: 0.8722 - Test Loss: 6.9661 - MSE: 6.9661 - MAE: 1.9659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9708/20000 - Train Loss: 0.8720 - Test Loss: 6.9653 - MSE: 6.9653 - MAE: 1.9658\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9709/20000 - Train Loss: 0.8719 - Test Loss: 6.9643 - MSE: 6.9643 - MAE: 1.9657\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9710/20000 - Train Loss: 0.8717 - Test Loss: 6.9633 - MSE: 6.9633 - MAE: 1.9655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9711/20000 - Train Loss: 0.8715 - Test Loss: 6.9625 - MSE: 6.9625 - MAE: 1.9654\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9712/20000 - Train Loss: 0.8714 - Test Loss: 6.9616 - MSE: 6.9616 - MAE: 1.9653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9713/20000 - Train Loss: 0.8712 - Test Loss: 6.9606 - MSE: 6.9606 - MAE: 1.9652\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9714/20000 - Train Loss: 0.8710 - Test Loss: 6.9597 - MSE: 6.9597 - MAE: 1.9650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9715/20000 - Train Loss: 0.8709 - Test Loss: 6.9589 - MSE: 6.9589 - MAE: 1.9649\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9716/20000 - Train Loss: 0.8707 - Test Loss: 6.9580 - MSE: 6.9580 - MAE: 1.9648\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9717/20000 - Train Loss: 0.8705 - Test Loss: 6.9569 - MSE: 6.9569 - MAE: 1.9646\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9718/20000 - Train Loss: 0.8704 - Test Loss: 6.9561 - MSE: 6.9561 - MAE: 1.9645\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9719/20000 - Train Loss: 0.8702 - Test Loss: 6.9553 - MSE: 6.9553 - MAE: 1.9644\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9720/20000 - Train Loss: 0.8700 - Test Loss: 6.9543 - MSE: 6.9543 - MAE: 1.9643\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9721/20000 - Train Loss: 0.8699 - Test Loss: 6.9533 - MSE: 6.9533 - MAE: 1.9641\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9722/20000 - Train Loss: 0.8697 - Test Loss: 6.9526 - MSE: 6.9526 - MAE: 1.9640\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9723/20000 - Train Loss: 0.8695 - Test Loss: 6.9516 - MSE: 6.9516 - MAE: 1.9639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9724/20000 - Train Loss: 0.8694 - Test Loss: 6.9506 - MSE: 6.9506 - MAE: 1.9638\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9725/20000 - Train Loss: 0.8692 - Test Loss: 6.9498 - MSE: 6.9498 - MAE: 1.9636\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9726/20000 - Train Loss: 0.8690 - Test Loss: 6.9489 - MSE: 6.9489 - MAE: 1.9635\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9727/20000 - Train Loss: 0.8689 - Test Loss: 6.9479 - MSE: 6.9479 - MAE: 1.9634\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9728/20000 - Train Loss: 0.8687 - Test Loss: 6.9470 - MSE: 6.9470 - MAE: 1.9633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9729/20000 - Train Loss: 0.8685 - Test Loss: 6.9462 - MSE: 6.9462 - MAE: 1.9631\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9730/20000 - Train Loss: 0.8683 - Test Loss: 6.9453 - MSE: 6.9453 - MAE: 1.9630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9731/20000 - Train Loss: 0.8682 - Test Loss: 6.9443 - MSE: 6.9443 - MAE: 1.9629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9732/20000 - Train Loss: 0.8680 - Test Loss: 6.9434 - MSE: 6.9434 - MAE: 1.9628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9733/20000 - Train Loss: 0.8678 - Test Loss: 6.9426 - MSE: 6.9426 - MAE: 1.9626\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9734/20000 - Train Loss: 0.8677 - Test Loss: 6.9416 - MSE: 6.9416 - MAE: 1.9625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9735/20000 - Train Loss: 0.8675 - Test Loss: 6.9407 - MSE: 6.9407 - MAE: 1.9624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9736/20000 - Train Loss: 0.8673 - Test Loss: 6.9398 - MSE: 6.9398 - MAE: 1.9622\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9737/20000 - Train Loss: 0.8672 - Test Loss: 6.9389 - MSE: 6.9389 - MAE: 1.9621\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9738/20000 - Train Loss: 0.8670 - Test Loss: 6.9380 - MSE: 6.9380 - MAE: 1.9620\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9739/20000 - Train Loss: 0.8668 - Test Loss: 6.9371 - MSE: 6.9371 - MAE: 1.9620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9740/20000 - Train Loss: 0.8667 - Test Loss: 6.9362 - MSE: 6.9362 - MAE: 1.9619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9741/20000 - Train Loss: 0.8665 - Test Loss: 6.9353 - MSE: 6.9353 - MAE: 1.9618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9742/20000 - Train Loss: 0.8663 - Test Loss: 6.9344 - MSE: 6.9344 - MAE: 1.9618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9743/20000 - Train Loss: 0.8662 - Test Loss: 6.9335 - MSE: 6.9335 - MAE: 1.9617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9744/20000 - Train Loss: 0.8660 - Test Loss: 6.9325 - MSE: 6.9325 - MAE: 1.9617\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9745/20000 - Train Loss: 0.8658 - Test Loss: 6.9317 - MSE: 6.9317 - MAE: 1.9616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9746/20000 - Train Loss: 0.8657 - Test Loss: 6.9308 - MSE: 6.9308 - MAE: 1.9616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9747/20000 - Train Loss: 0.8655 - Test Loss: 6.9299 - MSE: 6.9299 - MAE: 1.9615\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9748/20000 - Train Loss: 0.8654 - Test Loss: 6.9290 - MSE: 6.9289 - MAE: 1.9615\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9749/20000 - Train Loss: 0.8652 - Test Loss: 6.9281 - MSE: 6.9281 - MAE: 1.9614\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9750/20000 - Train Loss: 0.8650 - Test Loss: 6.9272 - MSE: 6.9272 - MAE: 1.9614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9751/20000 - Train Loss: 0.8649 - Test Loss: 6.9263 - MSE: 6.9263 - MAE: 1.9613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9752/20000 - Train Loss: 0.8647 - Test Loss: 6.9253 - MSE: 6.9253 - MAE: 1.9613\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9753/20000 - Train Loss: 0.8645 - Test Loss: 6.9245 - MSE: 6.9245 - MAE: 1.9612\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9754/20000 - Train Loss: 0.8644 - Test Loss: 6.9236 - MSE: 6.9236 - MAE: 1.9612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9755/20000 - Train Loss: 0.8642 - Test Loss: 6.9226 - MSE: 6.9226 - MAE: 1.9611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9756/20000 - Train Loss: 0.8640 - Test Loss: 6.9218 - MSE: 6.9218 - MAE: 1.9611\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9757/20000 - Train Loss: 0.8639 - Test Loss: 6.9209 - MSE: 6.9209 - MAE: 1.9610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9758/20000 - Train Loss: 0.8637 - Test Loss: 6.9199 - MSE: 6.9199 - MAE: 1.9610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9759/20000 - Train Loss: 0.8635 - Test Loss: 6.9190 - MSE: 6.9190 - MAE: 1.9609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9760/20000 - Train Loss: 0.8634 - Test Loss: 6.9181 - MSE: 6.9181 - MAE: 1.9609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9761/20000 - Train Loss: 0.8632 - Test Loss: 6.9173 - MSE: 6.9173 - MAE: 1.9609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9762/20000 - Train Loss: 0.8630 - Test Loss: 6.9163 - MSE: 6.9163 - MAE: 1.9608\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9763/20000 - Train Loss: 0.8629 - Test Loss: 6.9154 - MSE: 6.9154 - MAE: 1.9608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9764/20000 - Train Loss: 0.8627 - Test Loss: 6.9146 - MSE: 6.9146 - MAE: 1.9607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9765/20000 - Train Loss: 0.8625 - Test Loss: 6.9136 - MSE: 6.9136 - MAE: 1.9607\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9766/20000 - Train Loss: 0.8624 - Test Loss: 6.9127 - MSE: 6.9127 - MAE: 1.9606\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9767/20000 - Train Loss: 0.8622 - Test Loss: 6.9118 - MSE: 6.9118 - MAE: 1.9606\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9768/20000 - Train Loss: 0.8621 - Test Loss: 6.9109 - MSE: 6.9109 - MAE: 1.9605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9769/20000 - Train Loss: 0.8619 - Test Loss: 6.9100 - MSE: 6.9100 - MAE: 1.9605\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9770/20000 - Train Loss: 0.8617 - Test Loss: 6.9092 - MSE: 6.9092 - MAE: 1.9604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9771/20000 - Train Loss: 0.8616 - Test Loss: 6.9082 - MSE: 6.9082 - MAE: 1.9604\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9772/20000 - Train Loss: 0.8614 - Test Loss: 6.9073 - MSE: 6.9073 - MAE: 1.9603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9773/20000 - Train Loss: 0.8612 - Test Loss: 6.9065 - MSE: 6.9065 - MAE: 1.9603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9774/20000 - Train Loss: 0.8611 - Test Loss: 6.9055 - MSE: 6.9055 - MAE: 1.9602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9775/20000 - Train Loss: 0.8609 - Test Loss: 6.9046 - MSE: 6.9046 - MAE: 1.9602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9776/20000 - Train Loss: 0.8607 - Test Loss: 6.9038 - MSE: 6.9038 - MAE: 1.9601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9777/20000 - Train Loss: 0.8606 - Test Loss: 6.9028 - MSE: 6.9028 - MAE: 1.9601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9778/20000 - Train Loss: 0.8604 - Test Loss: 6.9019 - MSE: 6.9019 - MAE: 1.9600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9779/20000 - Train Loss: 0.8603 - Test Loss: 6.9011 - MSE: 6.9011 - MAE: 1.9600\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9780/20000 - Train Loss: 0.8601 - Test Loss: 6.9002 - MSE: 6.9002 - MAE: 1.9599\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9781/20000 - Train Loss: 0.8599 - Test Loss: 6.8992 - MSE: 6.8992 - MAE: 1.9599\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9782/20000 - Train Loss: 0.8598 - Test Loss: 6.8983 - MSE: 6.8983 - MAE: 1.9598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9783/20000 - Train Loss: 0.8596 - Test Loss: 6.8975 - MSE: 6.8975 - MAE: 1.9598\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9784/20000 - Train Loss: 0.8594 - Test Loss: 6.8965 - MSE: 6.8965 - MAE: 1.9597\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9785/20000 - Train Loss: 0.8593 - Test Loss: 6.8956 - MSE: 6.8956 - MAE: 1.9597\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9786/20000 - Train Loss: 0.8591 - Test Loss: 6.8948 - MSE: 6.8948 - MAE: 1.9596\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9787/20000 - Train Loss: 0.8589 - Test Loss: 6.8938 - MSE: 6.8938 - MAE: 1.9596\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9788/20000 - Train Loss: 0.8588 - Test Loss: 6.8929 - MSE: 6.8929 - MAE: 1.9595\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9789/20000 - Train Loss: 0.8586 - Test Loss: 6.8920 - MSE: 6.8920 - MAE: 1.9595\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9790/20000 - Train Loss: 0.8585 - Test Loss: 6.8912 - MSE: 6.8912 - MAE: 1.9594\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9791/20000 - Train Loss: 0.8583 - Test Loss: 6.8902 - MSE: 6.8902 - MAE: 1.9594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9792/20000 - Train Loss: 0.8581 - Test Loss: 6.8893 - MSE: 6.8893 - MAE: 1.9593\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9793/20000 - Train Loss: 0.8580 - Test Loss: 6.8885 - MSE: 6.8885 - MAE: 1.9593\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9794/20000 - Train Loss: 0.8578 - Test Loss: 6.8875 - MSE: 6.8875 - MAE: 1.9592\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9795/20000 - Train Loss: 0.8576 - Test Loss: 6.8866 - MSE: 6.8866 - MAE: 1.9592\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9796/20000 - Train Loss: 0.8575 - Test Loss: 6.8858 - MSE: 6.8858 - MAE: 1.9591\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9797/20000 - Train Loss: 0.8573 - Test Loss: 6.8848 - MSE: 6.8848 - MAE: 1.9591\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9798/20000 - Train Loss: 0.8572 - Test Loss: 6.8840 - MSE: 6.8840 - MAE: 1.9590\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9799/20000 - Train Loss: 0.8570 - Test Loss: 6.8831 - MSE: 6.8831 - MAE: 1.9590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9800/20000 - Train Loss: 0.8568 - Test Loss: 6.8822 - MSE: 6.8822 - MAE: 1.9589\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9801/20000 - Train Loss: 0.8567 - Test Loss: 6.8813 - MSE: 6.8813 - MAE: 1.9589\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9802/20000 - Train Loss: 0.8565 - Test Loss: 6.8804 - MSE: 6.8804 - MAE: 1.9588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9803/20000 - Train Loss: 0.8564 - Test Loss: 6.8795 - MSE: 6.8795 - MAE: 1.9588\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9804/20000 - Train Loss: 0.8562 - Test Loss: 6.8786 - MSE: 6.8786 - MAE: 1.9587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9805/20000 - Train Loss: 0.8560 - Test Loss: 6.8777 - MSE: 6.8777 - MAE: 1.9587\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9806/20000 - Train Loss: 0.8559 - Test Loss: 6.8768 - MSE: 6.8768 - MAE: 1.9586\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9807/20000 - Train Loss: 0.8557 - Test Loss: 6.8759 - MSE: 6.8759 - MAE: 1.9586\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9808/20000 - Train Loss: 0.8555 - Test Loss: 6.8750 - MSE: 6.8750 - MAE: 1.9585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9809/20000 - Train Loss: 0.8554 - Test Loss: 6.8741 - MSE: 6.8741 - MAE: 1.9585\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9810/20000 - Train Loss: 0.8552 - Test Loss: 6.8732 - MSE: 6.8732 - MAE: 1.9584\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9811/20000 - Train Loss: 0.8551 - Test Loss: 6.8723 - MSE: 6.8723 - MAE: 1.9584\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9812/20000 - Train Loss: 0.8549 - Test Loss: 6.8714 - MSE: 6.8714 - MAE: 1.9583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9813/20000 - Train Loss: 0.8547 - Test Loss: 6.8705 - MSE: 6.8705 - MAE: 1.9583\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9814/20000 - Train Loss: 0.8546 - Test Loss: 6.8697 - MSE: 6.8697 - MAE: 1.9582\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9815/20000 - Train Loss: 0.8544 - Test Loss: 6.8687 - MSE: 6.8687 - MAE: 1.9582\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9816/20000 - Train Loss: 0.8543 - Test Loss: 6.8678 - MSE: 6.8678 - MAE: 1.9581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9817/20000 - Train Loss: 0.8541 - Test Loss: 6.8669 - MSE: 6.8669 - MAE: 1.9581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9818/20000 - Train Loss: 0.8539 - Test Loss: 6.8661 - MSE: 6.8661 - MAE: 1.9580\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9819/20000 - Train Loss: 0.8538 - Test Loss: 6.8651 - MSE: 6.8651 - MAE: 1.9580\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9820/20000 - Train Loss: 0.8536 - Test Loss: 6.8642 - MSE: 6.8642 - MAE: 1.9579\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9821/20000 - Train Loss: 0.8535 - Test Loss: 6.8634 - MSE: 6.8634 - MAE: 1.9579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9822/20000 - Train Loss: 0.8533 - Test Loss: 6.8625 - MSE: 6.8625 - MAE: 1.9578\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9823/20000 - Train Loss: 0.8531 - Test Loss: 6.8616 - MSE: 6.8616 - MAE: 1.9578\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9824/20000 - Train Loss: 0.8530 - Test Loss: 6.8607 - MSE: 6.8607 - MAE: 1.9577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9825/20000 - Train Loss: 0.8528 - Test Loss: 6.8598 - MSE: 6.8598 - MAE: 1.9577\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9826/20000 - Train Loss: 0.8527 - Test Loss: 6.8589 - MSE: 6.8589 - MAE: 1.9576\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9827/20000 - Train Loss: 0.8525 - Test Loss: 6.8580 - MSE: 6.8580 - MAE: 1.9576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9828/20000 - Train Loss: 0.8523 - Test Loss: 6.8571 - MSE: 6.8571 - MAE: 1.9575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9829/20000 - Train Loss: 0.8522 - Test Loss: 6.8562 - MSE: 6.8562 - MAE: 1.9575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9830/20000 - Train Loss: 0.8520 - Test Loss: 6.8553 - MSE: 6.8553 - MAE: 1.9574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9831/20000 - Train Loss: 0.8519 - Test Loss: 6.8545 - MSE: 6.8545 - MAE: 1.9574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9832/20000 - Train Loss: 0.8517 - Test Loss: 6.8535 - MSE: 6.8535 - MAE: 1.9573\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9833/20000 - Train Loss: 0.8515 - Test Loss: 6.8526 - MSE: 6.8526 - MAE: 1.9572\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9834/20000 - Train Loss: 0.8514 - Test Loss: 6.8518 - MSE: 6.8518 - MAE: 1.9572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9835/20000 - Train Loss: 0.8512 - Test Loss: 6.8509 - MSE: 6.8509 - MAE: 1.9572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9836/20000 - Train Loss: 0.8511 - Test Loss: 6.8499 - MSE: 6.8499 - MAE: 1.9571\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9837/20000 - Train Loss: 0.8509 - Test Loss: 6.8491 - MSE: 6.8491 - MAE: 1.9570\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9838/20000 - Train Loss: 0.8507 - Test Loss: 6.8482 - MSE: 6.8482 - MAE: 1.9570\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9839/20000 - Train Loss: 0.8506 - Test Loss: 6.8473 - MSE: 6.8473 - MAE: 1.9569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9840/20000 - Train Loss: 0.8504 - Test Loss: 6.8464 - MSE: 6.8464 - MAE: 1.9569\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9841/20000 - Train Loss: 0.8503 - Test Loss: 6.8455 - MSE: 6.8455 - MAE: 1.9568\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9842/20000 - Train Loss: 0.8501 - Test Loss: 6.8446 - MSE: 6.8446 - MAE: 1.9568\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9843/20000 - Train Loss: 0.8500 - Test Loss: 6.8437 - MSE: 6.8437 - MAE: 1.9567\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9844/20000 - Train Loss: 0.8498 - Test Loss: 6.8429 - MSE: 6.8429 - MAE: 1.9567\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9845/20000 - Train Loss: 0.8496 - Test Loss: 6.8419 - MSE: 6.8419 - MAE: 1.9566\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9846/20000 - Train Loss: 0.8495 - Test Loss: 6.8410 - MSE: 6.8410 - MAE: 1.9566\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9847/20000 - Train Loss: 0.8493 - Test Loss: 6.8402 - MSE: 6.8402 - MAE: 1.9565\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9848/20000 - Train Loss: 0.8492 - Test Loss: 6.8393 - MSE: 6.8393 - MAE: 1.9565\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9849/20000 - Train Loss: 0.8490 - Test Loss: 6.8384 - MSE: 6.8384 - MAE: 1.9564\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9850/20000 - Train Loss: 0.8488 - Test Loss: 6.8375 - MSE: 6.8375 - MAE: 1.9564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9851/20000 - Train Loss: 0.8487 - Test Loss: 6.8366 - MSE: 6.8366 - MAE: 1.9563\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9852/20000 - Train Loss: 0.8485 - Test Loss: 6.8357 - MSE: 6.8357 - MAE: 1.9563\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9853/20000 - Train Loss: 0.8484 - Test Loss: 6.8348 - MSE: 6.8348 - MAE: 1.9562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9854/20000 - Train Loss: 0.8482 - Test Loss: 6.8339 - MSE: 6.8339 - MAE: 1.9561\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 9855/20000 - Train Loss: 0.8481 - Test Loss: 6.8331 - MSE: 6.8331 - MAE: 1.9561\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9856/20000 - Train Loss: 0.8479 - Test Loss: 6.8322 - MSE: 6.8322 - MAE: 1.9560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9857/20000 - Train Loss: 0.8477 - Test Loss: 6.8313 - MSE: 6.8313 - MAE: 1.9560\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9858/20000 - Train Loss: 0.8476 - Test Loss: 6.8304 - MSE: 6.8304 - MAE: 1.9559\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9859/20000 - Train Loss: 0.8474 - Test Loss: 6.8295 - MSE: 6.8295 - MAE: 1.9559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9860/20000 - Train Loss: 0.8473 - Test Loss: 6.8286 - MSE: 6.8286 - MAE: 1.9558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9861/20000 - Train Loss: 0.8471 - Test Loss: 6.8277 - MSE: 6.8277 - MAE: 1.9558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9862/20000 - Train Loss: 0.8470 - Test Loss: 6.8268 - MSE: 6.8268 - MAE: 1.9557\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9863/20000 - Train Loss: 0.8468 - Test Loss: 6.8259 - MSE: 6.8259 - MAE: 1.9557\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9864/20000 - Train Loss: 0.8466 - Test Loss: 6.8251 - MSE: 6.8251 - MAE: 1.9556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9865/20000 - Train Loss: 0.8465 - Test Loss: 6.8241 - MSE: 6.8241 - MAE: 1.9556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9866/20000 - Train Loss: 0.8463 - Test Loss: 6.8233 - MSE: 6.8233 - MAE: 1.9555\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9867/20000 - Train Loss: 0.8462 - Test Loss: 6.8224 - MSE: 6.8224 - MAE: 1.9555\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9868/20000 - Train Loss: 0.8460 - Test Loss: 6.8215 - MSE: 6.8215 - MAE: 1.9554\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9869/20000 - Train Loss: 0.8459 - Test Loss: 6.8206 - MSE: 6.8206 - MAE: 1.9553\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9870/20000 - Train Loss: 0.8457 - Test Loss: 6.8198 - MSE: 6.8198 - MAE: 1.9553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9871/20000 - Train Loss: 0.8455 - Test Loss: 6.8188 - MSE: 6.8188 - MAE: 1.9552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9872/20000 - Train Loss: 0.8454 - Test Loss: 6.8179 - MSE: 6.8179 - MAE: 1.9552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9873/20000 - Train Loss: 0.8452 - Test Loss: 6.8171 - MSE: 6.8171 - MAE: 1.9551\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 9874/20000 - Train Loss: 0.8451 - Test Loss: 6.8162 - MSE: 6.8162 - MAE: 1.9551\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9875/20000 - Train Loss: 0.8449 - Test Loss: 6.8153 - MSE: 6.8153 - MAE: 1.9550\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9876/20000 - Train Loss: 0.8448 - Test Loss: 6.8144 - MSE: 6.8144 - MAE: 1.9550\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 9877/20000 - Train Loss: 0.8446 - Test Loss: 6.8135 - MSE: 6.8135 - MAE: 1.9549\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9878/20000 - Train Loss: 0.8444 - Test Loss: 6.8126 - MSE: 6.8126 - MAE: 1.9549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9879/20000 - Train Loss: 0.8443 - Test Loss: 6.8117 - MSE: 6.8117 - MAE: 1.9548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9880/20000 - Train Loss: 0.8441 - Test Loss: 6.8109 - MSE: 6.8109 - MAE: 1.9548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9881/20000 - Train Loss: 0.8440 - Test Loss: 6.8099 - MSE: 6.8099 - MAE: 1.9547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9882/20000 - Train Loss: 0.8438 - Test Loss: 6.8091 - MSE: 6.8091 - MAE: 1.9546\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9883/20000 - Train Loss: 0.8437 - Test Loss: 6.8082 - MSE: 6.8082 - MAE: 1.9546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9884/20000 - Train Loss: 0.8435 - Test Loss: 6.8073 - MSE: 6.8073 - MAE: 1.9545\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9885/20000 - Train Loss: 0.8434 - Test Loss: 6.8064 - MSE: 6.8064 - MAE: 1.9545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9886/20000 - Train Loss: 0.8432 - Test Loss: 6.8056 - MSE: 6.8056 - MAE: 1.9544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9887/20000 - Train Loss: 0.8430 - Test Loss: 6.8047 - MSE: 6.8047 - MAE: 1.9544\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9888/20000 - Train Loss: 0.8429 - Test Loss: 6.8037 - MSE: 6.8037 - MAE: 1.9543\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9889/20000 - Train Loss: 0.8427 - Test Loss: 6.8029 - MSE: 6.8029 - MAE: 1.9543\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9890/20000 - Train Loss: 0.8426 - Test Loss: 6.8020 - MSE: 6.8020 - MAE: 1.9542\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 9891/20000 - Train Loss: 0.8424 - Test Loss: 6.8011 - MSE: 6.8011 - MAE: 1.9542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9892/20000 - Train Loss: 0.8423 - Test Loss: 6.8002 - MSE: 6.8002 - MAE: 1.9541\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9893/20000 - Train Loss: 0.8421 - Test Loss: 6.7994 - MSE: 6.7994 - MAE: 1.9541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9894/20000 - Train Loss: 0.8420 - Test Loss: 6.7985 - MSE: 6.7985 - MAE: 1.9540\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9895/20000 - Train Loss: 0.8418 - Test Loss: 6.7976 - MSE: 6.7976 - MAE: 1.9539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9896/20000 - Train Loss: 0.8417 - Test Loss: 6.7967 - MSE: 6.7967 - MAE: 1.9539\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 9897/20000 - Train Loss: 0.8415 - Test Loss: 6.7959 - MSE: 6.7959 - MAE: 1.9538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9898/20000 - Train Loss: 0.8413 - Test Loss: 6.7949 - MSE: 6.7949 - MAE: 1.9538\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 9899/20000 - Train Loss: 0.8412 - Test Loss: 6.7941 - MSE: 6.7941 - MAE: 1.9537\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9900/20000 - Train Loss: 0.8410 - Test Loss: 6.7932 - MSE: 6.7932 - MAE: 1.9537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9901/20000 - Train Loss: 0.8409 - Test Loss: 6.7923 - MSE: 6.7923 - MAE: 1.9536\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9902/20000 - Train Loss: 0.8407 - Test Loss: 6.7914 - MSE: 6.7914 - MAE: 1.9536\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9903/20000 - Train Loss: 0.8406 - Test Loss: 6.7905 - MSE: 6.7905 - MAE: 1.9535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9904/20000 - Train Loss: 0.8404 - Test Loss: 6.7897 - MSE: 6.7897 - MAE: 1.9534\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9905/20000 - Train Loss: 0.8403 - Test Loss: 6.7887 - MSE: 6.7887 - MAE: 1.9534\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9906/20000 - Train Loss: 0.8401 - Test Loss: 6.7879 - MSE: 6.7879 - MAE: 1.9533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9907/20000 - Train Loss: 0.8400 - Test Loss: 6.7870 - MSE: 6.7870 - MAE: 1.9533\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9908/20000 - Train Loss: 0.8398 - Test Loss: 6.7861 - MSE: 6.7861 - MAE: 1.9532\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 9909/20000 - Train Loss: 0.8396 - Test Loss: 6.7853 - MSE: 6.7853 - MAE: 1.9532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9910/20000 - Train Loss: 0.8395 - Test Loss: 6.7843 - MSE: 6.7843 - MAE: 1.9531\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 9911/20000 - Train Loss: 0.8393 - Test Loss: 6.7835 - MSE: 6.7835 - MAE: 1.9530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9912/20000 - Train Loss: 0.8392 - Test Loss: 6.7826 - MSE: 6.7826 - MAE: 1.9530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9913/20000 - Train Loss: 0.8390 - Test Loss: 6.7817 - MSE: 6.7817 - MAE: 1.9529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9914/20000 - Train Loss: 0.8389 - Test Loss: 6.7808 - MSE: 6.7808 - MAE: 1.9529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9915/20000 - Train Loss: 0.8387 - Test Loss: 6.7800 - MSE: 6.7800 - MAE: 1.9528\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9916/20000 - Train Loss: 0.8386 - Test Loss: 6.7790 - MSE: 6.7790 - MAE: 1.9528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9917/20000 - Train Loss: 0.8384 - Test Loss: 6.7782 - MSE: 6.7782 - MAE: 1.9527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9918/20000 - Train Loss: 0.8383 - Test Loss: 6.7773 - MSE: 6.7773 - MAE: 1.9527\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9919/20000 - Train Loss: 0.8381 - Test Loss: 6.7764 - MSE: 6.7764 - MAE: 1.9526\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9920/20000 - Train Loss: 0.8380 - Test Loss: 6.7756 - MSE: 6.7756 - MAE: 1.9526\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9921/20000 - Train Loss: 0.8378 - Test Loss: 6.7747 - MSE: 6.7747 - MAE: 1.9525\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9922/20000 - Train Loss: 0.8377 - Test Loss: 6.7737 - MSE: 6.7737 - MAE: 1.9525\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9923/20000 - Train Loss: 0.8375 - Test Loss: 6.7729 - MSE: 6.7729 - MAE: 1.9524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9924/20000 - Train Loss: 0.8373 - Test Loss: 6.7721 - MSE: 6.7721 - MAE: 1.9524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9925/20000 - Train Loss: 0.8372 - Test Loss: 6.7711 - MSE: 6.7711 - MAE: 1.9523\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9926/20000 - Train Loss: 0.8370 - Test Loss: 6.7702 - MSE: 6.7702 - MAE: 1.9523\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9927/20000 - Train Loss: 0.8369 - Test Loss: 6.7695 - MSE: 6.7695 - MAE: 1.9522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9928/20000 - Train Loss: 0.8367 - Test Loss: 6.7686 - MSE: 6.7686 - MAE: 1.9522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9929/20000 - Train Loss: 0.8366 - Test Loss: 6.7675 - MSE: 6.7675 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9930/20000 - Train Loss: 0.8364 - Test Loss: 6.7668 - MSE: 6.7668 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9931/20000 - Train Loss: 0.8363 - Test Loss: 6.7660 - MSE: 6.7660 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9932/20000 - Train Loss: 0.8361 - Test Loss: 6.7650 - MSE: 6.7650 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9933/20000 - Train Loss: 0.8360 - Test Loss: 6.7641 - MSE: 6.7641 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9934/20000 - Train Loss: 0.8358 - Test Loss: 6.7633 - MSE: 6.7633 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9935/20000 - Train Loss: 0.8357 - Test Loss: 6.7624 - MSE: 6.7624 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9936/20000 - Train Loss: 0.8355 - Test Loss: 6.7614 - MSE: 6.7614 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9937/20000 - Train Loss: 0.8354 - Test Loss: 6.7607 - MSE: 6.7607 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9938/20000 - Train Loss: 0.8352 - Test Loss: 6.7598 - MSE: 6.7598 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9939/20000 - Train Loss: 0.8351 - Test Loss: 6.7588 - MSE: 6.7588 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9940/20000 - Train Loss: 0.8349 - Test Loss: 6.7580 - MSE: 6.7580 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9941/20000 - Train Loss: 0.8348 - Test Loss: 6.7572 - MSE: 6.7572 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9942/20000 - Train Loss: 0.8346 - Test Loss: 6.7562 - MSE: 6.7562 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9943/20000 - Train Loss: 0.8345 - Test Loss: 6.7553 - MSE: 6.7553 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9944/20000 - Train Loss: 0.8343 - Test Loss: 6.7545 - MSE: 6.7545 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9945/20000 - Train Loss: 0.8342 - Test Loss: 6.7536 - MSE: 6.7536 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9946/20000 - Train Loss: 0.8340 - Test Loss: 6.7527 - MSE: 6.7527 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9947/20000 - Train Loss: 0.8339 - Test Loss: 6.7519 - MSE: 6.7519 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9948/20000 - Train Loss: 0.8337 - Test Loss: 6.7510 - MSE: 6.7510 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9949/20000 - Train Loss: 0.8335 - Test Loss: 6.7500 - MSE: 6.7500 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9950/20000 - Train Loss: 0.8334 - Test Loss: 6.7492 - MSE: 6.7492 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9951/20000 - Train Loss: 0.8332 - Test Loss: 6.7484 - MSE: 6.7484 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9952/20000 - Train Loss: 0.8331 - Test Loss: 6.7474 - MSE: 6.7474 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9953/20000 - Train Loss: 0.8329 - Test Loss: 6.7466 - MSE: 6.7466 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9954/20000 - Train Loss: 0.8328 - Test Loss: 6.7458 - MSE: 6.7458 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9955/20000 - Train Loss: 0.8326 - Test Loss: 6.7449 - MSE: 6.7449 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9956/20000 - Train Loss: 0.8325 - Test Loss: 6.7439 - MSE: 6.7439 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9957/20000 - Train Loss: 0.8323 - Test Loss: 6.7431 - MSE: 6.7431 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9958/20000 - Train Loss: 0.8322 - Test Loss: 6.7423 - MSE: 6.7423 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9959/20000 - Train Loss: 0.8320 - Test Loss: 6.7413 - MSE: 6.7413 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9960/20000 - Train Loss: 0.8319 - Test Loss: 6.7405 - MSE: 6.7405 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9961/20000 - Train Loss: 0.8317 - Test Loss: 6.7397 - MSE: 6.7397 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9962/20000 - Train Loss: 0.8316 - Test Loss: 6.7387 - MSE: 6.7387 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 9963/20000 - Train Loss: 0.8314 - Test Loss: 6.7378 - MSE: 6.7378 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9964/20000 - Train Loss: 0.8313 - Test Loss: 6.7370 - MSE: 6.7370 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9965/20000 - Train Loss: 0.8311 - Test Loss: 6.7361 - MSE: 6.7361 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9966/20000 - Train Loss: 0.8310 - Test Loss: 6.7352 - MSE: 6.7352 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9967/20000 - Train Loss: 0.8308 - Test Loss: 6.7344 - MSE: 6.7344 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9968/20000 - Train Loss: 0.8307 - Test Loss: 6.7335 - MSE: 6.7335 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9969/20000 - Train Loss: 0.8305 - Test Loss: 6.7326 - MSE: 6.7326 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9970/20000 - Train Loss: 0.8304 - Test Loss: 6.7318 - MSE: 6.7318 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9971/20000 - Train Loss: 0.8302 - Test Loss: 6.7309 - MSE: 6.7309 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 9972/20000 - Train Loss: 0.8301 - Test Loss: 6.7300 - MSE: 6.7300 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 9973/20000 - Train Loss: 0.8299 - Test Loss: 6.7292 - MSE: 6.7292 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9974/20000 - Train Loss: 0.8298 - Test Loss: 6.7283 - MSE: 6.7283 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9975/20000 - Train Loss: 0.8296 - Test Loss: 6.7274 - MSE: 6.7274 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9976/20000 - Train Loss: 0.8295 - Test Loss: 6.7265 - MSE: 6.7265 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9977/20000 - Train Loss: 0.8293 - Test Loss: 6.7257 - MSE: 6.7257 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9978/20000 - Train Loss: 0.8292 - Test Loss: 6.7248 - MSE: 6.7248 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9979/20000 - Train Loss: 0.8290 - Test Loss: 6.7239 - MSE: 6.7239 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9980/20000 - Train Loss: 0.8289 - Test Loss: 6.7231 - MSE: 6.7231 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9981/20000 - Train Loss: 0.8287 - Test Loss: 6.7222 - MSE: 6.7222 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9982/20000 - Train Loss: 0.8286 - Test Loss: 6.7213 - MSE: 6.7213 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 9983/20000 - Train Loss: 0.8285 - Test Loss: 6.7205 - MSE: 6.7205 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 9984/20000 - Train Loss: 0.8283 - Test Loss: 6.7196 - MSE: 6.7196 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9985/20000 - Train Loss: 0.8282 - Test Loss: 6.7187 - MSE: 6.7187 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9986/20000 - Train Loss: 0.8280 - Test Loss: 6.7178 - MSE: 6.7178 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 9987/20000 - Train Loss: 0.8279 - Test Loss: 6.7170 - MSE: 6.7170 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9988/20000 - Train Loss: 0.8277 - Test Loss: 6.7161 - MSE: 6.7161 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9989/20000 - Train Loss: 0.8276 - Test Loss: 6.7152 - MSE: 6.7152 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9990/20000 - Train Loss: 0.8274 - Test Loss: 6.7144 - MSE: 6.7144 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9991/20000 - Train Loss: 0.8273 - Test Loss: 6.7135 - MSE: 6.7135 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 9992/20000 - Train Loss: 0.8271 - Test Loss: 6.7126 - MSE: 6.7126 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9993/20000 - Train Loss: 0.8270 - Test Loss: 6.7118 - MSE: 6.7118 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9994/20000 - Train Loss: 0.8268 - Test Loss: 6.7109 - MSE: 6.7109 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9995/20000 - Train Loss: 0.8267 - Test Loss: 6.7100 - MSE: 6.7100 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9996/20000 - Train Loss: 0.8265 - Test Loss: 6.7091 - MSE: 6.7091 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9997/20000 - Train Loss: 0.8264 - Test Loss: 6.7083 - MSE: 6.7083 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9998/20000 - Train Loss: 0.8262 - Test Loss: 6.7074 - MSE: 6.7074 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 9999/20000 - Train Loss: 0.8261 - Test Loss: 6.7066 - MSE: 6.7066 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10000/20000 - Train Loss: 0.8259 - Test Loss: 6.7057 - MSE: 6.7057 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10001/20000 - Train Loss: 0.8258 - Test Loss: 6.7048 - MSE: 6.7048 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10002/20000 - Train Loss: 0.8256 - Test Loss: 6.7039 - MSE: 6.7039 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10003/20000 - Train Loss: 0.8255 - Test Loss: 6.7031 - MSE: 6.7031 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10004/20000 - Train Loss: 0.8253 - Test Loss: 6.7023 - MSE: 6.7023 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10005/20000 - Train Loss: 0.8252 - Test Loss: 6.7013 - MSE: 6.7013 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10006/20000 - Train Loss: 0.8250 - Test Loss: 6.7005 - MSE: 6.7005 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10007/20000 - Train Loss: 0.8249 - Test Loss: 6.6997 - MSE: 6.6997 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10008/20000 - Train Loss: 0.8248 - Test Loss: 6.6988 - MSE: 6.6988 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 10009/20000 - Train Loss: 0.8246 - Test Loss: 6.6979 - MSE: 6.6979 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10010/20000 - Train Loss: 0.8245 - Test Loss: 6.6970 - MSE: 6.6970 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10011/20000 - Train Loss: 0.8243 - Test Loss: 6.6962 - MSE: 6.6962 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10012/20000 - Train Loss: 0.8242 - Test Loss: 6.6953 - MSE: 6.6953 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10013/20000 - Train Loss: 0.8240 - Test Loss: 6.6944 - MSE: 6.6944 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10014/20000 - Train Loss: 0.8239 - Test Loss: 6.6936 - MSE: 6.6936 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10015/20000 - Train Loss: 0.8237 - Test Loss: 6.6928 - MSE: 6.6928 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10016/20000 - Train Loss: 0.8236 - Test Loss: 6.6918 - MSE: 6.6918 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10017/20000 - Train Loss: 0.8234 - Test Loss: 6.6910 - MSE: 6.6910 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10018/20000 - Train Loss: 0.8233 - Test Loss: 6.6902 - MSE: 6.6902 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10019/20000 - Train Loss: 0.8231 - Test Loss: 6.6892 - MSE: 6.6892 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10020/20000 - Train Loss: 0.8230 - Test Loss: 6.6884 - MSE: 6.6884 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10021/20000 - Train Loss: 0.8228 - Test Loss: 6.6876 - MSE: 6.6876 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10022/20000 - Train Loss: 0.8227 - Test Loss: 6.6866 - MSE: 6.6866 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10023/20000 - Train Loss: 0.8225 - Test Loss: 6.6858 - MSE: 6.6858 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10024/20000 - Train Loss: 0.8224 - Test Loss: 6.6850 - MSE: 6.6850 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10025/20000 - Train Loss: 0.8223 - Test Loss: 6.6841 - MSE: 6.6840 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10026/20000 - Train Loss: 0.8221 - Test Loss: 6.6832 - MSE: 6.6832 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10027/20000 - Train Loss: 0.8220 - Test Loss: 6.6824 - MSE: 6.6824 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10028/20000 - Train Loss: 0.8218 - Test Loss: 6.6815 - MSE: 6.6815 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10029/20000 - Train Loss: 0.8217 - Test Loss: 6.6806 - MSE: 6.6806 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10030/20000 - Train Loss: 0.8215 - Test Loss: 6.6798 - MSE: 6.6798 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10031/20000 - Train Loss: 0.8214 - Test Loss: 6.6790 - MSE: 6.6790 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10032/20000 - Train Loss: 0.8212 - Test Loss: 6.6780 - MSE: 6.6780 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 10033/20000 - Train Loss: 0.8211 - Test Loss: 6.6772 - MSE: 6.6772 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10034/20000 - Train Loss: 0.8209 - Test Loss: 6.6763 - MSE: 6.6763 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10035/20000 - Train Loss: 0.8208 - Test Loss: 6.6755 - MSE: 6.6755 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10036/20000 - Train Loss: 0.8207 - Test Loss: 6.6746 - MSE: 6.6746 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10037/20000 - Train Loss: 0.8205 - Test Loss: 6.6738 - MSE: 6.6738 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10038/20000 - Train Loss: 0.8204 - Test Loss: 6.6729 - MSE: 6.6729 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10039/20000 - Train Loss: 0.8202 - Test Loss: 6.6720 - MSE: 6.6720 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10040/20000 - Train Loss: 0.8201 - Test Loss: 6.6712 - MSE: 6.6712 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10041/20000 - Train Loss: 0.8199 - Test Loss: 6.6703 - MSE: 6.6703 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10042/20000 - Train Loss: 0.8198 - Test Loss: 6.6694 - MSE: 6.6694 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10043/20000 - Train Loss: 0.8196 - Test Loss: 6.6686 - MSE: 6.6686 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10044/20000 - Train Loss: 0.8195 - Test Loss: 6.6677 - MSE: 6.6677 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10045/20000 - Train Loss: 0.8193 - Test Loss: 6.6669 - MSE: 6.6669 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10046/20000 - Train Loss: 0.8192 - Test Loss: 6.6660 - MSE: 6.6660 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10047/20000 - Train Loss: 0.8191 - Test Loss: 6.6652 - MSE: 6.6652 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10048/20000 - Train Loss: 0.8189 - Test Loss: 6.6643 - MSE: 6.6643 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10049/20000 - Train Loss: 0.8188 - Test Loss: 6.6635 - MSE: 6.6635 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10050/20000 - Train Loss: 0.8186 - Test Loss: 6.6626 - MSE: 6.6626 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10051/20000 - Train Loss: 0.8185 - Test Loss: 6.6617 - MSE: 6.6617 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10052/20000 - Train Loss: 0.8183 - Test Loss: 6.6609 - MSE: 6.6609 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10053/20000 - Train Loss: 0.8182 - Test Loss: 6.6600 - MSE: 6.6600 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10054/20000 - Train Loss: 0.8180 - Test Loss: 6.6591 - MSE: 6.6591 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10055/20000 - Train Loss: 0.8179 - Test Loss: 6.6583 - MSE: 6.6583 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10056/20000 - Train Loss: 0.8178 - Test Loss: 6.6575 - MSE: 6.6575 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10057/20000 - Train Loss: 0.8176 - Test Loss: 6.6566 - MSE: 6.6566 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10058/20000 - Train Loss: 0.8175 - Test Loss: 6.6557 - MSE: 6.6557 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10059/20000 - Train Loss: 0.8173 - Test Loss: 6.6549 - MSE: 6.6549 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10060/20000 - Train Loss: 0.8172 - Test Loss: 6.6540 - MSE: 6.6540 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10061/20000 - Train Loss: 0.8170 - Test Loss: 6.6532 - MSE: 6.6532 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10062/20000 - Train Loss: 0.8169 - Test Loss: 6.6523 - MSE: 6.6523 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10063/20000 - Train Loss: 0.8167 - Test Loss: 6.6514 - MSE: 6.6514 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10064/20000 - Train Loss: 0.8166 - Test Loss: 6.6506 - MSE: 6.6506 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10065/20000 - Train Loss: 0.8165 - Test Loss: 6.6498 - MSE: 6.6498 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10066/20000 - Train Loss: 0.8163 - Test Loss: 6.6488 - MSE: 6.6488 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10067/20000 - Train Loss: 0.8162 - Test Loss: 6.6481 - MSE: 6.6480 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10068/20000 - Train Loss: 0.8160 - Test Loss: 6.6472 - MSE: 6.6472 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10069/20000 - Train Loss: 0.8159 - Test Loss: 6.6462 - MSE: 6.6462 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10070/20000 - Train Loss: 0.8157 - Test Loss: 6.6455 - MSE: 6.6455 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10071/20000 - Train Loss: 0.8156 - Test Loss: 6.6447 - MSE: 6.6447 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10072/20000 - Train Loss: 0.8155 - Test Loss: 6.6437 - MSE: 6.6437 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10073/20000 - Train Loss: 0.8153 - Test Loss: 6.6429 - MSE: 6.6429 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10074/20000 - Train Loss: 0.8152 - Test Loss: 6.6421 - MSE: 6.6421 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10075/20000 - Train Loss: 0.8150 - Test Loss: 6.6411 - MSE: 6.6411 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10076/20000 - Train Loss: 0.8149 - Test Loss: 6.6403 - MSE: 6.6403 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10077/20000 - Train Loss: 0.8147 - Test Loss: 6.6396 - MSE: 6.6396 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10078/20000 - Train Loss: 0.8146 - Test Loss: 6.6386 - MSE: 6.6386 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10079/20000 - Train Loss: 0.8145 - Test Loss: 6.6378 - MSE: 6.6378 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10080/20000 - Train Loss: 0.8143 - Test Loss: 6.6370 - MSE: 6.6370 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10081/20000 - Train Loss: 0.8142 - Test Loss: 6.6361 - MSE: 6.6361 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10082/20000 - Train Loss: 0.8140 - Test Loss: 6.6352 - MSE: 6.6352 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10083/20000 - Train Loss: 0.8139 - Test Loss: 6.6344 - MSE: 6.6344 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10084/20000 - Train Loss: 0.8137 - Test Loss: 6.6335 - MSE: 6.6335 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10085/20000 - Train Loss: 0.8136 - Test Loss: 6.6326 - MSE: 6.6326 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10086/20000 - Train Loss: 0.8135 - Test Loss: 6.6319 - MSE: 6.6319 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10087/20000 - Train Loss: 0.8133 - Test Loss: 6.6310 - MSE: 6.6310 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10088/20000 - Train Loss: 0.8132 - Test Loss: 6.6300 - MSE: 6.6300 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10089/20000 - Train Loss: 0.8130 - Test Loss: 6.6293 - MSE: 6.6293 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10090/20000 - Train Loss: 0.8129 - Test Loss: 6.6284 - MSE: 6.6284 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10091/20000 - Train Loss: 0.8127 - Test Loss: 6.6275 - MSE: 6.6275 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10092/20000 - Train Loss: 0.8126 - Test Loss: 6.6267 - MSE: 6.6267 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10093/20000 - Train Loss: 0.8125 - Test Loss: 6.6259 - MSE: 6.6259 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10094/20000 - Train Loss: 0.8123 - Test Loss: 6.6250 - MSE: 6.6250 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10095/20000 - Train Loss: 0.8122 - Test Loss: 6.6242 - MSE: 6.6242 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10096/20000 - Train Loss: 0.8120 - Test Loss: 6.6233 - MSE: 6.6233 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10097/20000 - Train Loss: 0.8119 - Test Loss: 6.6225 - MSE: 6.6225 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10098/20000 - Train Loss: 0.8118 - Test Loss: 6.6217 - MSE: 6.6217 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10099/20000 - Train Loss: 0.8116 - Test Loss: 6.6207 - MSE: 6.6207 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10100/20000 - Train Loss: 0.8115 - Test Loss: 6.6199 - MSE: 6.6199 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10101/20000 - Train Loss: 0.8113 - Test Loss: 6.6191 - MSE: 6.6191 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10102/20000 - Train Loss: 0.8112 - Test Loss: 6.6182 - MSE: 6.6182 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10103/20000 - Train Loss: 0.8110 - Test Loss: 6.6174 - MSE: 6.6174 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10104/20000 - Train Loss: 0.8109 - Test Loss: 6.6165 - MSE: 6.6165 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10105/20000 - Train Loss: 0.8108 - Test Loss: 6.6157 - MSE: 6.6157 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10106/20000 - Train Loss: 0.8106 - Test Loss: 6.6148 - MSE: 6.6148 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10107/20000 - Train Loss: 0.8105 - Test Loss: 6.6140 - MSE: 6.6140 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10108/20000 - Train Loss: 0.8103 - Test Loss: 6.6131 - MSE: 6.6131 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10109/20000 - Train Loss: 0.8102 - Test Loss: 6.6123 - MSE: 6.6123 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10110/20000 - Train Loss: 0.8101 - Test Loss: 6.6115 - MSE: 6.6115 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10111/20000 - Train Loss: 0.8099 - Test Loss: 6.6106 - MSE: 6.6106 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10112/20000 - Train Loss: 0.8098 - Test Loss: 6.6097 - MSE: 6.6097 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10113/20000 - Train Loss: 0.8096 - Test Loss: 6.6089 - MSE: 6.6089 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10114/20000 - Train Loss: 0.8095 - Test Loss: 6.6081 - MSE: 6.6081 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10115/20000 - Train Loss: 0.8094 - Test Loss: 6.6072 - MSE: 6.6072 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10116/20000 - Train Loss: 0.8092 - Test Loss: 6.6064 - MSE: 6.6064 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10117/20000 - Train Loss: 0.8091 - Test Loss: 6.6055 - MSE: 6.6055 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10118/20000 - Train Loss: 0.8089 - Test Loss: 6.6047 - MSE: 6.6047 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10119/20000 - Train Loss: 0.8088 - Test Loss: 6.6038 - MSE: 6.6038 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10120/20000 - Train Loss: 0.8087 - Test Loss: 6.6030 - MSE: 6.6030 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10121/20000 - Train Loss: 0.8085 - Test Loss: 6.6021 - MSE: 6.6021 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10122/20000 - Train Loss: 0.8084 - Test Loss: 6.6013 - MSE: 6.6013 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10123/20000 - Train Loss: 0.8082 - Test Loss: 6.6005 - MSE: 6.6005 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10124/20000 - Train Loss: 0.8081 - Test Loss: 6.5996 - MSE: 6.5996 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10125/20000 - Train Loss: 0.8080 - Test Loss: 6.5988 - MSE: 6.5988 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10126/20000 - Train Loss: 0.8078 - Test Loss: 6.5979 - MSE: 6.5979 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10127/20000 - Train Loss: 0.8077 - Test Loss: 6.5971 - MSE: 6.5971 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10128/20000 - Train Loss: 0.8075 - Test Loss: 6.5962 - MSE: 6.5962 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10129/20000 - Train Loss: 0.8074 - Test Loss: 6.5954 - MSE: 6.5954 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10130/20000 - Train Loss: 0.8073 - Test Loss: 6.5946 - MSE: 6.5946 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10131/20000 - Train Loss: 0.8071 - Test Loss: 6.5937 - MSE: 6.5937 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10132/20000 - Train Loss: 0.8070 - Test Loss: 6.5929 - MSE: 6.5929 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10133/20000 - Train Loss: 0.8068 - Test Loss: 6.5920 - MSE: 6.5920 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10134/20000 - Train Loss: 0.8067 - Test Loss: 6.5912 - MSE: 6.5912 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10135/20000 - Train Loss: 0.8066 - Test Loss: 6.5904 - MSE: 6.5904 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10136/20000 - Train Loss: 0.8064 - Test Loss: 6.5895 - MSE: 6.5895 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10137/20000 - Train Loss: 0.8063 - Test Loss: 6.5887 - MSE: 6.5887 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10138/20000 - Train Loss: 0.8061 - Test Loss: 6.5878 - MSE: 6.5878 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10139/20000 - Train Loss: 0.8060 - Test Loss: 6.5870 - MSE: 6.5870 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 10140/20000 - Train Loss: 0.8059 - Test Loss: 6.5861 - MSE: 6.5861 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10141/20000 - Train Loss: 0.8057 - Test Loss: 6.5853 - MSE: 6.5853 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10142/20000 - Train Loss: 0.8056 - Test Loss: 6.5845 - MSE: 6.5845 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10143/20000 - Train Loss: 0.8054 - Test Loss: 6.5836 - MSE: 6.5836 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10144/20000 - Train Loss: 0.8053 - Test Loss: 6.5828 - MSE: 6.5828 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10145/20000 - Train Loss: 0.8052 - Test Loss: 6.5819 - MSE: 6.5819 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10146/20000 - Train Loss: 0.8050 - Test Loss: 6.5810 - MSE: 6.5810 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10147/20000 - Train Loss: 0.8049 - Test Loss: 6.5803 - MSE: 6.5803 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10148/20000 - Train Loss: 0.8048 - Test Loss: 6.5794 - MSE: 6.5794 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10149/20000 - Train Loss: 0.8046 - Test Loss: 6.5785 - MSE: 6.5785 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10150/20000 - Train Loss: 0.8045 - Test Loss: 6.5777 - MSE: 6.5777 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10151/20000 - Train Loss: 0.8043 - Test Loss: 6.5769 - MSE: 6.5769 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10152/20000 - Train Loss: 0.8042 - Test Loss: 6.5760 - MSE: 6.5760 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10153/20000 - Train Loss: 0.8041 - Test Loss: 6.5752 - MSE: 6.5752 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10154/20000 - Train Loss: 0.8039 - Test Loss: 6.5744 - MSE: 6.5744 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10155/20000 - Train Loss: 0.8038 - Test Loss: 6.5735 - MSE: 6.5735 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10156/20000 - Train Loss: 0.8036 - Test Loss: 6.5727 - MSE: 6.5727 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10157/20000 - Train Loss: 0.8035 - Test Loss: 6.5719 - MSE: 6.5719 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10158/20000 - Train Loss: 0.8034 - Test Loss: 6.5710 - MSE: 6.5710 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10159/20000 - Train Loss: 0.8032 - Test Loss: 6.5702 - MSE: 6.5702 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10160/20000 - Train Loss: 0.8031 - Test Loss: 6.5694 - MSE: 6.5694 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10161/20000 - Train Loss: 0.8030 - Test Loss: 6.5685 - MSE: 6.5685 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10162/20000 - Train Loss: 0.8028 - Test Loss: 6.5677 - MSE: 6.5677 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10163/20000 - Train Loss: 0.8027 - Test Loss: 6.5669 - MSE: 6.5669 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10164/20000 - Train Loss: 0.8025 - Test Loss: 6.5659 - MSE: 6.5659 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10165/20000 - Train Loss: 0.8024 - Test Loss: 6.5652 - MSE: 6.5652 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10166/20000 - Train Loss: 0.8023 - Test Loss: 6.5644 - MSE: 6.5644 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10167/20000 - Train Loss: 0.8021 - Test Loss: 6.5634 - MSE: 6.5634 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10168/20000 - Train Loss: 0.8020 - Test Loss: 6.5627 - MSE: 6.5627 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10169/20000 - Train Loss: 0.8019 - Test Loss: 6.5619 - MSE: 6.5619 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10170/20000 - Train Loss: 0.8017 - Test Loss: 6.5609 - MSE: 6.5609 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10171/20000 - Train Loss: 0.8016 - Test Loss: 6.5602 - MSE: 6.5602 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10172/20000 - Train Loss: 0.8014 - Test Loss: 6.5594 - MSE: 6.5594 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10173/20000 - Train Loss: 0.8013 - Test Loss: 6.5584 - MSE: 6.5584 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10174/20000 - Train Loss: 0.8012 - Test Loss: 6.5577 - MSE: 6.5577 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10175/20000 - Train Loss: 0.8010 - Test Loss: 6.5569 - MSE: 6.5569 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10176/20000 - Train Loss: 0.8009 - Test Loss: 6.5559 - MSE: 6.5559 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10177/20000 - Train Loss: 0.8008 - Test Loss: 6.5552 - MSE: 6.5552 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10178/20000 - Train Loss: 0.8006 - Test Loss: 6.5543 - MSE: 6.5543 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10179/20000 - Train Loss: 0.8005 - Test Loss: 6.5535 - MSE: 6.5535 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10180/20000 - Train Loss: 0.8003 - Test Loss: 6.5527 - MSE: 6.5527 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10181/20000 - Train Loss: 0.8002 - Test Loss: 6.5519 - MSE: 6.5519 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10182/20000 - Train Loss: 0.8001 - Test Loss: 6.5509 - MSE: 6.5509 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10183/20000 - Train Loss: 0.7999 - Test Loss: 6.5502 - MSE: 6.5502 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10184/20000 - Train Loss: 0.7998 - Test Loss: 6.5494 - MSE: 6.5494 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10185/20000 - Train Loss: 0.7997 - Test Loss: 6.5484 - MSE: 6.5484 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10186/20000 - Train Loss: 0.7995 - Test Loss: 6.5477 - MSE: 6.5477 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10187/20000 - Train Loss: 0.7994 - Test Loss: 6.5469 - MSE: 6.5469 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10188/20000 - Train Loss: 0.7993 - Test Loss: 6.5459 - MSE: 6.5459 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10189/20000 - Train Loss: 0.7991 - Test Loss: 6.5452 - MSE: 6.5452 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10190/20000 - Train Loss: 0.7990 - Test Loss: 6.5444 - MSE: 6.5444 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10191/20000 - Train Loss: 0.7988 - Test Loss: 6.5434 - MSE: 6.5434 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10192/20000 - Train Loss: 0.7987 - Test Loss: 6.5427 - MSE: 6.5427 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10193/20000 - Train Loss: 0.7986 - Test Loss: 6.5419 - MSE: 6.5419 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10194/20000 - Train Loss: 0.7984 - Test Loss: 6.5410 - MSE: 6.5410 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10195/20000 - Train Loss: 0.7983 - Test Loss: 6.5402 - MSE: 6.5402 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10196/20000 - Train Loss: 0.7982 - Test Loss: 6.5394 - MSE: 6.5394 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10197/20000 - Train Loss: 0.7980 - Test Loss: 6.5385 - MSE: 6.5385 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10198/20000 - Train Loss: 0.7979 - Test Loss: 6.5377 - MSE: 6.5377 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10199/20000 - Train Loss: 0.7978 - Test Loss: 6.5369 - MSE: 6.5369 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10200/20000 - Train Loss: 0.7976 - Test Loss: 6.5360 - MSE: 6.5360 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10201/20000 - Train Loss: 0.7975 - Test Loss: 6.5352 - MSE: 6.5352 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10202/20000 - Train Loss: 0.7974 - Test Loss: 6.5344 - MSE: 6.5344 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10203/20000 - Train Loss: 0.7972 - Test Loss: 6.5335 - MSE: 6.5335 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10204/20000 - Train Loss: 0.7971 - Test Loss: 6.5328 - MSE: 6.5328 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10205/20000 - Train Loss: 0.7969 - Test Loss: 6.5319 - MSE: 6.5319 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10206/20000 - Train Loss: 0.7968 - Test Loss: 6.5311 - MSE: 6.5311 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10207/20000 - Train Loss: 0.7967 - Test Loss: 6.5303 - MSE: 6.5303 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10208/20000 - Train Loss: 0.7965 - Test Loss: 6.5294 - MSE: 6.5294 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10209/20000 - Train Loss: 0.7964 - Test Loss: 6.5286 - MSE: 6.5286 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10210/20000 - Train Loss: 0.7963 - Test Loss: 6.5278 - MSE: 6.5278 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10211/20000 - Train Loss: 0.7961 - Test Loss: 6.5269 - MSE: 6.5269 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10212/20000 - Train Loss: 0.7960 - Test Loss: 6.5262 - MSE: 6.5262 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10213/20000 - Train Loss: 0.7959 - Test Loss: 6.5252 - MSE: 6.5252 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10214/20000 - Train Loss: 0.7957 - Test Loss: 6.5244 - MSE: 6.5244 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10215/20000 - Train Loss: 0.7956 - Test Loss: 6.5237 - MSE: 6.5237 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10216/20000 - Train Loss: 0.7955 - Test Loss: 6.5228 - MSE: 6.5228 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10217/20000 - Train Loss: 0.7953 - Test Loss: 6.5220 - MSE: 6.5220 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10218/20000 - Train Loss: 0.7952 - Test Loss: 6.5212 - MSE: 6.5212 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10219/20000 - Train Loss: 0.7951 - Test Loss: 6.5203 - MSE: 6.5203 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10220/20000 - Train Loss: 0.7949 - Test Loss: 6.5195 - MSE: 6.5195 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10221/20000 - Train Loss: 0.7948 - Test Loss: 6.5188 - MSE: 6.5188 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10222/20000 - Train Loss: 0.7947 - Test Loss: 6.5178 - MSE: 6.5178 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10223/20000 - Train Loss: 0.7945 - Test Loss: 6.5170 - MSE: 6.5170 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10224/20000 - Train Loss: 0.7944 - Test Loss: 6.5163 - MSE: 6.5163 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10225/20000 - Train Loss: 0.7943 - Test Loss: 6.5154 - MSE: 6.5154 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 10226/20000 - Train Loss: 0.7941 - Test Loss: 6.5145 - MSE: 6.5145 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10227/20000 - Train Loss: 0.7940 - Test Loss: 6.5138 - MSE: 6.5138 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10228/20000 - Train Loss: 0.7939 - Test Loss: 6.5129 - MSE: 6.5129 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10229/20000 - Train Loss: 0.7937 - Test Loss: 6.5121 - MSE: 6.5121 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10230/20000 - Train Loss: 0.7936 - Test Loss: 6.5113 - MSE: 6.5113 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10231/20000 - Train Loss: 0.7934 - Test Loss: 6.5104 - MSE: 6.5104 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10232/20000 - Train Loss: 0.7933 - Test Loss: 6.5096 - MSE: 6.5096 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10233/20000 - Train Loss: 0.7932 - Test Loss: 6.5088 - MSE: 6.5088 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10234/20000 - Train Loss: 0.7930 - Test Loss: 6.5080 - MSE: 6.5080 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10235/20000 - Train Loss: 0.7929 - Test Loss: 6.5072 - MSE: 6.5072 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10236/20000 - Train Loss: 0.7928 - Test Loss: 6.5063 - MSE: 6.5063 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10237/20000 - Train Loss: 0.7926 - Test Loss: 6.5055 - MSE: 6.5055 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10238/20000 - Train Loss: 0.7925 - Test Loss: 6.5047 - MSE: 6.5047 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10239/20000 - Train Loss: 0.7924 - Test Loss: 6.5039 - MSE: 6.5039 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10240/20000 - Train Loss: 0.7922 - Test Loss: 6.5031 - MSE: 6.5031 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10241/20000 - Train Loss: 0.7921 - Test Loss: 6.5023 - MSE: 6.5023 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10242/20000 - Train Loss: 0.7920 - Test Loss: 6.5014 - MSE: 6.5014 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10243/20000 - Train Loss: 0.7918 - Test Loss: 6.5006 - MSE: 6.5006 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10244/20000 - Train Loss: 0.7917 - Test Loss: 6.4998 - MSE: 6.4998 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10245/20000 - Train Loss: 0.7916 - Test Loss: 6.4989 - MSE: 6.4989 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10246/20000 - Train Loss: 0.7914 - Test Loss: 6.4981 - MSE: 6.4981 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10247/20000 - Train Loss: 0.7913 - Test Loss: 6.4974 - MSE: 6.4974 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10248/20000 - Train Loss: 0.7912 - Test Loss: 6.4965 - MSE: 6.4965 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10249/20000 - Train Loss: 0.7911 - Test Loss: 6.4957 - MSE: 6.4957 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10250/20000 - Train Loss: 0.7909 - Test Loss: 6.4949 - MSE: 6.4949 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10251/20000 - Train Loss: 0.7908 - Test Loss: 6.4940 - MSE: 6.4940 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10252/20000 - Train Loss: 0.7907 - Test Loss: 6.4932 - MSE: 6.4932 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10253/20000 - Train Loss: 0.7905 - Test Loss: 6.4925 - MSE: 6.4925 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10254/20000 - Train Loss: 0.7904 - Test Loss: 6.4916 - MSE: 6.4916 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10255/20000 - Train Loss: 0.7903 - Test Loss: 6.4908 - MSE: 6.4908 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10256/20000 - Train Loss: 0.7901 - Test Loss: 6.4900 - MSE: 6.4900 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10257/20000 - Train Loss: 0.7900 - Test Loss: 6.4891 - MSE: 6.4891 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10258/20000 - Train Loss: 0.7899 - Test Loss: 6.4884 - MSE: 6.4884 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10259/20000 - Train Loss: 0.7897 - Test Loss: 6.4875 - MSE: 6.4875 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10260/20000 - Train Loss: 0.7896 - Test Loss: 6.4867 - MSE: 6.4867 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10261/20000 - Train Loss: 0.7895 - Test Loss: 6.4859 - MSE: 6.4859 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10262/20000 - Train Loss: 0.7893 - Test Loss: 6.4851 - MSE: 6.4851 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10263/20000 - Train Loss: 0.7892 - Test Loss: 6.4842 - MSE: 6.4842 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10264/20000 - Train Loss: 0.7891 - Test Loss: 6.4835 - MSE: 6.4835 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10265/20000 - Train Loss: 0.7889 - Test Loss: 6.4826 - MSE: 6.4826 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10266/20000 - Train Loss: 0.7888 - Test Loss: 6.4818 - MSE: 6.4818 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10267/20000 - Train Loss: 0.7887 - Test Loss: 6.4810 - MSE: 6.4810 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10268/20000 - Train Loss: 0.7885 - Test Loss: 6.4802 - MSE: 6.4802 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10269/20000 - Train Loss: 0.7884 - Test Loss: 6.4794 - MSE: 6.4794 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10270/20000 - Train Loss: 0.7883 - Test Loss: 6.4785 - MSE: 6.4785 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10271/20000 - Train Loss: 0.7881 - Test Loss: 6.4777 - MSE: 6.4777 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10272/20000 - Train Loss: 0.7880 - Test Loss: 6.4769 - MSE: 6.4769 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10273/20000 - Train Loss: 0.7879 - Test Loss: 6.4761 - MSE: 6.4761 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10274/20000 - Train Loss: 0.7878 - Test Loss: 6.4753 - MSE: 6.4753 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10275/20000 - Train Loss: 0.7876 - Test Loss: 6.4745 - MSE: 6.4745 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10276/20000 - Train Loss: 0.7875 - Test Loss: 6.4737 - MSE: 6.4737 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10277/20000 - Train Loss: 0.7874 - Test Loss: 6.4728 - MSE: 6.4728 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10278/20000 - Train Loss: 0.7872 - Test Loss: 6.4721 - MSE: 6.4721 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10279/20000 - Train Loss: 0.7871 - Test Loss: 6.4713 - MSE: 6.4713 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10280/20000 - Train Loss: 0.7870 - Test Loss: 6.4703 - MSE: 6.4703 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10281/20000 - Train Loss: 0.7868 - Test Loss: 6.4696 - MSE: 6.4696 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10282/20000 - Train Loss: 0.7867 - Test Loss: 6.4688 - MSE: 6.4688 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10283/20000 - Train Loss: 0.7866 - Test Loss: 6.4679 - MSE: 6.4679 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10284/20000 - Train Loss: 0.7864 - Test Loss: 6.4672 - MSE: 6.4672 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10285/20000 - Train Loss: 0.7863 - Test Loss: 6.4663 - MSE: 6.4663 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10286/20000 - Train Loss: 0.7862 - Test Loss: 6.4655 - MSE: 6.4655 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10287/20000 - Train Loss: 0.7860 - Test Loss: 6.4648 - MSE: 6.4648 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10288/20000 - Train Loss: 0.7859 - Test Loss: 6.4639 - MSE: 6.4639 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10289/20000 - Train Loss: 0.7858 - Test Loss: 6.4631 - MSE: 6.4631 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10290/20000 - Train Loss: 0.7857 - Test Loss: 6.4624 - MSE: 6.4624 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10291/20000 - Train Loss: 0.7855 - Test Loss: 6.4614 - MSE: 6.4614 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10292/20000 - Train Loss: 0.7854 - Test Loss: 6.4607 - MSE: 6.4607 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10293/20000 - Train Loss: 0.7853 - Test Loss: 6.4599 - MSE: 6.4599 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10294/20000 - Train Loss: 0.7851 - Test Loss: 6.4590 - MSE: 6.4590 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10295/20000 - Train Loss: 0.7850 - Test Loss: 6.4582 - MSE: 6.4582 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10296/20000 - Train Loss: 0.7849 - Test Loss: 6.4575 - MSE: 6.4575 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10297/20000 - Train Loss: 0.7847 - Test Loss: 6.4565 - MSE: 6.4565 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10298/20000 - Train Loss: 0.7846 - Test Loss: 6.4559 - MSE: 6.4559 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10299/20000 - Train Loss: 0.7845 - Test Loss: 6.4550 - MSE: 6.4550 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10300/20000 - Train Loss: 0.7844 - Test Loss: 6.4541 - MSE: 6.4541 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10301/20000 - Train Loss: 0.7842 - Test Loss: 6.4535 - MSE: 6.4535 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10302/20000 - Train Loss: 0.7841 - Test Loss: 6.4526 - MSE: 6.4526 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10303/20000 - Train Loss: 0.7840 - Test Loss: 6.4517 - MSE: 6.4517 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10304/20000 - Train Loss: 0.7838 - Test Loss: 6.4511 - MSE: 6.4511 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10305/20000 - Train Loss: 0.7837 - Test Loss: 6.4502 - MSE: 6.4502 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10306/20000 - Train Loss: 0.7836 - Test Loss: 6.4493 - MSE: 6.4493 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10307/20000 - Train Loss: 0.7834 - Test Loss: 6.4486 - MSE: 6.4486 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10308/20000 - Train Loss: 0.7833 - Test Loss: 6.4477 - MSE: 6.4477 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10309/20000 - Train Loss: 0.7832 - Test Loss: 6.4469 - MSE: 6.4469 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10310/20000 - Train Loss: 0.7831 - Test Loss: 6.4462 - MSE: 6.4462 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10311/20000 - Train Loss: 0.7829 - Test Loss: 6.4453 - MSE: 6.4453 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10312/20000 - Train Loss: 0.7828 - Test Loss: 6.4445 - MSE: 6.4445 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10313/20000 - Train Loss: 0.7827 - Test Loss: 6.4437 - MSE: 6.4437 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10314/20000 - Train Loss: 0.7825 - Test Loss: 6.4429 - MSE: 6.4429 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10315/20000 - Train Loss: 0.7824 - Test Loss: 6.4421 - MSE: 6.4421 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10316/20000 - Train Loss: 0.7823 - Test Loss: 6.4413 - MSE: 6.4413 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10317/20000 - Train Loss: 0.7822 - Test Loss: 6.4405 - MSE: 6.4405 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10318/20000 - Train Loss: 0.7820 - Test Loss: 6.4397 - MSE: 6.4397 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10319/20000 - Train Loss: 0.7819 - Test Loss: 6.4389 - MSE: 6.4389 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10320/20000 - Train Loss: 0.7818 - Test Loss: 6.4381 - MSE: 6.4381 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10321/20000 - Train Loss: 0.7816 - Test Loss: 6.4373 - MSE: 6.4373 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10322/20000 - Train Loss: 0.7815 - Test Loss: 6.4365 - MSE: 6.4365 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10323/20000 - Train Loss: 0.7814 - Test Loss: 6.4356 - MSE: 6.4356 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10324/20000 - Train Loss: 0.7813 - Test Loss: 6.4349 - MSE: 6.4349 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10325/20000 - Train Loss: 0.7811 - Test Loss: 6.4341 - MSE: 6.4341 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10326/20000 - Train Loss: 0.7810 - Test Loss: 6.4333 - MSE: 6.4333 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10327/20000 - Train Loss: 0.7809 - Test Loss: 6.4325 - MSE: 6.4325 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10328/20000 - Train Loss: 0.7807 - Test Loss: 6.4317 - MSE: 6.4317 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10329/20000 - Train Loss: 0.7806 - Test Loss: 6.4309 - MSE: 6.4309 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10330/20000 - Train Loss: 0.7805 - Test Loss: 6.4301 - MSE: 6.4301 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10331/20000 - Train Loss: 0.7804 - Test Loss: 6.4293 - MSE: 6.4293 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10332/20000 - Train Loss: 0.7802 - Test Loss: 6.4285 - MSE: 6.4285 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10333/20000 - Train Loss: 0.7801 - Test Loss: 6.4277 - MSE: 6.4277 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10334/20000 - Train Loss: 0.7800 - Test Loss: 6.4269 - MSE: 6.4269 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10335/20000 - Train Loss: 0.7798 - Test Loss: 6.4261 - MSE: 6.4261 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10336/20000 - Train Loss: 0.7797 - Test Loss: 6.4253 - MSE: 6.4253 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10337/20000 - Train Loss: 0.7796 - Test Loss: 6.4245 - MSE: 6.4245 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10338/20000 - Train Loss: 0.7795 - Test Loss: 6.4237 - MSE: 6.4237 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10339/20000 - Train Loss: 0.7793 - Test Loss: 6.4229 - MSE: 6.4229 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10340/20000 - Train Loss: 0.7792 - Test Loss: 6.4221 - MSE: 6.4221 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10341/20000 - Train Loss: 0.7791 - Test Loss: 6.4213 - MSE: 6.4213 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10342/20000 - Train Loss: 0.7789 - Test Loss: 6.4205 - MSE: 6.4205 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10343/20000 - Train Loss: 0.7788 - Test Loss: 6.4196 - MSE: 6.4196 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10344/20000 - Train Loss: 0.7787 - Test Loss: 6.4189 - MSE: 6.4189 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10345/20000 - Train Loss: 0.7786 - Test Loss: 6.4181 - MSE: 6.4181 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10346/20000 - Train Loss: 0.7784 - Test Loss: 6.4173 - MSE: 6.4173 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10347/20000 - Train Loss: 0.7783 - Test Loss: 6.4165 - MSE: 6.4165 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10348/20000 - Train Loss: 0.7782 - Test Loss: 6.4157 - MSE: 6.4157 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10349/20000 - Train Loss: 0.7781 - Test Loss: 6.4149 - MSE: 6.4149 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10350/20000 - Train Loss: 0.7779 - Test Loss: 6.4141 - MSE: 6.4141 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10351/20000 - Train Loss: 0.7778 - Test Loss: 6.4133 - MSE: 6.4133 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "Epoch 10352/20000 - Train Loss: 0.7777 - Test Loss: 6.4125 - MSE: 6.4125 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10353/20000 - Train Loss: 0.7775 - Test Loss: 6.4117 - MSE: 6.4117 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10354/20000 - Train Loss: 0.7774 - Test Loss: 6.4109 - MSE: 6.4109 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10355/20000 - Train Loss: 0.7773 - Test Loss: 6.4101 - MSE: 6.4101 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10356/20000 - Train Loss: 0.7772 - Test Loss: 6.4093 - MSE: 6.4093 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10357/20000 - Train Loss: 0.7770 - Test Loss: 6.4086 - MSE: 6.4086 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10358/20000 - Train Loss: 0.7769 - Test Loss: 6.4077 - MSE: 6.4077 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10359/20000 - Train Loss: 0.7768 - Test Loss: 6.4069 - MSE: 6.4069 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10360/20000 - Train Loss: 0.7767 - Test Loss: 6.4062 - MSE: 6.4062 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10361/20000 - Train Loss: 0.7765 - Test Loss: 6.4053 - MSE: 6.4053 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10362/20000 - Train Loss: 0.7764 - Test Loss: 6.4046 - MSE: 6.4046 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10363/20000 - Train Loss: 0.7763 - Test Loss: 6.4038 - MSE: 6.4038 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10364/20000 - Train Loss: 0.7762 - Test Loss: 6.4029 - MSE: 6.4029 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10365/20000 - Train Loss: 0.7760 - Test Loss: 6.4022 - MSE: 6.4022 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10366/20000 - Train Loss: 0.7759 - Test Loss: 6.4014 - MSE: 6.4014 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10367/20000 - Train Loss: 0.7758 - Test Loss: 6.4006 - MSE: 6.4006 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10368/20000 - Train Loss: 0.7756 - Test Loss: 6.3998 - MSE: 6.3998 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10369/20000 - Train Loss: 0.7755 - Test Loss: 6.3990 - MSE: 6.3990 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10370/20000 - Train Loss: 0.7754 - Test Loss: 6.3982 - MSE: 6.3982 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10371/20000 - Train Loss: 0.7753 - Test Loss: 6.3975 - MSE: 6.3975 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10372/20000 - Train Loss: 0.7751 - Test Loss: 6.3966 - MSE: 6.3966 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10373/20000 - Train Loss: 0.7750 - Test Loss: 6.3959 - MSE: 6.3959 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10374/20000 - Train Loss: 0.7749 - Test Loss: 6.3951 - MSE: 6.3951 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10375/20000 - Train Loss: 0.7748 - Test Loss: 6.3942 - MSE: 6.3942 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10376/20000 - Train Loss: 0.7746 - Test Loss: 6.3935 - MSE: 6.3935 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10377/20000 - Train Loss: 0.7745 - Test Loss: 6.3927 - MSE: 6.3927 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10378/20000 - Train Loss: 0.7744 - Test Loss: 6.3918 - MSE: 6.3918 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10379/20000 - Train Loss: 0.7743 - Test Loss: 6.3912 - MSE: 6.3912 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10380/20000 - Train Loss: 0.7741 - Test Loss: 6.3902 - MSE: 6.3902 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10381/20000 - Train Loss: 0.7740 - Test Loss: 6.3895 - MSE: 6.3895 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10382/20000 - Train Loss: 0.7739 - Test Loss: 6.3888 - MSE: 6.3888 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10383/20000 - Train Loss: 0.7738 - Test Loss: 6.3879 - MSE: 6.3879 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10384/20000 - Train Loss: 0.7736 - Test Loss: 6.3872 - MSE: 6.3872 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10385/20000 - Train Loss: 0.7735 - Test Loss: 6.3864 - MSE: 6.3864 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10386/20000 - Train Loss: 0.7734 - Test Loss: 6.3855 - MSE: 6.3855 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10387/20000 - Train Loss: 0.7733 - Test Loss: 6.3848 - MSE: 6.3848 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10388/20000 - Train Loss: 0.7731 - Test Loss: 6.3840 - MSE: 6.3840 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10389/20000 - Train Loss: 0.7730 - Test Loss: 6.3831 - MSE: 6.3831 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10390/20000 - Train Loss: 0.7729 - Test Loss: 6.3825 - MSE: 6.3825 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10391/20000 - Train Loss: 0.7728 - Test Loss: 6.3816 - MSE: 6.3816 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10392/20000 - Train Loss: 0.7726 - Test Loss: 6.3808 - MSE: 6.3808 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10393/20000 - Train Loss: 0.7725 - Test Loss: 6.3801 - MSE: 6.3801 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10394/20000 - Train Loss: 0.7724 - Test Loss: 6.3792 - MSE: 6.3792 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10395/20000 - Train Loss: 0.7723 - Test Loss: 6.3785 - MSE: 6.3785 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 10396/20000 - Train Loss: 0.7721 - Test Loss: 6.3778 - MSE: 6.3778 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 10397/20000 - Train Loss: 0.7720 - Test Loss: 6.3768 - MSE: 6.3768 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10398/20000 - Train Loss: 0.7719 - Test Loss: 6.3762 - MSE: 6.3762 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10399/20000 - Train Loss: 0.7718 - Test Loss: 6.3753 - MSE: 6.3753 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10400/20000 - Train Loss: 0.7716 - Test Loss: 6.3745 - MSE: 6.3745 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10401/20000 - Train Loss: 0.7715 - Test Loss: 6.3739 - MSE: 6.3739 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10402/20000 - Train Loss: 0.7714 - Test Loss: 6.3729 - MSE: 6.3729 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10403/20000 - Train Loss: 0.7713 - Test Loss: 6.3722 - MSE: 6.3722 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10404/20000 - Train Loss: 0.7711 - Test Loss: 6.3715 - MSE: 6.3715 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10405/20000 - Train Loss: 0.7710 - Test Loss: 6.3706 - MSE: 6.3706 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10406/20000 - Train Loss: 0.7709 - Test Loss: 6.3699 - MSE: 6.3699 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10407/20000 - Train Loss: 0.7708 - Test Loss: 6.3691 - MSE: 6.3691 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10408/20000 - Train Loss: 0.7706 - Test Loss: 6.3682 - MSE: 6.3682 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10409/20000 - Train Loss: 0.7705 - Test Loss: 6.3675 - MSE: 6.3675 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10410/20000 - Train Loss: 0.7704 - Test Loss: 6.3667 - MSE: 6.3667 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10411/20000 - Train Loss: 0.7703 - Test Loss: 6.3659 - MSE: 6.3659 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10412/20000 - Train Loss: 0.7701 - Test Loss: 6.3652 - MSE: 6.3652 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10413/20000 - Train Loss: 0.7700 - Test Loss: 6.3643 - MSE: 6.3643 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10414/20000 - Train Loss: 0.7699 - Test Loss: 6.3636 - MSE: 6.3636 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10415/20000 - Train Loss: 0.7698 - Test Loss: 6.3628 - MSE: 6.3628 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10416/20000 - Train Loss: 0.7697 - Test Loss: 6.3620 - MSE: 6.3620 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10417/20000 - Train Loss: 0.7695 - Test Loss: 6.3612 - MSE: 6.3612 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10418/20000 - Train Loss: 0.7694 - Test Loss: 6.3605 - MSE: 6.3605 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10419/20000 - Train Loss: 0.7693 - Test Loss: 6.3596 - MSE: 6.3596 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10420/20000 - Train Loss: 0.7692 - Test Loss: 6.3589 - MSE: 6.3589 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10421/20000 - Train Loss: 0.7690 - Test Loss: 6.3581 - MSE: 6.3581 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10422/20000 - Train Loss: 0.7689 - Test Loss: 6.3573 - MSE: 6.3573 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10423/20000 - Train Loss: 0.7688 - Test Loss: 6.3566 - MSE: 6.3566 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10424/20000 - Train Loss: 0.7687 - Test Loss: 6.3558 - MSE: 6.3558 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10425/20000 - Train Loss: 0.7685 - Test Loss: 6.3549 - MSE: 6.3550 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10426/20000 - Train Loss: 0.7684 - Test Loss: 6.3543 - MSE: 6.3543 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10427/20000 - Train Loss: 0.7683 - Test Loss: 6.3534 - MSE: 6.3534 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10428/20000 - Train Loss: 0.7682 - Test Loss: 6.3527 - MSE: 6.3527 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10429/20000 - Train Loss: 0.7681 - Test Loss: 6.3519 - MSE: 6.3519 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10430/20000 - Train Loss: 0.7679 - Test Loss: 6.3510 - MSE: 6.3510 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10431/20000 - Train Loss: 0.7678 - Test Loss: 6.3504 - MSE: 6.3504 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 10432/20000 - Train Loss: 0.7677 - Test Loss: 6.3495 - MSE: 6.3495 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 10433/20000 - Train Loss: 0.7676 - Test Loss: 6.3487 - MSE: 6.3487 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10434/20000 - Train Loss: 0.7674 - Test Loss: 6.3480 - MSE: 6.3480 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10435/20000 - Train Loss: 0.7673 - Test Loss: 6.3472 - MSE: 6.3472 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10436/20000 - Train Loss: 0.7672 - Test Loss: 6.3465 - MSE: 6.3465 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10437/20000 - Train Loss: 0.7671 - Test Loss: 6.3456 - MSE: 6.3456 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10438/20000 - Train Loss: 0.7669 - Test Loss: 6.3449 - MSE: 6.3449 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10439/20000 - Train Loss: 0.7668 - Test Loss: 6.3441 - MSE: 6.3441 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10440/20000 - Train Loss: 0.7667 - Test Loss: 6.3433 - MSE: 6.3433 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10441/20000 - Train Loss: 0.7666 - Test Loss: 6.3425 - MSE: 6.3425 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10442/20000 - Train Loss: 0.7665 - Test Loss: 6.3418 - MSE: 6.3418 - MAE: 1.9520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10443/20000 - Train Loss: 0.7663 - Test Loss: 6.3409 - MSE: 6.3409 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10444/20000 - Train Loss: 0.7662 - Test Loss: 6.3402 - MSE: 6.3402 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10445/20000 - Train Loss: 0.7661 - Test Loss: 6.3395 - MSE: 6.3395 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 47ms/step\n",
      "Epoch 10446/20000 - Train Loss: 0.7660 - Test Loss: 6.3386 - MSE: 6.3386 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10447/20000 - Train Loss: 0.7658 - Test Loss: 6.3379 - MSE: 6.3379 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10448/20000 - Train Loss: 0.7657 - Test Loss: 6.3371 - MSE: 6.3371 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10449/20000 - Train Loss: 0.7656 - Test Loss: 6.3363 - MSE: 6.3363 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10450/20000 - Train Loss: 0.7655 - Test Loss: 6.3356 - MSE: 6.3356 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10451/20000 - Train Loss: 0.7654 - Test Loss: 6.3347 - MSE: 6.3347 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10452/20000 - Train Loss: 0.7652 - Test Loss: 6.3341 - MSE: 6.3341 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10453/20000 - Train Loss: 0.7651 - Test Loss: 6.3332 - MSE: 6.3332 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10454/20000 - Train Loss: 0.7650 - Test Loss: 6.3324 - MSE: 6.3324 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10455/20000 - Train Loss: 0.7649 - Test Loss: 6.3318 - MSE: 6.3318 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10456/20000 - Train Loss: 0.7647 - Test Loss: 6.3308 - MSE: 6.3308 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10457/20000 - Train Loss: 0.7646 - Test Loss: 6.3302 - MSE: 6.3302 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10458/20000 - Train Loss: 0.7645 - Test Loss: 6.3295 - MSE: 6.3295 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10459/20000 - Train Loss: 0.7644 - Test Loss: 6.3285 - MSE: 6.3285 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10460/20000 - Train Loss: 0.7643 - Test Loss: 6.3279 - MSE: 6.3279 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10461/20000 - Train Loss: 0.7641 - Test Loss: 6.3270 - MSE: 6.3270 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10462/20000 - Train Loss: 0.7640 - Test Loss: 6.3263 - MSE: 6.3263 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10463/20000 - Train Loss: 0.7639 - Test Loss: 6.3256 - MSE: 6.3256 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10464/20000 - Train Loss: 0.7638 - Test Loss: 6.3247 - MSE: 6.3247 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10465/20000 - Train Loss: 0.7637 - Test Loss: 6.3240 - MSE: 6.3240 - MAE: 1.9519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10466/20000 - Train Loss: 0.7635 - Test Loss: 6.3232 - MSE: 6.3232 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10467/20000 - Train Loss: 0.7634 - Test Loss: 6.3224 - MSE: 6.3224 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10468/20000 - Train Loss: 0.7633 - Test Loss: 6.3217 - MSE: 6.3217 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10469/20000 - Train Loss: 0.7632 - Test Loss: 6.3209 - MSE: 6.3209 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10470/20000 - Train Loss: 0.7631 - Test Loss: 6.3201 - MSE: 6.3201 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10471/20000 - Train Loss: 0.7629 - Test Loss: 6.3194 - MSE: 6.3194 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10472/20000 - Train Loss: 0.7628 - Test Loss: 6.3185 - MSE: 6.3185 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10473/20000 - Train Loss: 0.7627 - Test Loss: 6.3179 - MSE: 6.3179 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10474/20000 - Train Loss: 0.7626 - Test Loss: 6.3170 - MSE: 6.3170 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10475/20000 - Train Loss: 0.7625 - Test Loss: 6.3163 - MSE: 6.3163 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10476/20000 - Train Loss: 0.7623 - Test Loss: 6.3155 - MSE: 6.3155 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10477/20000 - Train Loss: 0.7622 - Test Loss: 6.3147 - MSE: 6.3147 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10478/20000 - Train Loss: 0.7621 - Test Loss: 6.3140 - MSE: 6.3140 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10479/20000 - Train Loss: 0.7620 - Test Loss: 6.3132 - MSE: 6.3132 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10480/20000 - Train Loss: 0.7618 - Test Loss: 6.3124 - MSE: 6.3124 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10481/20000 - Train Loss: 0.7617 - Test Loss: 6.3117 - MSE: 6.3117 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10482/20000 - Train Loss: 0.7616 - Test Loss: 6.3109 - MSE: 6.3109 - MAE: 1.9518\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10483/20000 - Train Loss: 0.7615 - Test Loss: 6.3101 - MSE: 6.3101 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10484/20000 - Train Loss: 0.7614 - Test Loss: 6.3094 - MSE: 6.3094 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10485/20000 - Train Loss: 0.7612 - Test Loss: 6.3085 - MSE: 6.3085 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10486/20000 - Train Loss: 0.7611 - Test Loss: 6.3079 - MSE: 6.3079 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10487/20000 - Train Loss: 0.7610 - Test Loss: 6.3070 - MSE: 6.3070 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10488/20000 - Train Loss: 0.7609 - Test Loss: 6.3063 - MSE: 6.3063 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10489/20000 - Train Loss: 0.7608 - Test Loss: 6.3057 - MSE: 6.3057 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10490/20000 - Train Loss: 0.7606 - Test Loss: 6.3046 - MSE: 6.3046 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10491/20000 - Train Loss: 0.7605 - Test Loss: 6.3041 - MSE: 6.3041 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10492/20000 - Train Loss: 0.7604 - Test Loss: 6.3032 - MSE: 6.3032 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10493/20000 - Train Loss: 0.7603 - Test Loss: 6.3024 - MSE: 6.3024 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10494/20000 - Train Loss: 0.7602 - Test Loss: 6.3019 - MSE: 6.3019 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10495/20000 - Train Loss: 0.7600 - Test Loss: 6.3008 - MSE: 6.3008 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10496/20000 - Train Loss: 0.7599 - Test Loss: 6.3002 - MSE: 6.3002 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10497/20000 - Train Loss: 0.7598 - Test Loss: 6.2995 - MSE: 6.2995 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10498/20000 - Train Loss: 0.7597 - Test Loss: 6.2985 - MSE: 6.2985 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10499/20000 - Train Loss: 0.7596 - Test Loss: 6.2980 - MSE: 6.2980 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10500/20000 - Train Loss: 0.7595 - Test Loss: 6.2971 - MSE: 6.2971 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10501/20000 - Train Loss: 0.7593 - Test Loss: 6.2963 - MSE: 6.2963 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10502/20000 - Train Loss: 0.7592 - Test Loss: 6.2957 - MSE: 6.2957 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10503/20000 - Train Loss: 0.7591 - Test Loss: 6.2948 - MSE: 6.2948 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10504/20000 - Train Loss: 0.7590 - Test Loss: 6.2942 - MSE: 6.2942 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10505/20000 - Train Loss: 0.7589 - Test Loss: 6.2933 - MSE: 6.2933 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10506/20000 - Train Loss: 0.7587 - Test Loss: 6.2925 - MSE: 6.2925 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10507/20000 - Train Loss: 0.7586 - Test Loss: 6.2919 - MSE: 6.2919 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10508/20000 - Train Loss: 0.7585 - Test Loss: 6.2910 - MSE: 6.2910 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10509/20000 - Train Loss: 0.7584 - Test Loss: 6.2903 - MSE: 6.2903 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10510/20000 - Train Loss: 0.7583 - Test Loss: 6.2896 - MSE: 6.2896 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10511/20000 - Train Loss: 0.7581 - Test Loss: 6.2887 - MSE: 6.2887 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10512/20000 - Train Loss: 0.7580 - Test Loss: 6.2881 - MSE: 6.2881 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10513/20000 - Train Loss: 0.7579 - Test Loss: 6.2872 - MSE: 6.2872 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10514/20000 - Train Loss: 0.7578 - Test Loss: 6.2865 - MSE: 6.2865 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10515/20000 - Train Loss: 0.7577 - Test Loss: 6.2858 - MSE: 6.2858 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10516/20000 - Train Loss: 0.7576 - Test Loss: 6.2849 - MSE: 6.2849 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10517/20000 - Train Loss: 0.7574 - Test Loss: 6.2842 - MSE: 6.2842 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10518/20000 - Train Loss: 0.7573 - Test Loss: 6.2835 - MSE: 6.2835 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10519/20000 - Train Loss: 0.7572 - Test Loss: 6.2826 - MSE: 6.2826 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10520/20000 - Train Loss: 0.7571 - Test Loss: 6.2820 - MSE: 6.2820 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10521/20000 - Train Loss: 0.7570 - Test Loss: 6.2811 - MSE: 6.2811 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10522/20000 - Train Loss: 0.7568 - Test Loss: 6.2804 - MSE: 6.2804 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10523/20000 - Train Loss: 0.7567 - Test Loss: 6.2797 - MSE: 6.2797 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10524/20000 - Train Loss: 0.7566 - Test Loss: 6.2788 - MSE: 6.2788 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10525/20000 - Train Loss: 0.7565 - Test Loss: 6.2783 - MSE: 6.2783 - MAE: 1.9515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10526/20000 - Train Loss: 0.7564 - Test Loss: 6.2773 - MSE: 6.2773 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10527/20000 - Train Loss: 0.7563 - Test Loss: 6.2767 - MSE: 6.2767 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10528/20000 - Train Loss: 0.7561 - Test Loss: 6.2759 - MSE: 6.2759 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10529/20000 - Train Loss: 0.7560 - Test Loss: 6.2751 - MSE: 6.2751 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10530/20000 - Train Loss: 0.7559 - Test Loss: 6.2744 - MSE: 6.2744 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10531/20000 - Train Loss: 0.7558 - Test Loss: 6.2736 - MSE: 6.2736 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10532/20000 - Train Loss: 0.7557 - Test Loss: 6.2729 - MSE: 6.2729 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10533/20000 - Train Loss: 0.7555 - Test Loss: 6.2721 - MSE: 6.2721 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10534/20000 - Train Loss: 0.7554 - Test Loss: 6.2713 - MSE: 6.2713 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10535/20000 - Train Loss: 0.7553 - Test Loss: 6.2707 - MSE: 6.2707 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10536/20000 - Train Loss: 0.7552 - Test Loss: 6.2698 - MSE: 6.2698 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10537/20000 - Train Loss: 0.7551 - Test Loss: 6.2691 - MSE: 6.2691 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 10538/20000 - Train Loss: 0.7550 - Test Loss: 6.2684 - MSE: 6.2684 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10539/20000 - Train Loss: 0.7548 - Test Loss: 6.2675 - MSE: 6.2675 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10540/20000 - Train Loss: 0.7547 - Test Loss: 6.2669 - MSE: 6.2669 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10541/20000 - Train Loss: 0.7546 - Test Loss: 6.2661 - MSE: 6.2661 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10542/20000 - Train Loss: 0.7545 - Test Loss: 6.2653 - MSE: 6.2653 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10543/20000 - Train Loss: 0.7544 - Test Loss: 6.2646 - MSE: 6.2646 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10544/20000 - Train Loss: 0.7543 - Test Loss: 6.2638 - MSE: 6.2638 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10545/20000 - Train Loss: 0.7541 - Test Loss: 6.2631 - MSE: 6.2631 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10546/20000 - Train Loss: 0.7540 - Test Loss: 6.2623 - MSE: 6.2623 - MAE: 1.9513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10547/20000 - Train Loss: 0.7539 - Test Loss: 6.2615 - MSE: 6.2615 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10548/20000 - Train Loss: 0.7538 - Test Loss: 6.2608 - MSE: 6.2608 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10549/20000 - Train Loss: 0.7537 - Test Loss: 6.2600 - MSE: 6.2600 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10550/20000 - Train Loss: 0.7536 - Test Loss: 6.2593 - MSE: 6.2593 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10551/20000 - Train Loss: 0.7534 - Test Loss: 6.2586 - MSE: 6.2586 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10552/20000 - Train Loss: 0.7533 - Test Loss: 6.2578 - MSE: 6.2578 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10553/20000 - Train Loss: 0.7532 - Test Loss: 6.2571 - MSE: 6.2571 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10554/20000 - Train Loss: 0.7531 - Test Loss: 6.2563 - MSE: 6.2563 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10555/20000 - Train Loss: 0.7530 - Test Loss: 6.2556 - MSE: 6.2556 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10556/20000 - Train Loss: 0.7529 - Test Loss: 6.2548 - MSE: 6.2548 - MAE: 1.9512\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10557/20000 - Train Loss: 0.7527 - Test Loss: 6.2540 - MSE: 6.2540 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10558/20000 - Train Loss: 0.7526 - Test Loss: 6.2534 - MSE: 6.2534 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10559/20000 - Train Loss: 0.7525 - Test Loss: 6.2525 - MSE: 6.2525 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10560/20000 - Train Loss: 0.7524 - Test Loss: 6.2518 - MSE: 6.2518 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10561/20000 - Train Loss: 0.7523 - Test Loss: 6.2511 - MSE: 6.2511 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10562/20000 - Train Loss: 0.7522 - Test Loss: 6.2503 - MSE: 6.2503 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10563/20000 - Train Loss: 0.7520 - Test Loss: 6.2496 - MSE: 6.2496 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10564/20000 - Train Loss: 0.7519 - Test Loss: 6.2488 - MSE: 6.2488 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10565/20000 - Train Loss: 0.7518 - Test Loss: 6.2481 - MSE: 6.2481 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10566/20000 - Train Loss: 0.7517 - Test Loss: 6.2473 - MSE: 6.2473 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10567/20000 - Train Loss: 0.7516 - Test Loss: 6.2465 - MSE: 6.2465 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10568/20000 - Train Loss: 0.7515 - Test Loss: 6.2459 - MSE: 6.2459 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10569/20000 - Train Loss: 0.7513 - Test Loss: 6.2450 - MSE: 6.2450 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10570/20000 - Train Loss: 0.7512 - Test Loss: 6.2444 - MSE: 6.2444 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10571/20000 - Train Loss: 0.7511 - Test Loss: 6.2436 - MSE: 6.2436 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10572/20000 - Train Loss: 0.7510 - Test Loss: 6.2427 - MSE: 6.2427 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10573/20000 - Train Loss: 0.7509 - Test Loss: 6.2422 - MSE: 6.2422 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10574/20000 - Train Loss: 0.7508 - Test Loss: 6.2413 - MSE: 6.2413 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10575/20000 - Train Loss: 0.7506 - Test Loss: 6.2406 - MSE: 6.2406 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10576/20000 - Train Loss: 0.7505 - Test Loss: 6.2399 - MSE: 6.2399 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10577/20000 - Train Loss: 0.7504 - Test Loss: 6.2390 - MSE: 6.2390 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10578/20000 - Train Loss: 0.7503 - Test Loss: 6.2385 - MSE: 6.2385 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10579/20000 - Train Loss: 0.7502 - Test Loss: 6.2375 - MSE: 6.2375 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10580/20000 - Train Loss: 0.7501 - Test Loss: 6.2369 - MSE: 6.2369 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10581/20000 - Train Loss: 0.7500 - Test Loss: 6.2362 - MSE: 6.2362 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10582/20000 - Train Loss: 0.7498 - Test Loss: 6.2353 - MSE: 6.2353 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10583/20000 - Train Loss: 0.7497 - Test Loss: 6.2348 - MSE: 6.2348 - MAE: 1.9509\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10584/20000 - Train Loss: 0.7496 - Test Loss: 6.2338 - MSE: 6.2338 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10585/20000 - Train Loss: 0.7495 - Test Loss: 6.2332 - MSE: 6.2332 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10586/20000 - Train Loss: 0.7494 - Test Loss: 6.2325 - MSE: 6.2325 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10587/20000 - Train Loss: 0.7493 - Test Loss: 6.2316 - MSE: 6.2316 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10588/20000 - Train Loss: 0.7492 - Test Loss: 6.2310 - MSE: 6.2310 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10589/20000 - Train Loss: 0.7490 - Test Loss: 6.2302 - MSE: 6.2302 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10590/20000 - Train Loss: 0.7489 - Test Loss: 6.2294 - MSE: 6.2294 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10591/20000 - Train Loss: 0.7488 - Test Loss: 6.2287 - MSE: 6.2287 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10592/20000 - Train Loss: 0.7487 - Test Loss: 6.2279 - MSE: 6.2279 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10593/20000 - Train Loss: 0.7486 - Test Loss: 6.2272 - MSE: 6.2272 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10594/20000 - Train Loss: 0.7485 - Test Loss: 6.2265 - MSE: 6.2265 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10595/20000 - Train Loss: 0.7483 - Test Loss: 6.2257 - MSE: 6.2257 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10596/20000 - Train Loss: 0.7482 - Test Loss: 6.2250 - MSE: 6.2250 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10597/20000 - Train Loss: 0.7481 - Test Loss: 6.2243 - MSE: 6.2243 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10598/20000 - Train Loss: 0.7480 - Test Loss: 6.2235 - MSE: 6.2235 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10599/20000 - Train Loss: 0.7479 - Test Loss: 6.2229 - MSE: 6.2229 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10600/20000 - Train Loss: 0.7478 - Test Loss: 6.2220 - MSE: 6.2220 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10601/20000 - Train Loss: 0.7477 - Test Loss: 6.2214 - MSE: 6.2214 - MAE: 1.9507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10602/20000 - Train Loss: 0.7475 - Test Loss: 6.2205 - MSE: 6.2205 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10603/20000 - Train Loss: 0.7474 - Test Loss: 6.2199 - MSE: 6.2199 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10604/20000 - Train Loss: 0.7473 - Test Loss: 6.2191 - MSE: 6.2191 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10605/20000 - Train Loss: 0.7472 - Test Loss: 6.2183 - MSE: 6.2183 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10606/20000 - Train Loss: 0.7471 - Test Loss: 6.2176 - MSE: 6.2176 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10607/20000 - Train Loss: 0.7470 - Test Loss: 6.2169 - MSE: 6.2169 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10608/20000 - Train Loss: 0.7469 - Test Loss: 6.2161 - MSE: 6.2161 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10609/20000 - Train Loss: 0.7468 - Test Loss: 6.2155 - MSE: 6.2155 - MAE: 1.9506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10610/20000 - Train Loss: 0.7466 - Test Loss: 6.2146 - MSE: 6.2146 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10611/20000 - Train Loss: 0.7465 - Test Loss: 6.2140 - MSE: 6.2140 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10612/20000 - Train Loss: 0.7464 - Test Loss: 6.2131 - MSE: 6.2131 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10613/20000 - Train Loss: 0.7463 - Test Loss: 6.2125 - MSE: 6.2125 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10614/20000 - Train Loss: 0.7462 - Test Loss: 6.2117 - MSE: 6.2117 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10615/20000 - Train Loss: 0.7461 - Test Loss: 6.2109 - MSE: 6.2109 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10616/20000 - Train Loss: 0.7460 - Test Loss: 6.2104 - MSE: 6.2104 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10617/20000 - Train Loss: 0.7458 - Test Loss: 6.2094 - MSE: 6.2094 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10618/20000 - Train Loss: 0.7457 - Test Loss: 6.2089 - MSE: 6.2089 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10619/20000 - Train Loss: 0.7456 - Test Loss: 6.2079 - MSE: 6.2079 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10620/20000 - Train Loss: 0.7455 - Test Loss: 6.2074 - MSE: 6.2074 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10621/20000 - Train Loss: 0.7454 - Test Loss: 6.2066 - MSE: 6.2066 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10622/20000 - Train Loss: 0.7453 - Test Loss: 6.2057 - MSE: 6.2057 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10623/20000 - Train Loss: 0.7452 - Test Loss: 6.2053 - MSE: 6.2053 - MAE: 1.9504\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10624/20000 - Train Loss: 0.7450 - Test Loss: 6.2042 - MSE: 6.2042 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10625/20000 - Train Loss: 0.7449 - Test Loss: 6.2037 - MSE: 6.2037 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10626/20000 - Train Loss: 0.7448 - Test Loss: 6.2029 - MSE: 6.2029 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10627/20000 - Train Loss: 0.7447 - Test Loss: 6.2021 - MSE: 6.2021 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10628/20000 - Train Loss: 0.7446 - Test Loss: 6.2016 - MSE: 6.2016 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10629/20000 - Train Loss: 0.7445 - Test Loss: 6.2006 - MSE: 6.2006 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10630/20000 - Train Loss: 0.7444 - Test Loss: 6.2001 - MSE: 6.2001 - MAE: 1.9503\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10631/20000 - Train Loss: 0.7443 - Test Loss: 6.1992 - MSE: 6.1992 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10632/20000 - Train Loss: 0.7441 - Test Loss: 6.1985 - MSE: 6.1985 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10633/20000 - Train Loss: 0.7440 - Test Loss: 6.1979 - MSE: 6.1979 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10634/20000 - Train Loss: 0.7439 - Test Loss: 6.1969 - MSE: 6.1969 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10635/20000 - Train Loss: 0.7438 - Test Loss: 6.1964 - MSE: 6.1964 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10636/20000 - Train Loss: 0.7437 - Test Loss: 6.1955 - MSE: 6.1955 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10637/20000 - Train Loss: 0.7436 - Test Loss: 6.1948 - MSE: 6.1948 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10638/20000 - Train Loss: 0.7435 - Test Loss: 6.1942 - MSE: 6.1942 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10639/20000 - Train Loss: 0.7434 - Test Loss: 6.1932 - MSE: 6.1932 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10640/20000 - Train Loss: 0.7432 - Test Loss: 6.1929 - MSE: 6.1929 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 10641/20000 - Train Loss: 0.7431 - Test Loss: 6.1918 - MSE: 6.1918 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10642/20000 - Train Loss: 0.7430 - Test Loss: 6.1913 - MSE: 6.1913 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10643/20000 - Train Loss: 0.7429 - Test Loss: 6.1904 - MSE: 6.1904 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10644/20000 - Train Loss: 0.7428 - Test Loss: 6.1897 - MSE: 6.1897 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10645/20000 - Train Loss: 0.7427 - Test Loss: 6.1892 - MSE: 6.1892 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10646/20000 - Train Loss: 0.7426 - Test Loss: 6.1881 - MSE: 6.1881 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10647/20000 - Train Loss: 0.7425 - Test Loss: 6.1877 - MSE: 6.1877 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10648/20000 - Train Loss: 0.7423 - Test Loss: 6.1867 - MSE: 6.1867 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10649/20000 - Train Loss: 0.7422 - Test Loss: 6.1862 - MSE: 6.1862 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10650/20000 - Train Loss: 0.7421 - Test Loss: 6.1854 - MSE: 6.1854 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10651/20000 - Train Loss: 0.7420 - Test Loss: 6.1845 - MSE: 6.1845 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10652/20000 - Train Loss: 0.7419 - Test Loss: 6.1841 - MSE: 6.1841 - MAE: 1.9500\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10653/20000 - Train Loss: 0.7418 - Test Loss: 6.1830 - MSE: 6.1830 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10654/20000 - Train Loss: 0.7417 - Test Loss: 6.1826 - MSE: 6.1826 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10655/20000 - Train Loss: 0.7416 - Test Loss: 6.1816 - MSE: 6.1816 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10656/20000 - Train Loss: 0.7415 - Test Loss: 6.1810 - MSE: 6.1810 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10657/20000 - Train Loss: 0.7413 - Test Loss: 6.1803 - MSE: 6.1803 - MAE: 1.9499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10658/20000 - Train Loss: 0.7412 - Test Loss: 6.1795 - MSE: 6.1795 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10659/20000 - Train Loss: 0.7411 - Test Loss: 6.1789 - MSE: 6.1789 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10660/20000 - Train Loss: 0.7410 - Test Loss: 6.1780 - MSE: 6.1780 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10661/20000 - Train Loss: 0.7409 - Test Loss: 6.1775 - MSE: 6.1775 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10662/20000 - Train Loss: 0.7408 - Test Loss: 6.1766 - MSE: 6.1766 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10663/20000 - Train Loss: 0.7407 - Test Loss: 6.1759 - MSE: 6.1759 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10664/20000 - Train Loss: 0.7406 - Test Loss: 6.1752 - MSE: 6.1752 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10665/20000 - Train Loss: 0.7405 - Test Loss: 6.1744 - MSE: 6.1744 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10666/20000 - Train Loss: 0.7403 - Test Loss: 6.1738 - MSE: 6.1738 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10667/20000 - Train Loss: 0.7402 - Test Loss: 6.1729 - MSE: 6.1729 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10668/20000 - Train Loss: 0.7401 - Test Loss: 6.1724 - MSE: 6.1724 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10669/20000 - Train Loss: 0.7400 - Test Loss: 6.1716 - MSE: 6.1716 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10670/20000 - Train Loss: 0.7399 - Test Loss: 6.1708 - MSE: 6.1708 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 10671/20000 - Train Loss: 0.7398 - Test Loss: 6.1702 - MSE: 6.1702 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10672/20000 - Train Loss: 0.7397 - Test Loss: 6.1693 - MSE: 6.1693 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10673/20000 - Train Loss: 0.7396 - Test Loss: 6.1688 - MSE: 6.1688 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10674/20000 - Train Loss: 0.7395 - Test Loss: 6.1679 - MSE: 6.1679 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10675/20000 - Train Loss: 0.7393 - Test Loss: 6.1673 - MSE: 6.1673 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10676/20000 - Train Loss: 0.7392 - Test Loss: 6.1665 - MSE: 6.1665 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10677/20000 - Train Loss: 0.7391 - Test Loss: 6.1658 - MSE: 6.1658 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10678/20000 - Train Loss: 0.7390 - Test Loss: 6.1651 - MSE: 6.1651 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10679/20000 - Train Loss: 0.7389 - Test Loss: 6.1643 - MSE: 6.1643 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 10680/20000 - Train Loss: 0.7388 - Test Loss: 6.1637 - MSE: 6.1637 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10681/20000 - Train Loss: 0.7387 - Test Loss: 6.1629 - MSE: 6.1629 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10682/20000 - Train Loss: 0.7386 - Test Loss: 6.1622 - MSE: 6.1622 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10683/20000 - Train Loss: 0.7385 - Test Loss: 6.1615 - MSE: 6.1615 - MAE: 1.9495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10684/20000 - Train Loss: 0.7383 - Test Loss: 6.1607 - MSE: 6.1607 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10685/20000 - Train Loss: 0.7382 - Test Loss: 6.1601 - MSE: 6.1601 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10686/20000 - Train Loss: 0.7381 - Test Loss: 6.1592 - MSE: 6.1592 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10687/20000 - Train Loss: 0.7380 - Test Loss: 6.1587 - MSE: 6.1587 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10688/20000 - Train Loss: 0.7379 - Test Loss: 6.1578 - MSE: 6.1578 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10689/20000 - Train Loss: 0.7378 - Test Loss: 6.1572 - MSE: 6.1572 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10690/20000 - Train Loss: 0.7377 - Test Loss: 6.1564 - MSE: 6.1564 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 10691/20000 - Train Loss: 0.7376 - Test Loss: 6.1557 - MSE: 6.1557 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10692/20000 - Train Loss: 0.7375 - Test Loss: 6.1550 - MSE: 6.1550 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10693/20000 - Train Loss: 0.7374 - Test Loss: 6.1543 - MSE: 6.1543 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10694/20000 - Train Loss: 0.7372 - Test Loss: 6.1536 - MSE: 6.1536 - MAE: 1.9493\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10695/20000 - Train Loss: 0.7371 - Test Loss: 6.1528 - MSE: 6.1528 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10696/20000 - Train Loss: 0.7370 - Test Loss: 6.1522 - MSE: 6.1522 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10697/20000 - Train Loss: 0.7369 - Test Loss: 6.1513 - MSE: 6.1513 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10698/20000 - Train Loss: 0.7368 - Test Loss: 6.1508 - MSE: 6.1508 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10699/20000 - Train Loss: 0.7367 - Test Loss: 6.1499 - MSE: 6.1499 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10700/20000 - Train Loss: 0.7366 - Test Loss: 6.1494 - MSE: 6.1494 - MAE: 1.9492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10701/20000 - Train Loss: 0.7365 - Test Loss: 6.1484 - MSE: 6.1484 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 964us/step\n",
      "Epoch 10702/20000 - Train Loss: 0.7364 - Test Loss: 6.1479 - MSE: 6.1479 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10703/20000 - Train Loss: 0.7363 - Test Loss: 6.1471 - MSE: 6.1471 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10704/20000 - Train Loss: 0.7362 - Test Loss: 6.1464 - MSE: 6.1464 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10705/20000 - Train Loss: 0.7360 - Test Loss: 6.1457 - MSE: 6.1457 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10706/20000 - Train Loss: 0.7359 - Test Loss: 6.1450 - MSE: 6.1450 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10707/20000 - Train Loss: 0.7358 - Test Loss: 6.1443 - MSE: 6.1443 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10708/20000 - Train Loss: 0.7357 - Test Loss: 6.1435 - MSE: 6.1435 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10709/20000 - Train Loss: 0.7356 - Test Loss: 6.1429 - MSE: 6.1429 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 10710/20000 - Train Loss: 0.7355 - Test Loss: 6.1420 - MSE: 6.1420 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10711/20000 - Train Loss: 0.7354 - Test Loss: 6.1415 - MSE: 6.1415 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10712/20000 - Train Loss: 0.7353 - Test Loss: 6.1406 - MSE: 6.1406 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10713/20000 - Train Loss: 0.7352 - Test Loss: 6.1400 - MSE: 6.1400 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10714/20000 - Train Loss: 0.7351 - Test Loss: 6.1392 - MSE: 6.1392 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10715/20000 - Train Loss: 0.7350 - Test Loss: 6.1386 - MSE: 6.1386 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10716/20000 - Train Loss: 0.7348 - Test Loss: 6.1379 - MSE: 6.1379 - MAE: 1.9489\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10717/20000 - Train Loss: 0.7347 - Test Loss: 6.1371 - MSE: 6.1371 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10718/20000 - Train Loss: 0.7346 - Test Loss: 6.1365 - MSE: 6.1365 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10719/20000 - Train Loss: 0.7345 - Test Loss: 6.1355 - MSE: 6.1355 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10720/20000 - Train Loss: 0.7344 - Test Loss: 6.1352 - MSE: 6.1352 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 10721/20000 - Train Loss: 0.7343 - Test Loss: 6.1341 - MSE: 6.1341 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10722/20000 - Train Loss: 0.7342 - Test Loss: 6.1337 - MSE: 6.1337 - MAE: 1.9488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10723/20000 - Train Loss: 0.7341 - Test Loss: 6.1328 - MSE: 6.1328 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10724/20000 - Train Loss: 0.7340 - Test Loss: 6.1322 - MSE: 6.1322 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10725/20000 - Train Loss: 0.7339 - Test Loss: 6.1316 - MSE: 6.1316 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10726/20000 - Train Loss: 0.7338 - Test Loss: 6.1305 - MSE: 6.1305 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10727/20000 - Train Loss: 0.7337 - Test Loss: 6.1303 - MSE: 6.1303 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10728/20000 - Train Loss: 0.7335 - Test Loss: 6.1290 - MSE: 6.1290 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10729/20000 - Train Loss: 0.7334 - Test Loss: 6.1290 - MSE: 6.1290 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10730/20000 - Train Loss: 0.7333 - Test Loss: 6.1275 - MSE: 6.1275 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Epoch 10731/20000 - Train Loss: 0.7332 - Test Loss: 6.1276 - MSE: 6.1276 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10732/20000 - Train Loss: 0.7331 - Test Loss: 6.1261 - MSE: 6.1261 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10733/20000 - Train Loss: 0.7330 - Test Loss: 6.1261 - MSE: 6.1261 - MAE: 1.9486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10734/20000 - Train Loss: 0.7329 - Test Loss: 6.1248 - MSE: 6.1248 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10735/20000 - Train Loss: 0.7328 - Test Loss: 6.1246 - MSE: 6.1246 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10736/20000 - Train Loss: 0.7327 - Test Loss: 6.1235 - MSE: 6.1235 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10737/20000 - Train Loss: 0.7326 - Test Loss: 6.1231 - MSE: 6.1231 - MAE: 1.9485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10738/20000 - Train Loss: 0.7325 - Test Loss: 6.1221 - MSE: 6.1221 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10739/20000 - Train Loss: 0.7324 - Test Loss: 6.1216 - MSE: 6.1216 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10740/20000 - Train Loss: 0.7322 - Test Loss: 6.1207 - MSE: 6.1207 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10741/20000 - Train Loss: 0.7321 - Test Loss: 6.1202 - MSE: 6.1202 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10742/20000 - Train Loss: 0.7320 - Test Loss: 6.1193 - MSE: 6.1193 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10743/20000 - Train Loss: 0.7319 - Test Loss: 6.1188 - MSE: 6.1188 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10744/20000 - Train Loss: 0.7318 - Test Loss: 6.1180 - MSE: 6.1180 - MAE: 1.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10745/20000 - Train Loss: 0.7317 - Test Loss: 6.1172 - MSE: 6.1172 - MAE: 1.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10746/20000 - Train Loss: 0.7316 - Test Loss: 6.1166 - MSE: 6.1166 - MAE: 1.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10747/20000 - Train Loss: 0.7315 - Test Loss: 6.1158 - MSE: 6.1158 - MAE: 1.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10748/20000 - Train Loss: 0.7314 - Test Loss: 6.1153 - MSE: 6.1153 - MAE: 1.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10749/20000 - Train Loss: 0.7313 - Test Loss: 6.1144 - MSE: 6.1144 - MAE: 1.9482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10750/20000 - Train Loss: 0.7312 - Test Loss: 6.1138 - MSE: 6.1138 - MAE: 1.9482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10751/20000 - Train Loss: 0.7311 - Test Loss: 6.1130 - MSE: 6.1130 - MAE: 1.9482\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 10752/20000 - Train Loss: 0.7310 - Test Loss: 6.1124 - MSE: 6.1124 - MAE: 1.9482\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10753/20000 - Train Loss: 0.7309 - Test Loss: 6.1116 - MSE: 6.1116 - MAE: 1.9481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10754/20000 - Train Loss: 0.7307 - Test Loss: 6.1110 - MSE: 6.1110 - MAE: 1.9481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10755/20000 - Train Loss: 0.7306 - Test Loss: 6.1102 - MSE: 6.1102 - MAE: 1.9481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10756/20000 - Train Loss: 0.7305 - Test Loss: 6.1096 - MSE: 6.1096 - MAE: 1.9481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10757/20000 - Train Loss: 0.7304 - Test Loss: 6.1087 - MSE: 6.1087 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10758/20000 - Train Loss: 0.7303 - Test Loss: 6.1082 - MSE: 6.1082 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10759/20000 - Train Loss: 0.7302 - Test Loss: 6.1074 - MSE: 6.1074 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10760/20000 - Train Loss: 0.7301 - Test Loss: 6.1068 - MSE: 6.1068 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10761/20000 - Train Loss: 0.7300 - Test Loss: 6.1060 - MSE: 6.1060 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10762/20000 - Train Loss: 0.7299 - Test Loss: 6.1053 - MSE: 6.1053 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10763/20000 - Train Loss: 0.7298 - Test Loss: 6.1047 - MSE: 6.1047 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10764/20000 - Train Loss: 0.7297 - Test Loss: 6.1038 - MSE: 6.1038 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10765/20000 - Train Loss: 0.7296 - Test Loss: 6.1033 - MSE: 6.1033 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10766/20000 - Train Loss: 0.7295 - Test Loss: 6.1024 - MSE: 6.1024 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10767/20000 - Train Loss: 0.7294 - Test Loss: 6.1020 - MSE: 6.1020 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10768/20000 - Train Loss: 0.7293 - Test Loss: 6.1010 - MSE: 6.1010 - MAE: 1.9478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10769/20000 - Train Loss: 0.7291 - Test Loss: 6.1006 - MSE: 6.1006 - MAE: 1.9478\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 10770/20000 - Train Loss: 0.7290 - Test Loss: 6.0996 - MSE: 6.0996 - MAE: 1.9478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10771/20000 - Train Loss: 0.7289 - Test Loss: 6.0991 - MSE: 6.0991 - MAE: 1.9478\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10772/20000 - Train Loss: 0.7288 - Test Loss: 6.0983 - MSE: 6.0983 - MAE: 1.9477\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 10773/20000 - Train Loss: 0.7287 - Test Loss: 6.0977 - MSE: 6.0977 - MAE: 1.9477\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10774/20000 - Train Loss: 0.7286 - Test Loss: 6.0969 - MSE: 6.0969 - MAE: 1.9477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10775/20000 - Train Loss: 0.7285 - Test Loss: 6.0962 - MSE: 6.0962 - MAE: 1.9477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10776/20000 - Train Loss: 0.7284 - Test Loss: 6.0955 - MSE: 6.0955 - MAE: 1.9477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10777/20000 - Train Loss: 0.7283 - Test Loss: 6.0948 - MSE: 6.0948 - MAE: 1.9476\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10778/20000 - Train Loss: 0.7282 - Test Loss: 6.0941 - MSE: 6.0941 - MAE: 1.9476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10779/20000 - Train Loss: 0.7281 - Test Loss: 6.0934 - MSE: 6.0934 - MAE: 1.9476\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10780/20000 - Train Loss: 0.7280 - Test Loss: 6.0927 - MSE: 6.0927 - MAE: 1.9476\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10781/20000 - Train Loss: 0.7279 - Test Loss: 6.0920 - MSE: 6.0920 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10782/20000 - Train Loss: 0.7278 - Test Loss: 6.0914 - MSE: 6.0914 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10783/20000 - Train Loss: 0.7277 - Test Loss: 6.0905 - MSE: 6.0905 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10784/20000 - Train Loss: 0.7276 - Test Loss: 6.0901 - MSE: 6.0901 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 10785/20000 - Train Loss: 0.7275 - Test Loss: 6.0891 - MSE: 6.0891 - MAE: 1.9474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10786/20000 - Train Loss: 0.7273 - Test Loss: 6.0888 - MSE: 6.0888 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10787/20000 - Train Loss: 0.7272 - Test Loss: 6.0876 - MSE: 6.0876 - MAE: 1.9474\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10788/20000 - Train Loss: 0.7271 - Test Loss: 6.0875 - MSE: 6.0875 - MAE: 1.9474\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10789/20000 - Train Loss: 0.7270 - Test Loss: 6.0861 - MSE: 6.0861 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 10790/20000 - Train Loss: 0.7269 - Test Loss: 6.0862 - MSE: 6.0862 - MAE: 1.9474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10791/20000 - Train Loss: 0.7268 - Test Loss: 6.0845 - MSE: 6.0845 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10792/20000 - Train Loss: 0.7267 - Test Loss: 6.0850 - MSE: 6.0850 - MAE: 1.9474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10793/20000 - Train Loss: 0.7266 - Test Loss: 6.0830 - MSE: 6.0830 - MAE: 1.9472\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10794/20000 - Train Loss: 0.7265 - Test Loss: 6.0838 - MSE: 6.0838 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10795/20000 - Train Loss: 0.7264 - Test Loss: 6.0814 - MSE: 6.0814 - MAE: 1.9471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10796/20000 - Train Loss: 0.7263 - Test Loss: 6.0827 - MSE: 6.0827 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10797/20000 - Train Loss: 0.7262 - Test Loss: 6.0797 - MSE: 6.0797 - MAE: 1.9471\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10798/20000 - Train Loss: 0.7261 - Test Loss: 6.0816 - MSE: 6.0816 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10799/20000 - Train Loss: 0.7260 - Test Loss: 6.0779 - MSE: 6.0779 - MAE: 1.9470\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10800/20000 - Train Loss: 0.7259 - Test Loss: 6.0808 - MSE: 6.0808 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10801/20000 - Train Loss: 0.7258 - Test Loss: 6.0758 - MSE: 6.0758 - MAE: 1.9468\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10802/20000 - Train Loss: 0.7257 - Test Loss: 6.0802 - MSE: 6.0802 - MAE: 1.9474\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10803/20000 - Train Loss: 0.7256 - Test Loss: 6.0734 - MSE: 6.0734 - MAE: 1.9467\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10804/20000 - Train Loss: 0.7255 - Test Loss: 6.0800 - MSE: 6.0800 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10805/20000 - Train Loss: 0.7254 - Test Loss: 6.0706 - MSE: 6.0706 - MAE: 1.9465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10806/20000 - Train Loss: 0.7253 - Test Loss: 6.0804 - MSE: 6.0804 - MAE: 1.9476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10807/20000 - Train Loss: 0.7251 - Test Loss: 6.0670 - MSE: 6.0670 - MAE: 1.9462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10808/20000 - Train Loss: 0.7250 - Test Loss: 6.0819 - MSE: 6.0819 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10809/20000 - Train Loss: 0.7250 - Test Loss: 6.0621 - MSE: 6.0621 - MAE: 1.9458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10810/20000 - Train Loss: 0.7249 - Test Loss: 6.0849 - MSE: 6.0849 - MAE: 1.9483\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10811/20000 - Train Loss: 0.7248 - Test Loss: 6.0553 - MSE: 6.0553 - MAE: 1.9451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10812/20000 - Train Loss: 0.7247 - Test Loss: 6.0906 - MSE: 6.0906 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10813/20000 - Train Loss: 0.7246 - Test Loss: 6.0452 - MSE: 6.0452 - MAE: 1.9441\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 10814/20000 - Train Loss: 0.7246 - Test Loss: 6.1006 - MSE: 6.1006 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 10815/20000 - Train Loss: 0.7246 - Test Loss: 6.0298 - MSE: 6.0298 - MAE: 1.9425\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10816/20000 - Train Loss: 0.7247 - Test Loss: 6.1180 - MSE: 6.1180 - MAE: 1.9521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10817/20000 - Train Loss: 0.7249 - Test Loss: 6.0058 - MSE: 6.0058 - MAE: 1.9399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10818/20000 - Train Loss: 0.7252 - Test Loss: 6.1476 - MSE: 6.1476 - MAE: 1.9553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10819/20000 - Train Loss: 0.7259 - Test Loss: 5.9684 - MSE: 5.9684 - MAE: 1.9358\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10820/20000 - Train Loss: 0.7270 - Test Loss: 6.1979 - MSE: 6.1979 - MAE: 1.9605\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10821/20000 - Train Loss: 0.7289 - Test Loss: 5.9107 - MSE: 5.9107 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10822/20000 - Train Loss: 0.7320 - Test Loss: 6.2817 - MSE: 6.2817 - MAE: 1.9688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10823/20000 - Train Loss: 0.7366 - Test Loss: 5.8274 - MSE: 5.8274 - MAE: 1.9188\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10824/20000 - Train Loss: 0.7434 - Test Loss: 6.4110 - MSE: 6.4110 - MAE: 1.9842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10825/20000 - Train Loss: 0.7523 - Test Loss: 5.7273 - MSE: 5.7273 - MAE: 1.9052\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10826/20000 - Train Loss: 0.7617 - Test Loss: 6.5610 - MSE: 6.5610 - MAE: 2.0012\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10827/20000 - Train Loss: 0.7678 - Test Loss: 5.6589 - MSE: 5.6589 - MAE: 1.8952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10828/20000 - Train Loss: 0.7657 - Test Loss: 6.5895 - MSE: 6.5895 - MAE: 2.0043\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10829/20000 - Train Loss: 0.7531 - Test Loss: 5.7191 - MSE: 5.7191 - MAE: 1.9043\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10830/20000 - Train Loss: 0.7357 - Test Loss: 6.3329 - MSE: 6.3329 - MAE: 1.9753\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10831/20000 - Train Loss: 0.7241 - Test Loss: 5.9770 - MSE: 5.9770 - MAE: 1.9374\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10832/20000 - Train Loss: 0.7241 - Test Loss: 5.9717 - MSE: 5.9717 - MAE: 1.9368\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10833/20000 - Train Loss: 0.7325 - Test Loss: 6.2961 - MSE: 6.2961 - MAE: 1.9710\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10834/20000 - Train Loss: 0.7403 - Test Loss: 5.7858 - MSE: 5.7858 - MAE: 1.9139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10835/20000 - Train Loss: 0.7403 - Test Loss: 6.3832 - MSE: 6.3832 - MAE: 1.9815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10836/20000 - Train Loss: 0.7326 - Test Loss: 5.8432 - MSE: 5.8432 - MAE: 1.9215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10837/20000 - Train Loss: 0.7244 - Test Loss: 6.1640 - MSE: 6.1640 - MAE: 1.9578\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10838/20000 - Train Loss: 0.7222 - Test Loss: 6.0842 - MSE: 6.0842 - MAE: 1.9496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10839/20000 - Train Loss: 0.7262 - Test Loss: 5.9136 - MSE: 5.9136 - MAE: 1.9304\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10840/20000 - Train Loss: 0.7309 - Test Loss: 6.2786 - MSE: 6.2786 - MAE: 1.9692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10841/20000 - Train Loss: 0.7311 - Test Loss: 5.8509 - MSE: 5.8509 - MAE: 1.9228\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10842/20000 - Train Loss: 0.7268 - Test Loss: 6.2193 - MSE: 6.2193 - MAE: 1.9636\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10843/20000 - Train Loss: 0.7224 - Test Loss: 5.9856 - MSE: 5.9856 - MAE: 1.9389\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10844/20000 - Train Loss: 0.7217 - Test Loss: 6.0131 - MSE: 6.0131 - MAE: 1.9421\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10845/20000 - Train Loss: 0.7242 - Test Loss: 6.1732 - MSE: 6.1732 - MAE: 1.9591\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10846/20000 - Train Loss: 0.7265 - Test Loss: 5.8961 - MSE: 5.8961 - MAE: 1.9286\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10847/20000 - Train Loss: 0.7259 - Test Loss: 6.2080 - MSE: 6.2080 - MAE: 1.9626\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10848/20000 - Train Loss: 0.7232 - Test Loss: 5.9481 - MSE: 5.9481 - MAE: 1.9349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10849/20000 - Train Loss: 0.7212 - Test Loss: 6.0749 - MSE: 6.0749 - MAE: 1.9490\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10850/20000 - Train Loss: 0.7214 - Test Loss: 6.0935 - MSE: 6.0935 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10851/20000 - Train Loss: 0.7229 - Test Loss: 5.9476 - MSE: 5.9476 - MAE: 1.9350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10852/20000 - Train Loss: 0.7237 - Test Loss: 6.1708 - MSE: 6.1708 - MAE: 1.9591\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10853/20000 - Train Loss: 0.7229 - Test Loss: 5.9425 - MSE: 5.9425 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10854/20000 - Train Loss: 0.7213 - Test Loss: 6.1057 - MSE: 6.1057 - MAE: 1.9525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10855/20000 - Train Loss: 0.7205 - Test Loss: 6.0392 - MSE: 6.0392 - MAE: 1.9454\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 10856/20000 - Train Loss: 0.7208 - Test Loss: 5.9944 - MSE: 5.9944 - MAE: 1.9405\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10857/20000 - Train Loss: 0.7216 - Test Loss: 6.1262 - MSE: 6.1262 - MAE: 1.9548\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10858/20000 - Train Loss: 0.7218 - Test Loss: 5.9542 - MSE: 5.9542 - MAE: 1.9360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10859/20000 - Train Loss: 0.7211 - Test Loss: 6.1132 - MSE: 6.1132 - MAE: 1.9535\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10860/20000 - Train Loss: 0.7202 - Test Loss: 6.0058 - MSE: 6.0058 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10861/20000 - Train Loss: 0.7199 - Test Loss: 6.0314 - MSE: 6.0314 - MAE: 1.9449\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10862/20000 - Train Loss: 0.7202 - Test Loss: 6.0833 - MSE: 6.0833 - MAE: 1.9505\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 10863/20000 - Train Loss: 0.7206 - Test Loss: 5.9751 - MSE: 5.9751 - MAE: 1.9387\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10864/20000 - Train Loss: 0.7205 - Test Loss: 6.1039 - MSE: 6.1039 - MAE: 1.9527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10865/20000 - Train Loss: 0.7200 - Test Loss: 5.9897 - MSE: 5.9897 - MAE: 1.9404\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10866/20000 - Train Loss: 0.7195 - Test Loss: 6.0560 - MSE: 6.0560 - MAE: 1.9477\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10867/20000 - Train Loss: 0.7194 - Test Loss: 6.0470 - MSE: 6.0470 - MAE: 1.9468\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10868/20000 - Train Loss: 0.7195 - Test Loss: 5.9995 - MSE: 5.9995 - MAE: 1.9416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10869/20000 - Train Loss: 0.7197 - Test Loss: 6.0839 - MSE: 6.0839 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10870/20000 - Train Loss: 0.7195 - Test Loss: 5.9875 - MSE: 5.9875 - MAE: 1.9404\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 10871/20000 - Train Loss: 0.7192 - Test Loss: 6.0669 - MSE: 6.0669 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10872/20000 - Train Loss: 0.7189 - Test Loss: 6.0207 - MSE: 6.0207 - MAE: 1.9442\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10873/20000 - Train Loss: 0.7188 - Test Loss: 6.0219 - MSE: 6.0219 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10874/20000 - Train Loss: 0.7189 - Test Loss: 6.0593 - MSE: 6.0593 - MAE: 1.9484\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10875/20000 - Train Loss: 0.7189 - Test Loss: 5.9952 - MSE: 5.9952 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10876/20000 - Train Loss: 0.7188 - Test Loss: 6.0652 - MSE: 6.0652 - MAE: 1.9491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10877/20000 - Train Loss: 0.7186 - Test Loss: 6.0055 - MSE: 6.0055 - MAE: 1.9427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10878/20000 - Train Loss: 0.7184 - Test Loss: 6.0381 - MSE: 6.0381 - MAE: 1.9463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10879/20000 - Train Loss: 0.7183 - Test Loss: 6.0355 - MSE: 6.0355 - MAE: 1.9461\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10880/20000 - Train Loss: 0.7183 - Test Loss: 6.0082 - MSE: 6.0082 - MAE: 1.9431\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10881/20000 - Train Loss: 0.7182 - Test Loss: 6.0538 - MSE: 6.0538 - MAE: 1.9481\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10882/20000 - Train Loss: 0.7181 - Test Loss: 6.0012 - MSE: 6.0012 - MAE: 1.9424\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10883/20000 - Train Loss: 0.7180 - Test Loss: 6.0450 - MSE: 6.0450 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10884/20000 - Train Loss: 0.7178 - Test Loss: 6.0174 - MSE: 6.0174 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10885/20000 - Train Loss: 0.7177 - Test Loss: 6.0213 - MSE: 6.0213 - MAE: 1.9448\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10886/20000 - Train Loss: 0.7177 - Test Loss: 6.0374 - MSE: 6.0374 - MAE: 1.9466\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10887/20000 - Train Loss: 0.7176 - Test Loss: 6.0051 - MSE: 6.0051 - MAE: 1.9431\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10888/20000 - Train Loss: 0.7175 - Test Loss: 6.0424 - MSE: 6.0424 - MAE: 1.9472\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10889/20000 - Train Loss: 0.7174 - Test Loss: 6.0073 - MSE: 6.0073 - MAE: 1.9434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10890/20000 - Train Loss: 0.7173 - Test Loss: 6.0300 - MSE: 6.0300 - MAE: 1.9459\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10891/20000 - Train Loss: 0.7172 - Test Loss: 6.0214 - MSE: 6.0214 - MAE: 1.9450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10892/20000 - Train Loss: 0.7171 - Test Loss: 6.0131 - MSE: 6.0131 - MAE: 1.9442\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10893/20000 - Train Loss: 0.7170 - Test Loss: 6.0326 - MSE: 6.0326 - MAE: 1.9463\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10894/20000 - Train Loss: 0.7170 - Test Loss: 6.0053 - MSE: 6.0053 - MAE: 1.9434\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10895/20000 - Train Loss: 0.7169 - Test Loss: 6.0314 - MSE: 6.0314 - MAE: 1.9463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10896/20000 - Train Loss: 0.7167 - Test Loss: 6.0101 - MSE: 6.0101 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10897/20000 - Train Loss: 0.7166 - Test Loss: 6.0202 - MSE: 6.0202 - MAE: 1.9451\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 10898/20000 - Train Loss: 0.7166 - Test Loss: 6.0202 - MSE: 6.0202 - MAE: 1.9452\n",
      "2/2 [==============================] - 0s 988us/step\n",
      "Epoch 10899/20000 - Train Loss: 0.7165 - Test Loss: 6.0089 - MSE: 6.0089 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10900/20000 - Train Loss: 0.7164 - Test Loss: 6.0258 - MSE: 6.0258 - MAE: 1.9459\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10901/20000 - Train Loss: 0.7163 - Test Loss: 6.0054 - MSE: 6.0054 - MAE: 1.9437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10902/20000 - Train Loss: 0.7162 - Test Loss: 6.0225 - MSE: 6.0225 - MAE: 1.9456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10903/20000 - Train Loss: 0.7161 - Test Loss: 6.0097 - MSE: 6.0097 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10904/20000 - Train Loss: 0.7160 - Test Loss: 6.0137 - MSE: 6.0137 - MAE: 1.9447\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10905/20000 - Train Loss: 0.7159 - Test Loss: 6.0164 - MSE: 6.0164 - MAE: 1.9451\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10906/20000 - Train Loss: 0.7158 - Test Loss: 6.0061 - MSE: 6.0061 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10907/20000 - Train Loss: 0.7158 - Test Loss: 6.0190 - MSE: 6.0190 - MAE: 1.9454\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10908/20000 - Train Loss: 0.7157 - Test Loss: 6.0042 - MSE: 6.0042 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10909/20000 - Train Loss: 0.7156 - Test Loss: 6.0156 - MSE: 6.0156 - MAE: 1.9451\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10910/20000 - Train Loss: 0.7155 - Test Loss: 6.0073 - MSE: 6.0073 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10911/20000 - Train Loss: 0.7154 - Test Loss: 6.0090 - MSE: 6.0090 - MAE: 1.9445\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10912/20000 - Train Loss: 0.7153 - Test Loss: 6.0114 - MSE: 6.0114 - MAE: 1.9448\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10913/20000 - Train Loss: 0.7152 - Test Loss: 6.0037 - MSE: 6.0037 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10914/20000 - Train Loss: 0.7151 - Test Loss: 6.0126 - MSE: 6.0126 - MAE: 1.9450\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10915/20000 - Train Loss: 0.7150 - Test Loss: 6.0021 - MSE: 6.0021 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10916/20000 - Train Loss: 0.7149 - Test Loss: 6.0099 - MSE: 6.0099 - MAE: 1.9448\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10917/20000 - Train Loss: 0.7148 - Test Loss: 6.0039 - MSE: 6.0039 - MAE: 1.9442\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10918/20000 - Train Loss: 0.7148 - Test Loss: 6.0050 - MSE: 6.0050 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10919/20000 - Train Loss: 0.7147 - Test Loss: 6.0063 - MSE: 6.0063 - MAE: 1.9445\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10920/20000 - Train Loss: 0.7146 - Test Loss: 6.0009 - MSE: 6.0009 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10921/20000 - Train Loss: 0.7145 - Test Loss: 6.0069 - MSE: 6.0069 - MAE: 1.9447\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10922/20000 - Train Loss: 0.7144 - Test Loss: 5.9993 - MSE: 5.9993 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10923/20000 - Train Loss: 0.7143 - Test Loss: 6.0049 - MSE: 6.0049 - MAE: 1.9445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10924/20000 - Train Loss: 0.7142 - Test Loss: 5.9999 - MSE: 5.9999 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10925/20000 - Train Loss: 0.7141 - Test Loss: 6.0013 - MSE: 6.0013 - MAE: 1.9442\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10926/20000 - Train Loss: 0.7140 - Test Loss: 6.0012 - MSE: 6.0012 - MAE: 1.9442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10927/20000 - Train Loss: 0.7140 - Test Loss: 5.9979 - MSE: 5.9979 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 10928/20000 - Train Loss: 0.7139 - Test Loss: 6.0015 - MSE: 6.0015 - MAE: 1.9444\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10929/20000 - Train Loss: 0.7138 - Test Loss: 5.9961 - MSE: 5.9961 - MAE: 1.9438\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10930/20000 - Train Loss: 0.7137 - Test Loss: 6.0001 - MSE: 6.0001 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10931/20000 - Train Loss: 0.7136 - Test Loss: 5.9959 - MSE: 5.9959 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10932/20000 - Train Loss: 0.7135 - Test Loss: 5.9975 - MSE: 5.9975 - MAE: 1.9441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10933/20000 - Train Loss: 0.7134 - Test Loss: 5.9963 - MSE: 5.9963 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 10934/20000 - Train Loss: 0.7133 - Test Loss: 5.9948 - MSE: 5.9948 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10935/20000 - Train Loss: 0.7132 - Test Loss: 5.9963 - MSE: 5.9963 - MAE: 1.9441\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10936/20000 - Train Loss: 0.7132 - Test Loss: 5.9928 - MSE: 5.9928 - MAE: 1.9437\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10937/20000 - Train Loss: 0.7131 - Test Loss: 5.9953 - MSE: 5.9953 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10938/20000 - Train Loss: 0.7130 - Test Loss: 5.9919 - MSE: 5.9919 - MAE: 1.9437\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10939/20000 - Train Loss: 0.7129 - Test Loss: 5.9935 - MSE: 5.9935 - MAE: 1.9439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10940/20000 - Train Loss: 0.7128 - Test Loss: 5.9915 - MSE: 5.9915 - MAE: 1.9437\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10941/20000 - Train Loss: 0.7127 - Test Loss: 5.9914 - MSE: 5.9914 - MAE: 1.9438\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10942/20000 - Train Loss: 0.7126 - Test Loss: 5.9913 - MSE: 5.9913 - MAE: 1.9438\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10943/20000 - Train Loss: 0.7125 - Test Loss: 5.9894 - MSE: 5.9894 - MAE: 1.9436\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10944/20000 - Train Loss: 0.7124 - Test Loss: 5.9907 - MSE: 5.9907 - MAE: 1.9438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10945/20000 - Train Loss: 0.7124 - Test Loss: 5.9880 - MSE: 5.9880 - MAE: 1.9435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10946/20000 - Train Loss: 0.7123 - Test Loss: 5.9894 - MSE: 5.9894 - MAE: 1.9437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10947/20000 - Train Loss: 0.7122 - Test Loss: 5.9872 - MSE: 5.9872 - MAE: 1.9435\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10948/20000 - Train Loss: 0.7121 - Test Loss: 5.9877 - MSE: 5.9877 - MAE: 1.9436\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10949/20000 - Train Loss: 0.7120 - Test Loss: 5.9866 - MSE: 5.9866 - MAE: 1.9435\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 10950/20000 - Train Loss: 0.7119 - Test Loss: 5.9858 - MSE: 5.9858 - MAE: 1.9435\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 10951/20000 - Train Loss: 0.7118 - Test Loss: 5.9860 - MSE: 5.9860 - MAE: 1.9435\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10952/20000 - Train Loss: 0.7117 - Test Loss: 5.9843 - MSE: 5.9843 - MAE: 1.9434\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 10953/20000 - Train Loss: 0.7116 - Test Loss: 5.9850 - MSE: 5.9850 - MAE: 1.9435\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10954/20000 - Train Loss: 0.7116 - Test Loss: 5.9832 - MSE: 5.9832 - MAE: 1.9434\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10955/20000 - Train Loss: 0.7115 - Test Loss: 5.9836 - MSE: 5.9836 - MAE: 1.9434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10956/20000 - Train Loss: 0.7114 - Test Loss: 5.9823 - MSE: 5.9823 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10957/20000 - Train Loss: 0.7113 - Test Loss: 5.9820 - MSE: 5.9820 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10958/20000 - Train Loss: 0.7112 - Test Loss: 5.9815 - MSE: 5.9815 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 10959/20000 - Train Loss: 0.7111 - Test Loss: 5.9805 - MSE: 5.9805 - MAE: 1.9432\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10960/20000 - Train Loss: 0.7110 - Test Loss: 5.9806 - MSE: 5.9806 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 10961/20000 - Train Loss: 0.7109 - Test Loss: 5.9790 - MSE: 5.9790 - MAE: 1.9432\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 10962/20000 - Train Loss: 0.7109 - Test Loss: 5.9796 - MSE: 5.9796 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10963/20000 - Train Loss: 0.7108 - Test Loss: 5.9778 - MSE: 5.9778 - MAE: 1.9431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10964/20000 - Train Loss: 0.7107 - Test Loss: 5.9784 - MSE: 5.9784 - MAE: 1.9432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10965/20000 - Train Loss: 0.7106 - Test Loss: 5.9768 - MSE: 5.9768 - MAE: 1.9431\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10966/20000 - Train Loss: 0.7105 - Test Loss: 5.9770 - MSE: 5.9770 - MAE: 1.9431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10967/20000 - Train Loss: 0.7104 - Test Loss: 5.9758 - MSE: 5.9758 - MAE: 1.9430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10968/20000 - Train Loss: 0.7103 - Test Loss: 5.9756 - MSE: 5.9756 - MAE: 1.9430\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 10969/20000 - Train Loss: 0.7102 - Test Loss: 5.9749 - MSE: 5.9749 - MAE: 1.9430\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 10970/20000 - Train Loss: 0.7101 - Test Loss: 5.9742 - MSE: 5.9742 - MAE: 1.9430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10971/20000 - Train Loss: 0.7101 - Test Loss: 5.9739 - MSE: 5.9739 - MAE: 1.9430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10972/20000 - Train Loss: 0.7100 - Test Loss: 5.9728 - MSE: 5.9728 - MAE: 1.9429\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10973/20000 - Train Loss: 0.7099 - Test Loss: 5.9729 - MSE: 5.9729 - MAE: 1.9429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10974/20000 - Train Loss: 0.7098 - Test Loss: 5.9715 - MSE: 5.9715 - MAE: 1.9428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10975/20000 - Train Loss: 0.7097 - Test Loss: 5.9718 - MSE: 5.9718 - MAE: 1.9429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10976/20000 - Train Loss: 0.7096 - Test Loss: 5.9703 - MSE: 5.9703 - MAE: 1.9428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10977/20000 - Train Loss: 0.7095 - Test Loss: 5.9706 - MSE: 5.9706 - MAE: 1.9428\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10978/20000 - Train Loss: 0.7094 - Test Loss: 5.9693 - MSE: 5.9693 - MAE: 1.9427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10979/20000 - Train Loss: 0.7094 - Test Loss: 5.9692 - MSE: 5.9692 - MAE: 1.9428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10980/20000 - Train Loss: 0.7093 - Test Loss: 5.9683 - MSE: 5.9683 - MAE: 1.9427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10981/20000 - Train Loss: 0.7092 - Test Loss: 5.9679 - MSE: 5.9679 - MAE: 1.9427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10982/20000 - Train Loss: 0.7091 - Test Loss: 5.9673 - MSE: 5.9673 - MAE: 1.9426\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10983/20000 - Train Loss: 0.7090 - Test Loss: 5.9666 - MSE: 5.9666 - MAE: 1.9426\n",
      "2/2 [==============================] - 0s 982us/step\n",
      "Epoch 10984/20000 - Train Loss: 0.7089 - Test Loss: 5.9662 - MSE: 5.9662 - MAE: 1.9426\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10985/20000 - Train Loss: 0.7088 - Test Loss: 5.9652 - MSE: 5.9652 - MAE: 1.9425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10986/20000 - Train Loss: 0.7087 - Test Loss: 5.9652 - MSE: 5.9652 - MAE: 1.9426\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10987/20000 - Train Loss: 0.7087 - Test Loss: 5.9640 - MSE: 5.9640 - MAE: 1.9425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10988/20000 - Train Loss: 0.7086 - Test Loss: 5.9640 - MSE: 5.9640 - MAE: 1.9425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10989/20000 - Train Loss: 0.7085 - Test Loss: 5.9629 - MSE: 5.9629 - MAE: 1.9424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10990/20000 - Train Loss: 0.7084 - Test Loss: 5.9628 - MSE: 5.9628 - MAE: 1.9424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10991/20000 - Train Loss: 0.7083 - Test Loss: 5.9618 - MSE: 5.9618 - MAE: 1.9424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10992/20000 - Train Loss: 0.7082 - Test Loss: 5.9615 - MSE: 5.9615 - MAE: 1.9424\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 10993/20000 - Train Loss: 0.7081 - Test Loss: 5.9608 - MSE: 5.9608 - MAE: 1.9423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10994/20000 - Train Loss: 0.7080 - Test Loss: 5.9602 - MSE: 5.9602 - MAE: 1.9423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10995/20000 - Train Loss: 0.7080 - Test Loss: 5.9597 - MSE: 5.9597 - MAE: 1.9423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10996/20000 - Train Loss: 0.7079 - Test Loss: 5.9589 - MSE: 5.9589 - MAE: 1.9422\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 10997/20000 - Train Loss: 0.7078 - Test Loss: 5.9586 - MSE: 5.9586 - MAE: 1.9422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 10998/20000 - Train Loss: 0.7077 - Test Loss: 5.9576 - MSE: 5.9576 - MAE: 1.9422\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 10999/20000 - Train Loss: 0.7076 - Test Loss: 5.9576 - MSE: 5.9576 - MAE: 1.9422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11000/20000 - Train Loss: 0.7075 - Test Loss: 5.9564 - MSE: 5.9564 - MAE: 1.9421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11001/20000 - Train Loss: 0.7074 - Test Loss: 5.9565 - MSE: 5.9565 - MAE: 1.9421\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 11002/20000 - Train Loss: 0.7073 - Test Loss: 5.9552 - MSE: 5.9552 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11003/20000 - Train Loss: 0.7073 - Test Loss: 5.9553 - MSE: 5.9553 - MAE: 1.9421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11004/20000 - Train Loss: 0.7072 - Test Loss: 5.9540 - MSE: 5.9540 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11005/20000 - Train Loss: 0.7071 - Test Loss: 5.9540 - MSE: 5.9540 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11006/20000 - Train Loss: 0.7070 - Test Loss: 5.9530 - MSE: 5.9530 - MAE: 1.9419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11007/20000 - Train Loss: 0.7069 - Test Loss: 5.9528 - MSE: 5.9528 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11008/20000 - Train Loss: 0.7068 - Test Loss: 5.9519 - MSE: 5.9519 - MAE: 1.9419\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11009/20000 - Train Loss: 0.7067 - Test Loss: 5.9515 - MSE: 5.9515 - MAE: 1.9419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11010/20000 - Train Loss: 0.7067 - Test Loss: 5.9509 - MSE: 5.9509 - MAE: 1.9418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11011/20000 - Train Loss: 0.7066 - Test Loss: 5.9502 - MSE: 5.9502 - MAE: 1.9418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11012/20000 - Train Loss: 0.7065 - Test Loss: 5.9498 - MSE: 5.9498 - MAE: 1.9418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11013/20000 - Train Loss: 0.7064 - Test Loss: 5.9489 - MSE: 5.9489 - MAE: 1.9417\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11014/20000 - Train Loss: 0.7063 - Test Loss: 5.9488 - MSE: 5.9488 - MAE: 1.9418\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11015/20000 - Train Loss: 0.7062 - Test Loss: 5.9477 - MSE: 5.9477 - MAE: 1.9417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11016/20000 - Train Loss: 0.7061 - Test Loss: 5.9477 - MSE: 5.9477 - MAE: 1.9417\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11017/20000 - Train Loss: 0.7060 - Test Loss: 5.9464 - MSE: 5.9464 - MAE: 1.9416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11018/20000 - Train Loss: 0.7060 - Test Loss: 5.9465 - MSE: 5.9465 - MAE: 1.9417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11019/20000 - Train Loss: 0.7059 - Test Loss: 5.9452 - MSE: 5.9452 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11020/20000 - Train Loss: 0.7058 - Test Loss: 5.9454 - MSE: 5.9454 - MAE: 1.9416\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 11021/20000 - Train Loss: 0.7057 - Test Loss: 5.9440 - MSE: 5.9440 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11022/20000 - Train Loss: 0.7056 - Test Loss: 5.9443 - MSE: 5.9443 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11023/20000 - Train Loss: 0.7055 - Test Loss: 5.9428 - MSE: 5.9428 - MAE: 1.9414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11024/20000 - Train Loss: 0.7054 - Test Loss: 5.9433 - MSE: 5.9433 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11025/20000 - Train Loss: 0.7054 - Test Loss: 5.9415 - MSE: 5.9415 - MAE: 1.9413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11026/20000 - Train Loss: 0.7053 - Test Loss: 5.9422 - MSE: 5.9422 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11027/20000 - Train Loss: 0.7052 - Test Loss: 5.9402 - MSE: 5.9402 - MAE: 1.9413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11028/20000 - Train Loss: 0.7051 - Test Loss: 5.9412 - MSE: 5.9412 - MAE: 1.9414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11029/20000 - Train Loss: 0.7050 - Test Loss: 5.9389 - MSE: 5.9389 - MAE: 1.9412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11030/20000 - Train Loss: 0.7049 - Test Loss: 5.9402 - MSE: 5.9402 - MAE: 1.9414\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11031/20000 - Train Loss: 0.7048 - Test Loss: 5.9375 - MSE: 5.9375 - MAE: 1.9411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11032/20000 - Train Loss: 0.7047 - Test Loss: 5.9393 - MSE: 5.9393 - MAE: 1.9413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11033/20000 - Train Loss: 0.7047 - Test Loss: 5.9361 - MSE: 5.9361 - MAE: 1.9410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11034/20000 - Train Loss: 0.7046 - Test Loss: 5.9384 - MSE: 5.9384 - MAE: 1.9413\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11035/20000 - Train Loss: 0.7045 - Test Loss: 5.9346 - MSE: 5.9346 - MAE: 1.9409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11036/20000 - Train Loss: 0.7044 - Test Loss: 5.9377 - MSE: 5.9377 - MAE: 1.9413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11037/20000 - Train Loss: 0.7043 - Test Loss: 5.9329 - MSE: 5.9329 - MAE: 1.9408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11038/20000 - Train Loss: 0.7042 - Test Loss: 5.9373 - MSE: 5.9373 - MAE: 1.9413\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 11039/20000 - Train Loss: 0.7041 - Test Loss: 5.9309 - MSE: 5.9309 - MAE: 1.9406\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11040/20000 - Train Loss: 0.7041 - Test Loss: 5.9371 - MSE: 5.9371 - MAE: 1.9414\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11041/20000 - Train Loss: 0.7040 - Test Loss: 5.9285 - MSE: 5.9285 - MAE: 1.9404\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11042/20000 - Train Loss: 0.7039 - Test Loss: 5.9374 - MSE: 5.9374 - MAE: 1.9415\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11043/20000 - Train Loss: 0.7038 - Test Loss: 5.9256 - MSE: 5.9256 - MAE: 1.9402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11044/20000 - Train Loss: 0.7037 - Test Loss: 5.9384 - MSE: 5.9384 - MAE: 1.9416\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 11045/20000 - Train Loss: 0.7036 - Test Loss: 5.9218 - MSE: 5.9218 - MAE: 1.9398\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11046/20000 - Train Loss: 0.7036 - Test Loss: 5.9406 - MSE: 5.9406 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11047/20000 - Train Loss: 0.7035 - Test Loss: 5.9165 - MSE: 5.9165 - MAE: 1.9393\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11048/20000 - Train Loss: 0.7034 - Test Loss: 5.9446 - MSE: 5.9446 - MAE: 1.9425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11049/20000 - Train Loss: 0.7034 - Test Loss: 5.9090 - MSE: 5.9090 - MAE: 1.9385\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11050/20000 - Train Loss: 0.7033 - Test Loss: 5.9516 - MSE: 5.9516 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11051/20000 - Train Loss: 0.7033 - Test Loss: 5.8980 - MSE: 5.8980 - MAE: 1.9374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11052/20000 - Train Loss: 0.7033 - Test Loss: 5.9633 - MSE: 5.9633 - MAE: 1.9446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11053/20000 - Train Loss: 0.7034 - Test Loss: 5.8814 - MSE: 5.8814 - MAE: 1.9355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11054/20000 - Train Loss: 0.7035 - Test Loss: 5.9827 - MSE: 5.9827 - MAE: 1.9468\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11055/20000 - Train Loss: 0.7038 - Test Loss: 5.8561 - MSE: 5.8561 - MAE: 1.9327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11056/20000 - Train Loss: 0.7043 - Test Loss: 6.0148 - MSE: 6.0148 - MAE: 1.9502\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11057/20000 - Train Loss: 0.7052 - Test Loss: 5.8173 - MSE: 5.8173 - MAE: 1.9282\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 11058/20000 - Train Loss: 0.7065 - Test Loss: 6.0678 - MSE: 6.0678 - MAE: 1.9558\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 11059/20000 - Train Loss: 0.7087 - Test Loss: 5.7594 - MSE: 5.7594 - MAE: 1.9211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11060/20000 - Train Loss: 0.7121 - Test Loss: 6.1527 - MSE: 6.1527 - MAE: 1.9643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11061/20000 - Train Loss: 0.7170 - Test Loss: 5.6800 - MSE: 5.6800 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11062/20000 - Train Loss: 0.7237 - Test Loss: 6.2749 - MSE: 6.2749 - MAE: 1.9784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11063/20000 - Train Loss: 0.7316 - Test Loss: 5.5927 - MSE: 5.5927 - MAE: 1.8986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11064/20000 - Train Loss: 0.7388 - Test Loss: 6.3969 - MSE: 6.3969 - MAE: 1.9925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11065/20000 - Train Loss: 0.7417 - Test Loss: 5.5476 - MSE: 5.5476 - MAE: 1.8918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11066/20000 - Train Loss: 0.7367 - Test Loss: 6.3816 - MSE: 6.3816 - MAE: 1.9908\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11067/20000 - Train Loss: 0.7241 - Test Loss: 5.6279 - MSE: 5.6279 - MAE: 1.9039\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11068/20000 - Train Loss: 0.7099 - Test Loss: 6.1280 - MSE: 6.1280 - MAE: 1.9620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11069/20000 - Train Loss: 0.7020 - Test Loss: 5.8721 - MSE: 5.8721 - MAE: 1.9350\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11070/20000 - Train Loss: 0.7036 - Test Loss: 5.8200 - MSE: 5.8200 - MAE: 1.9290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11071/20000 - Train Loss: 0.7109 - Test Loss: 6.1426 - MSE: 6.1426 - MAE: 1.9636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11072/20000 - Train Loss: 0.7169 - Test Loss: 5.6687 - MSE: 5.6687 - MAE: 1.9098\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11073/20000 - Train Loss: 0.7166 - Test Loss: 6.2086 - MSE: 6.2086 - MAE: 1.9709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11074/20000 - Train Loss: 0.7104 - Test Loss: 5.7204 - MSE: 5.7204 - MAE: 1.9167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11075/20000 - Train Loss: 0.7035 - Test Loss: 6.0232 - MSE: 6.0232 - MAE: 1.9517\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 11076/20000 - Train Loss: 0.7011 - Test Loss: 5.9249 - MSE: 5.9249 - MAE: 1.9412\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11077/20000 - Train Loss: 0.7037 - Test Loss: 5.8026 - MSE: 5.8026 - MAE: 1.9271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11078/20000 - Train Loss: 0.7077 - Test Loss: 6.1033 - MSE: 6.1033 - MAE: 1.9599\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11079/20000 - Train Loss: 0.7090 - Test Loss: 5.7283 - MSE: 5.7283 - MAE: 1.9179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11080/20000 - Train Loss: 0.7064 - Test Loss: 6.0832 - MSE: 6.0832 - MAE: 1.9579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11081/20000 - Train Loss: 0.7025 - Test Loss: 5.8211 - MSE: 5.8211 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11082/20000 - Train Loss: 0.7006 - Test Loss: 5.9157 - MSE: 5.9157 - MAE: 1.9403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11083/20000 - Train Loss: 0.7017 - Test Loss: 5.9854 - MSE: 5.9854 - MAE: 1.9479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11084/20000 - Train Loss: 0.7039 - Test Loss: 5.7874 - MSE: 5.7874 - MAE: 1.9255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11085/20000 - Train Loss: 0.7047 - Test Loss: 6.0586 - MSE: 6.0586 - MAE: 1.9555\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11086/20000 - Train Loss: 0.7034 - Test Loss: 5.7916 - MSE: 5.7916 - MAE: 1.9261\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11087/20000 - Train Loss: 0.7013 - Test Loss: 5.9802 - MSE: 5.9802 - MAE: 1.9475\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11088/20000 - Train Loss: 0.7001 - Test Loss: 5.8996 - MSE: 5.8996 - MAE: 1.9387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11089/20000 - Train Loss: 0.7006 - Test Loss: 5.8558 - MSE: 5.8558 - MAE: 1.9337\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11090/20000 - Train Loss: 0.7018 - Test Loss: 6.0005 - MSE: 6.0005 - MAE: 1.9497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11091/20000 - Train Loss: 0.7022 - Test Loss: 5.8044 - MSE: 5.8044 - MAE: 1.9278\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11092/20000 - Train Loss: 0.7015 - Test Loss: 5.9977 - MSE: 5.9977 - MAE: 1.9494\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11093/20000 - Train Loss: 0.7004 - Test Loss: 5.8514 - MSE: 5.8514 - MAE: 1.9334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11094/20000 - Train Loss: 0.6997 - Test Loss: 5.9120 - MSE: 5.9120 - MAE: 1.9402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11095/20000 - Train Loss: 0.6999 - Test Loss: 5.9392 - MSE: 5.9392 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11096/20000 - Train Loss: 0.7004 - Test Loss: 5.8387 - MSE: 5.8387 - MAE: 1.9320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11097/20000 - Train Loss: 0.7007 - Test Loss: 5.9810 - MSE: 5.9810 - MAE: 1.9478\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11098/20000 - Train Loss: 0.7003 - Test Loss: 5.8358 - MSE: 5.8358 - MAE: 1.9317\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11099/20000 - Train Loss: 0.6997 - Test Loss: 5.9448 - MSE: 5.9448 - MAE: 1.9440\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11100/20000 - Train Loss: 0.6992 - Test Loss: 5.8909 - MSE: 5.8909 - MAE: 1.9381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11101/20000 - Train Loss: 0.6993 - Test Loss: 5.8784 - MSE: 5.8784 - MAE: 1.9367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11102/20000 - Train Loss: 0.6995 - Test Loss: 5.9460 - MSE: 5.9460 - MAE: 1.9442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11103/20000 - Train Loss: 0.6997 - Test Loss: 5.8447 - MSE: 5.8447 - MAE: 1.9329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11104/20000 - Train Loss: 0.6995 - Test Loss: 5.9512 - MSE: 5.9512 - MAE: 1.9448\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 11105/20000 - Train Loss: 0.6991 - Test Loss: 5.8632 - MSE: 5.8632 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11106/20000 - Train Loss: 0.6988 - Test Loss: 5.9104 - MSE: 5.9104 - MAE: 1.9404\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11107/20000 - Train Loss: 0.6987 - Test Loss: 5.9082 - MSE: 5.9082 - MAE: 1.9402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11108/20000 - Train Loss: 0.6988 - Test Loss: 5.8674 - MSE: 5.8674 - MAE: 1.9356\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11109/20000 - Train Loss: 0.6989 - Test Loss: 5.9363 - MSE: 5.9363 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11110/20000 - Train Loss: 0.6988 - Test Loss: 5.8569 - MSE: 5.8569 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11111/20000 - Train Loss: 0.6986 - Test Loss: 5.9256 - MSE: 5.9256 - MAE: 1.9422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11112/20000 - Train Loss: 0.6984 - Test Loss: 5.8797 - MSE: 5.8797 - MAE: 1.9371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11113/20000 - Train Loss: 0.6982 - Test Loss: 5.8921 - MSE: 5.8921 - MAE: 1.9386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11114/20000 - Train Loss: 0.6982 - Test Loss: 5.9106 - MSE: 5.9106 - MAE: 1.9406\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11115/20000 - Train Loss: 0.6982 - Test Loss: 5.8668 - MSE: 5.8668 - MAE: 1.9358\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11116/20000 - Train Loss: 0.6982 - Test Loss: 5.9223 - MSE: 5.9223 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11117/20000 - Train Loss: 0.6981 - Test Loss: 5.8669 - MSE: 5.8669 - MAE: 1.9358\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 11118/20000 - Train Loss: 0.6979 - Test Loss: 5.9081 - MSE: 5.9081 - MAE: 1.9405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11119/20000 - Train Loss: 0.6978 - Test Loss: 5.8864 - MSE: 5.8864 - MAE: 1.9381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11120/20000 - Train Loss: 0.6977 - Test Loss: 5.8837 - MSE: 5.8837 - MAE: 1.9378\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11121/20000 - Train Loss: 0.6977 - Test Loss: 5.9059 - MSE: 5.9059 - MAE: 1.9403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11122/20000 - Train Loss: 0.6976 - Test Loss: 5.8692 - MSE: 5.8692 - MAE: 1.9362\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11123/20000 - Train Loss: 0.6976 - Test Loss: 5.9096 - MSE: 5.9096 - MAE: 1.9408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11124/20000 - Train Loss: 0.6975 - Test Loss: 5.8724 - MSE: 5.8724 - MAE: 1.9366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11125/20000 - Train Loss: 0.6973 - Test Loss: 5.8971 - MSE: 5.8971 - MAE: 1.9394\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11126/20000 - Train Loss: 0.6973 - Test Loss: 5.8867 - MSE: 5.8867 - MAE: 1.9383\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11127/20000 - Train Loss: 0.6972 - Test Loss: 5.8802 - MSE: 5.8802 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11128/20000 - Train Loss: 0.6971 - Test Loss: 5.8988 - MSE: 5.8988 - MAE: 1.9397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11129/20000 - Train Loss: 0.6971 - Test Loss: 5.8713 - MSE: 5.8713 - MAE: 1.9367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11130/20000 - Train Loss: 0.6970 - Test Loss: 5.8996 - MSE: 5.8996 - MAE: 1.9398\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11131/20000 - Train Loss: 0.6969 - Test Loss: 5.8743 - MSE: 5.8743 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11132/20000 - Train Loss: 0.6968 - Test Loss: 5.8901 - MSE: 5.8901 - MAE: 1.9388\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11133/20000 - Train Loss: 0.6967 - Test Loss: 5.8840 - MSE: 5.8840 - MAE: 1.9382\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11134/20000 - Train Loss: 0.6967 - Test Loss: 5.8783 - MSE: 5.8783 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11135/20000 - Train Loss: 0.6966 - Test Loss: 5.8917 - MSE: 5.8917 - MAE: 1.9391\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 11136/20000 - Train Loss: 0.6965 - Test Loss: 5.8721 - MSE: 5.8721 - MAE: 1.9369\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11137/20000 - Train Loss: 0.6964 - Test Loss: 5.8919 - MSE: 5.8919 - MAE: 1.9392\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11138/20000 - Train Loss: 0.6964 - Test Loss: 5.8736 - MSE: 5.8736 - MAE: 1.9372\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11139/20000 - Train Loss: 0.6963 - Test Loss: 5.8853 - MSE: 5.8853 - MAE: 1.9385\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 11140/20000 - Train Loss: 0.6962 - Test Loss: 5.8797 - MSE: 5.8797 - MAE: 1.9379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11141/20000 - Train Loss: 0.6961 - Test Loss: 5.8770 - MSE: 5.8770 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11142/20000 - Train Loss: 0.6961 - Test Loss: 5.8849 - MSE: 5.8849 - MAE: 1.9385\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11143/20000 - Train Loss: 0.6960 - Test Loss: 5.8719 - MSE: 5.8719 - MAE: 1.9371\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11144/20000 - Train Loss: 0.6959 - Test Loss: 5.8855 - MSE: 5.8855 - MAE: 1.9386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11145/20000 - Train Loss: 0.6958 - Test Loss: 5.8718 - MSE: 5.8718 - MAE: 1.9371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11146/20000 - Train Loss: 0.6958 - Test Loss: 5.8813 - MSE: 5.8813 - MAE: 1.9382\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11147/20000 - Train Loss: 0.6957 - Test Loss: 5.8753 - MSE: 5.8753 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11148/20000 - Train Loss: 0.6956 - Test Loss: 5.8753 - MSE: 5.8753 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11149/20000 - Train Loss: 0.6955 - Test Loss: 5.8788 - MSE: 5.8788 - MAE: 1.9380\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11150/20000 - Train Loss: 0.6955 - Test Loss: 5.8709 - MSE: 5.8709 - MAE: 1.9372\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11151/20000 - Train Loss: 0.6954 - Test Loss: 5.8797 - MSE: 5.8797 - MAE: 1.9382\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 11152/20000 - Train Loss: 0.6953 - Test Loss: 5.8696 - MSE: 5.8696 - MAE: 1.9371\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11153/20000 - Train Loss: 0.6952 - Test Loss: 5.8774 - MSE: 5.8774 - MAE: 1.9380\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11154/20000 - Train Loss: 0.6952 - Test Loss: 5.8710 - MSE: 5.8710 - MAE: 1.9373\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11155/20000 - Train Loss: 0.6951 - Test Loss: 5.8734 - MSE: 5.8734 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11156/20000 - Train Loss: 0.6950 - Test Loss: 5.8731 - MSE: 5.8731 - MAE: 1.9376\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11157/20000 - Train Loss: 0.6949 - Test Loss: 5.8696 - MSE: 5.8696 - MAE: 1.9372\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 11158/20000 - Train Loss: 0.6949 - Test Loss: 5.8742 - MSE: 5.8742 - MAE: 1.9377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11159/20000 - Train Loss: 0.6948 - Test Loss: 5.8675 - MSE: 5.8675 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 11160/20000 - Train Loss: 0.6947 - Test Loss: 5.8733 - MSE: 5.8733 - MAE: 1.9377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11161/20000 - Train Loss: 0.6946 - Test Loss: 5.8673 - MSE: 5.8673 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11162/20000 - Train Loss: 0.6946 - Test Loss: 5.8707 - MSE: 5.8707 - MAE: 1.9375\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11163/20000 - Train Loss: 0.6945 - Test Loss: 5.8681 - MSE: 5.8681 - MAE: 1.9372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11164/20000 - Train Loss: 0.6944 - Test Loss: 5.8677 - MSE: 5.8677 - MAE: 1.9372\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11165/20000 - Train Loss: 0.6943 - Test Loss: 5.8689 - MSE: 5.8689 - MAE: 1.9373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11166/20000 - Train Loss: 0.6943 - Test Loss: 5.8653 - MSE: 5.8653 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11167/20000 - Train Loss: 0.6942 - Test Loss: 5.8687 - MSE: 5.8687 - MAE: 1.9374\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11168/20000 - Train Loss: 0.6941 - Test Loss: 5.8641 - MSE: 5.8641 - MAE: 1.9369\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11169/20000 - Train Loss: 0.6940 - Test Loss: 5.8674 - MSE: 5.8674 - MAE: 1.9373\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11170/20000 - Train Loss: 0.6940 - Test Loss: 5.8639 - MSE: 5.8639 - MAE: 1.9369\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11171/20000 - Train Loss: 0.6939 - Test Loss: 5.8653 - MSE: 5.8653 - MAE: 1.9371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11172/20000 - Train Loss: 0.6938 - Test Loss: 5.8641 - MSE: 5.8641 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11173/20000 - Train Loss: 0.6937 - Test Loss: 5.8631 - MSE: 5.8631 - MAE: 1.9369\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11174/20000 - Train Loss: 0.6937 - Test Loss: 5.8640 - MSE: 5.8640 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11175/20000 - Train Loss: 0.6936 - Test Loss: 5.8614 - MSE: 5.8614 - MAE: 1.9367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11176/20000 - Train Loss: 0.6935 - Test Loss: 5.8634 - MSE: 5.8634 - MAE: 1.9370\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11177/20000 - Train Loss: 0.6934 - Test Loss: 5.8603 - MSE: 5.8603 - MAE: 1.9367\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11178/20000 - Train Loss: 0.6934 - Test Loss: 5.8622 - MSE: 5.8622 - MAE: 1.9369\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11179/20000 - Train Loss: 0.6933 - Test Loss: 5.8598 - MSE: 5.8598 - MAE: 1.9366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11180/20000 - Train Loss: 0.6932 - Test Loss: 5.8606 - MSE: 5.8606 - MAE: 1.9368\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11181/20000 - Train Loss: 0.6931 - Test Loss: 5.8594 - MSE: 5.8594 - MAE: 1.9367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11182/20000 - Train Loss: 0.6931 - Test Loss: 5.8589 - MSE: 5.8589 - MAE: 1.9366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11183/20000 - Train Loss: 0.6930 - Test Loss: 5.8590 - MSE: 5.8590 - MAE: 1.9367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11184/20000 - Train Loss: 0.6929 - Test Loss: 5.8574 - MSE: 5.8574 - MAE: 1.9365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11185/20000 - Train Loss: 0.6928 - Test Loss: 5.8583 - MSE: 5.8583 - MAE: 1.9366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11186/20000 - Train Loss: 0.6928 - Test Loss: 5.8563 - MSE: 5.8563 - MAE: 1.9364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11187/20000 - Train Loss: 0.6927 - Test Loss: 5.8572 - MSE: 5.8572 - MAE: 1.9366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11188/20000 - Train Loss: 0.6926 - Test Loss: 5.8554 - MSE: 5.8554 - MAE: 1.9364\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11189/20000 - Train Loss: 0.6925 - Test Loss: 5.8559 - MSE: 5.8559 - MAE: 1.9365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11190/20000 - Train Loss: 0.6925 - Test Loss: 5.8548 - MSE: 5.8548 - MAE: 1.9364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11191/20000 - Train Loss: 0.6924 - Test Loss: 5.8545 - MSE: 5.8545 - MAE: 1.9364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11192/20000 - Train Loss: 0.6923 - Test Loss: 5.8542 - MSE: 5.8542 - MAE: 1.9363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11193/20000 - Train Loss: 0.6922 - Test Loss: 5.8532 - MSE: 5.8532 - MAE: 1.9363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11194/20000 - Train Loss: 0.6922 - Test Loss: 5.8534 - MSE: 5.8534 - MAE: 1.9363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11195/20000 - Train Loss: 0.6921 - Test Loss: 5.8519 - MSE: 5.8519 - MAE: 1.9362\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11196/20000 - Train Loss: 0.6920 - Test Loss: 5.8526 - MSE: 5.8526 - MAE: 1.9363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11197/20000 - Train Loss: 0.6919 - Test Loss: 5.8509 - MSE: 5.8509 - MAE: 1.9361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11198/20000 - Train Loss: 0.6919 - Test Loss: 5.8515 - MSE: 5.8515 - MAE: 1.9362\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11199/20000 - Train Loss: 0.6918 - Test Loss: 5.8500 - MSE: 5.8500 - MAE: 1.9360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11200/20000 - Train Loss: 0.6917 - Test Loss: 5.8503 - MSE: 5.8503 - MAE: 1.9361\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11201/20000 - Train Loss: 0.6916 - Test Loss: 5.8493 - MSE: 5.8493 - MAE: 1.9360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11202/20000 - Train Loss: 0.6916 - Test Loss: 5.8490 - MSE: 5.8490 - MAE: 1.9360\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11203/20000 - Train Loss: 0.6915 - Test Loss: 5.8486 - MSE: 5.8486 - MAE: 1.9360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11204/20000 - Train Loss: 0.6914 - Test Loss: 5.8477 - MSE: 5.8477 - MAE: 1.9359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11205/20000 - Train Loss: 0.6913 - Test Loss: 5.8478 - MSE: 5.8478 - MAE: 1.9359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11206/20000 - Train Loss: 0.6913 - Test Loss: 5.8465 - MSE: 5.8465 - MAE: 1.9358\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11207/20000 - Train Loss: 0.6912 - Test Loss: 5.8469 - MSE: 5.8469 - MAE: 1.9359\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11208/20000 - Train Loss: 0.6911 - Test Loss: 5.8454 - MSE: 5.8454 - MAE: 1.9357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11209/20000 - Train Loss: 0.6911 - Test Loss: 5.8459 - MSE: 5.8459 - MAE: 1.9358\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 11210/20000 - Train Loss: 0.6910 - Test Loss: 5.8444 - MSE: 5.8444 - MAE: 1.9357\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11211/20000 - Train Loss: 0.6909 - Test Loss: 5.8449 - MSE: 5.8449 - MAE: 1.9357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11212/20000 - Train Loss: 0.6908 - Test Loss: 5.8435 - MSE: 5.8435 - MAE: 1.9356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11213/20000 - Train Loss: 0.6908 - Test Loss: 5.8438 - MSE: 5.8438 - MAE: 1.9357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11214/20000 - Train Loss: 0.6907 - Test Loss: 5.8426 - MSE: 5.8426 - MAE: 1.9356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11215/20000 - Train Loss: 0.6906 - Test Loss: 5.8426 - MSE: 5.8426 - MAE: 1.9356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11216/20000 - Train Loss: 0.6905 - Test Loss: 5.8418 - MSE: 5.8418 - MAE: 1.9355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11217/20000 - Train Loss: 0.6905 - Test Loss: 5.8414 - MSE: 5.8414 - MAE: 1.9355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11218/20000 - Train Loss: 0.6904 - Test Loss: 5.8409 - MSE: 5.8409 - MAE: 1.9355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11219/20000 - Train Loss: 0.6903 - Test Loss: 5.8403 - MSE: 5.8403 - MAE: 1.9354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11220/20000 - Train Loss: 0.6902 - Test Loss: 5.8400 - MSE: 5.8400 - MAE: 1.9354\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 11221/20000 - Train Loss: 0.6902 - Test Loss: 5.8392 - MSE: 5.8392 - MAE: 1.9353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11222/20000 - Train Loss: 0.6901 - Test Loss: 5.8391 - MSE: 5.8391 - MAE: 1.9354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11223/20000 - Train Loss: 0.6900 - Test Loss: 5.8381 - MSE: 5.8381 - MAE: 1.9353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11224/20000 - Train Loss: 0.6899 - Test Loss: 5.8381 - MSE: 5.8381 - MAE: 1.9353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11225/20000 - Train Loss: 0.6899 - Test Loss: 5.8372 - MSE: 5.8372 - MAE: 1.9352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11226/20000 - Train Loss: 0.6898 - Test Loss: 5.8370 - MSE: 5.8370 - MAE: 1.9352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11227/20000 - Train Loss: 0.6897 - Test Loss: 5.8362 - MSE: 5.8362 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11228/20000 - Train Loss: 0.6897 - Test Loss: 5.8360 - MSE: 5.8360 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11229/20000 - Train Loss: 0.6896 - Test Loss: 5.8352 - MSE: 5.8352 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11230/20000 - Train Loss: 0.6895 - Test Loss: 5.8350 - MSE: 5.8350 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11231/20000 - Train Loss: 0.6894 - Test Loss: 5.8342 - MSE: 5.8342 - MAE: 1.9350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11232/20000 - Train Loss: 0.6894 - Test Loss: 5.8341 - MSE: 5.8341 - MAE: 1.9350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11233/20000 - Train Loss: 0.6893 - Test Loss: 5.8331 - MSE: 5.8331 - MAE: 1.9349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11234/20000 - Train Loss: 0.6892 - Test Loss: 5.8331 - MSE: 5.8331 - MAE: 1.9349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11235/20000 - Train Loss: 0.6891 - Test Loss: 5.8322 - MSE: 5.8322 - MAE: 1.9349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11236/20000 - Train Loss: 0.6891 - Test Loss: 5.8320 - MSE: 5.8320 - MAE: 1.9349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11237/20000 - Train Loss: 0.6890 - Test Loss: 5.8312 - MSE: 5.8312 - MAE: 1.9348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11238/20000 - Train Loss: 0.6889 - Test Loss: 5.8309 - MSE: 5.8309 - MAE: 1.9348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11239/20000 - Train Loss: 0.6888 - Test Loss: 5.8303 - MSE: 5.8303 - MAE: 1.9347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11240/20000 - Train Loss: 0.6888 - Test Loss: 5.8298 - MSE: 5.8298 - MAE: 1.9347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11241/20000 - Train Loss: 0.6887 - Test Loss: 5.8294 - MSE: 5.8294 - MAE: 1.9347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11242/20000 - Train Loss: 0.6886 - Test Loss: 5.8287 - MSE: 5.8287 - MAE: 1.9346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11243/20000 - Train Loss: 0.6885 - Test Loss: 5.8286 - MSE: 5.8286 - MAE: 1.9346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11244/20000 - Train Loss: 0.6885 - Test Loss: 5.8275 - MSE: 5.8275 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11245/20000 - Train Loss: 0.6884 - Test Loss: 5.8278 - MSE: 5.8278 - MAE: 1.9346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11246/20000 - Train Loss: 0.6883 - Test Loss: 5.8263 - MSE: 5.8263 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11247/20000 - Train Loss: 0.6883 - Test Loss: 5.8270 - MSE: 5.8270 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11248/20000 - Train Loss: 0.6882 - Test Loss: 5.8250 - MSE: 5.8250 - MAE: 1.9344\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11249/20000 - Train Loss: 0.6881 - Test Loss: 5.8263 - MSE: 5.8263 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11250/20000 - Train Loss: 0.6880 - Test Loss: 5.8237 - MSE: 5.8237 - MAE: 1.9342\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11251/20000 - Train Loss: 0.6880 - Test Loss: 5.8257 - MSE: 5.8257 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11252/20000 - Train Loss: 0.6879 - Test Loss: 5.8223 - MSE: 5.8223 - MAE: 1.9341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11253/20000 - Train Loss: 0.6878 - Test Loss: 5.8251 - MSE: 5.8251 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11254/20000 - Train Loss: 0.6877 - Test Loss: 5.8209 - MSE: 5.8209 - MAE: 1.9340\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11255/20000 - Train Loss: 0.6877 - Test Loss: 5.8246 - MSE: 5.8246 - MAE: 1.9344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11256/20000 - Train Loss: 0.6876 - Test Loss: 5.8193 - MSE: 5.8193 - MAE: 1.9339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11257/20000 - Train Loss: 0.6875 - Test Loss: 5.8242 - MSE: 5.8242 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11258/20000 - Train Loss: 0.6875 - Test Loss: 5.8175 - MSE: 5.8175 - MAE: 1.9337\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11259/20000 - Train Loss: 0.6874 - Test Loss: 5.8242 - MSE: 5.8242 - MAE: 1.9345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11260/20000 - Train Loss: 0.6873 - Test Loss: 5.8153 - MSE: 5.8153 - MAE: 1.9335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11261/20000 - Train Loss: 0.6872 - Test Loss: 5.8247 - MSE: 5.8247 - MAE: 1.9346\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11262/20000 - Train Loss: 0.6872 - Test Loss: 5.8125 - MSE: 5.8125 - MAE: 1.9332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11263/20000 - Train Loss: 0.6871 - Test Loss: 5.8259 - MSE: 5.8259 - MAE: 1.9348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11264/20000 - Train Loss: 0.6870 - Test Loss: 5.8088 - MSE: 5.8088 - MAE: 1.9329\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11265/20000 - Train Loss: 0.6870 - Test Loss: 5.8283 - MSE: 5.8283 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11266/20000 - Train Loss: 0.6869 - Test Loss: 5.8037 - MSE: 5.8037 - MAE: 1.9323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11267/20000 - Train Loss: 0.6868 - Test Loss: 5.8325 - MSE: 5.8325 - MAE: 1.9356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11268/20000 - Train Loss: 0.6868 - Test Loss: 5.7964 - MSE: 5.7964 - MAE: 1.9315\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11269/20000 - Train Loss: 0.6868 - Test Loss: 5.8395 - MSE: 5.8395 - MAE: 1.9364\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11270/20000 - Train Loss: 0.6868 - Test Loss: 5.7857 - MSE: 5.7857 - MAE: 1.9303\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11271/20000 - Train Loss: 0.6868 - Test Loss: 5.8511 - MSE: 5.8511 - MAE: 1.9377\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11272/20000 - Train Loss: 0.6869 - Test Loss: 5.7697 - MSE: 5.7697 - MAE: 1.9285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11273/20000 - Train Loss: 0.6870 - Test Loss: 5.8701 - MSE: 5.8701 - MAE: 1.9399\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11274/20000 - Train Loss: 0.6873 - Test Loss: 5.7452 - MSE: 5.7452 - MAE: 1.9257\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11275/20000 - Train Loss: 0.6878 - Test Loss: 5.9014 - MSE: 5.9014 - MAE: 1.9433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11276/20000 - Train Loss: 0.6887 - Test Loss: 5.7079 - MSE: 5.7079 - MAE: 1.9212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11277/20000 - Train Loss: 0.6900 - Test Loss: 5.9527 - MSE: 5.9527 - MAE: 1.9487\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11278/20000 - Train Loss: 0.6922 - Test Loss: 5.6525 - MSE: 5.6525 - MAE: 1.9143\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11279/20000 - Train Loss: 0.6954 - Test Loss: 6.0343 - MSE: 6.0343 - MAE: 1.9570\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11280/20000 - Train Loss: 0.7002 - Test Loss: 5.5767 - MSE: 5.5767 - MAE: 1.9043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11281/20000 - Train Loss: 0.7066 - Test Loss: 6.1512 - MSE: 6.1512 - MAE: 1.9700\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11282/20000 - Train Loss: 0.7142 - Test Loss: 5.4935 - MSE: 5.4935 - MAE: 1.8923\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 11283/20000 - Train Loss: 0.7212 - Test Loss: 6.2682 - MSE: 6.2682 - MAE: 1.9837\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11284/20000 - Train Loss: 0.7242 - Test Loss: 5.4496 - MSE: 5.4496 - MAE: 1.8855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11285/20000 - Train Loss: 0.7197 - Test Loss: 6.2577 - MSE: 6.2577 - MAE: 1.9825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11286/20000 - Train Loss: 0.7079 - Test Loss: 5.5225 - MSE: 5.5225 - MAE: 1.8968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11287/20000 - Train Loss: 0.6941 - Test Loss: 6.0208 - MSE: 6.0208 - MAE: 1.9558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11288/20000 - Train Loss: 0.6860 - Test Loss: 5.7511 - MSE: 5.7511 - MAE: 1.9267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11289/20000 - Train Loss: 0.6868 - Test Loss: 5.7241 - MSE: 5.7241 - MAE: 1.9235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11290/20000 - Train Loss: 0.6935 - Test Loss: 6.0130 - MSE: 6.0130 - MAE: 1.9551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11291/20000 - Train Loss: 0.6996 - Test Loss: 5.5705 - MSE: 5.5705 - MAE: 1.9037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11292/20000 - Train Loss: 0.7001 - Test Loss: 6.0910 - MSE: 6.0910 - MAE: 1.9629\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11293/20000 - Train Loss: 0.6947 - Test Loss: 5.6081 - MSE: 5.6081 - MAE: 1.9089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11294/20000 - Train Loss: 0.6879 - Test Loss: 5.9261 - MSE: 5.9261 - MAE: 1.9462\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11295/20000 - Train Loss: 0.6848 - Test Loss: 5.7961 - MSE: 5.7961 - MAE: 1.9320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11296/20000 - Train Loss: 0.6867 - Test Loss: 5.7107 - MSE: 5.7107 - MAE: 1.9220\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11297/20000 - Train Loss: 0.6906 - Test Loss: 5.9761 - MSE: 5.9761 - MAE: 1.9514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11298/20000 - Train Loss: 0.6925 - Test Loss: 5.6249 - MSE: 5.6249 - MAE: 1.9112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11299/20000 - Train Loss: 0.6906 - Test Loss: 5.9773 - MSE: 5.9773 - MAE: 1.9516\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 11300/20000 - Train Loss: 0.6869 - Test Loss: 5.6988 - MSE: 5.6988 - MAE: 1.9206\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11301/20000 - Train Loss: 0.6846 - Test Loss: 5.8255 - MSE: 5.8255 - MAE: 1.9355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11302/20000 - Train Loss: 0.6850 - Test Loss: 5.8543 - MSE: 5.8543 - MAE: 1.9387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11303/20000 - Train Loss: 0.6870 - Test Loss: 5.6922 - MSE: 5.6922 - MAE: 1.9199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11304/20000 - Train Loss: 0.6883 - Test Loss: 5.9417 - MSE: 5.9417 - MAE: 1.9480\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11305/20000 - Train Loss: 0.6876 - Test Loss: 5.6786 - MSE: 5.6786 - MAE: 1.9183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11306/20000 - Train Loss: 0.6857 - Test Loss: 5.8848 - MSE: 5.8848 - MAE: 1.9420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11307/20000 - Train Loss: 0.6842 - Test Loss: 5.7712 - MSE: 5.7712 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11308/20000 - Train Loss: 0.6842 - Test Loss: 5.7653 - MSE: 5.7653 - MAE: 1.9287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11309/20000 - Train Loss: 0.6852 - Test Loss: 5.8756 - MSE: 5.8756 - MAE: 1.9411\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11310/20000 - Train Loss: 0.6860 - Test Loss: 5.7010 - MSE: 5.7010 - MAE: 1.9211\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11311/20000 - Train Loss: 0.6857 - Test Loss: 5.8926 - MSE: 5.8926 - MAE: 1.9430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11312/20000 - Train Loss: 0.6847 - Test Loss: 5.7302 - MSE: 5.7302 - MAE: 1.9247\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11313/20000 - Train Loss: 0.6838 - Test Loss: 5.8208 - MSE: 5.8208 - MAE: 1.9351\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11314/20000 - Train Loss: 0.6836 - Test Loss: 5.8118 - MSE: 5.8118 - MAE: 1.9342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11315/20000 - Train Loss: 0.6841 - Test Loss: 5.7430 - MSE: 5.7430 - MAE: 1.9263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11316/20000 - Train Loss: 0.6845 - Test Loss: 5.8657 - MSE: 5.8657 - MAE: 1.9401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11317/20000 - Train Loss: 0.6845 - Test Loss: 5.7244 - MSE: 5.7244 - MAE: 1.9241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11318/20000 - Train Loss: 0.6839 - Test Loss: 5.8470 - MSE: 5.8470 - MAE: 1.9381\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11319/20000 - Train Loss: 0.6834 - Test Loss: 5.7669 - MSE: 5.7669 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11320/20000 - Train Loss: 0.6832 - Test Loss: 5.7859 - MSE: 5.7859 - MAE: 1.9313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11321/20000 - Train Loss: 0.6834 - Test Loss: 5.8242 - MSE: 5.8242 - MAE: 1.9357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11322/20000 - Train Loss: 0.6836 - Test Loss: 5.7426 - MSE: 5.7426 - MAE: 1.9263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11323/20000 - Train Loss: 0.6836 - Test Loss: 5.8438 - MSE: 5.8438 - MAE: 1.9379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11324/20000 - Train Loss: 0.6833 - Test Loss: 5.7471 - MSE: 5.7471 - MAE: 1.9269\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 11325/20000 - Train Loss: 0.6830 - Test Loss: 5.8150 - MSE: 5.8150 - MAE: 1.9347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11326/20000 - Train Loss: 0.6828 - Test Loss: 5.7857 - MSE: 5.7857 - MAE: 1.9314\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11327/20000 - Train Loss: 0.6828 - Test Loss: 5.7713 - MSE: 5.7713 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11328/20000 - Train Loss: 0.6829 - Test Loss: 5.8206 - MSE: 5.8206 - MAE: 1.9354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11329/20000 - Train Loss: 0.6829 - Test Loss: 5.7500 - MSE: 5.7500 - MAE: 1.9273\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 11330/20000 - Train Loss: 0.6828 - Test Loss: 5.8227 - MSE: 5.8227 - MAE: 1.9356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11331/20000 - Train Loss: 0.6826 - Test Loss: 5.7624 - MSE: 5.7624 - MAE: 1.9288\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11332/20000 - Train Loss: 0.6824 - Test Loss: 5.7961 - MSE: 5.7961 - MAE: 1.9327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11333/20000 - Train Loss: 0.6823 - Test Loss: 5.7916 - MSE: 5.7916 - MAE: 1.9322\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11334/20000 - Train Loss: 0.6824 - Test Loss: 5.7671 - MSE: 5.7671 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11335/20000 - Train Loss: 0.6824 - Test Loss: 5.8111 - MSE: 5.8111 - MAE: 1.9344\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11336/20000 - Train Loss: 0.6823 - Test Loss: 5.7577 - MSE: 5.7577 - MAE: 1.9284\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11337/20000 - Train Loss: 0.6822 - Test Loss: 5.8068 - MSE: 5.8068 - MAE: 1.9340\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11338/20000 - Train Loss: 0.6821 - Test Loss: 5.7700 - MSE: 5.7700 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 11339/20000 - Train Loss: 0.6820 - Test Loss: 5.7861 - MSE: 5.7861 - MAE: 1.9317\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11340/20000 - Train Loss: 0.6819 - Test Loss: 5.7902 - MSE: 5.7902 - MAE: 1.9322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11341/20000 - Train Loss: 0.6819 - Test Loss: 5.7672 - MSE: 5.7672 - MAE: 1.9295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11342/20000 - Train Loss: 0.6818 - Test Loss: 5.8012 - MSE: 5.8012 - MAE: 1.9334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11343/20000 - Train Loss: 0.6818 - Test Loss: 5.7626 - MSE: 5.7626 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11344/20000 - Train Loss: 0.6817 - Test Loss: 5.7960 - MSE: 5.7960 - MAE: 1.9329\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11345/20000 - Train Loss: 0.6816 - Test Loss: 5.7722 - MSE: 5.7722 - MAE: 1.9302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11346/20000 - Train Loss: 0.6815 - Test Loss: 5.7809 - MSE: 5.7809 - MAE: 1.9312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11347/20000 - Train Loss: 0.6814 - Test Loss: 5.7858 - MSE: 5.7858 - MAE: 1.9318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11348/20000 - Train Loss: 0.6814 - Test Loss: 5.7681 - MSE: 5.7681 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11349/20000 - Train Loss: 0.6813 - Test Loss: 5.7924 - MSE: 5.7924 - MAE: 1.9326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11350/20000 - Train Loss: 0.6813 - Test Loss: 5.7652 - MSE: 5.7652 - MAE: 1.9295\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11351/20000 - Train Loss: 0.6812 - Test Loss: 5.7884 - MSE: 5.7884 - MAE: 1.9321\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11352/20000 - Train Loss: 0.6811 - Test Loss: 5.7714 - MSE: 5.7714 - MAE: 1.9302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11353/20000 - Train Loss: 0.6810 - Test Loss: 5.7780 - MSE: 5.7780 - MAE: 1.9310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11354/20000 - Train Loss: 0.6810 - Test Loss: 5.7803 - MSE: 5.7803 - MAE: 1.9313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11355/20000 - Train Loss: 0.6809 - Test Loss: 5.7687 - MSE: 5.7687 - MAE: 1.9300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11356/20000 - Train Loss: 0.6809 - Test Loss: 5.7851 - MSE: 5.7851 - MAE: 1.9318\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11357/20000 - Train Loss: 0.6808 - Test Loss: 5.7657 - MSE: 5.7657 - MAE: 1.9296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11358/20000 - Train Loss: 0.6807 - Test Loss: 5.7828 - MSE: 5.7828 - MAE: 1.9316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11359/20000 - Train Loss: 0.6807 - Test Loss: 5.7691 - MSE: 5.7691 - MAE: 1.9301\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11360/20000 - Train Loss: 0.6806 - Test Loss: 5.7757 - MSE: 5.7757 - MAE: 1.9308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11361/20000 - Train Loss: 0.6805 - Test Loss: 5.7750 - MSE: 5.7750 - MAE: 1.9308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11362/20000 - Train Loss: 0.6805 - Test Loss: 5.7686 - MSE: 5.7686 - MAE: 1.9301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11363/20000 - Train Loss: 0.6804 - Test Loss: 5.7787 - MSE: 5.7787 - MAE: 1.9312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11364/20000 - Train Loss: 0.6803 - Test Loss: 5.7654 - MSE: 5.7654 - MAE: 1.9297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11365/20000 - Train Loss: 0.6803 - Test Loss: 5.7779 - MSE: 5.7779 - MAE: 1.9312\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 11366/20000 - Train Loss: 0.6802 - Test Loss: 5.7665 - MSE: 5.7665 - MAE: 1.9299\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11367/20000 - Train Loss: 0.6801 - Test Loss: 5.7735 - MSE: 5.7735 - MAE: 1.9307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11368/20000 - Train Loss: 0.6801 - Test Loss: 5.7698 - MSE: 5.7698 - MAE: 1.9303\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11369/20000 - Train Loss: 0.6800 - Test Loss: 5.7683 - MSE: 5.7683 - MAE: 1.9301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11370/20000 - Train Loss: 0.6799 - Test Loss: 5.7727 - MSE: 5.7727 - MAE: 1.9307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11371/20000 - Train Loss: 0.6799 - Test Loss: 5.7648 - MSE: 5.7648 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11372/20000 - Train Loss: 0.6798 - Test Loss: 5.7731 - MSE: 5.7731 - MAE: 1.9307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11373/20000 - Train Loss: 0.6798 - Test Loss: 5.7640 - MSE: 5.7640 - MAE: 1.9297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11374/20000 - Train Loss: 0.6797 - Test Loss: 5.7709 - MSE: 5.7709 - MAE: 1.9305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11375/20000 - Train Loss: 0.6796 - Test Loss: 5.7654 - MSE: 5.7654 - MAE: 1.9299\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11376/20000 - Train Loss: 0.6796 - Test Loss: 5.7671 - MSE: 5.7671 - MAE: 1.9301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11377/20000 - Train Loss: 0.6795 - Test Loss: 5.7674 - MSE: 5.7674 - MAE: 1.9302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11378/20000 - Train Loss: 0.6794 - Test Loss: 5.7638 - MSE: 5.7638 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11379/20000 - Train Loss: 0.6794 - Test Loss: 5.7683 - MSE: 5.7683 - MAE: 1.9303\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 11380/20000 - Train Loss: 0.6793 - Test Loss: 5.7620 - MSE: 5.7620 - MAE: 1.9296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11381/20000 - Train Loss: 0.6792 - Test Loss: 5.7675 - MSE: 5.7675 - MAE: 1.9302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11382/20000 - Train Loss: 0.6792 - Test Loss: 5.7618 - MSE: 5.7618 - MAE: 1.9296\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11383/20000 - Train Loss: 0.6791 - Test Loss: 5.7653 - MSE: 5.7653 - MAE: 1.9300\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11384/20000 - Train Loss: 0.6790 - Test Loss: 5.7626 - MSE: 5.7626 - MAE: 1.9297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11385/20000 - Train Loss: 0.6790 - Test Loss: 5.7626 - MSE: 5.7626 - MAE: 1.9297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11386/20000 - Train Loss: 0.6789 - Test Loss: 5.7634 - MSE: 5.7634 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11387/20000 - Train Loss: 0.6789 - Test Loss: 5.7603 - MSE: 5.7603 - MAE: 1.9295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11388/20000 - Train Loss: 0.6788 - Test Loss: 5.7634 - MSE: 5.7634 - MAE: 1.9299\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11389/20000 - Train Loss: 0.6787 - Test Loss: 5.7590 - MSE: 5.7590 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11390/20000 - Train Loss: 0.6787 - Test Loss: 5.7624 - MSE: 5.7624 - MAE: 1.9298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11391/20000 - Train Loss: 0.6786 - Test Loss: 5.7587 - MSE: 5.7587 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11392/20000 - Train Loss: 0.6785 - Test Loss: 5.7606 - MSE: 5.7606 - MAE: 1.9296\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11393/20000 - Train Loss: 0.6785 - Test Loss: 5.7589 - MSE: 5.7589 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11394/20000 - Train Loss: 0.6784 - Test Loss: 5.7587 - MSE: 5.7587 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11395/20000 - Train Loss: 0.6783 - Test Loss: 5.7590 - MSE: 5.7590 - MAE: 1.9295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11396/20000 - Train Loss: 0.6783 - Test Loss: 5.7570 - MSE: 5.7570 - MAE: 1.9293\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11397/20000 - Train Loss: 0.6782 - Test Loss: 5.7587 - MSE: 5.7587 - MAE: 1.9295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11398/20000 - Train Loss: 0.6781 - Test Loss: 5.7557 - MSE: 5.7557 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11399/20000 - Train Loss: 0.6781 - Test Loss: 5.7579 - MSE: 5.7579 - MAE: 1.9294\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 11400/20000 - Train Loss: 0.6780 - Test Loss: 5.7550 - MSE: 5.7550 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 11401/20000 - Train Loss: 0.6780 - Test Loss: 5.7566 - MSE: 5.7566 - MAE: 1.9293\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11402/20000 - Train Loss: 0.6779 - Test Loss: 5.7548 - MSE: 5.7548 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11403/20000 - Train Loss: 0.6778 - Test Loss: 5.7550 - MSE: 5.7550 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11404/20000 - Train Loss: 0.6778 - Test Loss: 5.7546 - MSE: 5.7546 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11405/20000 - Train Loss: 0.6777 - Test Loss: 5.7535 - MSE: 5.7535 - MAE: 1.9290\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 11406/20000 - Train Loss: 0.6776 - Test Loss: 5.7542 - MSE: 5.7542 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 44ms/step\n",
      "Epoch 11407/20000 - Train Loss: 0.6776 - Test Loss: 5.7523 - MSE: 5.7523 - MAE: 1.9289\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11408/20000 - Train Loss: 0.6775 - Test Loss: 5.7534 - MSE: 5.7534 - MAE: 1.9290\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 11409/20000 - Train Loss: 0.6774 - Test Loss: 5.7515 - MSE: 5.7515 - MAE: 1.9288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11410/20000 - Train Loss: 0.6774 - Test Loss: 5.7523 - MSE: 5.7523 - MAE: 1.9289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11411/20000 - Train Loss: 0.6773 - Test Loss: 5.7509 - MSE: 5.7509 - MAE: 1.9288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11412/20000 - Train Loss: 0.6772 - Test Loss: 5.7511 - MSE: 5.7511 - MAE: 1.9288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11413/20000 - Train Loss: 0.6772 - Test Loss: 5.7505 - MSE: 5.7505 - MAE: 1.9288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11414/20000 - Train Loss: 0.6771 - Test Loss: 5.7498 - MSE: 5.7498 - MAE: 1.9287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11415/20000 - Train Loss: 0.6771 - Test Loss: 5.7499 - MSE: 5.7499 - MAE: 1.9287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11416/20000 - Train Loss: 0.6770 - Test Loss: 5.7486 - MSE: 5.7486 - MAE: 1.9286\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11417/20000 - Train Loss: 0.6769 - Test Loss: 5.7493 - MSE: 5.7493 - MAE: 1.9287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11418/20000 - Train Loss: 0.6769 - Test Loss: 5.7475 - MSE: 5.7475 - MAE: 1.9285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11419/20000 - Train Loss: 0.6768 - Test Loss: 5.7485 - MSE: 5.7485 - MAE: 1.9286\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 11420/20000 - Train Loss: 0.6767 - Test Loss: 5.7466 - MSE: 5.7466 - MAE: 1.9284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11421/20000 - Train Loss: 0.6767 - Test Loss: 5.7476 - MSE: 5.7476 - MAE: 1.9285\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 11422/20000 - Train Loss: 0.6766 - Test Loss: 5.7459 - MSE: 5.7459 - MAE: 1.9284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11423/20000 - Train Loss: 0.6765 - Test Loss: 5.7465 - MSE: 5.7465 - MAE: 1.9285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11424/20000 - Train Loss: 0.6765 - Test Loss: 5.7452 - MSE: 5.7452 - MAE: 1.9283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11425/20000 - Train Loss: 0.6764 - Test Loss: 5.7455 - MSE: 5.7455 - MAE: 1.9284\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11426/20000 - Train Loss: 0.6764 - Test Loss: 5.7444 - MSE: 5.7444 - MAE: 1.9283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11427/20000 - Train Loss: 0.6763 - Test Loss: 5.7445 - MSE: 5.7445 - MAE: 1.9283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11428/20000 - Train Loss: 0.6762 - Test Loss: 5.7437 - MSE: 5.7437 - MAE: 1.9282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11429/20000 - Train Loss: 0.6762 - Test Loss: 5.7435 - MSE: 5.7435 - MAE: 1.9282\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11430/20000 - Train Loss: 0.6761 - Test Loss: 5.7429 - MSE: 5.7429 - MAE: 1.9281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11431/20000 - Train Loss: 0.6760 - Test Loss: 5.7425 - MSE: 5.7425 - MAE: 1.9281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11432/20000 - Train Loss: 0.6760 - Test Loss: 5.7422 - MSE: 5.7422 - MAE: 1.9281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11433/20000 - Train Loss: 0.6759 - Test Loss: 5.7414 - MSE: 5.7414 - MAE: 1.9280\n",
      "2/2 [==============================] - 0s 975us/step\n",
      "Epoch 11434/20000 - Train Loss: 0.6758 - Test Loss: 5.7414 - MSE: 5.7414 - MAE: 1.9280\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11435/20000 - Train Loss: 0.6758 - Test Loss: 5.7405 - MSE: 5.7405 - MAE: 1.9279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11436/20000 - Train Loss: 0.6757 - Test Loss: 5.7405 - MSE: 5.7405 - MAE: 1.9279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11437/20000 - Train Loss: 0.6757 - Test Loss: 5.7397 - MSE: 5.7397 - MAE: 1.9279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11438/20000 - Train Loss: 0.6756 - Test Loss: 5.7395 - MSE: 5.7395 - MAE: 1.9279\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 11439/20000 - Train Loss: 0.6755 - Test Loss: 5.7389 - MSE: 5.7389 - MAE: 1.9278\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11440/20000 - Train Loss: 0.6755 - Test Loss: 5.7386 - MSE: 5.7386 - MAE: 1.9278\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11441/20000 - Train Loss: 0.6754 - Test Loss: 5.7381 - MSE: 5.7381 - MAE: 1.9277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11442/20000 - Train Loss: 0.6753 - Test Loss: 5.7376 - MSE: 5.7376 - MAE: 1.9277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11443/20000 - Train Loss: 0.6753 - Test Loss: 5.7373 - MSE: 5.7373 - MAE: 1.9277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11444/20000 - Train Loss: 0.6752 - Test Loss: 5.7366 - MSE: 5.7366 - MAE: 1.9276\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11445/20000 - Train Loss: 0.6751 - Test Loss: 5.7365 - MSE: 5.7365 - MAE: 1.9276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11446/20000 - Train Loss: 0.6751 - Test Loss: 5.7357 - MSE: 5.7357 - MAE: 1.9275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11447/20000 - Train Loss: 0.6750 - Test Loss: 5.7356 - MSE: 5.7356 - MAE: 1.9275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11448/20000 - Train Loss: 0.6750 - Test Loss: 5.7349 - MSE: 5.7349 - MAE: 1.9275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11449/20000 - Train Loss: 0.6749 - Test Loss: 5.7347 - MSE: 5.7347 - MAE: 1.9275\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11450/20000 - Train Loss: 0.6748 - Test Loss: 5.7340 - MSE: 5.7340 - MAE: 1.9274\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11451/20000 - Train Loss: 0.6748 - Test Loss: 5.7339 - MSE: 5.7339 - MAE: 1.9274\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11452/20000 - Train Loss: 0.6747 - Test Loss: 5.7331 - MSE: 5.7331 - MAE: 1.9273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11453/20000 - Train Loss: 0.6746 - Test Loss: 5.7330 - MSE: 5.7330 - MAE: 1.9273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11454/20000 - Train Loss: 0.6746 - Test Loss: 5.7322 - MSE: 5.7322 - MAE: 1.9272\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 11455/20000 - Train Loss: 0.6745 - Test Loss: 5.7321 - MSE: 5.7321 - MAE: 1.9272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11456/20000 - Train Loss: 0.6744 - Test Loss: 5.7314 - MSE: 5.7314 - MAE: 1.9272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11457/20000 - Train Loss: 0.6744 - Test Loss: 5.7312 - MSE: 5.7312 - MAE: 1.9272\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11458/20000 - Train Loss: 0.6743 - Test Loss: 5.7305 - MSE: 5.7305 - MAE: 1.9271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11459/20000 - Train Loss: 0.6743 - Test Loss: 5.7302 - MSE: 5.7302 - MAE: 1.9271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11460/20000 - Train Loss: 0.6742 - Test Loss: 5.7297 - MSE: 5.7297 - MAE: 1.9270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11461/20000 - Train Loss: 0.6741 - Test Loss: 5.7293 - MSE: 5.7293 - MAE: 1.9270\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 11462/20000 - Train Loss: 0.6741 - Test Loss: 5.7289 - MSE: 5.7289 - MAE: 1.9270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11463/20000 - Train Loss: 0.6740 - Test Loss: 5.7283 - MSE: 5.7283 - MAE: 1.9269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11464/20000 - Train Loss: 0.6739 - Test Loss: 5.7281 - MSE: 5.7281 - MAE: 1.9269\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11465/20000 - Train Loss: 0.6739 - Test Loss: 5.7274 - MSE: 5.7274 - MAE: 1.9268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11466/20000 - Train Loss: 0.6738 - Test Loss: 5.7272 - MSE: 5.7272 - MAE: 1.9268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11467/20000 - Train Loss: 0.6737 - Test Loss: 5.7265 - MSE: 5.7265 - MAE: 1.9267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11468/20000 - Train Loss: 0.6737 - Test Loss: 5.7264 - MSE: 5.7264 - MAE: 1.9268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11469/20000 - Train Loss: 0.6736 - Test Loss: 5.7255 - MSE: 5.7255 - MAE: 1.9267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11470/20000 - Train Loss: 0.6736 - Test Loss: 5.7256 - MSE: 5.7256 - MAE: 1.9267\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11471/20000 - Train Loss: 0.6735 - Test Loss: 5.7246 - MSE: 5.7246 - MAE: 1.9266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11472/20000 - Train Loss: 0.6734 - Test Loss: 5.7249 - MSE: 5.7249 - MAE: 1.9266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11473/20000 - Train Loss: 0.6734 - Test Loss: 5.7236 - MSE: 5.7236 - MAE: 1.9265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11474/20000 - Train Loss: 0.6733 - Test Loss: 5.7241 - MSE: 5.7241 - MAE: 1.9266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11475/20000 - Train Loss: 0.6732 - Test Loss: 5.7225 - MSE: 5.7225 - MAE: 1.9264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11476/20000 - Train Loss: 0.6732 - Test Loss: 5.7234 - MSE: 5.7234 - MAE: 1.9265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11477/20000 - Train Loss: 0.6731 - Test Loss: 5.7214 - MSE: 5.7214 - MAE: 1.9263\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11478/20000 - Train Loss: 0.6730 - Test Loss: 5.7228 - MSE: 5.7228 - MAE: 1.9265\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 11479/20000 - Train Loss: 0.6730 - Test Loss: 5.7202 - MSE: 5.7202 - MAE: 1.9262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11480/20000 - Train Loss: 0.6729 - Test Loss: 5.7224 - MSE: 5.7224 - MAE: 1.9264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11481/20000 - Train Loss: 0.6729 - Test Loss: 5.7188 - MSE: 5.7188 - MAE: 1.9260\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11482/20000 - Train Loss: 0.6728 - Test Loss: 5.7222 - MSE: 5.7222 - MAE: 1.9264\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11483/20000 - Train Loss: 0.6727 - Test Loss: 5.7171 - MSE: 5.7171 - MAE: 1.9259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11484/20000 - Train Loss: 0.6727 - Test Loss: 5.7223 - MSE: 5.7223 - MAE: 1.9265\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11485/20000 - Train Loss: 0.6726 - Test Loss: 5.7149 - MSE: 5.7149 - MAE: 1.9256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11486/20000 - Train Loss: 0.6725 - Test Loss: 5.7231 - MSE: 5.7231 - MAE: 1.9266\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11487/20000 - Train Loss: 0.6725 - Test Loss: 5.7120 - MSE: 5.7120 - MAE: 1.9253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11488/20000 - Train Loss: 0.6724 - Test Loss: 5.7249 - MSE: 5.7249 - MAE: 1.9268\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11489/20000 - Train Loss: 0.6724 - Test Loss: 5.7077 - MSE: 5.7077 - MAE: 1.9249\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11490/20000 - Train Loss: 0.6723 - Test Loss: 5.7283 - MSE: 5.7283 - MAE: 1.9272\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11491/20000 - Train Loss: 0.6723 - Test Loss: 5.7015 - MSE: 5.7015 - MAE: 1.9241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11492/20000 - Train Loss: 0.6722 - Test Loss: 5.7345 - MSE: 5.7345 - MAE: 1.9280\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11493/20000 - Train Loss: 0.6722 - Test Loss: 5.6918 - MSE: 5.6918 - MAE: 1.9230\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 11494/20000 - Train Loss: 0.6722 - Test Loss: 5.7452 - MSE: 5.7452 - MAE: 1.9292\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11495/20000 - Train Loss: 0.6723 - Test Loss: 5.6766 - MSE: 5.6766 - MAE: 1.9213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11496/20000 - Train Loss: 0.6725 - Test Loss: 5.7639 - MSE: 5.7639 - MAE: 1.9313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11497/20000 - Train Loss: 0.6727 - Test Loss: 5.6520 - MSE: 5.6520 - MAE: 1.9184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11498/20000 - Train Loss: 0.6733 - Test Loss: 5.7963 - MSE: 5.7963 - MAE: 1.9349\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11499/20000 - Train Loss: 0.6742 - Test Loss: 5.6125 - MSE: 5.6125 - MAE: 1.9135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11500/20000 - Train Loss: 0.6757 - Test Loss: 5.8526 - MSE: 5.8526 - MAE: 1.9410\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11501/20000 - Train Loss: 0.6783 - Test Loss: 5.5506 - MSE: 5.5506 - MAE: 1.9056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11502/20000 - Train Loss: 0.6825 - Test Loss: 5.9484 - MSE: 5.9484 - MAE: 1.9508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11503/20000 - Train Loss: 0.6889 - Test Loss: 5.4615 - MSE: 5.4615 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11504/20000 - Train Loss: 0.6981 - Test Loss: 6.0959 - MSE: 6.0959 - MAE: 1.9674\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11505/20000 - Train Loss: 0.7093 - Test Loss: 5.3617 - MSE: 5.3617 - MAE: 1.8781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11506/20000 - Train Loss: 0.7195 - Test Loss: 6.2475 - MSE: 6.2475 - MAE: 1.9849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11507/20000 - Train Loss: 0.7224 - Test Loss: 5.3162 - MSE: 5.3162 - MAE: 1.8704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11508/20000 - Train Loss: 0.7126 - Test Loss: 6.2022 - MSE: 6.2022 - MAE: 1.9799\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11509/20000 - Train Loss: 0.6928 - Test Loss: 5.4339 - MSE: 5.4339 - MAE: 1.8894\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11510/20000 - Train Loss: 0.6754 - Test Loss: 5.8538 - MSE: 5.8538 - MAE: 1.9412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11511/20000 - Train Loss: 0.6715 - Test Loss: 5.7537 - MSE: 5.7537 - MAE: 1.9303\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11512/20000 - Train Loss: 0.6801 - Test Loss: 5.5209 - MSE: 5.5209 - MAE: 1.9018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11513/20000 - Train Loss: 0.6907 - Test Loss: 6.0335 - MSE: 6.0335 - MAE: 1.9600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11514/20000 - Train Loss: 0.6924 - Test Loss: 5.4325 - MSE: 5.4325 - MAE: 1.8893\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11515/20000 - Train Loss: 0.6839 - Test Loss: 5.9671 - MSE: 5.9671 - MAE: 1.9527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11516/20000 - Train Loss: 0.6736 - Test Loss: 5.5978 - MSE: 5.5978 - MAE: 1.9119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11517/20000 - Train Loss: 0.6709 - Test Loss: 5.6715 - MSE: 5.6715 - MAE: 1.9209\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11518/20000 - Train Loss: 0.6762 - Test Loss: 5.8703 - MSE: 5.8703 - MAE: 1.9429\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11519/20000 - Train Loss: 0.6818 - Test Loss: 5.5003 - MSE: 5.5003 - MAE: 1.8991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11520/20000 - Train Loss: 0.6811 - Test Loss: 5.9373 - MSE: 5.9373 - MAE: 1.9498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11521/20000 - Train Loss: 0.6753 - Test Loss: 5.5654 - MSE: 5.5654 - MAE: 1.9078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11522/20000 - Train Loss: 0.6707 - Test Loss: 5.7421 - MSE: 5.7421 - MAE: 1.9291\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11523/20000 - Train Loss: 0.6714 - Test Loss: 5.7753 - MSE: 5.7753 - MAE: 1.9328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11524/20000 - Train Loss: 0.6752 - Test Loss: 5.5635 - MSE: 5.5635 - MAE: 1.9076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11525/20000 - Train Loss: 0.6768 - Test Loss: 5.8830 - MSE: 5.8830 - MAE: 1.9443\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11526/20000 - Train Loss: 0.6745 - Test Loss: 5.5704 - MSE: 5.5704 - MAE: 1.9086\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11527/20000 - Train Loss: 0.6711 - Test Loss: 5.7689 - MSE: 5.7689 - MAE: 1.9322\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11528/20000 - Train Loss: 0.6701 - Test Loss: 5.7211 - MSE: 5.7211 - MAE: 1.9268\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11529/20000 - Train Loss: 0.6719 - Test Loss: 5.6125 - MSE: 5.6125 - MAE: 1.9139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11530/20000 - Train Loss: 0.6736 - Test Loss: 5.8325 - MSE: 5.8325 - MAE: 1.9391\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 11531/20000 - Train Loss: 0.6731 - Test Loss: 5.5865 - MSE: 5.5865 - MAE: 1.9107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11532/20000 - Train Loss: 0.6710 - Test Loss: 5.7750 - MSE: 5.7750 - MAE: 1.9329\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11533/20000 - Train Loss: 0.6698 - Test Loss: 5.6892 - MSE: 5.6892 - MAE: 1.9232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11534/20000 - Train Loss: 0.6703 - Test Loss: 5.6491 - MSE: 5.6491 - MAE: 1.9184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11535/20000 - Train Loss: 0.6715 - Test Loss: 5.7902 - MSE: 5.7902 - MAE: 1.9346\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11536/20000 - Train Loss: 0.6717 - Test Loss: 5.6055 - MSE: 5.6055 - MAE: 1.9131\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11537/20000 - Train Loss: 0.6707 - Test Loss: 5.7710 - MSE: 5.7710 - MAE: 1.9325\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11538/20000 - Train Loss: 0.6696 - Test Loss: 5.6700 - MSE: 5.6700 - MAE: 1.9210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11539/20000 - Train Loss: 0.6695 - Test Loss: 5.6759 - MSE: 5.6759 - MAE: 1.9217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11540/20000 - Train Loss: 0.6701 - Test Loss: 5.7555 - MSE: 5.7555 - MAE: 1.9308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11541/20000 - Train Loss: 0.6705 - Test Loss: 5.6247 - MSE: 5.6247 - MAE: 1.9156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11542/20000 - Train Loss: 0.6702 - Test Loss: 5.7614 - MSE: 5.7614 - MAE: 1.9314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11543/20000 - Train Loss: 0.6695 - Test Loss: 5.6593 - MSE: 5.6593 - MAE: 1.9198\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11544/20000 - Train Loss: 0.6691 - Test Loss: 5.6949 - MSE: 5.6949 - MAE: 1.9239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11545/20000 - Train Loss: 0.6693 - Test Loss: 5.7275 - MSE: 5.7275 - MAE: 1.9277\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11546/20000 - Train Loss: 0.6697 - Test Loss: 5.6429 - MSE: 5.6429 - MAE: 1.9178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11547/20000 - Train Loss: 0.6696 - Test Loss: 5.7486 - MSE: 5.7486 - MAE: 1.9301\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11548/20000 - Train Loss: 0.6693 - Test Loss: 5.6547 - MSE: 5.6547 - MAE: 1.9193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11549/20000 - Train Loss: 0.6689 - Test Loss: 5.7071 - MSE: 5.7071 - MAE: 1.9254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11550/20000 - Train Loss: 0.6689 - Test Loss: 5.7053 - MSE: 5.7053 - MAE: 1.9252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11551/20000 - Train Loss: 0.6690 - Test Loss: 5.6595 - MSE: 5.6595 - MAE: 1.9199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11552/20000 - Train Loss: 0.6691 - Test Loss: 5.7339 - MSE: 5.7339 - MAE: 1.9285\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11553/20000 - Train Loss: 0.6690 - Test Loss: 5.6549 - MSE: 5.6549 - MAE: 1.9193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11554/20000 - Train Loss: 0.6687 - Test Loss: 5.7131 - MSE: 5.7131 - MAE: 1.9261\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11555/20000 - Train Loss: 0.6685 - Test Loss: 5.6885 - MSE: 5.6885 - MAE: 1.9233\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11556/20000 - Train Loss: 0.6685 - Test Loss: 5.6739 - MSE: 5.6739 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11557/20000 - Train Loss: 0.6686 - Test Loss: 5.7185 - MSE: 5.7185 - MAE: 1.9268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11558/20000 - Train Loss: 0.6686 - Test Loss: 5.6588 - MSE: 5.6588 - MAE: 1.9198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11559/20000 - Train Loss: 0.6685 - Test Loss: 5.7138 - MSE: 5.7138 - MAE: 1.9262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11560/20000 - Train Loss: 0.6683 - Test Loss: 5.6770 - MSE: 5.6770 - MAE: 1.9220\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 11561/20000 - Train Loss: 0.6682 - Test Loss: 5.6853 - MSE: 5.6853 - MAE: 1.9230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11562/20000 - Train Loss: 0.6682 - Test Loss: 5.7035 - MSE: 5.7035 - MAE: 1.9251\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11563/20000 - Train Loss: 0.6682 - Test Loss: 5.6654 - MSE: 5.6654 - MAE: 1.9207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11564/20000 - Train Loss: 0.6682 - Test Loss: 5.7098 - MSE: 5.7098 - MAE: 1.9258\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11565/20000 - Train Loss: 0.6680 - Test Loss: 5.6706 - MSE: 5.6706 - MAE: 1.9213\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11566/20000 - Train Loss: 0.6679 - Test Loss: 5.6927 - MSE: 5.6927 - MAE: 1.9239\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11567/20000 - Train Loss: 0.6679 - Test Loss: 5.6904 - MSE: 5.6904 - MAE: 1.9236\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11568/20000 - Train Loss: 0.6679 - Test Loss: 5.6728 - MSE: 5.6728 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11569/20000 - Train Loss: 0.6678 - Test Loss: 5.7023 - MSE: 5.7023 - MAE: 1.9250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11570/20000 - Train Loss: 0.6678 - Test Loss: 5.6688 - MSE: 5.6688 - MAE: 1.9211\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11571/20000 - Train Loss: 0.6677 - Test Loss: 5.6957 - MSE: 5.6957 - MAE: 1.9243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11572/20000 - Train Loss: 0.6676 - Test Loss: 5.6804 - MSE: 5.6804 - MAE: 1.9225\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11573/20000 - Train Loss: 0.6676 - Test Loss: 5.6798 - MSE: 5.6798 - MAE: 1.9224\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11574/20000 - Train Loss: 0.6675 - Test Loss: 5.6932 - MSE: 5.6932 - MAE: 1.9240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11575/20000 - Train Loss: 0.6675 - Test Loss: 5.6705 - MSE: 5.6705 - MAE: 1.9214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11576/20000 - Train Loss: 0.6674 - Test Loss: 5.6944 - MSE: 5.6944 - MAE: 1.9242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11577/20000 - Train Loss: 0.6673 - Test Loss: 5.6741 - MSE: 5.6741 - MAE: 1.9218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11578/20000 - Train Loss: 0.6673 - Test Loss: 5.6846 - MSE: 5.6846 - MAE: 1.9230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11579/20000 - Train Loss: 0.6672 - Test Loss: 5.6841 - MSE: 5.6841 - MAE: 1.9230\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11580/20000 - Train Loss: 0.6672 - Test Loss: 5.6741 - MSE: 5.6741 - MAE: 1.9218\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11581/20000 - Train Loss: 0.6671 - Test Loss: 5.6897 - MSE: 5.6897 - MAE: 1.9237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11582/20000 - Train Loss: 0.6671 - Test Loss: 5.6716 - MSE: 5.6716 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11583/20000 - Train Loss: 0.6670 - Test Loss: 5.6862 - MSE: 5.6862 - MAE: 1.9233\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 11584/20000 - Train Loss: 0.6669 - Test Loss: 5.6769 - MSE: 5.6769 - MAE: 1.9222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11585/20000 - Train Loss: 0.6669 - Test Loss: 5.6778 - MSE: 5.6778 - MAE: 1.9223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11586/20000 - Train Loss: 0.6668 - Test Loss: 5.6833 - MSE: 5.6833 - MAE: 1.9230\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11587/20000 - Train Loss: 0.6668 - Test Loss: 5.6720 - MSE: 5.6720 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11588/20000 - Train Loss: 0.6667 - Test Loss: 5.6846 - MSE: 5.6846 - MAE: 1.9231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11589/20000 - Train Loss: 0.6667 - Test Loss: 5.6724 - MSE: 5.6724 - MAE: 1.9217\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 11590/20000 - Train Loss: 0.6666 - Test Loss: 5.6800 - MSE: 5.6800 - MAE: 1.9226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11591/20000 - Train Loss: 0.6666 - Test Loss: 5.6769 - MSE: 5.6769 - MAE: 1.9223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11592/20000 - Train Loss: 0.6665 - Test Loss: 5.6739 - MSE: 5.6739 - MAE: 1.9219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11593/20000 - Train Loss: 0.6665 - Test Loss: 5.6804 - MSE: 5.6804 - MAE: 1.9227\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11594/20000 - Train Loss: 0.6664 - Test Loss: 5.6708 - MSE: 5.6708 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11595/20000 - Train Loss: 0.6663 - Test Loss: 5.6796 - MSE: 5.6796 - MAE: 1.9226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11596/20000 - Train Loss: 0.6663 - Test Loss: 5.6721 - MSE: 5.6721 - MAE: 1.9217\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11597/20000 - Train Loss: 0.6662 - Test Loss: 5.6755 - MSE: 5.6755 - MAE: 1.9221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11598/20000 - Train Loss: 0.6662 - Test Loss: 5.6751 - MSE: 5.6751 - MAE: 1.9221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11599/20000 - Train Loss: 0.6661 - Test Loss: 5.6713 - MSE: 5.6713 - MAE: 1.9217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11600/20000 - Train Loss: 0.6661 - Test Loss: 5.6767 - MSE: 5.6767 - MAE: 1.9223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11601/20000 - Train Loss: 0.6660 - Test Loss: 5.6696 - MSE: 5.6696 - MAE: 1.9215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11602/20000 - Train Loss: 0.6660 - Test Loss: 5.6754 - MSE: 5.6754 - MAE: 1.9222\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11603/20000 - Train Loss: 0.6659 - Test Loss: 5.6707 - MSE: 5.6707 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 982us/step\n",
      "Epoch 11604/20000 - Train Loss: 0.6658 - Test Loss: 5.6720 - MSE: 5.6720 - MAE: 1.9218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11605/20000 - Train Loss: 0.6658 - Test Loss: 5.6726 - MSE: 5.6726 - MAE: 1.9219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11606/20000 - Train Loss: 0.6657 - Test Loss: 5.6691 - MSE: 5.6691 - MAE: 1.9215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11607/20000 - Train Loss: 0.6657 - Test Loss: 5.6731 - MSE: 5.6731 - MAE: 1.9219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11608/20000 - Train Loss: 0.6656 - Test Loss: 5.6680 - MSE: 5.6680 - MAE: 1.9214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11609/20000 - Train Loss: 0.6656 - Test Loss: 5.6718 - MSE: 5.6718 - MAE: 1.9218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11610/20000 - Train Loss: 0.6655 - Test Loss: 5.6686 - MSE: 5.6686 - MAE: 1.9214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11611/20000 - Train Loss: 0.6655 - Test Loss: 5.6693 - MSE: 5.6693 - MAE: 1.9215\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11612/20000 - Train Loss: 0.6654 - Test Loss: 5.6696 - MSE: 5.6696 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11613/20000 - Train Loss: 0.6653 - Test Loss: 5.6670 - MSE: 5.6670 - MAE: 1.9213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11614/20000 - Train Loss: 0.6653 - Test Loss: 5.6698 - MSE: 5.6698 - MAE: 1.9216\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11615/20000 - Train Loss: 0.6652 - Test Loss: 5.6659 - MSE: 5.6659 - MAE: 1.9212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11616/20000 - Train Loss: 0.6652 - Test Loss: 5.6686 - MSE: 5.6686 - MAE: 1.9215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11617/20000 - Train Loss: 0.6651 - Test Loss: 5.6661 - MSE: 5.6661 - MAE: 1.9212\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11618/20000 - Train Loss: 0.6651 - Test Loss: 5.6666 - MSE: 5.6666 - MAE: 1.9213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11619/20000 - Train Loss: 0.6650 - Test Loss: 5.6667 - MSE: 5.6667 - MAE: 1.9213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11620/20000 - Train Loss: 0.6650 - Test Loss: 5.6647 - MSE: 5.6647 - MAE: 1.9211\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11621/20000 - Train Loss: 0.6649 - Test Loss: 5.6667 - MSE: 5.6667 - MAE: 1.9213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11622/20000 - Train Loss: 0.6649 - Test Loss: 5.6637 - MSE: 5.6637 - MAE: 1.9210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11623/20000 - Train Loss: 0.6648 - Test Loss: 5.6656 - MSE: 5.6656 - MAE: 1.9212\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 11624/20000 - Train Loss: 0.6647 - Test Loss: 5.6636 - MSE: 5.6636 - MAE: 1.9210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11625/20000 - Train Loss: 0.6647 - Test Loss: 5.6640 - MSE: 5.6640 - MAE: 1.9210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11626/20000 - Train Loss: 0.6646 - Test Loss: 5.6638 - MSE: 5.6638 - MAE: 1.9210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11627/20000 - Train Loss: 0.6646 - Test Loss: 5.6623 - MSE: 5.6623 - MAE: 1.9208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11628/20000 - Train Loss: 0.6645 - Test Loss: 5.6637 - MSE: 5.6637 - MAE: 1.9210\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 11629/20000 - Train Loss: 0.6645 - Test Loss: 5.6612 - MSE: 5.6612 - MAE: 1.9207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11630/20000 - Train Loss: 0.6644 - Test Loss: 5.6629 - MSE: 5.6629 - MAE: 1.9209\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11631/20000 - Train Loss: 0.6644 - Test Loss: 5.6608 - MSE: 5.6608 - MAE: 1.9207\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11632/20000 - Train Loss: 0.6643 - Test Loss: 5.6616 - MSE: 5.6616 - MAE: 1.9208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11633/20000 - Train Loss: 0.6643 - Test Loss: 5.6606 - MSE: 5.6606 - MAE: 1.9207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11634/20000 - Train Loss: 0.6642 - Test Loss: 5.6602 - MSE: 5.6602 - MAE: 1.9206\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11635/20000 - Train Loss: 0.6641 - Test Loss: 5.6604 - MSE: 5.6604 - MAE: 1.9207\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11636/20000 - Train Loss: 0.6641 - Test Loss: 5.6591 - MSE: 5.6591 - MAE: 1.9205\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 11637/20000 - Train Loss: 0.6640 - Test Loss: 5.6598 - MSE: 5.6598 - MAE: 1.9206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11638/20000 - Train Loss: 0.6640 - Test Loss: 5.6584 - MSE: 5.6584 - MAE: 1.9204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11639/20000 - Train Loss: 0.6639 - Test Loss: 5.6588 - MSE: 5.6588 - MAE: 1.9205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11640/20000 - Train Loss: 0.6639 - Test Loss: 5.6580 - MSE: 5.6580 - MAE: 1.9204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11641/20000 - Train Loss: 0.6638 - Test Loss: 5.6576 - MSE: 5.6576 - MAE: 1.9204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11642/20000 - Train Loss: 0.6638 - Test Loss: 5.6576 - MSE: 5.6576 - MAE: 1.9204\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11643/20000 - Train Loss: 0.6637 - Test Loss: 5.6565 - MSE: 5.6565 - MAE: 1.9203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11644/20000 - Train Loss: 0.6636 - Test Loss: 5.6571 - MSE: 5.6571 - MAE: 1.9203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11645/20000 - Train Loss: 0.6636 - Test Loss: 5.6556 - MSE: 5.6556 - MAE: 1.9202\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 11646/20000 - Train Loss: 0.6635 - Test Loss: 5.6563 - MSE: 5.6563 - MAE: 1.9203\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11647/20000 - Train Loss: 0.6635 - Test Loss: 5.6550 - MSE: 5.6550 - MAE: 1.9201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11648/20000 - Train Loss: 0.6634 - Test Loss: 5.6553 - MSE: 5.6553 - MAE: 1.9202\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11649/20000 - Train Loss: 0.6634 - Test Loss: 5.6546 - MSE: 5.6546 - MAE: 1.9201\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11650/20000 - Train Loss: 0.6633 - Test Loss: 5.6541 - MSE: 5.6541 - MAE: 1.9200\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11651/20000 - Train Loss: 0.6633 - Test Loss: 5.6542 - MSE: 5.6542 - MAE: 1.9201\n",
      "2/2 [==============================] - 0s 981us/step\n",
      "Epoch 11652/20000 - Train Loss: 0.6632 - Test Loss: 5.6531 - MSE: 5.6531 - MAE: 1.9199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11653/20000 - Train Loss: 0.6632 - Test Loss: 5.6537 - MSE: 5.6537 - MAE: 1.9200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11654/20000 - Train Loss: 0.6631 - Test Loss: 5.6522 - MSE: 5.6522 - MAE: 1.9198\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11655/20000 - Train Loss: 0.6630 - Test Loss: 5.6528 - MSE: 5.6528 - MAE: 1.9199\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11656/20000 - Train Loss: 0.6630 - Test Loss: 5.6517 - MSE: 5.6517 - MAE: 1.9198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11657/20000 - Train Loss: 0.6629 - Test Loss: 5.6518 - MSE: 5.6518 - MAE: 1.9198\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11658/20000 - Train Loss: 0.6629 - Test Loss: 5.6512 - MSE: 5.6512 - MAE: 1.9197\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11659/20000 - Train Loss: 0.6628 - Test Loss: 5.6507 - MSE: 5.6507 - MAE: 1.9197\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11660/20000 - Train Loss: 0.6628 - Test Loss: 5.6507 - MSE: 5.6507 - MAE: 1.9197\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11661/20000 - Train Loss: 0.6627 - Test Loss: 5.6499 - MSE: 5.6499 - MAE: 1.9196\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11662/20000 - Train Loss: 0.6627 - Test Loss: 5.6499 - MSE: 5.6499 - MAE: 1.9196\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11663/20000 - Train Loss: 0.6626 - Test Loss: 5.6491 - MSE: 5.6491 - MAE: 1.9195\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11664/20000 - Train Loss: 0.6626 - Test Loss: 5.6492 - MSE: 5.6492 - MAE: 1.9195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11665/20000 - Train Loss: 0.6625 - Test Loss: 5.6484 - MSE: 5.6484 - MAE: 1.9195\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11666/20000 - Train Loss: 0.6624 - Test Loss: 5.6483 - MSE: 5.6483 - MAE: 1.9195\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11667/20000 - Train Loss: 0.6624 - Test Loss: 5.6477 - MSE: 5.6477 - MAE: 1.9194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11668/20000 - Train Loss: 0.6623 - Test Loss: 5.6474 - MSE: 5.6474 - MAE: 1.9194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11669/20000 - Train Loss: 0.6623 - Test Loss: 5.6471 - MSE: 5.6471 - MAE: 1.9193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11670/20000 - Train Loss: 0.6622 - Test Loss: 5.6465 - MSE: 5.6465 - MAE: 1.9193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11671/20000 - Train Loss: 0.6622 - Test Loss: 5.6464 - MSE: 5.6464 - MAE: 1.9193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11672/20000 - Train Loss: 0.6621 - Test Loss: 5.6457 - MSE: 5.6457 - MAE: 1.9192\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11673/20000 - Train Loss: 0.6621 - Test Loss: 5.6457 - MSE: 5.6457 - MAE: 1.9192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11674/20000 - Train Loss: 0.6620 - Test Loss: 5.6450 - MSE: 5.6450 - MAE: 1.9191\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11675/20000 - Train Loss: 0.6620 - Test Loss: 5.6448 - MSE: 5.6448 - MAE: 1.9191\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11676/20000 - Train Loss: 0.6619 - Test Loss: 5.6443 - MSE: 5.6443 - MAE: 1.9190\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11677/20000 - Train Loss: 0.6618 - Test Loss: 5.6440 - MSE: 5.6440 - MAE: 1.9190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11678/20000 - Train Loss: 0.6618 - Test Loss: 5.6436 - MSE: 5.6436 - MAE: 1.9190\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11679/20000 - Train Loss: 0.6617 - Test Loss: 5.6432 - MSE: 5.6432 - MAE: 1.9189\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11680/20000 - Train Loss: 0.6617 - Test Loss: 5.6428 - MSE: 5.6428 - MAE: 1.9189\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11681/20000 - Train Loss: 0.6616 - Test Loss: 5.6424 - MSE: 5.6424 - MAE: 1.9189\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11682/20000 - Train Loss: 0.6616 - Test Loss: 5.6421 - MSE: 5.6421 - MAE: 1.9188\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11683/20000 - Train Loss: 0.6615 - Test Loss: 5.6417 - MSE: 5.6417 - MAE: 1.9188\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11684/20000 - Train Loss: 0.6615 - Test Loss: 5.6413 - MSE: 5.6413 - MAE: 1.9187\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11685/20000 - Train Loss: 0.6614 - Test Loss: 5.6409 - MSE: 5.6409 - MAE: 1.9187\n",
      "2/2 [==============================] - 0s 984us/step\n",
      "Epoch 11686/20000 - Train Loss: 0.6614 - Test Loss: 5.6406 - MSE: 5.6406 - MAE: 1.9187\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11687/20000 - Train Loss: 0.6613 - Test Loss: 5.6401 - MSE: 5.6401 - MAE: 1.9186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11688/20000 - Train Loss: 0.6612 - Test Loss: 5.6399 - MSE: 5.6399 - MAE: 1.9186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11689/20000 - Train Loss: 0.6612 - Test Loss: 5.6393 - MSE: 5.6393 - MAE: 1.9185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11690/20000 - Train Loss: 0.6611 - Test Loss: 5.6392 - MSE: 5.6392 - MAE: 1.9185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11691/20000 - Train Loss: 0.6611 - Test Loss: 5.6385 - MSE: 5.6385 - MAE: 1.9185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11692/20000 - Train Loss: 0.6610 - Test Loss: 5.6384 - MSE: 5.6384 - MAE: 1.9185\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11693/20000 - Train Loss: 0.6610 - Test Loss: 5.6377 - MSE: 5.6377 - MAE: 1.9184\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11694/20000 - Train Loss: 0.6609 - Test Loss: 5.6376 - MSE: 5.6376 - MAE: 1.9184\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 11695/20000 - Train Loss: 0.6609 - Test Loss: 5.6370 - MSE: 5.6370 - MAE: 1.9183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11696/20000 - Train Loss: 0.6608 - Test Loss: 5.6369 - MSE: 5.6369 - MAE: 1.9183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11697/20000 - Train Loss: 0.6608 - Test Loss: 5.6363 - MSE: 5.6363 - MAE: 1.9182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11698/20000 - Train Loss: 0.6607 - Test Loss: 5.6360 - MSE: 5.6360 - MAE: 1.9182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11699/20000 - Train Loss: 0.6606 - Test Loss: 5.6356 - MSE: 5.6356 - MAE: 1.9182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11700/20000 - Train Loss: 0.6606 - Test Loss: 5.6352 - MSE: 5.6352 - MAE: 1.9181\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11701/20000 - Train Loss: 0.6605 - Test Loss: 5.6349 - MSE: 5.6349 - MAE: 1.9181\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11702/20000 - Train Loss: 0.6605 - Test Loss: 5.6343 - MSE: 5.6343 - MAE: 1.9180\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11703/20000 - Train Loss: 0.6604 - Test Loss: 5.6343 - MSE: 5.6343 - MAE: 1.9180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11704/20000 - Train Loss: 0.6604 - Test Loss: 5.6334 - MSE: 5.6334 - MAE: 1.9179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11705/20000 - Train Loss: 0.6603 - Test Loss: 5.6336 - MSE: 5.6336 - MAE: 1.9180\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11706/20000 - Train Loss: 0.6603 - Test Loss: 5.6326 - MSE: 5.6326 - MAE: 1.9178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11707/20000 - Train Loss: 0.6602 - Test Loss: 5.6329 - MSE: 5.6329 - MAE: 1.9179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11708/20000 - Train Loss: 0.6602 - Test Loss: 5.6318 - MSE: 5.6318 - MAE: 1.9178\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 11709/20000 - Train Loss: 0.6601 - Test Loss: 5.6322 - MSE: 5.6322 - MAE: 1.9178\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11710/20000 - Train Loss: 0.6600 - Test Loss: 5.6310 - MSE: 5.6310 - MAE: 1.9177\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11711/20000 - Train Loss: 0.6600 - Test Loss: 5.6314 - MSE: 5.6314 - MAE: 1.9177\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11712/20000 - Train Loss: 0.6599 - Test Loss: 5.6302 - MSE: 5.6302 - MAE: 1.9176\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11713/20000 - Train Loss: 0.6599 - Test Loss: 5.6307 - MSE: 5.6307 - MAE: 1.9177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11714/20000 - Train Loss: 0.6598 - Test Loss: 5.6294 - MSE: 5.6294 - MAE: 1.9175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11715/20000 - Train Loss: 0.6598 - Test Loss: 5.6300 - MSE: 5.6300 - MAE: 1.9176\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11716/20000 - Train Loss: 0.6597 - Test Loss: 5.6286 - MSE: 5.6286 - MAE: 1.9174\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11717/20000 - Train Loss: 0.6597 - Test Loss: 5.6293 - MSE: 5.6293 - MAE: 1.9175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11718/20000 - Train Loss: 0.6596 - Test Loss: 5.6278 - MSE: 5.6278 - MAE: 1.9173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11719/20000 - Train Loss: 0.6596 - Test Loss: 5.6285 - MSE: 5.6285 - MAE: 1.9174\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11720/20000 - Train Loss: 0.6595 - Test Loss: 5.6271 - MSE: 5.6271 - MAE: 1.9173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11721/20000 - Train Loss: 0.6594 - Test Loss: 5.6277 - MSE: 5.6277 - MAE: 1.9173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11722/20000 - Train Loss: 0.6594 - Test Loss: 5.6263 - MSE: 5.6263 - MAE: 1.9172\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11723/20000 - Train Loss: 0.6593 - Test Loss: 5.6269 - MSE: 5.6269 - MAE: 1.9173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11724/20000 - Train Loss: 0.6593 - Test Loss: 5.6255 - MSE: 5.6255 - MAE: 1.9171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11725/20000 - Train Loss: 0.6592 - Test Loss: 5.6262 - MSE: 5.6262 - MAE: 1.9172\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11726/20000 - Train Loss: 0.6592 - Test Loss: 5.6247 - MSE: 5.6247 - MAE: 1.9170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11727/20000 - Train Loss: 0.6591 - Test Loss: 5.6255 - MSE: 5.6255 - MAE: 1.9171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11728/20000 - Train Loss: 0.6591 - Test Loss: 5.6239 - MSE: 5.6239 - MAE: 1.9169\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11729/20000 - Train Loss: 0.6590 - Test Loss: 5.6248 - MSE: 5.6248 - MAE: 1.9170\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11730/20000 - Train Loss: 0.6590 - Test Loss: 5.6230 - MSE: 5.6230 - MAE: 1.9168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11731/20000 - Train Loss: 0.6589 - Test Loss: 5.6242 - MSE: 5.6242 - MAE: 1.9170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11732/20000 - Train Loss: 0.6589 - Test Loss: 5.6221 - MSE: 5.6221 - MAE: 1.9167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11733/20000 - Train Loss: 0.6588 - Test Loss: 5.6237 - MSE: 5.6237 - MAE: 1.9169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11734/20000 - Train Loss: 0.6587 - Test Loss: 5.6211 - MSE: 5.6211 - MAE: 1.9166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11735/20000 - Train Loss: 0.6587 - Test Loss: 5.6232 - MSE: 5.6232 - MAE: 1.9169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11736/20000 - Train Loss: 0.6586 - Test Loss: 5.6200 - MSE: 5.6200 - MAE: 1.9165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11737/20000 - Train Loss: 0.6586 - Test Loss: 5.6229 - MSE: 5.6229 - MAE: 1.9169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11738/20000 - Train Loss: 0.6585 - Test Loss: 5.6185 - MSE: 5.6185 - MAE: 1.9163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11739/20000 - Train Loss: 0.6585 - Test Loss: 5.6229 - MSE: 5.6229 - MAE: 1.9169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11740/20000 - Train Loss: 0.6584 - Test Loss: 5.6169 - MSE: 5.6169 - MAE: 1.9162\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11741/20000 - Train Loss: 0.6584 - Test Loss: 5.6233 - MSE: 5.6233 - MAE: 1.9169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11742/20000 - Train Loss: 0.6583 - Test Loss: 5.6148 - MSE: 5.6148 - MAE: 1.9159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11743/20000 - Train Loss: 0.6583 - Test Loss: 5.6241 - MSE: 5.6241 - MAE: 1.9170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11744/20000 - Train Loss: 0.6582 - Test Loss: 5.6122 - MSE: 5.6121 - MAE: 1.9156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11745/20000 - Train Loss: 0.6582 - Test Loss: 5.6257 - MSE: 5.6257 - MAE: 1.9172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11746/20000 - Train Loss: 0.6581 - Test Loss: 5.6084 - MSE: 5.6084 - MAE: 1.9152\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11747/20000 - Train Loss: 0.6581 - Test Loss: 5.6286 - MSE: 5.6286 - MAE: 1.9176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11748/20000 - Train Loss: 0.6580 - Test Loss: 5.6031 - MSE: 5.6031 - MAE: 1.9146\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11749/20000 - Train Loss: 0.6580 - Test Loss: 5.6337 - MSE: 5.6337 - MAE: 1.9182\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11750/20000 - Train Loss: 0.6580 - Test Loss: 5.5953 - MSE: 5.5953 - MAE: 1.9136\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11751/20000 - Train Loss: 0.6580 - Test Loss: 5.6421 - MSE: 5.6421 - MAE: 1.9191\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11752/20000 - Train Loss: 0.6580 - Test Loss: 5.5834 - MSE: 5.5834 - MAE: 1.9122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11753/20000 - Train Loss: 0.6581 - Test Loss: 5.6559 - MSE: 5.6559 - MAE: 1.9207\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11754/20000 - Train Loss: 0.6583 - Test Loss: 5.5652 - MSE: 5.5652 - MAE: 1.9100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11755/20000 - Train Loss: 0.6585 - Test Loss: 5.6789 - MSE: 5.6789 - MAE: 1.9233\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11756/20000 - Train Loss: 0.6590 - Test Loss: 5.5369 - MSE: 5.5369 - MAE: 1.9065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11757/20000 - Train Loss: 0.6598 - Test Loss: 5.7170 - MSE: 5.7170 - MAE: 1.9276\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11758/20000 - Train Loss: 0.6612 - Test Loss: 5.4934 - MSE: 5.4934 - MAE: 1.9010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11759/20000 - Train Loss: 0.6633 - Test Loss: 5.7799 - MSE: 5.7799 - MAE: 1.9343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11760/20000 - Train Loss: 0.6665 - Test Loss: 5.4297 - MSE: 5.4297 - MAE: 1.8925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11761/20000 - Train Loss: 0.6714 - Test Loss: 5.8788 - MSE: 5.8788 - MAE: 1.9444\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11762/20000 - Train Loss: 0.6781 - Test Loss: 5.3475 - MSE: 5.3475 - MAE: 1.8806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11763/20000 - Train Loss: 0.6864 - Test Loss: 6.0096 - MSE: 6.0096 - MAE: 1.9596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11764/20000 - Train Loss: 0.6944 - Test Loss: 5.2730 - MSE: 5.2730 - MAE: 1.8687\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11765/20000 - Train Loss: 0.6985 - Test Loss: 6.0959 - MSE: 6.0959 - MAE: 1.9698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11766/20000 - Train Loss: 0.6946 - Test Loss: 5.2711 - MSE: 5.2711 - MAE: 1.8685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11767/20000 - Train Loss: 0.6821 - Test Loss: 5.9760 - MSE: 5.9760 - MAE: 1.9556\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11768/20000 - Train Loss: 0.6668 - Test Loss: 5.4204 - MSE: 5.4204 - MAE: 1.8913\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11769/20000 - Train Loss: 0.6576 - Test Loss: 5.6675 - MSE: 5.6675 - MAE: 1.9221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11770/20000 - Train Loss: 0.6586 - Test Loss: 5.6984 - MSE: 5.6984 - MAE: 1.9255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11771/20000 - Train Loss: 0.6662 - Test Loss: 5.4238 - MSE: 5.4238 - MAE: 1.8918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11772/20000 - Train Loss: 0.6729 - Test Loss: 5.8953 - MSE: 5.8953 - MAE: 1.9460\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 11773/20000 - Train Loss: 0.6729 - Test Loss: 5.3716 - MSE: 5.3716 - MAE: 1.8843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11774/20000 - Train Loss: 0.6664 - Test Loss: 5.8263 - MSE: 5.8263 - MAE: 1.9391\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11775/20000 - Train Loss: 0.6590 - Test Loss: 5.5085 - MSE: 5.5085 - MAE: 1.9031\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11776/20000 - Train Loss: 0.6566 - Test Loss: 5.5935 - MSE: 5.5935 - MAE: 1.9135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11777/20000 - Train Loss: 0.6595 - Test Loss: 5.7254 - MSE: 5.7254 - MAE: 1.9285\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11778/20000 - Train Loss: 0.6639 - Test Loss: 5.4405 - MSE: 5.4405 - MAE: 1.8941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11779/20000 - Train Loss: 0.6650 - Test Loss: 5.8099 - MSE: 5.8099 - MAE: 1.9374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11780/20000 - Train Loss: 0.6620 - Test Loss: 5.4598 - MSE: 5.4598 - MAE: 1.8967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11781/20000 - Train Loss: 0.6579 - Test Loss: 5.6895 - MSE: 5.6895 - MAE: 1.9246\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11782/20000 - Train Loss: 0.6562 - Test Loss: 5.6089 - MSE: 5.6089 - MAE: 1.9154\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11783/20000 - Train Loss: 0.6577 - Test Loss: 5.5256 - MSE: 5.5256 - MAE: 1.9053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11784/20000 - Train Loss: 0.6601 - Test Loss: 5.7394 - MSE: 5.7394 - MAE: 1.9300\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 11785/20000 - Train Loss: 0.6606 - Test Loss: 5.4719 - MSE: 5.4719 - MAE: 1.8984\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11786/20000 - Train Loss: 0.6590 - Test Loss: 5.7193 - MSE: 5.7193 - MAE: 1.9279\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11787/20000 - Train Loss: 0.6568 - Test Loss: 5.5469 - MSE: 5.5469 - MAE: 1.9079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11788/20000 - Train Loss: 0.6559 - Test Loss: 5.5958 - MSE: 5.5958 - MAE: 1.9138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11789/20000 - Train Loss: 0.6568 - Test Loss: 5.6662 - MSE: 5.6662 - MAE: 1.9220\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 11790/20000 - Train Loss: 0.6580 - Test Loss: 5.5090 - MSE: 5.5090 - MAE: 1.9032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11791/20000 - Train Loss: 0.6582 - Test Loss: 5.7070 - MSE: 5.7070 - MAE: 1.9265\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11792/20000 - Train Loss: 0.6572 - Test Loss: 5.5238 - MSE: 5.5238 - MAE: 1.9051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11793/20000 - Train Loss: 0.6560 - Test Loss: 5.6404 - MSE: 5.6404 - MAE: 1.9191\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11794/20000 - Train Loss: 0.6557 - Test Loss: 5.6082 - MSE: 5.6082 - MAE: 1.9153\n",
      "2/2 [==============================] - 0s 980us/step\n",
      "Epoch 11795/20000 - Train Loss: 0.6561 - Test Loss: 5.5531 - MSE: 5.5531 - MAE: 1.9087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11796/20000 - Train Loss: 0.6568 - Test Loss: 5.6734 - MSE: 5.6734 - MAE: 1.9228\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 11797/20000 - Train Loss: 0.6568 - Test Loss: 5.5270 - MSE: 5.5270 - MAE: 1.9055\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11798/20000 - Train Loss: 0.6562 - Test Loss: 5.6584 - MSE: 5.6584 - MAE: 1.9211\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11799/20000 - Train Loss: 0.6556 - Test Loss: 5.5708 - MSE: 5.5708 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11800/20000 - Train Loss: 0.6554 - Test Loss: 5.5926 - MSE: 5.5926 - MAE: 1.9135\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11801/20000 - Train Loss: 0.6556 - Test Loss: 5.6335 - MSE: 5.6335 - MAE: 1.9183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11802/20000 - Train Loss: 0.6559 - Test Loss: 5.5464 - MSE: 5.5464 - MAE: 1.9079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11803/20000 - Train Loss: 0.6559 - Test Loss: 5.6535 - MSE: 5.6535 - MAE: 1.9206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11804/20000 - Train Loss: 0.6556 - Test Loss: 5.5543 - MSE: 5.5543 - MAE: 1.9089\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11805/20000 - Train Loss: 0.6552 - Test Loss: 5.6193 - MSE: 5.6193 - MAE: 1.9166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11806/20000 - Train Loss: 0.6551 - Test Loss: 5.5985 - MSE: 5.5985 - MAE: 1.9142\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 11807/20000 - Train Loss: 0.6551 - Test Loss: 5.5726 - MSE: 5.5726 - MAE: 1.9111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11808/20000 - Train Loss: 0.6553 - Test Loss: 5.6335 - MSE: 5.6335 - MAE: 1.9183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11809/20000 - Train Loss: 0.6553 - Test Loss: 5.5554 - MSE: 5.5554 - MAE: 1.9091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11810/20000 - Train Loss: 0.6551 - Test Loss: 5.6291 - MSE: 5.6291 - MAE: 1.9178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11811/20000 - Train Loss: 0.6549 - Test Loss: 5.5754 - MSE: 5.5754 - MAE: 1.9115\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11812/20000 - Train Loss: 0.6548 - Test Loss: 5.5963 - MSE: 5.5963 - MAE: 1.9140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11813/20000 - Train Loss: 0.6548 - Test Loss: 5.6082 - MSE: 5.6082 - MAE: 1.9154\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11814/20000 - Train Loss: 0.6548 - Test Loss: 5.5685 - MSE: 5.5685 - MAE: 1.9107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11815/20000 - Train Loss: 0.6548 - Test Loss: 5.6233 - MSE: 5.6233 - MAE: 1.9171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11816/20000 - Train Loss: 0.6547 - Test Loss: 5.5666 - MSE: 5.5666 - MAE: 1.9104\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11817/20000 - Train Loss: 0.6546 - Test Loss: 5.6106 - MSE: 5.6106 - MAE: 1.9157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11818/20000 - Train Loss: 0.6545 - Test Loss: 5.5865 - MSE: 5.5865 - MAE: 1.9128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11819/20000 - Train Loss: 0.6544 - Test Loss: 5.5857 - MSE: 5.5857 - MAE: 1.9127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11820/20000 - Train Loss: 0.6544 - Test Loss: 5.6075 - MSE: 5.6075 - MAE: 1.9153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11821/20000 - Train Loss: 0.6544 - Test Loss: 5.5706 - MSE: 5.5706 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11822/20000 - Train Loss: 0.6544 - Test Loss: 5.6118 - MSE: 5.6118 - MAE: 1.9158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11823/20000 - Train Loss: 0.6543 - Test Loss: 5.5746 - MSE: 5.5746 - MAE: 1.9114\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11824/20000 - Train Loss: 0.6542 - Test Loss: 5.5988 - MSE: 5.5988 - MAE: 1.9143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11825/20000 - Train Loss: 0.6541 - Test Loss: 5.5901 - MSE: 5.5901 - MAE: 1.9133\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11826/20000 - Train Loss: 0.6541 - Test Loss: 5.5816 - MSE: 5.5816 - MAE: 1.9123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11827/20000 - Train Loss: 0.6541 - Test Loss: 5.6025 - MSE: 5.6025 - MAE: 1.9147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11828/20000 - Train Loss: 0.6540 - Test Loss: 5.5737 - MSE: 5.5737 - MAE: 1.9113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11829/20000 - Train Loss: 0.6540 - Test Loss: 5.6025 - MSE: 5.6025 - MAE: 1.9147\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11830/20000 - Train Loss: 0.6539 - Test Loss: 5.5785 - MSE: 5.5785 - MAE: 1.9119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11831/20000 - Train Loss: 0.6539 - Test Loss: 5.5920 - MSE: 5.5920 - MAE: 1.9135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11832/20000 - Train Loss: 0.6538 - Test Loss: 5.5894 - MSE: 5.5894 - MAE: 1.9132\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11833/20000 - Train Loss: 0.6538 - Test Loss: 5.5804 - MSE: 5.5804 - MAE: 1.9121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11834/20000 - Train Loss: 0.6537 - Test Loss: 5.5968 - MSE: 5.5968 - MAE: 1.9141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11835/20000 - Train Loss: 0.6537 - Test Loss: 5.5757 - MSE: 5.5757 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11836/20000 - Train Loss: 0.6536 - Test Loss: 5.5956 - MSE: 5.5956 - MAE: 1.9139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11837/20000 - Train Loss: 0.6536 - Test Loss: 5.5795 - MSE: 5.5795 - MAE: 1.9120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11838/20000 - Train Loss: 0.6535 - Test Loss: 5.5879 - MSE: 5.5879 - MAE: 1.9130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11839/20000 - Train Loss: 0.6535 - Test Loss: 5.5868 - MSE: 5.5868 - MAE: 1.9129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11840/20000 - Train Loss: 0.6534 - Test Loss: 5.5798 - MSE: 5.5798 - MAE: 1.9121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11841/20000 - Train Loss: 0.6534 - Test Loss: 5.5915 - MSE: 5.5915 - MAE: 1.9135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11842/20000 - Train Loss: 0.6533 - Test Loss: 5.5765 - MSE: 5.5765 - MAE: 1.9117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11843/20000 - Train Loss: 0.6533 - Test Loss: 5.5905 - MSE: 5.5905 - MAE: 1.9134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11844/20000 - Train Loss: 0.6532 - Test Loss: 5.5787 - MSE: 5.5787 - MAE: 1.9120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11845/20000 - Train Loss: 0.6532 - Test Loss: 5.5852 - MSE: 5.5852 - MAE: 1.9127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11846/20000 - Train Loss: 0.6531 - Test Loss: 5.5834 - MSE: 5.5834 - MAE: 1.9125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11847/20000 - Train Loss: 0.6531 - Test Loss: 5.5794 - MSE: 5.5794 - MAE: 1.9120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11848/20000 - Train Loss: 0.6530 - Test Loss: 5.5867 - MSE: 5.5867 - MAE: 1.9129\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11849/20000 - Train Loss: 0.6530 - Test Loss: 5.5764 - MSE: 5.5764 - MAE: 1.9117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11850/20000 - Train Loss: 0.6529 - Test Loss: 5.5864 - MSE: 5.5864 - MAE: 1.9129\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11851/20000 - Train Loss: 0.6529 - Test Loss: 5.5772 - MSE: 5.5772 - MAE: 1.9118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11852/20000 - Train Loss: 0.6528 - Test Loss: 5.5830 - MSE: 5.5830 - MAE: 1.9125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11853/20000 - Train Loss: 0.6528 - Test Loss: 5.5800 - MSE: 5.5800 - MAE: 1.9121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11854/20000 - Train Loss: 0.6527 - Test Loss: 5.5787 - MSE: 5.5787 - MAE: 1.9120\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11855/20000 - Train Loss: 0.6527 - Test Loss: 5.5824 - MSE: 5.5824 - MAE: 1.9124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11856/20000 - Train Loss: 0.6526 - Test Loss: 5.5759 - MSE: 5.5759 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11857/20000 - Train Loss: 0.6526 - Test Loss: 5.5827 - MSE: 5.5827 - MAE: 1.9124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11858/20000 - Train Loss: 0.6525 - Test Loss: 5.5754 - MSE: 5.5754 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11859/20000 - Train Loss: 0.6525 - Test Loss: 5.5807 - MSE: 5.5807 - MAE: 1.9122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11860/20000 - Train Loss: 0.6524 - Test Loss: 5.5768 - MSE: 5.5768 - MAE: 1.9118\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11861/20000 - Train Loss: 0.6524 - Test Loss: 5.5776 - MSE: 5.5776 - MAE: 1.9118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11862/20000 - Train Loss: 0.6523 - Test Loss: 5.5785 - MSE: 5.5785 - MAE: 1.9120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11863/20000 - Train Loss: 0.6523 - Test Loss: 5.5750 - MSE: 5.5750 - MAE: 1.9115\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11864/20000 - Train Loss: 0.6523 - Test Loss: 5.5790 - MSE: 5.5790 - MAE: 1.9120\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11865/20000 - Train Loss: 0.6522 - Test Loss: 5.5738 - MSE: 5.5738 - MAE: 1.9114\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11866/20000 - Train Loss: 0.6522 - Test Loss: 5.5781 - MSE: 5.5781 - MAE: 1.9119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11867/20000 - Train Loss: 0.6521 - Test Loss: 5.5740 - MSE: 5.5740 - MAE: 1.9114\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11868/20000 - Train Loss: 0.6521 - Test Loss: 5.5761 - MSE: 5.5761 - MAE: 1.9117\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11869/20000 - Train Loss: 0.6520 - Test Loss: 5.5748 - MSE: 5.5748 - MAE: 1.9115\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11870/20000 - Train Loss: 0.6520 - Test Loss: 5.5740 - MSE: 5.5740 - MAE: 1.9114\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11871/20000 - Train Loss: 0.6519 - Test Loss: 5.5754 - MSE: 5.5754 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11872/20000 - Train Loss: 0.6519 - Test Loss: 5.5725 - MSE: 5.5725 - MAE: 1.9113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11873/20000 - Train Loss: 0.6518 - Test Loss: 5.5751 - MSE: 5.5751 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11874/20000 - Train Loss: 0.6518 - Test Loss: 5.5718 - MSE: 5.5718 - MAE: 1.9112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11875/20000 - Train Loss: 0.6517 - Test Loss: 5.5740 - MSE: 5.5740 - MAE: 1.9114\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11876/20000 - Train Loss: 0.6517 - Test Loss: 5.5718 - MSE: 5.5718 - MAE: 1.9112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11877/20000 - Train Loss: 0.6516 - Test Loss: 5.5725 - MSE: 5.5725 - MAE: 1.9113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11878/20000 - Train Loss: 0.6516 - Test Loss: 5.5719 - MSE: 5.5719 - MAE: 1.9112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11879/20000 - Train Loss: 0.6515 - Test Loss: 5.5711 - MSE: 5.5711 - MAE: 1.9111\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11880/20000 - Train Loss: 0.6515 - Test Loss: 5.5718 - MSE: 5.5718 - MAE: 1.9112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11881/20000 - Train Loss: 0.6514 - Test Loss: 5.5700 - MSE: 5.5700 - MAE: 1.9110\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11882/20000 - Train Loss: 0.6514 - Test Loss: 5.5713 - MSE: 5.5713 - MAE: 1.9111\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11883/20000 - Train Loss: 0.6513 - Test Loss: 5.5694 - MSE: 5.5694 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11884/20000 - Train Loss: 0.6513 - Test Loss: 5.5705 - MSE: 5.5705 - MAE: 1.9110\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11885/20000 - Train Loss: 0.6512 - Test Loss: 5.5690 - MSE: 5.5690 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11886/20000 - Train Loss: 0.6512 - Test Loss: 5.5694 - MSE: 5.5694 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11887/20000 - Train Loss: 0.6511 - Test Loss: 5.5688 - MSE: 5.5688 - MAE: 1.9108\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11888/20000 - Train Loss: 0.6511 - Test Loss: 5.5682 - MSE: 5.5682 - MAE: 1.9108\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11889/20000 - Train Loss: 0.6510 - Test Loss: 5.5685 - MSE: 5.5685 - MAE: 1.9108\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11890/20000 - Train Loss: 0.6510 - Test Loss: 5.5672 - MSE: 5.5672 - MAE: 1.9106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11891/20000 - Train Loss: 0.6509 - Test Loss: 5.5681 - MSE: 5.5681 - MAE: 1.9107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11892/20000 - Train Loss: 0.6509 - Test Loss: 5.5664 - MSE: 5.5664 - MAE: 1.9105\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11893/20000 - Train Loss: 0.6508 - Test Loss: 5.5674 - MSE: 5.5674 - MAE: 1.9107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11894/20000 - Train Loss: 0.6508 - Test Loss: 5.5658 - MSE: 5.5658 - MAE: 1.9105\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 11895/20000 - Train Loss: 0.6508 - Test Loss: 5.5665 - MSE: 5.5665 - MAE: 1.9106\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11896/20000 - Train Loss: 0.6507 - Test Loss: 5.5654 - MSE: 5.5654 - MAE: 1.9104\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 11897/20000 - Train Loss: 0.6507 - Test Loss: 5.5656 - MSE: 5.5656 - MAE: 1.9105\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11898/20000 - Train Loss: 0.6506 - Test Loss: 5.5649 - MSE: 5.5649 - MAE: 1.9104\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11899/20000 - Train Loss: 0.6506 - Test Loss: 5.5647 - MSE: 5.5647 - MAE: 1.9104\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11900/20000 - Train Loss: 0.6505 - Test Loss: 5.5644 - MSE: 5.5644 - MAE: 1.9103\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11901/20000 - Train Loss: 0.6505 - Test Loss: 5.5638 - MSE: 5.5638 - MAE: 1.9102\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11902/20000 - Train Loss: 0.6504 - Test Loss: 5.5639 - MSE: 5.5639 - MAE: 1.9103\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11903/20000 - Train Loss: 0.6504 - Test Loss: 5.5630 - MSE: 5.5630 - MAE: 1.9102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11904/20000 - Train Loss: 0.6503 - Test Loss: 5.5633 - MSE: 5.5633 - MAE: 1.9102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11905/20000 - Train Loss: 0.6503 - Test Loss: 5.5623 - MSE: 5.5623 - MAE: 1.9101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11906/20000 - Train Loss: 0.6502 - Test Loss: 5.5627 - MSE: 5.5627 - MAE: 1.9101\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11907/20000 - Train Loss: 0.6502 - Test Loss: 5.5616 - MSE: 5.5616 - MAE: 1.9100\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11908/20000 - Train Loss: 0.6501 - Test Loss: 5.5618 - MSE: 5.5618 - MAE: 1.9100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11909/20000 - Train Loss: 0.6501 - Test Loss: 5.5612 - MSE: 5.5612 - MAE: 1.9099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11910/20000 - Train Loss: 0.6500 - Test Loss: 5.5610 - MSE: 5.5610 - MAE: 1.9099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11911/20000 - Train Loss: 0.6500 - Test Loss: 5.5606 - MSE: 5.5606 - MAE: 1.9099\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11912/20000 - Train Loss: 0.6499 - Test Loss: 5.5601 - MSE: 5.5601 - MAE: 1.9098\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11913/20000 - Train Loss: 0.6499 - Test Loss: 5.5600 - MSE: 5.5600 - MAE: 1.9098\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11914/20000 - Train Loss: 0.6498 - Test Loss: 5.5594 - MSE: 5.5594 - MAE: 1.9097\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11915/20000 - Train Loss: 0.6498 - Test Loss: 5.5594 - MSE: 5.5594 - MAE: 1.9097\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11916/20000 - Train Loss: 0.6497 - Test Loss: 5.5586 - MSE: 5.5586 - MAE: 1.9096\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11917/20000 - Train Loss: 0.6497 - Test Loss: 5.5588 - MSE: 5.5588 - MAE: 1.9097\n",
      "2/2 [==============================] - 0s 985us/step\n",
      "Epoch 11918/20000 - Train Loss: 0.6496 - Test Loss: 5.5580 - MSE: 5.5580 - MAE: 1.9096\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11919/20000 - Train Loss: 0.6496 - Test Loss: 5.5580 - MSE: 5.5580 - MAE: 1.9096\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11920/20000 - Train Loss: 0.6495 - Test Loss: 5.5574 - MSE: 5.5574 - MAE: 1.9095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11921/20000 - Train Loss: 0.6495 - Test Loss: 5.5573 - MSE: 5.5573 - MAE: 1.9095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11922/20000 - Train Loss: 0.6494 - Test Loss: 5.5568 - MSE: 5.5568 - MAE: 1.9094\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11923/20000 - Train Loss: 0.6494 - Test Loss: 5.5565 - MSE: 5.5565 - MAE: 1.9094\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11924/20000 - Train Loss: 0.6494 - Test Loss: 5.5562 - MSE: 5.5562 - MAE: 1.9093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11925/20000 - Train Loss: 0.6493 - Test Loss: 5.5557 - MSE: 5.5557 - MAE: 1.9093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11926/20000 - Train Loss: 0.6493 - Test Loss: 5.5556 - MSE: 5.5556 - MAE: 1.9093\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11927/20000 - Train Loss: 0.6492 - Test Loss: 5.5550 - MSE: 5.5550 - MAE: 1.9092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11928/20000 - Train Loss: 0.6492 - Test Loss: 5.5549 - MSE: 5.5549 - MAE: 1.9092\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11929/20000 - Train Loss: 0.6491 - Test Loss: 5.5543 - MSE: 5.5543 - MAE: 1.9091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11930/20000 - Train Loss: 0.6491 - Test Loss: 5.5543 - MSE: 5.5543 - MAE: 1.9091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11931/20000 - Train Loss: 0.6490 - Test Loss: 5.5536 - MSE: 5.5536 - MAE: 1.9090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11932/20000 - Train Loss: 0.6490 - Test Loss: 5.5536 - MSE: 5.5536 - MAE: 1.9090\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 11933/20000 - Train Loss: 0.6489 - Test Loss: 5.5529 - MSE: 5.5529 - MAE: 1.9090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11934/20000 - Train Loss: 0.6489 - Test Loss: 5.5529 - MSE: 5.5529 - MAE: 1.9090\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11935/20000 - Train Loss: 0.6488 - Test Loss: 5.5523 - MSE: 5.5523 - MAE: 1.9089\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11936/20000 - Train Loss: 0.6488 - Test Loss: 5.5521 - MSE: 5.5521 - MAE: 1.9089\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11937/20000 - Train Loss: 0.6487 - Test Loss: 5.5517 - MSE: 5.5517 - MAE: 1.9088\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11938/20000 - Train Loss: 0.6487 - Test Loss: 5.5513 - MSE: 5.5513 - MAE: 1.9088\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11939/20000 - Train Loss: 0.6486 - Test Loss: 5.5511 - MSE: 5.5511 - MAE: 1.9087\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 11940/20000 - Train Loss: 0.6486 - Test Loss: 5.5505 - MSE: 5.5505 - MAE: 1.9087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11941/20000 - Train Loss: 0.6485 - Test Loss: 5.5506 - MSE: 5.5506 - MAE: 1.9087\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11942/20000 - Train Loss: 0.6485 - Test Loss: 5.5497 - MSE: 5.5497 - MAE: 1.9086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11943/20000 - Train Loss: 0.6484 - Test Loss: 5.5500 - MSE: 5.5500 - MAE: 1.9086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11944/20000 - Train Loss: 0.6484 - Test Loss: 5.5490 - MSE: 5.5490 - MAE: 1.9085\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11945/20000 - Train Loss: 0.6483 - Test Loss: 5.5493 - MSE: 5.5493 - MAE: 1.9085\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11946/20000 - Train Loss: 0.6483 - Test Loss: 5.5483 - MSE: 5.5483 - MAE: 1.9084\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11947/20000 - Train Loss: 0.6482 - Test Loss: 5.5486 - MSE: 5.5486 - MAE: 1.9084\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11948/20000 - Train Loss: 0.6482 - Test Loss: 5.5476 - MSE: 5.5476 - MAE: 1.9083\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 11949/20000 - Train Loss: 0.6481 - Test Loss: 5.5480 - MSE: 5.5480 - MAE: 1.9084\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11950/20000 - Train Loss: 0.6481 - Test Loss: 5.5468 - MSE: 5.5468 - MAE: 1.9082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11951/20000 - Train Loss: 0.6480 - Test Loss: 5.5474 - MSE: 5.5474 - MAE: 1.9083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11952/20000 - Train Loss: 0.6480 - Test Loss: 5.5461 - MSE: 5.5461 - MAE: 1.9081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11953/20000 - Train Loss: 0.6480 - Test Loss: 5.5468 - MSE: 5.5468 - MAE: 1.9082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11954/20000 - Train Loss: 0.6479 - Test Loss: 5.5453 - MSE: 5.5453 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11955/20000 - Train Loss: 0.6479 - Test Loss: 5.5462 - MSE: 5.5462 - MAE: 1.9082\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11956/20000 - Train Loss: 0.6478 - Test Loss: 5.5445 - MSE: 5.5445 - MAE: 1.9079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11957/20000 - Train Loss: 0.6478 - Test Loss: 5.5457 - MSE: 5.5457 - MAE: 1.9081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11958/20000 - Train Loss: 0.6477 - Test Loss: 5.5436 - MSE: 5.5436 - MAE: 1.9078\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11959/20000 - Train Loss: 0.6477 - Test Loss: 5.5453 - MSE: 5.5453 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11960/20000 - Train Loss: 0.6476 - Test Loss: 5.5426 - MSE: 5.5426 - MAE: 1.9077\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11961/20000 - Train Loss: 0.6476 - Test Loss: 5.5450 - MSE: 5.5450 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 11962/20000 - Train Loss: 0.6475 - Test Loss: 5.5415 - MSE: 5.5415 - MAE: 1.9076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11963/20000 - Train Loss: 0.6475 - Test Loss: 5.5448 - MSE: 5.5448 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11964/20000 - Train Loss: 0.6474 - Test Loss: 5.5402 - MSE: 5.5402 - MAE: 1.9074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11965/20000 - Train Loss: 0.6474 - Test Loss: 5.5449 - MSE: 5.5449 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11966/20000 - Train Loss: 0.6473 - Test Loss: 5.5386 - MSE: 5.5386 - MAE: 1.9072\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11967/20000 - Train Loss: 0.6473 - Test Loss: 5.5453 - MSE: 5.5453 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11968/20000 - Train Loss: 0.6472 - Test Loss: 5.5366 - MSE: 5.5366 - MAE: 1.9070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11969/20000 - Train Loss: 0.6472 - Test Loss: 5.5462 - MSE: 5.5462 - MAE: 1.9081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11970/20000 - Train Loss: 0.6471 - Test Loss: 5.5340 - MSE: 5.5340 - MAE: 1.9067\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 11971/20000 - Train Loss: 0.6471 - Test Loss: 5.5479 - MSE: 5.5479 - MAE: 1.9083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11972/20000 - Train Loss: 0.6471 - Test Loss: 5.5304 - MSE: 5.5304 - MAE: 1.9062\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11973/20000 - Train Loss: 0.6470 - Test Loss: 5.5509 - MSE: 5.5509 - MAE: 1.9087\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 11974/20000 - Train Loss: 0.6470 - Test Loss: 5.5252 - MSE: 5.5252 - MAE: 1.9056\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11975/20000 - Train Loss: 0.6470 - Test Loss: 5.5559 - MSE: 5.5559 - MAE: 1.9093\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11976/20000 - Train Loss: 0.6469 - Test Loss: 5.5176 - MSE: 5.5176 - MAE: 1.9047\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11977/20000 - Train Loss: 0.6470 - Test Loss: 5.5641 - MSE: 5.5641 - MAE: 1.9102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11978/20000 - Train Loss: 0.6470 - Test Loss: 5.5061 - MSE: 5.5061 - MAE: 1.9033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11979/20000 - Train Loss: 0.6471 - Test Loss: 5.5778 - MSE: 5.5778 - MAE: 1.9118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11980/20000 - Train Loss: 0.6472 - Test Loss: 5.4883 - MSE: 5.4883 - MAE: 1.9011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11981/20000 - Train Loss: 0.6475 - Test Loss: 5.6004 - MSE: 5.6004 - MAE: 1.9144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11982/20000 - Train Loss: 0.6480 - Test Loss: 5.4606 - MSE: 5.4606 - MAE: 1.8976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11983/20000 - Train Loss: 0.6488 - Test Loss: 5.6379 - MSE: 5.6379 - MAE: 1.9186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11984/20000 - Train Loss: 0.6502 - Test Loss: 5.4182 - MSE: 5.4182 - MAE: 1.8921\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11985/20000 - Train Loss: 0.6522 - Test Loss: 5.6995 - MSE: 5.6995 - MAE: 1.9253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11986/20000 - Train Loss: 0.6555 - Test Loss: 5.3561 - MSE: 5.3561 - MAE: 1.8837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11987/20000 - Train Loss: 0.6602 - Test Loss: 5.7960 - MSE: 5.7960 - MAE: 1.9353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11988/20000 - Train Loss: 0.6668 - Test Loss: 5.2764 - MSE: 5.2764 - MAE: 1.8719\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 11989/20000 - Train Loss: 0.6749 - Test Loss: 5.9235 - MSE: 5.9235 - MAE: 1.9501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11990/20000 - Train Loss: 0.6829 - Test Loss: 5.2040 - MSE: 5.2040 - MAE: 1.8602\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11991/20000 - Train Loss: 0.6870 - Test Loss: 6.0083 - MSE: 6.0083 - MAE: 1.9602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11992/20000 - Train Loss: 0.6833 - Test Loss: 5.2014 - MSE: 5.2014 - MAE: 1.8597\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11993/20000 - Train Loss: 0.6712 - Test Loss: 5.8943 - MSE: 5.8943 - MAE: 1.9465\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 11994/20000 - Train Loss: 0.6562 - Test Loss: 5.3440 - MSE: 5.3440 - MAE: 1.8820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11995/20000 - Train Loss: 0.6469 - Test Loss: 5.5948 - MSE: 5.5948 - MAE: 1.9138\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 11996/20000 - Train Loss: 0.6474 - Test Loss: 5.6135 - MSE: 5.6135 - MAE: 1.9159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11997/20000 - Train Loss: 0.6547 - Test Loss: 5.3548 - MSE: 5.3548 - MAE: 1.8835\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 11998/20000 - Train Loss: 0.6615 - Test Loss: 5.8097 - MSE: 5.8097 - MAE: 1.9366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 11999/20000 - Train Loss: 0.6619 - Test Loss: 5.2992 - MSE: 5.2992 - MAE: 1.8755\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12000/20000 - Train Loss: 0.6558 - Test Loss: 5.7501 - MSE: 5.7501 - MAE: 1.9306\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12001/20000 - Train Loss: 0.6485 - Test Loss: 5.4272 - MSE: 5.4272 - MAE: 1.8933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12002/20000 - Train Loss: 0.6456 - Test Loss: 5.5250 - MSE: 5.5250 - MAE: 1.9056\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12003/20000 - Train Loss: 0.6483 - Test Loss: 5.6384 - MSE: 5.6384 - MAE: 1.9186\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12004/20000 - Train Loss: 0.6525 - Test Loss: 5.3710 - MSE: 5.3710 - MAE: 1.8858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12005/20000 - Train Loss: 0.6540 - Test Loss: 5.7290 - MSE: 5.7290 - MAE: 1.9284\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12006/20000 - Train Loss: 0.6514 - Test Loss: 5.3826 - MSE: 5.3826 - MAE: 1.8874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12007/20000 - Train Loss: 0.6473 - Test Loss: 5.6192 - MSE: 5.6192 - MAE: 1.9165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12008/20000 - Train Loss: 0.6454 - Test Loss: 5.5235 - MSE: 5.5235 - MAE: 1.9054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12009/20000 - Train Loss: 0.6466 - Test Loss: 5.4579 - MSE: 5.4579 - MAE: 1.8973\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12010/20000 - Train Loss: 0.6489 - Test Loss: 5.6552 - MSE: 5.6552 - MAE: 1.9205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12011/20000 - Train Loss: 0.6498 - Test Loss: 5.3982 - MSE: 5.3982 - MAE: 1.8895\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12012/20000 - Train Loss: 0.6483 - Test Loss: 5.6452 - MSE: 5.6452 - MAE: 1.9193\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12013/20000 - Train Loss: 0.6461 - Test Loss: 5.4645 - MSE: 5.4645 - MAE: 1.8981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12014/20000 - Train Loss: 0.6451 - Test Loss: 5.5281 - MSE: 5.5281 - MAE: 1.9059\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12015/20000 - Train Loss: 0.6458 - Test Loss: 5.5808 - MSE: 5.5808 - MAE: 1.9121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12016/20000 - Train Loss: 0.6470 - Test Loss: 5.4384 - MSE: 5.4384 - MAE: 1.8948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12017/20000 - Train Loss: 0.6474 - Test Loss: 5.6288 - MSE: 5.6288 - MAE: 1.9175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12018/20000 - Train Loss: 0.6466 - Test Loss: 5.4451 - MSE: 5.4451 - MAE: 1.8956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12019/20000 - Train Loss: 0.6454 - Test Loss: 5.5709 - MSE: 5.5709 - MAE: 1.9109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12020/20000 - Train Loss: 0.6449 - Test Loss: 5.5237 - MSE: 5.5237 - MAE: 1.9054\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12021/20000 - Train Loss: 0.6452 - Test Loss: 5.4846 - MSE: 5.4846 - MAE: 1.9006\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12022/20000 - Train Loss: 0.6458 - Test Loss: 5.5918 - MSE: 5.5918 - MAE: 1.9133\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12023/20000 - Train Loss: 0.6460 - Test Loss: 5.4522 - MSE: 5.4522 - MAE: 1.8966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12024/20000 - Train Loss: 0.6456 - Test Loss: 5.5853 - MSE: 5.5853 - MAE: 1.9126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12025/20000 - Train Loss: 0.6449 - Test Loss: 5.4890 - MSE: 5.4890 - MAE: 1.9012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12026/20000 - Train Loss: 0.6446 - Test Loss: 5.5241 - MSE: 5.5241 - MAE: 1.9054\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12027/20000 - Train Loss: 0.6447 - Test Loss: 5.5505 - MSE: 5.5505 - MAE: 1.9086\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12028/20000 - Train Loss: 0.6451 - Test Loss: 5.4748 - MSE: 5.4748 - MAE: 1.8994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12029/20000 - Train Loss: 0.6452 - Test Loss: 5.5765 - MSE: 5.5765 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12030/20000 - Train Loss: 0.6449 - Test Loss: 5.4761 - MSE: 5.4761 - MAE: 1.8996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12031/20000 - Train Loss: 0.6446 - Test Loss: 5.5488 - MSE: 5.5488 - MAE: 1.9083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12032/20000 - Train Loss: 0.6443 - Test Loss: 5.5163 - MSE: 5.5163 - MAE: 1.9045\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12033/20000 - Train Loss: 0.6444 - Test Loss: 5.5028 - MSE: 5.5028 - MAE: 1.9028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12034/20000 - Train Loss: 0.6445 - Test Loss: 5.5536 - MSE: 5.5536 - MAE: 1.9089\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12035/20000 - Train Loss: 0.6446 - Test Loss: 5.4810 - MSE: 5.4810 - MAE: 1.9002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12036/20000 - Train Loss: 0.6445 - Test Loss: 5.5553 - MSE: 5.5553 - MAE: 1.9091\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12037/20000 - Train Loss: 0.6443 - Test Loss: 5.4957 - MSE: 5.4957 - MAE: 1.9020\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12038/20000 - Train Loss: 0.6441 - Test Loss: 5.5262 - MSE: 5.5262 - MAE: 1.9056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12039/20000 - Train Loss: 0.6440 - Test Loss: 5.5273 - MSE: 5.5273 - MAE: 1.9058\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12040/20000 - Train Loss: 0.6441 - Test Loss: 5.4969 - MSE: 5.4969 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12041/20000 - Train Loss: 0.6441 - Test Loss: 5.5460 - MSE: 5.5460 - MAE: 1.9080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12042/20000 - Train Loss: 0.6441 - Test Loss: 5.4905 - MSE: 5.4905 - MAE: 1.9013\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12043/20000 - Train Loss: 0.6440 - Test Loss: 5.5380 - MSE: 5.5380 - MAE: 1.9070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12044/20000 - Train Loss: 0.6438 - Test Loss: 5.5069 - MSE: 5.5069 - MAE: 1.9033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12045/20000 - Train Loss: 0.6438 - Test Loss: 5.5148 - MSE: 5.5148 - MAE: 1.9043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12046/20000 - Train Loss: 0.6438 - Test Loss: 5.5283 - MSE: 5.5283 - MAE: 1.9059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12047/20000 - Train Loss: 0.6438 - Test Loss: 5.4975 - MSE: 5.4975 - MAE: 1.9022\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12048/20000 - Train Loss: 0.6437 - Test Loss: 5.5364 - MSE: 5.5364 - MAE: 1.9068\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12049/20000 - Train Loss: 0.6437 - Test Loss: 5.4977 - MSE: 5.4977 - MAE: 1.9022\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12050/20000 - Train Loss: 0.6436 - Test Loss: 5.5267 - MSE: 5.5267 - MAE: 1.9057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12051/20000 - Train Loss: 0.6435 - Test Loss: 5.5112 - MSE: 5.5112 - MAE: 1.9038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12052/20000 - Train Loss: 0.6435 - Test Loss: 5.5099 - MSE: 5.5099 - MAE: 1.9037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12053/20000 - Train Loss: 0.6435 - Test Loss: 5.5250 - MSE: 5.5250 - MAE: 1.9055\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12054/20000 - Train Loss: 0.6434 - Test Loss: 5.4996 - MSE: 5.4996 - MAE: 1.9024\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12055/20000 - Train Loss: 0.6434 - Test Loss: 5.5281 - MSE: 5.5281 - MAE: 1.9058\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12056/20000 - Train Loss: 0.6433 - Test Loss: 5.5016 - MSE: 5.5016 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12057/20000 - Train Loss: 0.6433 - Test Loss: 5.5197 - MSE: 5.5197 - MAE: 1.9048\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12058/20000 - Train Loss: 0.6432 - Test Loss: 5.5116 - MSE: 5.5116 - MAE: 1.9038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12059/20000 - Train Loss: 0.6432 - Test Loss: 5.5080 - MSE: 5.5080 - MAE: 1.9034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12060/20000 - Train Loss: 0.6431 - Test Loss: 5.5203 - MSE: 5.5203 - MAE: 1.9049\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12061/20000 - Train Loss: 0.6431 - Test Loss: 5.5014 - MSE: 5.5014 - MAE: 1.9026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12062/20000 - Train Loss: 0.6431 - Test Loss: 5.5215 - MSE: 5.5215 - MAE: 1.9050\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12063/20000 - Train Loss: 0.6430 - Test Loss: 5.5031 - MSE: 5.5031 - MAE: 1.9028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12064/20000 - Train Loss: 0.6430 - Test Loss: 5.5154 - MSE: 5.5154 - MAE: 1.9043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12065/20000 - Train Loss: 0.6429 - Test Loss: 5.5098 - MSE: 5.5098 - MAE: 1.9036\n",
      "2/2 [==============================] - 0s 983us/step\n",
      "Epoch 12066/20000 - Train Loss: 0.6429 - Test Loss: 5.5071 - MSE: 5.5071 - MAE: 1.9033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12067/20000 - Train Loss: 0.6428 - Test Loss: 5.5156 - MSE: 5.5156 - MAE: 1.9043\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 12068/20000 - Train Loss: 0.6428 - Test Loss: 5.5024 - MSE: 5.5024 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12069/20000 - Train Loss: 0.6427 - Test Loss: 5.5163 - MSE: 5.5163 - MAE: 1.9044\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12070/20000 - Train Loss: 0.6427 - Test Loss: 5.5032 - MSE: 5.5032 - MAE: 1.9028\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12071/20000 - Train Loss: 0.6427 - Test Loss: 5.5122 - MSE: 5.5122 - MAE: 1.9039\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 12072/20000 - Train Loss: 0.6426 - Test Loss: 5.5074 - MSE: 5.5074 - MAE: 1.9033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12073/20000 - Train Loss: 0.6426 - Test Loss: 5.5064 - MSE: 5.5064 - MAE: 1.9032\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12074/20000 - Train Loss: 0.6425 - Test Loss: 5.5112 - MSE: 5.5112 - MAE: 1.9038\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12075/20000 - Train Loss: 0.6425 - Test Loss: 5.5027 - MSE: 5.5027 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12076/20000 - Train Loss: 0.6424 - Test Loss: 5.5121 - MSE: 5.5121 - MAE: 1.9039\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12077/20000 - Train Loss: 0.6424 - Test Loss: 5.5024 - MSE: 5.5024 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12078/20000 - Train Loss: 0.6423 - Test Loss: 5.5096 - MSE: 5.5096 - MAE: 1.9036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12079/20000 - Train Loss: 0.6423 - Test Loss: 5.5047 - MSE: 5.5047 - MAE: 1.9030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12080/20000 - Train Loss: 0.6423 - Test Loss: 5.5055 - MSE: 5.5055 - MAE: 1.9031\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12081/20000 - Train Loss: 0.6422 - Test Loss: 5.5074 - MSE: 5.5074 - MAE: 1.9033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12082/20000 - Train Loss: 0.6422 - Test Loss: 5.5023 - MSE: 5.5023 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12083/20000 - Train Loss: 0.6421 - Test Loss: 5.5083 - MSE: 5.5083 - MAE: 1.9034\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 12084/20000 - Train Loss: 0.6421 - Test Loss: 5.5013 - MSE: 5.5013 - MAE: 1.9025\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12085/20000 - Train Loss: 0.6420 - Test Loss: 5.5071 - MSE: 5.5071 - MAE: 1.9032\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12086/20000 - Train Loss: 0.6420 - Test Loss: 5.5021 - MSE: 5.5021 - MAE: 1.9026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12087/20000 - Train Loss: 0.6420 - Test Loss: 5.5045 - MSE: 5.5045 - MAE: 1.9029\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12088/20000 - Train Loss: 0.6419 - Test Loss: 5.5037 - MSE: 5.5037 - MAE: 1.9028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12089/20000 - Train Loss: 0.6419 - Test Loss: 5.5019 - MSE: 5.5019 - MAE: 1.9026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12090/20000 - Train Loss: 0.6418 - Test Loss: 5.5046 - MSE: 5.5046 - MAE: 1.9029\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12091/20000 - Train Loss: 0.6418 - Test Loss: 5.5003 - MSE: 5.5003 - MAE: 1.9024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12092/20000 - Train Loss: 0.6417 - Test Loss: 5.5043 - MSE: 5.5043 - MAE: 1.9029\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12093/20000 - Train Loss: 0.6417 - Test Loss: 5.5000 - MSE: 5.5000 - MAE: 1.9024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12094/20000 - Train Loss: 0.6417 - Test Loss: 5.5029 - MSE: 5.5029 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12095/20000 - Train Loss: 0.6416 - Test Loss: 5.5006 - MSE: 5.5006 - MAE: 1.9024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12096/20000 - Train Loss: 0.6416 - Test Loss: 5.5009 - MSE: 5.5009 - MAE: 1.9025\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12097/20000 - Train Loss: 0.6415 - Test Loss: 5.5012 - MSE: 5.5012 - MAE: 1.9025\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12098/20000 - Train Loss: 0.6415 - Test Loss: 5.4993 - MSE: 5.4993 - MAE: 1.9023\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 12099/20000 - Train Loss: 0.6414 - Test Loss: 5.5013 - MSE: 5.5013 - MAE: 1.9025\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12100/20000 - Train Loss: 0.6414 - Test Loss: 5.4983 - MSE: 5.4983 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12101/20000 - Train Loss: 0.6414 - Test Loss: 5.5006 - MSE: 5.5006 - MAE: 1.9024\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "Epoch 12102/20000 - Train Loss: 0.6413 - Test Loss: 5.4981 - MSE: 5.4981 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12103/20000 - Train Loss: 0.6413 - Test Loss: 5.4994 - MSE: 5.4994 - MAE: 1.9023\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12104/20000 - Train Loss: 0.6412 - Test Loss: 5.4982 - MSE: 5.4982 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 981us/step\n",
      "Epoch 12105/20000 - Train Loss: 0.6412 - Test Loss: 5.4981 - MSE: 5.4981 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12106/20000 - Train Loss: 0.6411 - Test Loss: 5.4982 - MSE: 5.4982 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12107/20000 - Train Loss: 0.6411 - Test Loss: 5.4969 - MSE: 5.4969 - MAE: 1.9019\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12108/20000 - Train Loss: 0.6410 - Test Loss: 5.4980 - MSE: 5.4980 - MAE: 1.9021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12109/20000 - Train Loss: 0.6410 - Test Loss: 5.4961 - MSE: 5.4961 - MAE: 1.9018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12110/20000 - Train Loss: 0.6410 - Test Loss: 5.4974 - MSE: 5.4974 - MAE: 1.9020\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12111/20000 - Train Loss: 0.6409 - Test Loss: 5.4957 - MSE: 5.4957 - MAE: 1.9018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12112/20000 - Train Loss: 0.6409 - Test Loss: 5.4964 - MSE: 5.4964 - MAE: 1.9019\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12113/20000 - Train Loss: 0.6408 - Test Loss: 5.4954 - MSE: 5.4954 - MAE: 1.9018\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12114/20000 - Train Loss: 0.6408 - Test Loss: 5.4954 - MSE: 5.4954 - MAE: 1.9017\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12115/20000 - Train Loss: 0.6407 - Test Loss: 5.4952 - MSE: 5.4952 - MAE: 1.9017\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12116/20000 - Train Loss: 0.6407 - Test Loss: 5.4945 - MSE: 5.4945 - MAE: 1.9016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12117/20000 - Train Loss: 0.6407 - Test Loss: 5.4948 - MSE: 5.4948 - MAE: 1.9017\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12118/20000 - Train Loss: 0.6406 - Test Loss: 5.4937 - MSE: 5.4937 - MAE: 1.9015\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12119/20000 - Train Loss: 0.6406 - Test Loss: 5.4943 - MSE: 5.4943 - MAE: 1.9016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12120/20000 - Train Loss: 0.6405 - Test Loss: 5.4930 - MSE: 5.4930 - MAE: 1.9014\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12121/20000 - Train Loss: 0.6405 - Test Loss: 5.4936 - MSE: 5.4936 - MAE: 1.9015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12122/20000 - Train Loss: 0.6404 - Test Loss: 5.4926 - MSE: 5.4926 - MAE: 1.9014\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12123/20000 - Train Loss: 0.6404 - Test Loss: 5.4929 - MSE: 5.4929 - MAE: 1.9014\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12124/20000 - Train Loss: 0.6404 - Test Loss: 5.4921 - MSE: 5.4921 - MAE: 1.9013\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12125/20000 - Train Loss: 0.6403 - Test Loss: 5.4920 - MSE: 5.4920 - MAE: 1.9013\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 12126/20000 - Train Loss: 0.6403 - Test Loss: 5.4917 - MSE: 5.4917 - MAE: 1.9013\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12127/20000 - Train Loss: 0.6402 - Test Loss: 5.4912 - MSE: 5.4912 - MAE: 1.9012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12128/20000 - Train Loss: 0.6402 - Test Loss: 5.4912 - MSE: 5.4912 - MAE: 1.9012\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12129/20000 - Train Loss: 0.6401 - Test Loss: 5.4905 - MSE: 5.4905 - MAE: 1.9011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12130/20000 - Train Loss: 0.6401 - Test Loss: 5.4907 - MSE: 5.4907 - MAE: 1.9011\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12131/20000 - Train Loss: 0.6401 - Test Loss: 5.4899 - MSE: 5.4899 - MAE: 1.9010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12132/20000 - Train Loss: 0.6400 - Test Loss: 5.4901 - MSE: 5.4901 - MAE: 1.9010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12133/20000 - Train Loss: 0.6400 - Test Loss: 5.4893 - MSE: 5.4893 - MAE: 1.9009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12134/20000 - Train Loss: 0.6399 - Test Loss: 5.4894 - MSE: 5.4894 - MAE: 1.9009\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12135/20000 - Train Loss: 0.6399 - Test Loss: 5.4887 - MSE: 5.4887 - MAE: 1.9009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12136/20000 - Train Loss: 0.6398 - Test Loss: 5.4887 - MSE: 5.4887 - MAE: 1.9009\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12137/20000 - Train Loss: 0.6398 - Test Loss: 5.4881 - MSE: 5.4881 - MAE: 1.9008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12138/20000 - Train Loss: 0.6397 - Test Loss: 5.4880 - MSE: 5.4880 - MAE: 1.9008\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12139/20000 - Train Loss: 0.6397 - Test Loss: 5.4876 - MSE: 5.4876 - MAE: 1.9007\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12140/20000 - Train Loss: 0.6397 - Test Loss: 5.4873 - MSE: 5.4873 - MAE: 1.9007\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12141/20000 - Train Loss: 0.6396 - Test Loss: 5.4871 - MSE: 5.4871 - MAE: 1.9006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12142/20000 - Train Loss: 0.6396 - Test Loss: 5.4867 - MSE: 5.4867 - MAE: 1.9006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12143/20000 - Train Loss: 0.6395 - Test Loss: 5.4865 - MSE: 5.4865 - MAE: 1.9006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12144/20000 - Train Loss: 0.6395 - Test Loss: 5.4860 - MSE: 5.4860 - MAE: 1.9005\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12145/20000 - Train Loss: 0.6394 - Test Loss: 5.4859 - MSE: 5.4859 - MAE: 1.9005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12146/20000 - Train Loss: 0.6394 - Test Loss: 5.4854 - MSE: 5.4854 - MAE: 1.9004\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12147/20000 - Train Loss: 0.6394 - Test Loss: 5.4852 - MSE: 5.4852 - MAE: 1.9004\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12148/20000 - Train Loss: 0.6393 - Test Loss: 5.4848 - MSE: 5.4848 - MAE: 1.9003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12149/20000 - Train Loss: 0.6393 - Test Loss: 5.4846 - MSE: 5.4846 - MAE: 1.9003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12150/20000 - Train Loss: 0.6392 - Test Loss: 5.4843 - MSE: 5.4843 - MAE: 1.9003\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12151/20000 - Train Loss: 0.6392 - Test Loss: 5.4839 - MSE: 5.4839 - MAE: 1.9002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12152/20000 - Train Loss: 0.6391 - Test Loss: 5.4837 - MSE: 5.4837 - MAE: 1.9002\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12153/20000 - Train Loss: 0.6391 - Test Loss: 5.4833 - MSE: 5.4833 - MAE: 1.9001\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12154/20000 - Train Loss: 0.6391 - Test Loss: 5.4831 - MSE: 5.4831 - MAE: 1.9001\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 12155/20000 - Train Loss: 0.6390 - Test Loss: 5.4826 - MSE: 5.4826 - MAE: 1.9000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12156/20000 - Train Loss: 0.6390 - Test Loss: 5.4825 - MSE: 5.4825 - MAE: 1.9000\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12157/20000 - Train Loss: 0.6389 - Test Loss: 5.4819 - MSE: 5.4819 - MAE: 1.9000\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12158/20000 - Train Loss: 0.6389 - Test Loss: 5.4819 - MSE: 5.4819 - MAE: 1.9000\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12159/20000 - Train Loss: 0.6388 - Test Loss: 5.4813 - MSE: 5.4813 - MAE: 1.8999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12160/20000 - Train Loss: 0.6388 - Test Loss: 5.4813 - MSE: 5.4813 - MAE: 1.8999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12161/20000 - Train Loss: 0.6388 - Test Loss: 5.4807 - MSE: 5.4807 - MAE: 1.8998\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12162/20000 - Train Loss: 0.6387 - Test Loss: 5.4806 - MSE: 5.4806 - MAE: 1.8998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12163/20000 - Train Loss: 0.6387 - Test Loss: 5.4802 - MSE: 5.4802 - MAE: 1.8997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12164/20000 - Train Loss: 0.6386 - Test Loss: 5.4799 - MSE: 5.4799 - MAE: 1.8997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12165/20000 - Train Loss: 0.6386 - Test Loss: 5.4796 - MSE: 5.4796 - MAE: 1.8996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12166/20000 - Train Loss: 0.6385 - Test Loss: 5.4793 - MSE: 5.4793 - MAE: 1.8996\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12167/20000 - Train Loss: 0.6385 - Test Loss: 5.4790 - MSE: 5.4790 - MAE: 1.8996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12168/20000 - Train Loss: 0.6384 - Test Loss: 5.4787 - MSE: 5.4787 - MAE: 1.8995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12169/20000 - Train Loss: 0.6384 - Test Loss: 5.4783 - MSE: 5.4783 - MAE: 1.8995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12170/20000 - Train Loss: 0.6384 - Test Loss: 5.4782 - MSE: 5.4782 - MAE: 1.8994\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12171/20000 - Train Loss: 0.6383 - Test Loss: 5.4776 - MSE: 5.4776 - MAE: 1.8994\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12172/20000 - Train Loss: 0.6383 - Test Loss: 5.4777 - MSE: 5.4777 - MAE: 1.8994\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12173/20000 - Train Loss: 0.6382 - Test Loss: 5.4768 - MSE: 5.4768 - MAE: 1.8993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12174/20000 - Train Loss: 0.6382 - Test Loss: 5.4772 - MSE: 5.4772 - MAE: 1.8993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12175/20000 - Train Loss: 0.6381 - Test Loss: 5.4760 - MSE: 5.4760 - MAE: 1.8992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12176/20000 - Train Loss: 0.6381 - Test Loss: 5.4768 - MSE: 5.4768 - MAE: 1.8993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12177/20000 - Train Loss: 0.6381 - Test Loss: 5.4752 - MSE: 5.4752 - MAE: 1.8991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12178/20000 - Train Loss: 0.6380 - Test Loss: 5.4764 - MSE: 5.4764 - MAE: 1.8992\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12179/20000 - Train Loss: 0.6380 - Test Loss: 5.4742 - MSE: 5.4742 - MAE: 1.8989\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12180/20000 - Train Loss: 0.6379 - Test Loss: 5.4762 - MSE: 5.4762 - MAE: 1.8992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12181/20000 - Train Loss: 0.6379 - Test Loss: 5.4732 - MSE: 5.4732 - MAE: 1.8988\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12182/20000 - Train Loss: 0.6378 - Test Loss: 5.4760 - MSE: 5.4760 - MAE: 1.8991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12183/20000 - Train Loss: 0.6378 - Test Loss: 5.4721 - MSE: 5.4721 - MAE: 1.8986\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12184/20000 - Train Loss: 0.6378 - Test Loss: 5.4760 - MSE: 5.4760 - MAE: 1.8991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12185/20000 - Train Loss: 0.6377 - Test Loss: 5.4707 - MSE: 5.4707 - MAE: 1.8985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12186/20000 - Train Loss: 0.6377 - Test Loss: 5.4762 - MSE: 5.4762 - MAE: 1.8991\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12187/20000 - Train Loss: 0.6376 - Test Loss: 5.4691 - MSE: 5.4691 - MAE: 1.8983\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 12188/20000 - Train Loss: 0.6376 - Test Loss: 5.4768 - MSE: 5.4768 - MAE: 1.8992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12189/20000 - Train Loss: 0.6375 - Test Loss: 5.4671 - MSE: 5.4671 - MAE: 1.8980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12190/20000 - Train Loss: 0.6375 - Test Loss: 5.4778 - MSE: 5.4778 - MAE: 1.8993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12191/20000 - Train Loss: 0.6375 - Test Loss: 5.4645 - MSE: 5.4645 - MAE: 1.8977\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12192/20000 - Train Loss: 0.6374 - Test Loss: 5.4797 - MSE: 5.4797 - MAE: 1.8995\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12193/20000 - Train Loss: 0.6374 - Test Loss: 5.4609 - MSE: 5.4609 - MAE: 1.8972\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12194/20000 - Train Loss: 0.6374 - Test Loss: 5.4828 - MSE: 5.4828 - MAE: 1.8999\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12195/20000 - Train Loss: 0.6373 - Test Loss: 5.4557 - MSE: 5.4557 - MAE: 1.8966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12196/20000 - Train Loss: 0.6373 - Test Loss: 5.4879 - MSE: 5.4879 - MAE: 1.9005\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12197/20000 - Train Loss: 0.6373 - Test Loss: 5.4482 - MSE: 5.4482 - MAE: 1.8957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12198/20000 - Train Loss: 0.6373 - Test Loss: 5.4961 - MSE: 5.4961 - MAE: 1.9015\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12199/20000 - Train Loss: 0.6374 - Test Loss: 5.4371 - MSE: 5.4371 - MAE: 1.8943\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12200/20000 - Train Loss: 0.6375 - Test Loss: 5.5092 - MSE: 5.5092 - MAE: 1.9030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12201/20000 - Train Loss: 0.6376 - Test Loss: 5.4203 - MSE: 5.4203 - MAE: 1.8922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12202/20000 - Train Loss: 0.6379 - Test Loss: 5.5304 - MSE: 5.5304 - MAE: 1.9054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12203/20000 - Train Loss: 0.6383 - Test Loss: 5.3948 - MSE: 5.3948 - MAE: 1.8889\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12204/20000 - Train Loss: 0.6391 - Test Loss: 5.5646 - MSE: 5.5646 - MAE: 1.9093\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12205/20000 - Train Loss: 0.6402 - Test Loss: 5.3564 - MSE: 5.3564 - MAE: 1.8839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12206/20000 - Train Loss: 0.6420 - Test Loss: 5.6195 - MSE: 5.6195 - MAE: 1.9154\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12207/20000 - Train Loss: 0.6447 - Test Loss: 5.3010 - MSE: 5.3010 - MAE: 1.8762\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12208/20000 - Train Loss: 0.6487 - Test Loss: 5.7040 - MSE: 5.7040 - MAE: 1.9243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12209/20000 - Train Loss: 0.6541 - Test Loss: 5.2298 - MSE: 5.2298 - MAE: 1.8658\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12210/20000 - Train Loss: 0.6609 - Test Loss: 5.8158 - MSE: 5.8158 - MAE: 1.9368\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12211/20000 - Train Loss: 0.6679 - Test Loss: 5.1619 - MSE: 5.1619 - MAE: 1.8548\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12212/20000 - Train Loss: 0.6725 - Test Loss: 5.9015 - MSE: 5.9015 - MAE: 1.9473\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12213/20000 - Train Loss: 0.6715 - Test Loss: 5.1470 - MSE: 5.1470 - MAE: 1.8523\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12214/20000 - Train Loss: 0.6631 - Test Loss: 5.8335 - MSE: 5.8335 - MAE: 1.9390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12215/20000 - Train Loss: 0.6504 - Test Loss: 5.2506 - MSE: 5.2506 - MAE: 1.8689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12216/20000 - Train Loss: 0.6397 - Test Loss: 5.5840 - MSE: 5.5840 - MAE: 1.9114\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12217/20000 - Train Loss: 0.6364 - Test Loss: 5.4781 - MSE: 5.4781 - MAE: 1.8992\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12218/20000 - Train Loss: 0.6404 - Test Loss: 5.3417 - MSE: 5.3417 - MAE: 1.8819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12219/20000 - Train Loss: 0.6471 - Test Loss: 5.6880 - MSE: 5.6880 - MAE: 1.9226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12220/20000 - Train Loss: 0.6508 - Test Loss: 5.2452 - MSE: 5.2452 - MAE: 1.8681\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12221/20000 - Train Loss: 0.6487 - Test Loss: 5.7057 - MSE: 5.7057 - MAE: 1.9244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12222/20000 - Train Loss: 0.6426 - Test Loss: 5.3118 - MSE: 5.3118 - MAE: 1.8777\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12223/20000 - Train Loss: 0.6373 - Test Loss: 5.5334 - MSE: 5.5334 - MAE: 1.9057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12224/20000 - Train Loss: 0.6363 - Test Loss: 5.4897 - MSE: 5.4897 - MAE: 1.9006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12225/20000 - Train Loss: 0.6390 - Test Loss: 5.3568 - MSE: 5.3568 - MAE: 1.8839\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12226/20000 - Train Loss: 0.6423 - Test Loss: 5.6299 - MSE: 5.6299 - MAE: 1.9164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12227/20000 - Train Loss: 0.6430 - Test Loss: 5.3042 - MSE: 5.3042 - MAE: 1.8767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12228/20000 - Train Loss: 0.6407 - Test Loss: 5.6059 - MSE: 5.6059 - MAE: 1.9138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12229/20000 - Train Loss: 0.6374 - Test Loss: 5.3839 - MSE: 5.3839 - MAE: 1.8874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12230/20000 - Train Loss: 0.6358 - Test Loss: 5.4672 - MSE: 5.4672 - MAE: 1.8978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12231/20000 - Train Loss: 0.6367 - Test Loss: 5.5199 - MSE: 5.5199 - MAE: 1.9041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12232/20000 - Train Loss: 0.6385 - Test Loss: 5.3590 - MSE: 5.3590 - MAE: 1.8841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12233/20000 - Train Loss: 0.6394 - Test Loss: 5.5867 - MSE: 5.5867 - MAE: 1.9116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12234/20000 - Train Loss: 0.6386 - Test Loss: 5.3549 - MSE: 5.3549 - MAE: 1.8836\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12235/20000 - Train Loss: 0.6369 - Test Loss: 5.5317 - MSE: 5.5317 - MAE: 1.9054\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12236/20000 - Train Loss: 0.6357 - Test Loss: 5.4377 - MSE: 5.4377 - MAE: 1.8942\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12237/20000 - Train Loss: 0.6358 - Test Loss: 5.4288 - MSE: 5.4288 - MAE: 1.8931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12238/20000 - Train Loss: 0.6367 - Test Loss: 5.5274 - MSE: 5.5274 - MAE: 1.9049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12239/20000 - Train Loss: 0.6374 - Test Loss: 5.3737 - MSE: 5.3737 - MAE: 1.8861\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12240/20000 - Train Loss: 0.6372 - Test Loss: 5.5434 - MSE: 5.5434 - MAE: 1.9067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12241/20000 - Train Loss: 0.6363 - Test Loss: 5.3970 - MSE: 5.3970 - MAE: 1.8891\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12242/20000 - Train Loss: 0.6355 - Test Loss: 5.4839 - MSE: 5.4839 - MAE: 1.8998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12243/20000 - Train Loss: 0.6353 - Test Loss: 5.4663 - MSE: 5.4663 - MAE: 1.8977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12244/20000 - Train Loss: 0.6357 - Test Loss: 5.4156 - MSE: 5.4156 - MAE: 1.8914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12245/20000 - Train Loss: 0.6361 - Test Loss: 5.5168 - MSE: 5.5168 - MAE: 1.9036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12246/20000 - Train Loss: 0.6362 - Test Loss: 5.3940 - MSE: 5.3940 - MAE: 1.8887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12247/20000 - Train Loss: 0.6358 - Test Loss: 5.5079 - MSE: 5.5079 - MAE: 1.9026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12248/20000 - Train Loss: 0.6353 - Test Loss: 5.4252 - MSE: 5.4252 - MAE: 1.8926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12249/20000 - Train Loss: 0.6351 - Test Loss: 5.4583 - MSE: 5.4583 - MAE: 1.8967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12250/20000 - Train Loss: 0.6351 - Test Loss: 5.4752 - MSE: 5.4752 - MAE: 1.8987\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12251/20000 - Train Loss: 0.6354 - Test Loss: 5.4163 - MSE: 5.4163 - MAE: 1.8915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12252/20000 - Train Loss: 0.6355 - Test Loss: 5.5002 - MSE: 5.5002 - MAE: 1.9016\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12253/20000 - Train Loss: 0.6354 - Test Loss: 5.4118 - MSE: 5.4118 - MAE: 1.8909\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12254/20000 - Train Loss: 0.6351 - Test Loss: 5.4838 - MSE: 5.4838 - MAE: 1.8997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12255/20000 - Train Loss: 0.6349 - Test Loss: 5.4401 - MSE: 5.4401 - MAE: 1.8944\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12256/20000 - Train Loss: 0.6348 - Test Loss: 5.4470 - MSE: 5.4470 - MAE: 1.8952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12257/20000 - Train Loss: 0.6349 - Test Loss: 5.4734 - MSE: 5.4734 - MAE: 1.8984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12258/20000 - Train Loss: 0.6350 - Test Loss: 5.4220 - MSE: 5.4220 - MAE: 1.8921\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12259/20000 - Train Loss: 0.6349 - Test Loss: 5.4848 - MSE: 5.4848 - MAE: 1.8998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12260/20000 - Train Loss: 0.6348 - Test Loss: 5.4238 - MSE: 5.4238 - MAE: 1.8924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12261/20000 - Train Loss: 0.6347 - Test Loss: 5.4693 - MSE: 5.4693 - MAE: 1.8979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12262/20000 - Train Loss: 0.6346 - Test Loss: 5.4455 - MSE: 5.4455 - MAE: 1.8950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12263/20000 - Train Loss: 0.6345 - Test Loss: 5.4436 - MSE: 5.4436 - MAE: 1.8948\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 12264/20000 - Train Loss: 0.6346 - Test Loss: 5.4672 - MSE: 5.4672 - MAE: 1.8976\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12265/20000 - Train Loss: 0.6346 - Test Loss: 5.4280 - MSE: 5.4280 - MAE: 1.8929\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12266/20000 - Train Loss: 0.6345 - Test Loss: 5.4728 - MSE: 5.4728 - MAE: 1.8983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12267/20000 - Train Loss: 0.6345 - Test Loss: 5.4308 - MSE: 5.4308 - MAE: 1.8932\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12268/20000 - Train Loss: 0.6344 - Test Loss: 5.4609 - MSE: 5.4609 - MAE: 1.8969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12269/20000 - Train Loss: 0.6343 - Test Loss: 5.4460 - MSE: 5.4460 - MAE: 1.8950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12270/20000 - Train Loss: 0.6343 - Test Loss: 5.4432 - MSE: 5.4432 - MAE: 1.8947\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12271/20000 - Train Loss: 0.6342 - Test Loss: 5.4604 - MSE: 5.4604 - MAE: 1.8968\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12272/20000 - Train Loss: 0.6342 - Test Loss: 5.4325 - MSE: 5.4325 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12273/20000 - Train Loss: 0.6342 - Test Loss: 5.4639 - MSE: 5.4639 - MAE: 1.8972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12274/20000 - Train Loss: 0.6341 - Test Loss: 5.4341 - MSE: 5.4341 - MAE: 1.8936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12275/20000 - Train Loss: 0.6341 - Test Loss: 5.4559 - MSE: 5.4559 - MAE: 1.8962\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12276/20000 - Train Loss: 0.6340 - Test Loss: 5.4441 - MSE: 5.4441 - MAE: 1.8948\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12277/20000 - Train Loss: 0.6340 - Test Loss: 5.4437 - MSE: 5.4437 - MAE: 1.8947\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12278/20000 - Train Loss: 0.6339 - Test Loss: 5.4540 - MSE: 5.4540 - MAE: 1.8960\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12279/20000 - Train Loss: 0.6339 - Test Loss: 5.4357 - MSE: 5.4357 - MAE: 1.8937\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12280/20000 - Train Loss: 0.6339 - Test Loss: 5.4572 - MSE: 5.4572 - MAE: 1.8963\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12281/20000 - Train Loss: 0.6338 - Test Loss: 5.4354 - MSE: 5.4354 - MAE: 1.8937\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12282/20000 - Train Loss: 0.6338 - Test Loss: 5.4527 - MSE: 5.4527 - MAE: 1.8958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12283/20000 - Train Loss: 0.6337 - Test Loss: 5.4413 - MSE: 5.4413 - MAE: 1.8944\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12284/20000 - Train Loss: 0.6337 - Test Loss: 5.4445 - MSE: 5.4445 - MAE: 1.8948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12285/20000 - Train Loss: 0.6337 - Test Loss: 5.4481 - MSE: 5.4481 - MAE: 1.8952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12286/20000 - Train Loss: 0.6336 - Test Loss: 5.4379 - MSE: 5.4379 - MAE: 1.8940\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12287/20000 - Train Loss: 0.6336 - Test Loss: 5.4514 - MSE: 5.4514 - MAE: 1.8956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12288/20000 - Train Loss: 0.6336 - Test Loss: 5.4360 - MSE: 5.4360 - MAE: 1.8937\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12289/20000 - Train Loss: 0.6335 - Test Loss: 5.4497 - MSE: 5.4497 - MAE: 1.8954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12290/20000 - Train Loss: 0.6335 - Test Loss: 5.4386 - MSE: 5.4386 - MAE: 1.8940\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 12291/20000 - Train Loss: 0.6334 - Test Loss: 5.4447 - MSE: 5.4447 - MAE: 1.8948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12292/20000 - Train Loss: 0.6334 - Test Loss: 5.4430 - MSE: 5.4430 - MAE: 1.8946\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12293/20000 - Train Loss: 0.6333 - Test Loss: 5.4394 - MSE: 5.4394 - MAE: 1.8941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12294/20000 - Train Loss: 0.6333 - Test Loss: 5.4461 - MSE: 5.4461 - MAE: 1.8949\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12295/20000 - Train Loss: 0.6333 - Test Loss: 5.4366 - MSE: 5.4366 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12296/20000 - Train Loss: 0.6332 - Test Loss: 5.4463 - MSE: 5.4463 - MAE: 1.8949\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12297/20000 - Train Loss: 0.6332 - Test Loss: 5.4368 - MSE: 5.4368 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12298/20000 - Train Loss: 0.6331 - Test Loss: 5.4437 - MSE: 5.4437 - MAE: 1.8946\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12299/20000 - Train Loss: 0.6331 - Test Loss: 5.4390 - MSE: 5.4390 - MAE: 1.8940\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12300/20000 - Train Loss: 0.6331 - Test Loss: 5.4401 - MSE: 5.4401 - MAE: 1.8941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12301/20000 - Train Loss: 0.6330 - Test Loss: 5.4413 - MSE: 5.4413 - MAE: 1.8943\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12302/20000 - Train Loss: 0.6330 - Test Loss: 5.4371 - MSE: 5.4371 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12303/20000 - Train Loss: 0.6330 - Test Loss: 5.4424 - MSE: 5.4424 - MAE: 1.8944\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 12304/20000 - Train Loss: 0.6329 - Test Loss: 5.4358 - MSE: 5.4358 - MAE: 1.8936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12305/20000 - Train Loss: 0.6329 - Test Loss: 5.4417 - MSE: 5.4417 - MAE: 1.8943\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12306/20000 - Train Loss: 0.6328 - Test Loss: 5.4361 - MSE: 5.4361 - MAE: 1.8936\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12307/20000 - Train Loss: 0.6328 - Test Loss: 5.4398 - MSE: 5.4398 - MAE: 1.8941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12308/20000 - Train Loss: 0.6328 - Test Loss: 5.4373 - MSE: 5.4373 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12309/20000 - Train Loss: 0.6327 - Test Loss: 5.4374 - MSE: 5.4374 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12310/20000 - Train Loss: 0.6327 - Test Loss: 5.4383 - MSE: 5.4383 - MAE: 1.8939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12311/20000 - Train Loss: 0.6326 - Test Loss: 5.4355 - MSE: 5.4355 - MAE: 1.8935\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12312/20000 - Train Loss: 0.6326 - Test Loss: 5.4387 - MSE: 5.4387 - MAE: 1.8939\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12313/20000 - Train Loss: 0.6326 - Test Loss: 5.4345 - MSE: 5.4345 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12314/20000 - Train Loss: 0.6325 - Test Loss: 5.4381 - MSE: 5.4381 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 12315/20000 - Train Loss: 0.6325 - Test Loss: 5.4344 - MSE: 5.4344 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 12316/20000 - Train Loss: 0.6324 - Test Loss: 5.4368 - MSE: 5.4368 - MAE: 1.8937\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12317/20000 - Train Loss: 0.6324 - Test Loss: 5.4347 - MSE: 5.4347 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12318/20000 - Train Loss: 0.6324 - Test Loss: 5.4352 - MSE: 5.4352 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12319/20000 - Train Loss: 0.6323 - Test Loss: 5.4351 - MSE: 5.4351 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12320/20000 - Train Loss: 0.6323 - Test Loss: 5.4338 - MSE: 5.4338 - MAE: 1.8933\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12321/20000 - Train Loss: 0.6322 - Test Loss: 5.4352 - MSE: 5.4352 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12322/20000 - Train Loss: 0.6322 - Test Loss: 5.4328 - MSE: 5.4328 - MAE: 1.8931\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12323/20000 - Train Loss: 0.6322 - Test Loss: 5.4348 - MSE: 5.4348 - MAE: 1.8934\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12324/20000 - Train Loss: 0.6321 - Test Loss: 5.4323 - MSE: 5.4323 - MAE: 1.8931\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12325/20000 - Train Loss: 0.6321 - Test Loss: 5.4340 - MSE: 5.4340 - MAE: 1.8933\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12326/20000 - Train Loss: 0.6320 - Test Loss: 5.4322 - MSE: 5.4322 - MAE: 1.8930\n",
      "2/2 [==============================] - 0s 988us/step\n",
      "Epoch 12327/20000 - Train Loss: 0.6320 - Test Loss: 5.4329 - MSE: 5.4329 - MAE: 1.8931\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12328/20000 - Train Loss: 0.6320 - Test Loss: 5.4321 - MSE: 5.4321 - MAE: 1.8930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12329/20000 - Train Loss: 0.6319 - Test Loss: 5.4319 - MSE: 5.4319 - MAE: 1.8930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12330/20000 - Train Loss: 0.6319 - Test Loss: 5.4320 - MSE: 5.4320 - MAE: 1.8930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12331/20000 - Train Loss: 0.6318 - Test Loss: 5.4309 - MSE: 5.4309 - MAE: 1.8928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12332/20000 - Train Loss: 0.6318 - Test Loss: 5.4317 - MSE: 5.4317 - MAE: 1.8929\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12333/20000 - Train Loss: 0.6318 - Test Loss: 5.4302 - MSE: 5.4302 - MAE: 1.8927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12334/20000 - Train Loss: 0.6317 - Test Loss: 5.4312 - MSE: 5.4312 - MAE: 1.8929\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12335/20000 - Train Loss: 0.6317 - Test Loss: 5.4296 - MSE: 5.4296 - MAE: 1.8927\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12336/20000 - Train Loss: 0.6316 - Test Loss: 5.4305 - MSE: 5.4305 - MAE: 1.8928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12337/20000 - Train Loss: 0.6316 - Test Loss: 5.4292 - MSE: 5.4292 - MAE: 1.8926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12338/20000 - Train Loss: 0.6316 - Test Loss: 5.4297 - MSE: 5.4297 - MAE: 1.8926\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 12339/20000 - Train Loss: 0.6315 - Test Loss: 5.4290 - MSE: 5.4290 - MAE: 1.8926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12340/20000 - Train Loss: 0.6315 - Test Loss: 5.4288 - MSE: 5.4288 - MAE: 1.8925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12341/20000 - Train Loss: 0.6314 - Test Loss: 5.4287 - MSE: 5.4287 - MAE: 1.8925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12342/20000 - Train Loss: 0.6314 - Test Loss: 5.4280 - MSE: 5.4280 - MAE: 1.8924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12343/20000 - Train Loss: 0.6314 - Test Loss: 5.4283 - MSE: 5.4283 - MAE: 1.8924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12344/20000 - Train Loss: 0.6313 - Test Loss: 5.4273 - MSE: 5.4273 - MAE: 1.8923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12345/20000 - Train Loss: 0.6313 - Test Loss: 5.4278 - MSE: 5.4278 - MAE: 1.8924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12346/20000 - Train Loss: 0.6313 - Test Loss: 5.4268 - MSE: 5.4268 - MAE: 1.8922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12347/20000 - Train Loss: 0.6312 - Test Loss: 5.4272 - MSE: 5.4272 - MAE: 1.8923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12348/20000 - Train Loss: 0.6312 - Test Loss: 5.4263 - MSE: 5.4263 - MAE: 1.8922\n",
      "2/2 [==============================] - 0s 975us/step\n",
      "Epoch 12349/20000 - Train Loss: 0.6311 - Test Loss: 5.4265 - MSE: 5.4265 - MAE: 1.8922\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12350/20000 - Train Loss: 0.6311 - Test Loss: 5.4258 - MSE: 5.4258 - MAE: 1.8921\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12351/20000 - Train Loss: 0.6311 - Test Loss: 5.4259 - MSE: 5.4259 - MAE: 1.8921\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12352/20000 - Train Loss: 0.6310 - Test Loss: 5.4253 - MSE: 5.4253 - MAE: 1.8920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12353/20000 - Train Loss: 0.6310 - Test Loss: 5.4252 - MSE: 5.4252 - MAE: 1.8920\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12354/20000 - Train Loss: 0.6309 - Test Loss: 5.4248 - MSE: 5.4248 - MAE: 1.8919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12355/20000 - Train Loss: 0.6309 - Test Loss: 5.4246 - MSE: 5.4246 - MAE: 1.8919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12356/20000 - Train Loss: 0.6309 - Test Loss: 5.4242 - MSE: 5.4242 - MAE: 1.8919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12357/20000 - Train Loss: 0.6308 - Test Loss: 5.4240 - MSE: 5.4240 - MAE: 1.8918\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12358/20000 - Train Loss: 0.6308 - Test Loss: 5.4237 - MSE: 5.4237 - MAE: 1.8918\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12359/20000 - Train Loss: 0.6307 - Test Loss: 5.4234 - MSE: 5.4234 - MAE: 1.8917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12360/20000 - Train Loss: 0.6307 - Test Loss: 5.4232 - MSE: 5.4232 - MAE: 1.8917\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12361/20000 - Train Loss: 0.6307 - Test Loss: 5.4228 - MSE: 5.4228 - MAE: 1.8916\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12362/20000 - Train Loss: 0.6306 - Test Loss: 5.4226 - MSE: 5.4226 - MAE: 1.8916\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12363/20000 - Train Loss: 0.6306 - Test Loss: 5.4223 - MSE: 5.4223 - MAE: 1.8916\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12364/20000 - Train Loss: 0.6305 - Test Loss: 5.4220 - MSE: 5.4220 - MAE: 1.8915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12365/20000 - Train Loss: 0.6305 - Test Loss: 5.4217 - MSE: 5.4217 - MAE: 1.8915\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12366/20000 - Train Loss: 0.6305 - Test Loss: 5.4214 - MSE: 5.4214 - MAE: 1.8914\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12367/20000 - Train Loss: 0.6304 - Test Loss: 5.4212 - MSE: 5.4212 - MAE: 1.8914\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12368/20000 - Train Loss: 0.6304 - Test Loss: 5.4208 - MSE: 5.4208 - MAE: 1.8914\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12369/20000 - Train Loss: 0.6303 - Test Loss: 5.4206 - MSE: 5.4206 - MAE: 1.8913\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12370/20000 - Train Loss: 0.6303 - Test Loss: 5.4202 - MSE: 5.4202 - MAE: 1.8913\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12371/20000 - Train Loss: 0.6303 - Test Loss: 5.4201 - MSE: 5.4201 - MAE: 1.8912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12372/20000 - Train Loss: 0.6302 - Test Loss: 5.4196 - MSE: 5.4196 - MAE: 1.8912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12373/20000 - Train Loss: 0.6302 - Test Loss: 5.4195 - MSE: 5.4195 - MAE: 1.8912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12374/20000 - Train Loss: 0.6301 - Test Loss: 5.4191 - MSE: 5.4191 - MAE: 1.8911\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12375/20000 - Train Loss: 0.6301 - Test Loss: 5.4189 - MSE: 5.4189 - MAE: 1.8911\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12376/20000 - Train Loss: 0.6301 - Test Loss: 5.4186 - MSE: 5.4186 - MAE: 1.8910\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12377/20000 - Train Loss: 0.6300 - Test Loss: 5.4183 - MSE: 5.4183 - MAE: 1.8910\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12378/20000 - Train Loss: 0.6300 - Test Loss: 5.4180 - MSE: 5.4180 - MAE: 1.8909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12379/20000 - Train Loss: 0.6299 - Test Loss: 5.4177 - MSE: 5.4177 - MAE: 1.8909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12380/20000 - Train Loss: 0.6299 - Test Loss: 5.4174 - MSE: 5.4174 - MAE: 1.8909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12381/20000 - Train Loss: 0.6299 - Test Loss: 5.4172 - MSE: 5.4172 - MAE: 1.8908\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12382/20000 - Train Loss: 0.6298 - Test Loss: 5.4169 - MSE: 5.4169 - MAE: 1.8908\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12383/20000 - Train Loss: 0.6298 - Test Loss: 5.4166 - MSE: 5.4166 - MAE: 1.8907\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12384/20000 - Train Loss: 0.6297 - Test Loss: 5.4163 - MSE: 5.4163 - MAE: 1.8907\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12385/20000 - Train Loss: 0.6297 - Test Loss: 5.4160 - MSE: 5.4160 - MAE: 1.8906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12386/20000 - Train Loss: 0.6297 - Test Loss: 5.4157 - MSE: 5.4157 - MAE: 1.8906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12387/20000 - Train Loss: 0.6296 - Test Loss: 5.4154 - MSE: 5.4154 - MAE: 1.8906\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12388/20000 - Train Loss: 0.6296 - Test Loss: 5.4152 - MSE: 5.4152 - MAE: 1.8905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12389/20000 - Train Loss: 0.6295 - Test Loss: 5.4148 - MSE: 5.4148 - MAE: 1.8905\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12390/20000 - Train Loss: 0.6295 - Test Loss: 5.4147 - MSE: 5.4147 - MAE: 1.8904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12391/20000 - Train Loss: 0.6295 - Test Loss: 5.4142 - MSE: 5.4142 - MAE: 1.8904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12392/20000 - Train Loss: 0.6294 - Test Loss: 5.4141 - MSE: 5.4141 - MAE: 1.8904\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12393/20000 - Train Loss: 0.6294 - Test Loss: 5.4136 - MSE: 5.4136 - MAE: 1.8903\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12394/20000 - Train Loss: 0.6294 - Test Loss: 5.4136 - MSE: 5.4136 - MAE: 1.8903\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12395/20000 - Train Loss: 0.6293 - Test Loss: 5.4130 - MSE: 5.4130 - MAE: 1.8902\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 12396/20000 - Train Loss: 0.6293 - Test Loss: 5.4130 - MSE: 5.4130 - MAE: 1.8902\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12397/20000 - Train Loss: 0.6292 - Test Loss: 5.4124 - MSE: 5.4124 - MAE: 1.8901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12398/20000 - Train Loss: 0.6292 - Test Loss: 5.4125 - MSE: 5.4125 - MAE: 1.8901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12399/20000 - Train Loss: 0.6292 - Test Loss: 5.4118 - MSE: 5.4118 - MAE: 1.8900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12400/20000 - Train Loss: 0.6291 - Test Loss: 5.4120 - MSE: 5.4120 - MAE: 1.8900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12401/20000 - Train Loss: 0.6291 - Test Loss: 5.4111 - MSE: 5.4111 - MAE: 1.8899\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12402/20000 - Train Loss: 0.6290 - Test Loss: 5.4115 - MSE: 5.4115 - MAE: 1.8900\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12403/20000 - Train Loss: 0.6290 - Test Loss: 5.4104 - MSE: 5.4104 - MAE: 1.8898\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12404/20000 - Train Loss: 0.6290 - Test Loss: 5.4112 - MSE: 5.4112 - MAE: 1.8899\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12405/20000 - Train Loss: 0.6289 - Test Loss: 5.4096 - MSE: 5.4096 - MAE: 1.8897\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12406/20000 - Train Loss: 0.6289 - Test Loss: 5.4109 - MSE: 5.4109 - MAE: 1.8899\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12407/20000 - Train Loss: 0.6288 - Test Loss: 5.4087 - MSE: 5.4087 - MAE: 1.8896\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12408/20000 - Train Loss: 0.6288 - Test Loss: 5.4107 - MSE: 5.4107 - MAE: 1.8898\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12409/20000 - Train Loss: 0.6288 - Test Loss: 5.4075 - MSE: 5.4075 - MAE: 1.8894\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12410/20000 - Train Loss: 0.6287 - Test Loss: 5.4109 - MSE: 5.4109 - MAE: 1.8898\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12411/20000 - Train Loss: 0.6287 - Test Loss: 5.4061 - MSE: 5.4061 - MAE: 1.8892\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12412/20000 - Train Loss: 0.6286 - Test Loss: 5.4115 - MSE: 5.4115 - MAE: 1.8899\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12413/20000 - Train Loss: 0.6286 - Test Loss: 5.4040 - MSE: 5.4040 - MAE: 1.8890\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12414/20000 - Train Loss: 0.6286 - Test Loss: 5.4129 - MSE: 5.4129 - MAE: 1.8900\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12415/20000 - Train Loss: 0.6285 - Test Loss: 5.4009 - MSE: 5.4009 - MAE: 1.8886\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12416/20000 - Train Loss: 0.6285 - Test Loss: 5.4155 - MSE: 5.4155 - MAE: 1.8903\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12417/20000 - Train Loss: 0.6285 - Test Loss: 5.3963 - MSE: 5.3963 - MAE: 1.8880\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12418/20000 - Train Loss: 0.6284 - Test Loss: 5.4203 - MSE: 5.4203 - MAE: 1.8909\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12419/20000 - Train Loss: 0.6284 - Test Loss: 5.3888 - MSE: 5.3888 - MAE: 1.8870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12420/20000 - Train Loss: 0.6285 - Test Loss: 5.4290 - MSE: 5.4290 - MAE: 1.8919\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12421/20000 - Train Loss: 0.6285 - Test Loss: 5.3766 - MSE: 5.3766 - MAE: 1.8855\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12422/20000 - Train Loss: 0.6286 - Test Loss: 5.4444 - MSE: 5.4444 - MAE: 1.8938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12423/20000 - Train Loss: 0.6288 - Test Loss: 5.3560 - MSE: 5.3560 - MAE: 1.8829\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 12424/20000 - Train Loss: 0.6293 - Test Loss: 5.4722 - MSE: 5.4722 - MAE: 1.8970\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12425/20000 - Train Loss: 0.6300 - Test Loss: 5.3216 - MSE: 5.3216 - MAE: 1.8784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12426/20000 - Train Loss: 0.6313 - Test Loss: 5.5223 - MSE: 5.5223 - MAE: 1.9028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12427/20000 - Train Loss: 0.6337 - Test Loss: 5.2652 - MSE: 5.2652 - MAE: 1.8707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12428/20000 - Train Loss: 0.6376 - Test Loss: 5.6118 - MSE: 5.6118 - MAE: 1.9125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12429/20000 - Train Loss: 0.6439 - Test Loss: 5.1796 - MSE: 5.1796 - MAE: 1.8581\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12430/20000 - Train Loss: 0.6537 - Test Loss: 5.7612 - MSE: 5.7612 - MAE: 1.9293\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12431/20000 - Train Loss: 0.6670 - Test Loss: 5.0754 - MSE: 5.0754 - MAE: 1.8407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12432/20000 - Train Loss: 0.6811 - Test Loss: 5.9426 - MSE: 5.9426 - MAE: 1.9511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12433/20000 - Train Loss: 0.6888 - Test Loss: 5.0129 - MSE: 5.0129 - MAE: 1.8298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12434/20000 - Train Loss: 0.6811 - Test Loss: 5.9425 - MSE: 5.9425 - MAE: 1.9510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12435/20000 - Train Loss: 0.6580 - Test Loss: 5.1073 - MSE: 5.1073 - MAE: 1.8464\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12436/20000 - Train Loss: 0.6346 - Test Loss: 5.5766 - MSE: 5.5766 - MAE: 1.9086\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 12437/20000 - Train Loss: 0.6280 - Test Loss: 5.4391 - MSE: 5.4391 - MAE: 1.8930\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12438/20000 - Train Loss: 0.6389 - Test Loss: 5.2099 - MSE: 5.2099 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12439/20000 - Train Loss: 0.6524 - Test Loss: 5.7507 - MSE: 5.7507 - MAE: 1.9279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12440/20000 - Train Loss: 0.6534 - Test Loss: 5.1250 - MSE: 5.1250 - MAE: 1.8494\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12441/20000 - Train Loss: 0.6411 - Test Loss: 5.6511 - MSE: 5.6511 - MAE: 1.9165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12442/20000 - Train Loss: 0.6291 - Test Loss: 5.3235 - MSE: 5.3235 - MAE: 1.8785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12443/20000 - Train Loss: 0.6292 - Test Loss: 5.3211 - MSE: 5.3211 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 12444/20000 - Train Loss: 0.6377 - Test Loss: 5.6156 - MSE: 5.6156 - MAE: 1.9127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12445/20000 - Train Loss: 0.6424 - Test Loss: 5.1817 - MSE: 5.1817 - MAE: 1.8584\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12446/20000 - Train Loss: 0.6375 - Test Loss: 5.6137 - MSE: 5.6137 - MAE: 1.9125\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12447/20000 - Train Loss: 0.6295 - Test Loss: 5.3106 - MSE: 5.3106 - MAE: 1.8768\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 12448/20000 - Train Loss: 0.6276 - Test Loss: 5.3625 - MSE: 5.3625 - MAE: 1.8835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12449/20000 - Train Loss: 0.6322 - Test Loss: 5.5454 - MSE: 5.5454 - MAE: 1.9051\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12450/20000 - Train Loss: 0.6358 - Test Loss: 5.2288 - MSE: 5.2288 - MAE: 1.8654\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12451/20000 - Train Loss: 0.6336 - Test Loss: 5.5656 - MSE: 5.5656 - MAE: 1.9073\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12452/20000 - Train Loss: 0.6287 - Test Loss: 5.3218 - MSE: 5.3218 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12453/20000 - Train Loss: 0.6272 - Test Loss: 5.3760 - MSE: 5.3760 - MAE: 1.8852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12454/20000 - Train Loss: 0.6298 - Test Loss: 5.5049 - MSE: 5.5049 - MAE: 1.9005\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12455/20000 - Train Loss: 0.6321 - Test Loss: 5.2648 - MSE: 5.2648 - MAE: 1.8705\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 12456/20000 - Train Loss: 0.6308 - Test Loss: 5.5248 - MSE: 5.5248 - MAE: 1.9027\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12457/20000 - Train Loss: 0.6279 - Test Loss: 5.3362 - MSE: 5.3362 - MAE: 1.8801\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12458/20000 - Train Loss: 0.6270 - Test Loss: 5.3807 - MSE: 5.3807 - MAE: 1.8857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12459/20000 - Train Loss: 0.6285 - Test Loss: 5.4774 - MSE: 5.4774 - MAE: 1.8973\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 12460/20000 - Train Loss: 0.6299 - Test Loss: 5.2925 - MSE: 5.2925 - MAE: 1.8743\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12461/20000 - Train Loss: 0.6291 - Test Loss: 5.4933 - MSE: 5.4933 - MAE: 1.8991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12462/20000 - Train Loss: 0.6274 - Test Loss: 5.3480 - MSE: 5.3480 - MAE: 1.8816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12463/20000 - Train Loss: 0.6268 - Test Loss: 5.3835 - MSE: 5.3835 - MAE: 1.8861\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12464/20000 - Train Loss: 0.6277 - Test Loss: 5.4565 - MSE: 5.4565 - MAE: 1.8949\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12465/20000 - Train Loss: 0.6285 - Test Loss: 5.3141 - MSE: 5.3141 - MAE: 1.8772\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12466/20000 - Train Loss: 0.6280 - Test Loss: 5.4694 - MSE: 5.4694 - MAE: 1.8963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12467/20000 - Train Loss: 0.6270 - Test Loss: 5.3564 - MSE: 5.3564 - MAE: 1.8826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12468/20000 - Train Loss: 0.6266 - Test Loss: 5.3861 - MSE: 5.3861 - MAE: 1.8863\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12469/20000 - Train Loss: 0.6271 - Test Loss: 5.4397 - MSE: 5.4397 - MAE: 1.8928\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12470/20000 - Train Loss: 0.6276 - Test Loss: 5.3310 - MSE: 5.3310 - MAE: 1.8793\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12471/20000 - Train Loss: 0.6273 - Test Loss: 5.4514 - MSE: 5.4514 - MAE: 1.8942\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12472/20000 - Train Loss: 0.6267 - Test Loss: 5.3616 - MSE: 5.3616 - MAE: 1.8832\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12473/20000 - Train Loss: 0.6264 - Test Loss: 5.3890 - MSE: 5.3890 - MAE: 1.8867\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12474/20000 - Train Loss: 0.6267 - Test Loss: 5.4256 - MSE: 5.4256 - MAE: 1.8911\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12475/20000 - Train Loss: 0.6270 - Test Loss: 5.3442 - MSE: 5.3442 - MAE: 1.8810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12476/20000 - Train Loss: 0.6268 - Test Loss: 5.4377 - MSE: 5.4377 - MAE: 1.8925\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12477/20000 - Train Loss: 0.6265 - Test Loss: 5.3648 - MSE: 5.3648 - MAE: 1.8836\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12478/20000 - Train Loss: 0.6262 - Test Loss: 5.3917 - MSE: 5.3917 - MAE: 1.8870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12479/20000 - Train Loss: 0.6263 - Test Loss: 5.4140 - MSE: 5.4140 - MAE: 1.8897\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12480/20000 - Train Loss: 0.6265 - Test Loss: 5.3546 - MSE: 5.3546 - MAE: 1.8823\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12481/20000 - Train Loss: 0.6265 - Test Loss: 5.4269 - MSE: 5.4269 - MAE: 1.8912\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12482/20000 - Train Loss: 0.6262 - Test Loss: 5.3668 - MSE: 5.3668 - MAE: 1.8838\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12483/20000 - Train Loss: 0.6261 - Test Loss: 5.3939 - MSE: 5.3939 - MAE: 1.8872\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12484/20000 - Train Loss: 0.6261 - Test Loss: 5.4042 - MSE: 5.4042 - MAE: 1.8884\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12485/20000 - Train Loss: 0.6262 - Test Loss: 5.3629 - MSE: 5.3629 - MAE: 1.8833\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12486/20000 - Train Loss: 0.6262 - Test Loss: 5.4179 - MSE: 5.4179 - MAE: 1.8901\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12487/20000 - Train Loss: 0.6260 - Test Loss: 5.3682 - MSE: 5.3682 - MAE: 1.8840\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12488/20000 - Train Loss: 0.6259 - Test Loss: 5.3954 - MSE: 5.3954 - MAE: 1.8873\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12489/20000 - Train Loss: 0.6259 - Test Loss: 5.3962 - MSE: 5.3962 - MAE: 1.8874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12490/20000 - Train Loss: 0.6259 - Test Loss: 5.3696 - MSE: 5.3696 - MAE: 1.8841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12491/20000 - Train Loss: 0.6259 - Test Loss: 5.4102 - MSE: 5.4102 - MAE: 1.8891\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12492/20000 - Train Loss: 0.6258 - Test Loss: 5.3694 - MSE: 5.3694 - MAE: 1.8841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12493/20000 - Train Loss: 0.6257 - Test Loss: 5.3961 - MSE: 5.3961 - MAE: 1.8874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12494/20000 - Train Loss: 0.6257 - Test Loss: 5.3895 - MSE: 5.3895 - MAE: 1.8866\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12495/20000 - Train Loss: 0.6257 - Test Loss: 5.3749 - MSE: 5.3749 - MAE: 1.8848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12496/20000 - Train Loss: 0.6257 - Test Loss: 5.4032 - MSE: 5.4032 - MAE: 1.8882\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12497/20000 - Train Loss: 0.6256 - Test Loss: 5.3708 - MSE: 5.3708 - MAE: 1.8842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12498/20000 - Train Loss: 0.6256 - Test Loss: 5.3958 - MSE: 5.3958 - MAE: 1.8873\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12499/20000 - Train Loss: 0.6255 - Test Loss: 5.3843 - MSE: 5.3843 - MAE: 1.8859\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 12500/20000 - Train Loss: 0.6255 - Test Loss: 5.3791 - MSE: 5.3791 - MAE: 1.8852\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12501/20000 - Train Loss: 0.6255 - Test Loss: 5.3969 - MSE: 5.3969 - MAE: 1.8874\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12502/20000 - Train Loss: 0.6255 - Test Loss: 5.3724 - MSE: 5.3724 - MAE: 1.8844\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 12503/20000 - Train Loss: 0.6254 - Test Loss: 5.3945 - MSE: 5.3945 - MAE: 1.8871\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12504/20000 - Train Loss: 0.6253 - Test Loss: 5.3804 - MSE: 5.3804 - MAE: 1.8854\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12505/20000 - Train Loss: 0.6253 - Test Loss: 5.3821 - MSE: 5.3821 - MAE: 1.8856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12506/20000 - Train Loss: 0.6253 - Test Loss: 5.3913 - MSE: 5.3913 - MAE: 1.8867\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 12507/20000 - Train Loss: 0.6253 - Test Loss: 5.3742 - MSE: 5.3742 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12508/20000 - Train Loss: 0.6252 - Test Loss: 5.3924 - MSE: 5.3924 - MAE: 1.8868\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12509/20000 - Train Loss: 0.6252 - Test Loss: 5.3777 - MSE: 5.3777 - MAE: 1.8850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12510/20000 - Train Loss: 0.6251 - Test Loss: 5.3840 - MSE: 5.3840 - MAE: 1.8858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12511/20000 - Train Loss: 0.6251 - Test Loss: 5.3862 - MSE: 5.3862 - MAE: 1.8860\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12512/20000 - Train Loss: 0.6251 - Test Loss: 5.3762 - MSE: 5.3762 - MAE: 1.8848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12513/20000 - Train Loss: 0.6250 - Test Loss: 5.3895 - MSE: 5.3895 - MAE: 1.8864\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12514/20000 - Train Loss: 0.6250 - Test Loss: 5.3762 - MSE: 5.3762 - MAE: 1.8848\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12515/20000 - Train Loss: 0.6250 - Test Loss: 5.3848 - MSE: 5.3848 - MAE: 1.8858\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12516/20000 - Train Loss: 0.6249 - Test Loss: 5.3819 - MSE: 5.3819 - MAE: 1.8855\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12517/20000 - Train Loss: 0.6249 - Test Loss: 5.3779 - MSE: 5.3779 - MAE: 1.8850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12518/20000 - Train Loss: 0.6249 - Test Loss: 5.3861 - MSE: 5.3861 - MAE: 1.8860\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12519/20000 - Train Loss: 0.6248 - Test Loss: 5.3756 - MSE: 5.3756 - MAE: 1.8847\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12520/20000 - Train Loss: 0.6248 - Test Loss: 5.3843 - MSE: 5.3843 - MAE: 1.8857\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12521/20000 - Train Loss: 0.6248 - Test Loss: 5.3787 - MSE: 5.3787 - MAE: 1.8850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12522/20000 - Train Loss: 0.6247 - Test Loss: 5.3791 - MSE: 5.3791 - MAE: 1.8851\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12523/20000 - Train Loss: 0.6247 - Test Loss: 5.3827 - MSE: 5.3827 - MAE: 1.8855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12524/20000 - Train Loss: 0.6247 - Test Loss: 5.3756 - MSE: 5.3756 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12525/20000 - Train Loss: 0.6246 - Test Loss: 5.3830 - MSE: 5.3830 - MAE: 1.8855\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12526/20000 - Train Loss: 0.6246 - Test Loss: 5.3764 - MSE: 5.3764 - MAE: 1.8847\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12527/20000 - Train Loss: 0.6245 - Test Loss: 5.3797 - MSE: 5.3797 - MAE: 1.8851\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12528/20000 - Train Loss: 0.6245 - Test Loss: 5.3794 - MSE: 5.3794 - MAE: 1.8850\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12529/20000 - Train Loss: 0.6245 - Test Loss: 5.3760 - MSE: 5.3760 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12530/20000 - Train Loss: 0.6244 - Test Loss: 5.3810 - MSE: 5.3810 - MAE: 1.8852\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12531/20000 - Train Loss: 0.6244 - Test Loss: 5.3750 - MSE: 5.3750 - MAE: 1.8845\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12532/20000 - Train Loss: 0.6244 - Test Loss: 5.3794 - MSE: 5.3794 - MAE: 1.8850\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 12533/20000 - Train Loss: 0.6243 - Test Loss: 5.3766 - MSE: 5.3766 - MAE: 1.8847\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12534/20000 - Train Loss: 0.6243 - Test Loss: 5.3764 - MSE: 5.3764 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12535/20000 - Train Loss: 0.6243 - Test Loss: 5.3784 - MSE: 5.3784 - MAE: 1.8849\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12536/20000 - Train Loss: 0.6242 - Test Loss: 5.3743 - MSE: 5.3743 - MAE: 1.8844\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12537/20000 - Train Loss: 0.6242 - Test Loss: 5.3784 - MSE: 5.3784 - MAE: 1.8848\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12538/20000 - Train Loss: 0.6242 - Test Loss: 5.3745 - MSE: 5.3745 - MAE: 1.8844\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12539/20000 - Train Loss: 0.6241 - Test Loss: 5.3764 - MSE: 5.3764 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 12540/20000 - Train Loss: 0.6241 - Test Loss: 5.3758 - MSE: 5.3758 - MAE: 1.8845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12541/20000 - Train Loss: 0.6241 - Test Loss: 5.3742 - MSE: 5.3742 - MAE: 1.8843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12542/20000 - Train Loss: 0.6240 - Test Loss: 5.3765 - MSE: 5.3765 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12543/20000 - Train Loss: 0.6240 - Test Loss: 5.3732 - MSE: 5.3732 - MAE: 1.8842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12544/20000 - Train Loss: 0.6240 - Test Loss: 5.3757 - MSE: 5.3757 - MAE: 1.8845\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12545/20000 - Train Loss: 0.6239 - Test Loss: 5.3736 - MSE: 5.3736 - MAE: 1.8842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12546/20000 - Train Loss: 0.6239 - Test Loss: 5.3740 - MSE: 5.3740 - MAE: 1.8842\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12547/20000 - Train Loss: 0.6239 - Test Loss: 5.3743 - MSE: 5.3743 - MAE: 1.8843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12548/20000 - Train Loss: 0.6238 - Test Loss: 5.3725 - MSE: 5.3725 - MAE: 1.8840\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12549/20000 - Train Loss: 0.6238 - Test Loss: 5.3744 - MSE: 5.3744 - MAE: 1.8843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12550/20000 - Train Loss: 0.6237 - Test Loss: 5.3720 - MSE: 5.3720 - MAE: 1.8839\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12551/20000 - Train Loss: 0.6237 - Test Loss: 5.3734 - MSE: 5.3734 - MAE: 1.8841\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12552/20000 - Train Loss: 0.6237 - Test Loss: 5.3723 - MSE: 5.3723 - MAE: 1.8840\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 12553/20000 - Train Loss: 0.6236 - Test Loss: 5.3720 - MSE: 5.3720 - MAE: 1.8839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12554/20000 - Train Loss: 0.6236 - Test Loss: 5.3726 - MSE: 5.3726 - MAE: 1.8840\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12555/20000 - Train Loss: 0.6236 - Test Loss: 5.3710 - MSE: 5.3710 - MAE: 1.8838\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12556/20000 - Train Loss: 0.6235 - Test Loss: 5.3723 - MSE: 5.3723 - MAE: 1.8839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12557/20000 - Train Loss: 0.6235 - Test Loss: 5.3706 - MSE: 5.3706 - MAE: 1.8837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12558/20000 - Train Loss: 0.6235 - Test Loss: 5.3714 - MSE: 5.3714 - MAE: 1.8838\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 12559/20000 - Train Loss: 0.6234 - Test Loss: 5.3706 - MSE: 5.3706 - MAE: 1.8837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12560/20000 - Train Loss: 0.6234 - Test Loss: 5.3703 - MSE: 5.3703 - MAE: 1.8837\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12561/20000 - Train Loss: 0.6234 - Test Loss: 5.3706 - MSE: 5.3706 - MAE: 1.8837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12562/20000 - Train Loss: 0.6233 - Test Loss: 5.3694 - MSE: 5.3694 - MAE: 1.8835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12563/20000 - Train Loss: 0.6233 - Test Loss: 5.3703 - MSE: 5.3703 - MAE: 1.8836\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 12564/20000 - Train Loss: 0.6233 - Test Loss: 5.3690 - MSE: 5.3690 - MAE: 1.8835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12565/20000 - Train Loss: 0.6232 - Test Loss: 5.3695 - MSE: 5.3695 - MAE: 1.8835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12566/20000 - Train Loss: 0.6232 - Test Loss: 5.3689 - MSE: 5.3689 - MAE: 1.8834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12567/20000 - Train Loss: 0.6232 - Test Loss: 5.3686 - MSE: 5.3686 - MAE: 1.8834\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12568/20000 - Train Loss: 0.6231 - Test Loss: 5.3687 - MSE: 5.3687 - MAE: 1.8834\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12569/20000 - Train Loss: 0.6231 - Test Loss: 5.3678 - MSE: 5.3678 - MAE: 1.8833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12570/20000 - Train Loss: 0.6231 - Test Loss: 5.3683 - MSE: 5.3683 - MAE: 1.8833\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12571/20000 - Train Loss: 0.6230 - Test Loss: 5.3674 - MSE: 5.3674 - MAE: 1.8832\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12572/20000 - Train Loss: 0.6230 - Test Loss: 5.3676 - MSE: 5.3676 - MAE: 1.8832\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12573/20000 - Train Loss: 0.6229 - Test Loss: 5.3672 - MSE: 5.3672 - MAE: 1.8832\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12574/20000 - Train Loss: 0.6229 - Test Loss: 5.3668 - MSE: 5.3668 - MAE: 1.8831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12575/20000 - Train Loss: 0.6229 - Test Loss: 5.3669 - MSE: 5.3669 - MAE: 1.8831\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12576/20000 - Train Loss: 0.6228 - Test Loss: 5.3662 - MSE: 5.3662 - MAE: 1.8830\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12577/20000 - Train Loss: 0.6228 - Test Loss: 5.3664 - MSE: 5.3664 - MAE: 1.8830\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12578/20000 - Train Loss: 0.6228 - Test Loss: 5.3657 - MSE: 5.3657 - MAE: 1.8829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12579/20000 - Train Loss: 0.6227 - Test Loss: 5.3659 - MSE: 5.3659 - MAE: 1.8829\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12580/20000 - Train Loss: 0.6227 - Test Loss: 5.3653 - MSE: 5.3653 - MAE: 1.8829\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12581/20000 - Train Loss: 0.6227 - Test Loss: 5.3652 - MSE: 5.3652 - MAE: 1.8828\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12582/20000 - Train Loss: 0.6226 - Test Loss: 5.3650 - MSE: 5.3650 - MAE: 1.8828\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12583/20000 - Train Loss: 0.6226 - Test Loss: 5.3645 - MSE: 5.3645 - MAE: 1.8827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12584/20000 - Train Loss: 0.6226 - Test Loss: 5.3646 - MSE: 5.3646 - MAE: 1.8827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12585/20000 - Train Loss: 0.6225 - Test Loss: 5.3640 - MSE: 5.3640 - MAE: 1.8827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12586/20000 - Train Loss: 0.6225 - Test Loss: 5.3640 - MSE: 5.3640 - MAE: 1.8826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12587/20000 - Train Loss: 0.6225 - Test Loss: 5.3637 - MSE: 5.3637 - MAE: 1.8826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12588/20000 - Train Loss: 0.6224 - Test Loss: 5.3634 - MSE: 5.3634 - MAE: 1.8826\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12589/20000 - Train Loss: 0.6224 - Test Loss: 5.3632 - MSE: 5.3632 - MAE: 1.8825\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12590/20000 - Train Loss: 0.6224 - Test Loss: 5.3628 - MSE: 5.3628 - MAE: 1.8825\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12591/20000 - Train Loss: 0.6223 - Test Loss: 5.3628 - MSE: 5.3628 - MAE: 1.8824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12592/20000 - Train Loss: 0.6223 - Test Loss: 5.3623 - MSE: 5.3623 - MAE: 1.8824\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 12593/20000 - Train Loss: 0.6222 - Test Loss: 5.3622 - MSE: 5.3622 - MAE: 1.8824\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12594/20000 - Train Loss: 0.6222 - Test Loss: 5.3619 - MSE: 5.3619 - MAE: 1.8823\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12595/20000 - Train Loss: 0.6222 - Test Loss: 5.3616 - MSE: 5.3616 - MAE: 1.8823\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12596/20000 - Train Loss: 0.6221 - Test Loss: 5.3615 - MSE: 5.3615 - MAE: 1.8822\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12597/20000 - Train Loss: 0.6221 - Test Loss: 5.3610 - MSE: 5.3610 - MAE: 1.8822\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12598/20000 - Train Loss: 0.6221 - Test Loss: 5.3610 - MSE: 5.3610 - MAE: 1.8822\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12599/20000 - Train Loss: 0.6220 - Test Loss: 5.3605 - MSE: 5.3605 - MAE: 1.8821\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12600/20000 - Train Loss: 0.6220 - Test Loss: 5.3605 - MSE: 5.3605 - MAE: 1.8821\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12601/20000 - Train Loss: 0.6220 - Test Loss: 5.3600 - MSE: 5.3600 - MAE: 1.8820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12602/20000 - Train Loss: 0.6219 - Test Loss: 5.3599 - MSE: 5.3599 - MAE: 1.8820\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12603/20000 - Train Loss: 0.6219 - Test Loss: 5.3596 - MSE: 5.3596 - MAE: 1.8819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12604/20000 - Train Loss: 0.6219 - Test Loss: 5.3593 - MSE: 5.3593 - MAE: 1.8819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12605/20000 - Train Loss: 0.6218 - Test Loss: 5.3592 - MSE: 5.3592 - MAE: 1.8819\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12606/20000 - Train Loss: 0.6218 - Test Loss: 5.3588 - MSE: 5.3588 - MAE: 1.8818\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12607/20000 - Train Loss: 0.6218 - Test Loss: 5.3587 - MSE: 5.3587 - MAE: 1.8818\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 12608/20000 - Train Loss: 0.6217 - Test Loss: 5.3582 - MSE: 5.3582 - MAE: 1.8817\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12609/20000 - Train Loss: 0.6217 - Test Loss: 5.3582 - MSE: 5.3582 - MAE: 1.8817\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12610/20000 - Train Loss: 0.6217 - Test Loss: 5.3578 - MSE: 5.3578 - MAE: 1.8817\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12611/20000 - Train Loss: 0.6216 - Test Loss: 5.3576 - MSE: 5.3576 - MAE: 1.8816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12612/20000 - Train Loss: 0.6216 - Test Loss: 5.3573 - MSE: 5.3573 - MAE: 1.8816\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12613/20000 - Train Loss: 0.6216 - Test Loss: 5.3571 - MSE: 5.3571 - MAE: 1.8815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12614/20000 - Train Loss: 0.6215 - Test Loss: 5.3568 - MSE: 5.3568 - MAE: 1.8815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12615/20000 - Train Loss: 0.6215 - Test Loss: 5.3566 - MSE: 5.3566 - MAE: 1.8815\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12616/20000 - Train Loss: 0.6214 - Test Loss: 5.3563 - MSE: 5.3563 - MAE: 1.8814\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12617/20000 - Train Loss: 0.6214 - Test Loss: 5.3561 - MSE: 5.3561 - MAE: 1.8814\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12618/20000 - Train Loss: 0.6214 - Test Loss: 5.3558 - MSE: 5.3558 - MAE: 1.8813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12619/20000 - Train Loss: 0.6213 - Test Loss: 5.3556 - MSE: 5.3556 - MAE: 1.8813\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12620/20000 - Train Loss: 0.6213 - Test Loss: 5.3553 - MSE: 5.3553 - MAE: 1.8813\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12621/20000 - Train Loss: 0.6213 - Test Loss: 5.3551 - MSE: 5.3551 - MAE: 1.8812\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12622/20000 - Train Loss: 0.6212 - Test Loss: 5.3548 - MSE: 5.3548 - MAE: 1.8812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12623/20000 - Train Loss: 0.6212 - Test Loss: 5.3545 - MSE: 5.3545 - MAE: 1.8811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12624/20000 - Train Loss: 0.6212 - Test Loss: 5.3543 - MSE: 5.3543 - MAE: 1.8811\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12625/20000 - Train Loss: 0.6211 - Test Loss: 5.3539 - MSE: 5.3539 - MAE: 1.8810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12626/20000 - Train Loss: 0.6211 - Test Loss: 5.3539 - MSE: 5.3539 - MAE: 1.8810\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12627/20000 - Train Loss: 0.6211 - Test Loss: 5.3534 - MSE: 5.3534 - MAE: 1.8810\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12628/20000 - Train Loss: 0.6210 - Test Loss: 5.3534 - MSE: 5.3534 - MAE: 1.8809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12629/20000 - Train Loss: 0.6210 - Test Loss: 5.3528 - MSE: 5.3528 - MAE: 1.8809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12630/20000 - Train Loss: 0.6210 - Test Loss: 5.3529 - MSE: 5.3529 - MAE: 1.8809\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12631/20000 - Train Loss: 0.6209 - Test Loss: 5.3523 - MSE: 5.3523 - MAE: 1.8808\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12632/20000 - Train Loss: 0.6209 - Test Loss: 5.3524 - MSE: 5.3524 - MAE: 1.8808\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12633/20000 - Train Loss: 0.6209 - Test Loss: 5.3518 - MSE: 5.3518 - MAE: 1.8807\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12634/20000 - Train Loss: 0.6208 - Test Loss: 5.3518 - MSE: 5.3518 - MAE: 1.8807\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12635/20000 - Train Loss: 0.6208 - Test Loss: 5.3514 - MSE: 5.3514 - MAE: 1.8806\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12636/20000 - Train Loss: 0.6207 - Test Loss: 5.3512 - MSE: 5.3512 - MAE: 1.8806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12637/20000 - Train Loss: 0.6207 - Test Loss: 5.3511 - MSE: 5.3511 - MAE: 1.8806\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12638/20000 - Train Loss: 0.6207 - Test Loss: 5.3506 - MSE: 5.3506 - MAE: 1.8805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12639/20000 - Train Loss: 0.6206 - Test Loss: 5.3507 - MSE: 5.3507 - MAE: 1.8805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12640/20000 - Train Loss: 0.6206 - Test Loss: 5.3500 - MSE: 5.3500 - MAE: 1.8804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12641/20000 - Train Loss: 0.6206 - Test Loss: 5.3502 - MSE: 5.3502 - MAE: 1.8804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12642/20000 - Train Loss: 0.6205 - Test Loss: 5.3495 - MSE: 5.3495 - MAE: 1.8803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12643/20000 - Train Loss: 0.6205 - Test Loss: 5.3497 - MSE: 5.3497 - MAE: 1.8803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12644/20000 - Train Loss: 0.6205 - Test Loss: 5.3490 - MSE: 5.3490 - MAE: 1.8802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12645/20000 - Train Loss: 0.6204 - Test Loss: 5.3491 - MSE: 5.3491 - MAE: 1.8802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12646/20000 - Train Loss: 0.6204 - Test Loss: 5.3485 - MSE: 5.3485 - MAE: 1.8802\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12647/20000 - Train Loss: 0.6204 - Test Loss: 5.3485 - MSE: 5.3485 - MAE: 1.8802\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12648/20000 - Train Loss: 0.6203 - Test Loss: 5.3481 - MSE: 5.3481 - MAE: 1.8801\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12649/20000 - Train Loss: 0.6203 - Test Loss: 5.3479 - MSE: 5.3479 - MAE: 1.8801\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12650/20000 - Train Loss: 0.6203 - Test Loss: 5.3476 - MSE: 5.3476 - MAE: 1.8800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12651/20000 - Train Loss: 0.6202 - Test Loss: 5.3474 - MSE: 5.3474 - MAE: 1.8800\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12652/20000 - Train Loss: 0.6202 - Test Loss: 5.3471 - MSE: 5.3471 - MAE: 1.8799\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12653/20000 - Train Loss: 0.6201 - Test Loss: 5.3469 - MSE: 5.3469 - MAE: 1.8799\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12654/20000 - Train Loss: 0.6201 - Test Loss: 5.3467 - MSE: 5.3467 - MAE: 1.8799\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12655/20000 - Train Loss: 0.6201 - Test Loss: 5.3463 - MSE: 5.3463 - MAE: 1.8798\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12656/20000 - Train Loss: 0.6200 - Test Loss: 5.3462 - MSE: 5.3462 - MAE: 1.8798\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12657/20000 - Train Loss: 0.6200 - Test Loss: 5.3458 - MSE: 5.3458 - MAE: 1.8797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12658/20000 - Train Loss: 0.6200 - Test Loss: 5.3457 - MSE: 5.3457 - MAE: 1.8797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12659/20000 - Train Loss: 0.6199 - Test Loss: 5.3453 - MSE: 5.3453 - MAE: 1.8796\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12660/20000 - Train Loss: 0.6199 - Test Loss: 5.3452 - MSE: 5.3452 - MAE: 1.8796\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 12661/20000 - Train Loss: 0.6199 - Test Loss: 5.3448 - MSE: 5.3448 - MAE: 1.8795\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 12662/20000 - Train Loss: 0.6198 - Test Loss: 5.3447 - MSE: 5.3447 - MAE: 1.8795\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12663/20000 - Train Loss: 0.6198 - Test Loss: 5.3442 - MSE: 5.3442 - MAE: 1.8795\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12664/20000 - Train Loss: 0.6198 - Test Loss: 5.3442 - MSE: 5.3442 - MAE: 1.8794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12665/20000 - Train Loss: 0.6197 - Test Loss: 5.3438 - MSE: 5.3438 - MAE: 1.8794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12666/20000 - Train Loss: 0.6197 - Test Loss: 5.3436 - MSE: 5.3436 - MAE: 1.8794\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12667/20000 - Train Loss: 0.6197 - Test Loss: 5.3433 - MSE: 5.3433 - MAE: 1.8793\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12668/20000 - Train Loss: 0.6196 - Test Loss: 5.3430 - MSE: 5.3430 - MAE: 1.8793\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 12669/20000 - Train Loss: 0.6196 - Test Loss: 5.3428 - MSE: 5.3428 - MAE: 1.8792\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12670/20000 - Train Loss: 0.6195 - Test Loss: 5.3425 - MSE: 5.3425 - MAE: 1.8792\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12671/20000 - Train Loss: 0.6195 - Test Loss: 5.3423 - MSE: 5.3423 - MAE: 1.8791\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12672/20000 - Train Loss: 0.6195 - Test Loss: 5.3420 - MSE: 5.3420 - MAE: 1.8791\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12673/20000 - Train Loss: 0.6194 - Test Loss: 5.3418 - MSE: 5.3418 - MAE: 1.8791\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12674/20000 - Train Loss: 0.6194 - Test Loss: 5.3416 - MSE: 5.3416 - MAE: 1.8790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12675/20000 - Train Loss: 0.6194 - Test Loss: 5.3411 - MSE: 5.3411 - MAE: 1.8790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12676/20000 - Train Loss: 0.6193 - Test Loss: 5.3412 - MSE: 5.3412 - MAE: 1.8790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12677/20000 - Train Loss: 0.6193 - Test Loss: 5.3405 - MSE: 5.3405 - MAE: 1.8789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12678/20000 - Train Loss: 0.6193 - Test Loss: 5.3408 - MSE: 5.3408 - MAE: 1.8789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12679/20000 - Train Loss: 0.6192 - Test Loss: 5.3399 - MSE: 5.3399 - MAE: 1.8788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12680/20000 - Train Loss: 0.6192 - Test Loss: 5.3404 - MSE: 5.3404 - MAE: 1.8788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12681/20000 - Train Loss: 0.6192 - Test Loss: 5.3393 - MSE: 5.3393 - MAE: 1.8787\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12682/20000 - Train Loss: 0.6191 - Test Loss: 5.3399 - MSE: 5.3399 - MAE: 1.8787\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12683/20000 - Train Loss: 0.6191 - Test Loss: 5.3387 - MSE: 5.3387 - MAE: 1.8786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12684/20000 - Train Loss: 0.6191 - Test Loss: 5.3394 - MSE: 5.3394 - MAE: 1.8787\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12685/20000 - Train Loss: 0.6190 - Test Loss: 5.3382 - MSE: 5.3382 - MAE: 1.8785\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12686/20000 - Train Loss: 0.6190 - Test Loss: 5.3390 - MSE: 5.3390 - MAE: 1.8786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12687/20000 - Train Loss: 0.6190 - Test Loss: 5.3376 - MSE: 5.3376 - MAE: 1.8784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12688/20000 - Train Loss: 0.6189 - Test Loss: 5.3385 - MSE: 5.3385 - MAE: 1.8785\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 12689/20000 - Train Loss: 0.6189 - Test Loss: 5.3371 - MSE: 5.3371 - MAE: 1.8783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12690/20000 - Train Loss: 0.6188 - Test Loss: 5.3380 - MSE: 5.3380 - MAE: 1.8784\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12691/20000 - Train Loss: 0.6188 - Test Loss: 5.3365 - MSE: 5.3365 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12692/20000 - Train Loss: 0.6188 - Test Loss: 5.3376 - MSE: 5.3376 - MAE: 1.8783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12693/20000 - Train Loss: 0.6187 - Test Loss: 5.3358 - MSE: 5.3358 - MAE: 1.8781\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12694/20000 - Train Loss: 0.6187 - Test Loss: 5.3373 - MSE: 5.3373 - MAE: 1.8783\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12695/20000 - Train Loss: 0.6187 - Test Loss: 5.3351 - MSE: 5.3351 - MAE: 1.8780\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12696/20000 - Train Loss: 0.6186 - Test Loss: 5.3370 - MSE: 5.3370 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12697/20000 - Train Loss: 0.6186 - Test Loss: 5.3344 - MSE: 5.3344 - MAE: 1.8779\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12698/20000 - Train Loss: 0.6186 - Test Loss: 5.3368 - MSE: 5.3368 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12699/20000 - Train Loss: 0.6185 - Test Loss: 5.3334 - MSE: 5.3334 - MAE: 1.8777\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12700/20000 - Train Loss: 0.6185 - Test Loss: 5.3369 - MSE: 5.3369 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 12701/20000 - Train Loss: 0.6185 - Test Loss: 5.3320 - MSE: 5.3320 - MAE: 1.8776\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12702/20000 - Train Loss: 0.6184 - Test Loss: 5.3375 - MSE: 5.3375 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12703/20000 - Train Loss: 0.6184 - Test Loss: 5.3302 - MSE: 5.3302 - MAE: 1.8773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12704/20000 - Train Loss: 0.6184 - Test Loss: 5.3385 - MSE: 5.3385 - MAE: 1.8783\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12705/20000 - Train Loss: 0.6183 - Test Loss: 5.3277 - MSE: 5.3277 - MAE: 1.8770\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12706/20000 - Train Loss: 0.6183 - Test Loss: 5.3405 - MSE: 5.3405 - MAE: 1.8786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12707/20000 - Train Loss: 0.6183 - Test Loss: 5.3241 - MSE: 5.3241 - MAE: 1.8765\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12708/20000 - Train Loss: 0.6182 - Test Loss: 5.3441 - MSE: 5.3441 - MAE: 1.8790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12709/20000 - Train Loss: 0.6182 - Test Loss: 5.3186 - MSE: 5.3186 - MAE: 1.8758\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 12710/20000 - Train Loss: 0.6182 - Test Loss: 5.3501 - MSE: 5.3501 - MAE: 1.8797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12711/20000 - Train Loss: 0.6182 - Test Loss: 5.3099 - MSE: 5.3099 - MAE: 1.8747\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12712/20000 - Train Loss: 0.6183 - Test Loss: 5.3603 - MSE: 5.3603 - MAE: 1.8809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12713/20000 - Train Loss: 0.6184 - Test Loss: 5.2962 - MSE: 5.2962 - MAE: 1.8729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12714/20000 - Train Loss: 0.6185 - Test Loss: 5.3777 - MSE: 5.3777 - MAE: 1.8830\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12715/20000 - Train Loss: 0.6189 - Test Loss: 5.2743 - MSE: 5.2743 - MAE: 1.8700\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12716/20000 - Train Loss: 0.6194 - Test Loss: 5.4074 - MSE: 5.4074 - MAE: 1.8865\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12717/20000 - Train Loss: 0.6203 - Test Loss: 5.2391 - MSE: 5.2391 - MAE: 1.8653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12718/20000 - Train Loss: 0.6218 - Test Loss: 5.4585 - MSE: 5.4585 - MAE: 1.8924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12719/20000 - Train Loss: 0.6243 - Test Loss: 5.1842 - MSE: 5.1842 - MAE: 1.8576\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12720/20000 - Train Loss: 0.6282 - Test Loss: 5.5448 - MSE: 5.5448 - MAE: 1.9018\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12721/20000 - Train Loss: 0.6343 - Test Loss: 5.1063 - MSE: 5.1063 - MAE: 1.8458\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12722/20000 - Train Loss: 0.6429 - Test Loss: 5.6772 - MSE: 5.6772 - MAE: 1.9170\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12723/20000 - Train Loss: 0.6535 - Test Loss: 5.0190 - MSE: 5.0190 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12724/20000 - Train Loss: 0.6633 - Test Loss: 5.8162 - MSE: 5.8162 - MAE: 1.9341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12725/20000 - Train Loss: 0.6668 - Test Loss: 4.9766 - MSE: 4.9766 - MAE: 1.8236\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12726/20000 - Train Loss: 0.6588 - Test Loss: 5.7878 - MSE: 5.7878 - MAE: 1.9307\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12727/20000 - Train Loss: 0.6407 - Test Loss: 5.0699 - MSE: 5.0699 - MAE: 1.8399\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12728/20000 - Train Loss: 0.6233 - Test Loss: 5.4842 - MSE: 5.4842 - MAE: 1.8951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12729/20000 - Train Loss: 0.6176 - Test Loss: 5.3450 - MSE: 5.3450 - MAE: 1.8789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12730/20000 - Train Loss: 0.6244 - Test Loss: 5.1766 - MSE: 5.1766 - MAE: 1.8564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12731/20000 - Train Loss: 0.6348 - Test Loss: 5.6109 - MSE: 5.6109 - MAE: 1.9086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12732/20000 - Train Loss: 0.6385 - Test Loss: 5.0789 - MSE: 5.0789 - MAE: 1.8414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12733/20000 - Train Loss: 0.6319 - Test Loss: 5.5841 - MSE: 5.5841 - MAE: 1.9058\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12734/20000 - Train Loss: 0.6218 - Test Loss: 5.2039 - MSE: 5.2039 - MAE: 1.8603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12735/20000 - Train Loss: 0.6173 - Test Loss: 5.3259 - MSE: 5.3259 - MAE: 1.8764\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12736/20000 - Train Loss: 0.6209 - Test Loss: 5.4485 - MSE: 5.4485 - MAE: 1.8910\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12737/20000 - Train Loss: 0.6268 - Test Loss: 5.1512 - MSE: 5.1512 - MAE: 1.8527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12738/20000 - Train Loss: 0.6280 - Test Loss: 5.5447 - MSE: 5.5447 - MAE: 1.9016\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12739/20000 - Train Loss: 0.6235 - Test Loss: 5.1805 - MSE: 5.1805 - MAE: 1.8569\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12740/20000 - Train Loss: 0.6183 - Test Loss: 5.3935 - MSE: 5.3935 - MAE: 1.8846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12741/20000 - Train Loss: 0.6174 - Test Loss: 5.3576 - MSE: 5.3576 - MAE: 1.8803\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12742/20000 - Train Loss: 0.6204 - Test Loss: 5.2178 - MSE: 5.2178 - MAE: 1.8622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12743/20000 - Train Loss: 0.6231 - Test Loss: 5.4843 - MSE: 5.4843 - MAE: 1.8950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12744/20000 - Train Loss: 0.6222 - Test Loss: 5.1925 - MSE: 5.1925 - MAE: 1.8586\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12745/20000 - Train Loss: 0.6190 - Test Loss: 5.4150 - MSE: 5.4150 - MAE: 1.8871\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12746/20000 - Train Loss: 0.6170 - Test Loss: 5.3094 - MSE: 5.3094 - MAE: 1.8742\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12747/20000 - Train Loss: 0.6178 - Test Loss: 5.2683 - MSE: 5.2683 - MAE: 1.8689\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 12748/20000 - Train Loss: 0.6197 - Test Loss: 5.4304 - MSE: 5.4304 - MAE: 1.8888\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12749/20000 - Train Loss: 0.6203 - Test Loss: 5.2149 - MSE: 5.2149 - MAE: 1.8617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12750/20000 - Train Loss: 0.6189 - Test Loss: 5.4144 - MSE: 5.4144 - MAE: 1.8869\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12751/20000 - Train Loss: 0.6172 - Test Loss: 5.2842 - MSE: 5.2842 - MAE: 1.8710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12752/20000 - Train Loss: 0.6168 - Test Loss: 5.3047 - MSE: 5.3047 - MAE: 1.8736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12753/20000 - Train Loss: 0.6178 - Test Loss: 5.3868 - MSE: 5.3868 - MAE: 1.8837\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12754/20000 - Train Loss: 0.6186 - Test Loss: 5.2398 - MSE: 5.2398 - MAE: 1.8651\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12755/20000 - Train Loss: 0.6183 - Test Loss: 5.4031 - MSE: 5.4031 - MAE: 1.8856\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12756/20000 - Train Loss: 0.6173 - Test Loss: 5.2727 - MSE: 5.2727 - MAE: 1.8694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12757/20000 - Train Loss: 0.6166 - Test Loss: 5.3293 - MSE: 5.3293 - MAE: 1.8766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12758/20000 - Train Loss: 0.6168 - Test Loss: 5.3527 - MSE: 5.3527 - MAE: 1.8795\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12759/20000 - Train Loss: 0.6174 - Test Loss: 5.2642 - MSE: 5.2642 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12760/20000 - Train Loss: 0.6176 - Test Loss: 5.3865 - MSE: 5.3865 - MAE: 1.8835\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12761/20000 - Train Loss: 0.6172 - Test Loss: 5.2701 - MSE: 5.2701 - MAE: 1.8691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12762/20000 - Train Loss: 0.6166 - Test Loss: 5.3441 - MSE: 5.3441 - MAE: 1.8784\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12763/20000 - Train Loss: 0.6164 - Test Loss: 5.3271 - MSE: 5.3271 - MAE: 1.8763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12764/20000 - Train Loss: 0.6167 - Test Loss: 5.2863 - MSE: 5.2863 - MAE: 1.8711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12765/20000 - Train Loss: 0.6169 - Test Loss: 5.3675 - MSE: 5.3675 - MAE: 1.8812\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12766/20000 - Train Loss: 0.6169 - Test Loss: 5.2739 - MSE: 5.2739 - MAE: 1.8695\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12767/20000 - Train Loss: 0.6165 - Test Loss: 5.3506 - MSE: 5.3506 - MAE: 1.8792\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12768/20000 - Train Loss: 0.6163 - Test Loss: 5.3092 - MSE: 5.3092 - MAE: 1.8740\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12769/20000 - Train Loss: 0.6163 - Test Loss: 5.3051 - MSE: 5.3051 - MAE: 1.8735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12770/20000 - Train Loss: 0.6164 - Test Loss: 5.3482 - MSE: 5.3482 - MAE: 1.8788\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12771/20000 - Train Loss: 0.6165 - Test Loss: 5.2821 - MSE: 5.2821 - MAE: 1.8705\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12772/20000 - Train Loss: 0.6164 - Test Loss: 5.3500 - MSE: 5.3500 - MAE: 1.8790\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12773/20000 - Train Loss: 0.6162 - Test Loss: 5.2985 - MSE: 5.2985 - MAE: 1.8726\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12774/20000 - Train Loss: 0.6161 - Test Loss: 5.3193 - MSE: 5.3193 - MAE: 1.8752\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12775/20000 - Train Loss: 0.6161 - Test Loss: 5.3307 - MSE: 5.3307 - MAE: 1.8766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12776/20000 - Train Loss: 0.6162 - Test Loss: 5.2927 - MSE: 5.2927 - MAE: 1.8718\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 12777/20000 - Train Loss: 0.6162 - Test Loss: 5.3438 - MSE: 5.3438 - MAE: 1.8782\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12778/20000 - Train Loss: 0.6161 - Test Loss: 5.2942 - MSE: 5.2942 - MAE: 1.8720\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12779/20000 - Train Loss: 0.6159 - Test Loss: 5.3280 - MSE: 5.3280 - MAE: 1.8763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12780/20000 - Train Loss: 0.6159 - Test Loss: 5.3163 - MSE: 5.3163 - MAE: 1.8748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12781/20000 - Train Loss: 0.6159 - Test Loss: 5.3039 - MSE: 5.3039 - MAE: 1.8732\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12782/20000 - Train Loss: 0.6159 - Test Loss: 5.3340 - MSE: 5.3340 - MAE: 1.8770\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12783/20000 - Train Loss: 0.6159 - Test Loss: 5.2953 - MSE: 5.2953 - MAE: 1.8721\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12784/20000 - Train Loss: 0.6158 - Test Loss: 5.3308 - MSE: 5.3308 - MAE: 1.8765\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12785/20000 - Train Loss: 0.6157 - Test Loss: 5.3066 - MSE: 5.3066 - MAE: 1.8735\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 12786/20000 - Train Loss: 0.6157 - Test Loss: 5.3134 - MSE: 5.3134 - MAE: 1.8744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12787/20000 - Train Loss: 0.6157 - Test Loss: 5.3231 - MSE: 5.3231 - MAE: 1.8756\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12788/20000 - Train Loss: 0.6157 - Test Loss: 5.3002 - MSE: 5.3002 - MAE: 1.8727\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12789/20000 - Train Loss: 0.6156 - Test Loss: 5.3285 - MSE: 5.3285 - MAE: 1.8762\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12790/20000 - Train Loss: 0.6156 - Test Loss: 5.3017 - MSE: 5.3017 - MAE: 1.8728\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12791/20000 - Train Loss: 0.6155 - Test Loss: 5.3195 - MSE: 5.3195 - MAE: 1.8751\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12792/20000 - Train Loss: 0.6155 - Test Loss: 5.3133 - MSE: 5.3133 - MAE: 1.8743\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12793/20000 - Train Loss: 0.6155 - Test Loss: 5.3067 - MSE: 5.3067 - MAE: 1.8734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12794/20000 - Train Loss: 0.6155 - Test Loss: 5.3225 - MSE: 5.3225 - MAE: 1.8754\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12795/20000 - Train Loss: 0.6154 - Test Loss: 5.3015 - MSE: 5.3015 - MAE: 1.8728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12796/20000 - Train Loss: 0.6154 - Test Loss: 5.3213 - MSE: 5.3213 - MAE: 1.8752\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12797/20000 - Train Loss: 0.6153 - Test Loss: 5.3065 - MSE: 5.3065 - MAE: 1.8734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12798/20000 - Train Loss: 0.6153 - Test Loss: 5.3124 - MSE: 5.3124 - MAE: 1.8741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12799/20000 - Train Loss: 0.6153 - Test Loss: 5.3150 - MSE: 5.3150 - MAE: 1.8744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12800/20000 - Train Loss: 0.6153 - Test Loss: 5.3045 - MSE: 5.3045 - MAE: 1.8731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12801/20000 - Train Loss: 0.6152 - Test Loss: 5.3189 - MSE: 5.3189 - MAE: 1.8749\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12802/20000 - Train Loss: 0.6152 - Test Loss: 5.3035 - MSE: 5.3035 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12803/20000 - Train Loss: 0.6152 - Test Loss: 5.3154 - MSE: 5.3154 - MAE: 1.8744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12804/20000 - Train Loss: 0.6151 - Test Loss: 5.3085 - MSE: 5.3085 - MAE: 1.8736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12805/20000 - Train Loss: 0.6151 - Test Loss: 5.3086 - MSE: 5.3086 - MAE: 1.8736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12806/20000 - Train Loss: 0.6151 - Test Loss: 5.3138 - MSE: 5.3138 - MAE: 1.8742\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12807/20000 - Train Loss: 0.6150 - Test Loss: 5.3042 - MSE: 5.3042 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12808/20000 - Train Loss: 0.6150 - Test Loss: 5.3148 - MSE: 5.3148 - MAE: 1.8743\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12809/20000 - Train Loss: 0.6150 - Test Loss: 5.3048 - MSE: 5.3048 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 12810/20000 - Train Loss: 0.6149 - Test Loss: 5.3113 - MSE: 5.3113 - MAE: 1.8738\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12811/20000 - Train Loss: 0.6149 - Test Loss: 5.3085 - MSE: 5.3085 - MAE: 1.8735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12812/20000 - Train Loss: 0.6149 - Test Loss: 5.3064 - MSE: 5.3064 - MAE: 1.8732\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12813/20000 - Train Loss: 0.6148 - Test Loss: 5.3117 - MSE: 5.3117 - MAE: 1.8739\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12814/20000 - Train Loss: 0.6148 - Test Loss: 5.3039 - MSE: 5.3039 - MAE: 1.8729\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12815/20000 - Train Loss: 0.6148 - Test Loss: 5.3115 - MSE: 5.3115 - MAE: 1.8738\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12816/20000 - Train Loss: 0.6147 - Test Loss: 5.3047 - MSE: 5.3047 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12817/20000 - Train Loss: 0.6147 - Test Loss: 5.3085 - MSE: 5.3085 - MAE: 1.8734\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 12818/20000 - Train Loss: 0.6147 - Test Loss: 5.3074 - MSE: 5.3074 - MAE: 1.8733\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12819/20000 - Train Loss: 0.6146 - Test Loss: 5.3051 - MSE: 5.3051 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12820/20000 - Train Loss: 0.6146 - Test Loss: 5.3092 - MSE: 5.3092 - MAE: 1.8735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12821/20000 - Train Loss: 0.6146 - Test Loss: 5.3035 - MSE: 5.3035 - MAE: 1.8727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12822/20000 - Train Loss: 0.6145 - Test Loss: 5.3087 - MSE: 5.3087 - MAE: 1.8734\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12823/20000 - Train Loss: 0.6145 - Test Loss: 5.3041 - MSE: 5.3041 - MAE: 1.8728\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 12824/20000 - Train Loss: 0.6145 - Test Loss: 5.3064 - MSE: 5.3064 - MAE: 1.8731\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12825/20000 - Train Loss: 0.6145 - Test Loss: 5.3057 - MSE: 5.3057 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12826/20000 - Train Loss: 0.6144 - Test Loss: 5.3040 - MSE: 5.3040 - MAE: 1.8728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12827/20000 - Train Loss: 0.6144 - Test Loss: 5.3067 - MSE: 5.3067 - MAE: 1.8731\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 12828/20000 - Train Loss: 0.6144 - Test Loss: 5.3027 - MSE: 5.3027 - MAE: 1.8726\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12829/20000 - Train Loss: 0.6143 - Test Loss: 5.3064 - MSE: 5.3064 - MAE: 1.8730\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12830/20000 - Train Loss: 0.6143 - Test Loss: 5.3028 - MSE: 5.3028 - MAE: 1.8726\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12831/20000 - Train Loss: 0.6143 - Test Loss: 5.3048 - MSE: 5.3048 - MAE: 1.8728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12832/20000 - Train Loss: 0.6142 - Test Loss: 5.3038 - MSE: 5.3038 - MAE: 1.8727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12833/20000 - Train Loss: 0.6142 - Test Loss: 5.3029 - MSE: 5.3029 - MAE: 1.8725\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12834/20000 - Train Loss: 0.6142 - Test Loss: 5.3045 - MSE: 5.3045 - MAE: 1.8727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12835/20000 - Train Loss: 0.6141 - Test Loss: 5.3017 - MSE: 5.3017 - MAE: 1.8724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12836/20000 - Train Loss: 0.6141 - Test Loss: 5.3043 - MSE: 5.3043 - MAE: 1.8727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12837/20000 - Train Loss: 0.6141 - Test Loss: 5.3014 - MSE: 5.3014 - MAE: 1.8723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12838/20000 - Train Loss: 0.6140 - Test Loss: 5.3032 - MSE: 5.3032 - MAE: 1.8725\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12839/20000 - Train Loss: 0.6140 - Test Loss: 5.3019 - MSE: 5.3019 - MAE: 1.8724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12840/20000 - Train Loss: 0.6140 - Test Loss: 5.3017 - MSE: 5.3017 - MAE: 1.8723\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12841/20000 - Train Loss: 0.6139 - Test Loss: 5.3023 - MSE: 5.3023 - MAE: 1.8724\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12842/20000 - Train Loss: 0.6139 - Test Loss: 5.3006 - MSE: 5.3006 - MAE: 1.8722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12843/20000 - Train Loss: 0.6139 - Test Loss: 5.3022 - MSE: 5.3022 - MAE: 1.8723\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12844/20000 - Train Loss: 0.6139 - Test Loss: 5.3002 - MSE: 5.3002 - MAE: 1.8721\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12845/20000 - Train Loss: 0.6138 - Test Loss: 5.3014 - MSE: 5.3014 - MAE: 1.8722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12846/20000 - Train Loss: 0.6138 - Test Loss: 5.3002 - MSE: 5.3002 - MAE: 1.8721\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 12847/20000 - Train Loss: 0.6138 - Test Loss: 5.3003 - MSE: 5.3003 - MAE: 1.8721\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 12848/20000 - Train Loss: 0.6137 - Test Loss: 5.3003 - MSE: 5.3003 - MAE: 1.8721\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 12849/20000 - Train Loss: 0.6137 - Test Loss: 5.2994 - MSE: 5.2994 - MAE: 1.8719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12850/20000 - Train Loss: 0.6137 - Test Loss: 5.3001 - MSE: 5.3001 - MAE: 1.8720\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12851/20000 - Train Loss: 0.6136 - Test Loss: 5.2989 - MSE: 5.2989 - MAE: 1.8718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12852/20000 - Train Loss: 0.6136 - Test Loss: 5.2995 - MSE: 5.2995 - MAE: 1.8719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12853/20000 - Train Loss: 0.6136 - Test Loss: 5.2987 - MSE: 5.2987 - MAE: 1.8718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12854/20000 - Train Loss: 0.6135 - Test Loss: 5.2987 - MSE: 5.2987 - MAE: 1.8718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12855/20000 - Train Loss: 0.6135 - Test Loss: 5.2985 - MSE: 5.2985 - MAE: 1.8718\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12856/20000 - Train Loss: 0.6135 - Test Loss: 5.2980 - MSE: 5.2980 - MAE: 1.8717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12857/20000 - Train Loss: 0.6134 - Test Loss: 5.2983 - MSE: 5.2983 - MAE: 1.8717\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12858/20000 - Train Loss: 0.6134 - Test Loss: 5.2974 - MSE: 5.2974 - MAE: 1.8716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12859/20000 - Train Loss: 0.6134 - Test Loss: 5.2978 - MSE: 5.2978 - MAE: 1.8716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12860/20000 - Train Loss: 0.6133 - Test Loss: 5.2971 - MSE: 5.2971 - MAE: 1.8715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12861/20000 - Train Loss: 0.6133 - Test Loss: 5.2971 - MSE: 5.2971 - MAE: 1.8715\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12862/20000 - Train Loss: 0.6133 - Test Loss: 5.2969 - MSE: 5.2969 - MAE: 1.8715\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12863/20000 - Train Loss: 0.6132 - Test Loss: 5.2964 - MSE: 5.2964 - MAE: 1.8714\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12864/20000 - Train Loss: 0.6132 - Test Loss: 5.2966 - MSE: 5.2966 - MAE: 1.8714\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12865/20000 - Train Loss: 0.6132 - Test Loss: 5.2958 - MSE: 5.2958 - MAE: 1.8713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12866/20000 - Train Loss: 0.6132 - Test Loss: 5.2963 - MSE: 5.2963 - MAE: 1.8713\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 12867/20000 - Train Loss: 0.6131 - Test Loss: 5.2953 - MSE: 5.2953 - MAE: 1.8712\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12868/20000 - Train Loss: 0.6131 - Test Loss: 5.2958 - MSE: 5.2958 - MAE: 1.8713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12869/20000 - Train Loss: 0.6131 - Test Loss: 5.2949 - MSE: 5.2949 - MAE: 1.8711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12870/20000 - Train Loss: 0.6130 - Test Loss: 5.2952 - MSE: 5.2952 - MAE: 1.8712\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 12871/20000 - Train Loss: 0.6130 - Test Loss: 5.2945 - MSE: 5.2945 - MAE: 1.8711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12872/20000 - Train Loss: 0.6130 - Test Loss: 5.2946 - MSE: 5.2946 - MAE: 1.8711\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12873/20000 - Train Loss: 0.6129 - Test Loss: 5.2942 - MSE: 5.2942 - MAE: 1.8710\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12874/20000 - Train Loss: 0.6129 - Test Loss: 5.2941 - MSE: 5.2941 - MAE: 1.8710\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12875/20000 - Train Loss: 0.6129 - Test Loss: 5.2938 - MSE: 5.2938 - MAE: 1.8709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12876/20000 - Train Loss: 0.6128 - Test Loss: 5.2936 - MSE: 5.2936 - MAE: 1.8709\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12877/20000 - Train Loss: 0.6128 - Test Loss: 5.2933 - MSE: 5.2933 - MAE: 1.8709\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12878/20000 - Train Loss: 0.6128 - Test Loss: 5.2931 - MSE: 5.2931 - MAE: 1.8708\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12879/20000 - Train Loss: 0.6127 - Test Loss: 5.2929 - MSE: 5.2929 - MAE: 1.8708\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12880/20000 - Train Loss: 0.6127 - Test Loss: 5.2925 - MSE: 5.2925 - MAE: 1.8707\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12881/20000 - Train Loss: 0.6127 - Test Loss: 5.2925 - MSE: 5.2925 - MAE: 1.8707\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12882/20000 - Train Loss: 0.6126 - Test Loss: 5.2920 - MSE: 5.2920 - MAE: 1.8706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12883/20000 - Train Loss: 0.6126 - Test Loss: 5.2921 - MSE: 5.2921 - MAE: 1.8706\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12884/20000 - Train Loss: 0.6126 - Test Loss: 5.2915 - MSE: 5.2915 - MAE: 1.8705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12885/20000 - Train Loss: 0.6125 - Test Loss: 5.2917 - MSE: 5.2917 - MAE: 1.8706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12886/20000 - Train Loss: 0.6125 - Test Loss: 5.2910 - MSE: 5.2910 - MAE: 1.8705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12887/20000 - Train Loss: 0.6125 - Test Loss: 5.2912 - MSE: 5.2912 - MAE: 1.8705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12888/20000 - Train Loss: 0.6124 - Test Loss: 5.2906 - MSE: 5.2906 - MAE: 1.8704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12889/20000 - Train Loss: 0.6124 - Test Loss: 5.2906 - MSE: 5.2906 - MAE: 1.8704\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12890/20000 - Train Loss: 0.6124 - Test Loss: 5.2903 - MSE: 5.2903 - MAE: 1.8703\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12891/20000 - Train Loss: 0.6124 - Test Loss: 5.2900 - MSE: 5.2900 - MAE: 1.8703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12892/20000 - Train Loss: 0.6123 - Test Loss: 5.2900 - MSE: 5.2900 - MAE: 1.8703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12893/20000 - Train Loss: 0.6123 - Test Loss: 5.2893 - MSE: 5.2893 - MAE: 1.8702\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12894/20000 - Train Loss: 0.6123 - Test Loss: 5.2896 - MSE: 5.2896 - MAE: 1.8702\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12895/20000 - Train Loss: 0.6122 - Test Loss: 5.2888 - MSE: 5.2888 - MAE: 1.8701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12896/20000 - Train Loss: 0.6122 - Test Loss: 5.2892 - MSE: 5.2892 - MAE: 1.8701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12897/20000 - Train Loss: 0.6122 - Test Loss: 5.2883 - MSE: 5.2883 - MAE: 1.8700\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12898/20000 - Train Loss: 0.6121 - Test Loss: 5.2888 - MSE: 5.2888 - MAE: 1.8700\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12899/20000 - Train Loss: 0.6121 - Test Loss: 5.2878 - MSE: 5.2878 - MAE: 1.8699\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12900/20000 - Train Loss: 0.6121 - Test Loss: 5.2883 - MSE: 5.2883 - MAE: 1.8700\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12901/20000 - Train Loss: 0.6120 - Test Loss: 5.2874 - MSE: 5.2874 - MAE: 1.8698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 12902/20000 - Train Loss: 0.6120 - Test Loss: 5.2878 - MSE: 5.2878 - MAE: 1.8699\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12903/20000 - Train Loss: 0.6120 - Test Loss: 5.2870 - MSE: 5.2870 - MAE: 1.8698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12904/20000 - Train Loss: 0.6119 - Test Loss: 5.2872 - MSE: 5.2872 - MAE: 1.8698\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12905/20000 - Train Loss: 0.6119 - Test Loss: 5.2866 - MSE: 5.2866 - MAE: 1.8697\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 12906/20000 - Train Loss: 0.6119 - Test Loss: 5.2867 - MSE: 5.2867 - MAE: 1.8697\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12907/20000 - Train Loss: 0.6118 - Test Loss: 5.2862 - MSE: 5.2862 - MAE: 1.8696\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12908/20000 - Train Loss: 0.6118 - Test Loss: 5.2861 - MSE: 5.2861 - MAE: 1.8696\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 12909/20000 - Train Loss: 0.6118 - Test Loss: 5.2859 - MSE: 5.2859 - MAE: 1.8695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12910/20000 - Train Loss: 0.6117 - Test Loss: 5.2856 - MSE: 5.2856 - MAE: 1.8695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12911/20000 - Train Loss: 0.6117 - Test Loss: 5.2855 - MSE: 5.2855 - MAE: 1.8695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12912/20000 - Train Loss: 0.6117 - Test Loss: 5.2850 - MSE: 5.2850 - MAE: 1.8694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12913/20000 - Train Loss: 0.6116 - Test Loss: 5.2850 - MSE: 5.2850 - MAE: 1.8694\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12914/20000 - Train Loss: 0.6116 - Test Loss: 5.2845 - MSE: 5.2845 - MAE: 1.8693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12915/20000 - Train Loss: 0.6116 - Test Loss: 5.2846 - MSE: 5.2846 - MAE: 1.8693\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12916/20000 - Train Loss: 0.6116 - Test Loss: 5.2840 - MSE: 5.2840 - MAE: 1.8692\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12917/20000 - Train Loss: 0.6115 - Test Loss: 5.2841 - MSE: 5.2841 - MAE: 1.8692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12918/20000 - Train Loss: 0.6115 - Test Loss: 5.2836 - MSE: 5.2836 - MAE: 1.8692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12919/20000 - Train Loss: 0.6115 - Test Loss: 5.2836 - MSE: 5.2836 - MAE: 1.8691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12920/20000 - Train Loss: 0.6114 - Test Loss: 5.2832 - MSE: 5.2832 - MAE: 1.8691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12921/20000 - Train Loss: 0.6114 - Test Loss: 5.2831 - MSE: 5.2831 - MAE: 1.8691\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12922/20000 - Train Loss: 0.6114 - Test Loss: 5.2827 - MSE: 5.2827 - MAE: 1.8690\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 12923/20000 - Train Loss: 0.6113 - Test Loss: 5.2826 - MSE: 5.2826 - MAE: 1.8690\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 12924/20000 - Train Loss: 0.6113 - Test Loss: 5.2823 - MSE: 5.2823 - MAE: 1.8689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12925/20000 - Train Loss: 0.6113 - Test Loss: 5.2821 - MSE: 5.2821 - MAE: 1.8689\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12926/20000 - Train Loss: 0.6112 - Test Loss: 5.2819 - MSE: 5.2819 - MAE: 1.8688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12927/20000 - Train Loss: 0.6112 - Test Loss: 5.2815 - MSE: 5.2815 - MAE: 1.8688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12928/20000 - Train Loss: 0.6112 - Test Loss: 5.2815 - MSE: 5.2815 - MAE: 1.8688\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12929/20000 - Train Loss: 0.6111 - Test Loss: 5.2809 - MSE: 5.2809 - MAE: 1.8687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12930/20000 - Train Loss: 0.6111 - Test Loss: 5.2812 - MSE: 5.2812 - MAE: 1.8687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12931/20000 - Train Loss: 0.6111 - Test Loss: 5.2804 - MSE: 5.2804 - MAE: 1.8686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12932/20000 - Train Loss: 0.6110 - Test Loss: 5.2808 - MSE: 5.2808 - MAE: 1.8686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12933/20000 - Train Loss: 0.6110 - Test Loss: 5.2798 - MSE: 5.2798 - MAE: 1.8685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12934/20000 - Train Loss: 0.6110 - Test Loss: 5.2805 - MSE: 5.2805 - MAE: 1.8686\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12935/20000 - Train Loss: 0.6109 - Test Loss: 5.2792 - MSE: 5.2792 - MAE: 1.8684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12936/20000 - Train Loss: 0.6109 - Test Loss: 5.2801 - MSE: 5.2801 - MAE: 1.8685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12937/20000 - Train Loss: 0.6109 - Test Loss: 5.2786 - MSE: 5.2786 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12938/20000 - Train Loss: 0.6108 - Test Loss: 5.2798 - MSE: 5.2798 - MAE: 1.8684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12939/20000 - Train Loss: 0.6108 - Test Loss: 5.2779 - MSE: 5.2779 - MAE: 1.8682\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12940/20000 - Train Loss: 0.6108 - Test Loss: 5.2795 - MSE: 5.2795 - MAE: 1.8684\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12941/20000 - Train Loss: 0.6107 - Test Loss: 5.2772 - MSE: 5.2772 - MAE: 1.8681\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12942/20000 - Train Loss: 0.6107 - Test Loss: 5.2793 - MSE: 5.2793 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12943/20000 - Train Loss: 0.6107 - Test Loss: 5.2764 - MSE: 5.2764 - MAE: 1.8679\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12944/20000 - Train Loss: 0.6107 - Test Loss: 5.2793 - MSE: 5.2793 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 12945/20000 - Train Loss: 0.6106 - Test Loss: 5.2755 - MSE: 5.2755 - MAE: 1.8678\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12946/20000 - Train Loss: 0.6106 - Test Loss: 5.2793 - MSE: 5.2793 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12947/20000 - Train Loss: 0.6106 - Test Loss: 5.2743 - MSE: 5.2743 - MAE: 1.8676\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 12948/20000 - Train Loss: 0.6105 - Test Loss: 5.2796 - MSE: 5.2796 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12949/20000 - Train Loss: 0.6105 - Test Loss: 5.2730 - MSE: 5.2730 - MAE: 1.8674\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 12950/20000 - Train Loss: 0.6105 - Test Loss: 5.2803 - MSE: 5.2803 - MAE: 1.8683\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12951/20000 - Train Loss: 0.6104 - Test Loss: 5.2712 - MSE: 5.2712 - MAE: 1.8672\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12952/20000 - Train Loss: 0.6104 - Test Loss: 5.2813 - MSE: 5.2813 - MAE: 1.8685\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 12953/20000 - Train Loss: 0.6104 - Test Loss: 5.2689 - MSE: 5.2689 - MAE: 1.8669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12954/20000 - Train Loss: 0.6103 - Test Loss: 5.2832 - MSE: 5.2832 - MAE: 1.8687\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12955/20000 - Train Loss: 0.6103 - Test Loss: 5.2655 - MSE: 5.2655 - MAE: 1.8664\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 12956/20000 - Train Loss: 0.6103 - Test Loss: 5.2863 - MSE: 5.2863 - MAE: 1.8690\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12957/20000 - Train Loss: 0.6103 - Test Loss: 5.2607 - MSE: 5.2607 - MAE: 1.8658\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12958/20000 - Train Loss: 0.6103 - Test Loss: 5.2914 - MSE: 5.2914 - MAE: 1.8696\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12959/20000 - Train Loss: 0.6103 - Test Loss: 5.2535 - MSE: 5.2535 - MAE: 1.8648\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12960/20000 - Train Loss: 0.6103 - Test Loss: 5.2996 - MSE: 5.2996 - MAE: 1.8706\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12961/20000 - Train Loss: 0.6104 - Test Loss: 5.2426 - MSE: 5.2426 - MAE: 1.8634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12962/20000 - Train Loss: 0.6105 - Test Loss: 5.3128 - MSE: 5.3128 - MAE: 1.8722\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12963/20000 - Train Loss: 0.6107 - Test Loss: 5.2261 - MSE: 5.2261 - MAE: 1.8612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12964/20000 - Train Loss: 0.6110 - Test Loss: 5.3341 - MSE: 5.3341 - MAE: 1.8748\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12965/20000 - Train Loss: 0.6115 - Test Loss: 5.2007 - MSE: 5.2007 - MAE: 1.8578\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12966/20000 - Train Loss: 0.6123 - Test Loss: 5.3690 - MSE: 5.3690 - MAE: 1.8789\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12967/20000 - Train Loss: 0.6136 - Test Loss: 5.1622 - MSE: 5.1622 - MAE: 1.8525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12968/20000 - Train Loss: 0.6156 - Test Loss: 5.4253 - MSE: 5.4253 - MAE: 1.8853\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12969/20000 - Train Loss: 0.6186 - Test Loss: 5.1067 - MSE: 5.1067 - MAE: 1.8444\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12970/20000 - Train Loss: 0.6230 - Test Loss: 5.5123 - MSE: 5.5123 - MAE: 1.8948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12971/20000 - Train Loss: 0.6290 - Test Loss: 5.0363 - MSE: 5.0363 - MAE: 1.8333\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12972/20000 - Train Loss: 0.6363 - Test Loss: 5.6259 - MSE: 5.6259 - MAE: 1.9085\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12973/20000 - Train Loss: 0.6435 - Test Loss: 4.9725 - MSE: 4.9725 - MAE: 1.8223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12974/20000 - Train Loss: 0.6476 - Test Loss: 5.7038 - MSE: 5.7038 - MAE: 1.9183\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12975/20000 - Train Loss: 0.6449 - Test Loss: 4.9670 - MSE: 4.9670 - MAE: 1.8213\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12976/20000 - Train Loss: 0.6346 - Test Loss: 5.6125 - MSE: 5.6125 - MAE: 1.9067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12977/20000 - Train Loss: 0.6209 - Test Loss: 5.0843 - MSE: 5.0843 - MAE: 1.8409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12978/20000 - Train Loss: 0.6113 - Test Loss: 5.3513 - MSE: 5.3513 - MAE: 1.8766\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12979/20000 - Train Loss: 0.6102 - Test Loss: 5.3182 - MSE: 5.3182 - MAE: 1.8727\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12980/20000 - Train Loss: 0.6159 - Test Loss: 5.1263 - MSE: 5.1263 - MAE: 1.8472\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12981/20000 - Train Loss: 0.6226 - Test Loss: 5.5096 - MSE: 5.5096 - MAE: 1.8943\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12982/20000 - Train Loss: 0.6247 - Test Loss: 5.0564 - MSE: 5.0564 - MAE: 1.8365\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 12983/20000 - Train Loss: 0.6207 - Test Loss: 5.4899 - MSE: 5.4899 - MAE: 1.8922\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12984/20000 - Train Loss: 0.6139 - Test Loss: 5.1469 - MSE: 5.1469 - MAE: 1.8501\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12985/20000 - Train Loss: 0.6096 - Test Loss: 5.3010 - MSE: 5.3010 - MAE: 1.8705\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12986/20000 - Train Loss: 0.6104 - Test Loss: 5.3311 - MSE: 5.3311 - MAE: 1.8741\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12987/20000 - Train Loss: 0.6141 - Test Loss: 5.1430 - MSE: 5.1430 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12988/20000 - Train Loss: 0.6168 - Test Loss: 5.4453 - MSE: 5.4453 - MAE: 1.8873\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 12989/20000 - Train Loss: 0.6160 - Test Loss: 5.1206 - MSE: 5.1206 - MAE: 1.8463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12990/20000 - Train Loss: 0.6127 - Test Loss: 5.3850 - MSE: 5.3850 - MAE: 1.8804\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12991/20000 - Train Loss: 0.6097 - Test Loss: 5.2228 - MSE: 5.2228 - MAE: 1.8605\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 12992/20000 - Train Loss: 0.6093 - Test Loss: 5.2401 - MSE: 5.2401 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12993/20000 - Train Loss: 0.6111 - Test Loss: 5.3545 - MSE: 5.3545 - MAE: 1.8768\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12994/20000 - Train Loss: 0.6128 - Test Loss: 5.1553 - MSE: 5.1553 - MAE: 1.8512\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 12995/20000 - Train Loss: 0.6128 - Test Loss: 5.3894 - MSE: 5.3894 - MAE: 1.8809\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12996/20000 - Train Loss: 0.6112 - Test Loss: 5.1799 - MSE: 5.1799 - MAE: 1.8546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12997/20000 - Train Loss: 0.6095 - Test Loss: 5.3085 - MSE: 5.3085 - MAE: 1.8713\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12998/20000 - Train Loss: 0.6090 - Test Loss: 5.2759 - MSE: 5.2759 - MAE: 1.8672\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 12999/20000 - Train Loss: 0.6098 - Test Loss: 5.2110 - MSE: 5.2110 - MAE: 1.8588\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13000/20000 - Train Loss: 0.6108 - Test Loss: 5.3504 - MSE: 5.3504 - MAE: 1.8763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13001/20000 - Train Loss: 0.6110 - Test Loss: 5.1810 - MSE: 5.1810 - MAE: 1.8547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13002/20000 - Train Loss: 0.6102 - Test Loss: 5.3365 - MSE: 5.3365 - MAE: 1.8746\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13003/20000 - Train Loss: 0.6092 - Test Loss: 5.2271 - MSE: 5.2271 - MAE: 1.8609\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 13004/20000 - Train Loss: 0.6088 - Test Loss: 5.2637 - MSE: 5.2637 - MAE: 1.8656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13005/20000 - Train Loss: 0.6091 - Test Loss: 5.2988 - MSE: 5.2988 - MAE: 1.8700\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13006/20000 - Train Loss: 0.6096 - Test Loss: 5.2079 - MSE: 5.2079 - MAE: 1.8583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13007/20000 - Train Loss: 0.6098 - Test Loss: 5.3291 - MSE: 5.3291 - MAE: 1.8736\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13008/20000 - Train Loss: 0.6095 - Test Loss: 5.2095 - MSE: 5.2095 - MAE: 1.8585\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13009/20000 - Train Loss: 0.6090 - Test Loss: 5.2975 - MSE: 5.2975 - MAE: 1.8698\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13010/20000 - Train Loss: 0.6086 - Test Loss: 5.2555 - MSE: 5.2555 - MAE: 1.8645\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 13011/20000 - Train Loss: 0.6087 - Test Loss: 5.2441 - MSE: 5.2441 - MAE: 1.8630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13012/20000 - Train Loss: 0.6090 - Test Loss: 5.3005 - MSE: 5.3005 - MAE: 1.8701\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13013/20000 - Train Loss: 0.6091 - Test Loss: 5.2169 - MSE: 5.2169 - MAE: 1.8595\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13014/20000 - Train Loss: 0.6090 - Test Loss: 5.3059 - MSE: 5.3059 - MAE: 1.8707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13015/20000 - Train Loss: 0.6087 - Test Loss: 5.2312 - MSE: 5.2312 - MAE: 1.8613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13016/20000 - Train Loss: 0.6085 - Test Loss: 5.2743 - MSE: 5.2743 - MAE: 1.8668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13017/20000 - Train Loss: 0.6084 - Test Loss: 5.2676 - MSE: 5.2676 - MAE: 1.8659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13018/20000 - Train Loss: 0.6085 - Test Loss: 5.2391 - MSE: 5.2391 - MAE: 1.8623\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13019/20000 - Train Loss: 0.6086 - Test Loss: 5.2927 - MSE: 5.2927 - MAE: 1.8691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13020/20000 - Train Loss: 0.6086 - Test Loss: 5.2280 - MSE: 5.2280 - MAE: 1.8608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13021/20000 - Train Loss: 0.6085 - Test Loss: 5.2880 - MSE: 5.2880 - MAE: 1.8685\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13022/20000 - Train Loss: 0.6083 - Test Loss: 5.2440 - MSE: 5.2440 - MAE: 1.8629\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13023/20000 - Train Loss: 0.6082 - Test Loss: 5.2628 - MSE: 5.2628 - MAE: 1.8653\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13024/20000 - Train Loss: 0.6082 - Test Loss: 5.2695 - MSE: 5.2695 - MAE: 1.8661\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13025/20000 - Train Loss: 0.6083 - Test Loss: 5.2405 - MSE: 5.2405 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 13026/20000 - Train Loss: 0.6083 - Test Loss: 5.2830 - MSE: 5.2830 - MAE: 1.8678\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 13027/20000 - Train Loss: 0.6083 - Test Loss: 5.2367 - MSE: 5.2367 - MAE: 1.8619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13028/20000 - Train Loss: 0.6082 - Test Loss: 5.2762 - MSE: 5.2762 - MAE: 1.8669\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13029/20000 - Train Loss: 0.6081 - Test Loss: 5.2498 - MSE: 5.2498 - MAE: 1.8636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13030/20000 - Train Loss: 0.6080 - Test Loss: 5.2579 - MSE: 5.2579 - MAE: 1.8646\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13031/20000 - Train Loss: 0.6080 - Test Loss: 5.2670 - MSE: 5.2670 - MAE: 1.8657\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13032/20000 - Train Loss: 0.6080 - Test Loss: 5.2436 - MSE: 5.2436 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13033/20000 - Train Loss: 0.6080 - Test Loss: 5.2747 - MSE: 5.2747 - MAE: 1.8666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13034/20000 - Train Loss: 0.6080 - Test Loss: 5.2420 - MSE: 5.2420 - MAE: 1.8625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13035/20000 - Train Loss: 0.6079 - Test Loss: 5.2689 - MSE: 5.2689 - MAE: 1.8659\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13036/20000 - Train Loss: 0.6079 - Test Loss: 5.2515 - MSE: 5.2515 - MAE: 1.8637\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13037/20000 - Train Loss: 0.6078 - Test Loss: 5.2562 - MSE: 5.2562 - MAE: 1.8643\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 13038/20000 - Train Loss: 0.6078 - Test Loss: 5.2630 - MSE: 5.2630 - MAE: 1.8651\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13039/20000 - Train Loss: 0.6078 - Test Loss: 5.2463 - MSE: 5.2463 - MAE: 1.8630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13040/20000 - Train Loss: 0.6078 - Test Loss: 5.2682 - MSE: 5.2682 - MAE: 1.8657\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 13041/20000 - Train Loss: 0.6077 - Test Loss: 5.2449 - MSE: 5.2449 - MAE: 1.8628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13042/20000 - Train Loss: 0.6077 - Test Loss: 5.2644 - MSE: 5.2644 - MAE: 1.8652\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13043/20000 - Train Loss: 0.6077 - Test Loss: 5.2510 - MSE: 5.2510 - MAE: 1.8635\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13044/20000 - Train Loss: 0.6076 - Test Loss: 5.2557 - MSE: 5.2557 - MAE: 1.8641\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13045/20000 - Train Loss: 0.6076 - Test Loss: 5.2589 - MSE: 5.2589 - MAE: 1.8645\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13046/20000 - Train Loss: 0.6076 - Test Loss: 5.2484 - MSE: 5.2484 - MAE: 1.8632\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13047/20000 - Train Loss: 0.6076 - Test Loss: 5.2629 - MSE: 5.2629 - MAE: 1.8650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13048/20000 - Train Loss: 0.6075 - Test Loss: 5.2465 - MSE: 5.2465 - MAE: 1.8629\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13049/20000 - Train Loss: 0.6075 - Test Loss: 5.2611 - MSE: 5.2611 - MAE: 1.8647\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13050/20000 - Train Loss: 0.6075 - Test Loss: 5.2497 - MSE: 5.2497 - MAE: 1.8633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13051/20000 - Train Loss: 0.6074 - Test Loss: 5.2555 - MSE: 5.2555 - MAE: 1.8640\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13052/20000 - Train Loss: 0.6074 - Test Loss: 5.2549 - MSE: 5.2549 - MAE: 1.8639\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13053/20000 - Train Loss: 0.6074 - Test Loss: 5.2499 - MSE: 5.2499 - MAE: 1.8633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13054/20000 - Train Loss: 0.6073 - Test Loss: 5.2583 - MSE: 5.2583 - MAE: 1.8643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13055/20000 - Train Loss: 0.6073 - Test Loss: 5.2474 - MSE: 5.2474 - MAE: 1.8629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13056/20000 - Train Loss: 0.6073 - Test Loss: 5.2581 - MSE: 5.2581 - MAE: 1.8643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13057/20000 - Train Loss: 0.6072 - Test Loss: 5.2484 - MSE: 5.2484 - MAE: 1.8630\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13058/20000 - Train Loss: 0.6072 - Test Loss: 5.2549 - MSE: 5.2549 - MAE: 1.8638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13059/20000 - Train Loss: 0.6072 - Test Loss: 5.2515 - MSE: 5.2515 - MAE: 1.8634\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13060/20000 - Train Loss: 0.6072 - Test Loss: 5.2508 - MSE: 5.2508 - MAE: 1.8633\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13061/20000 - Train Loss: 0.6071 - Test Loss: 5.2542 - MSE: 5.2542 - MAE: 1.8637\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13062/20000 - Train Loss: 0.6071 - Test Loss: 5.2481 - MSE: 5.2481 - MAE: 1.8629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13063/20000 - Train Loss: 0.6071 - Test Loss: 5.2551 - MSE: 5.2551 - MAE: 1.8638\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13064/20000 - Train Loss: 0.6070 - Test Loss: 5.2475 - MSE: 5.2475 - MAE: 1.8628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13065/20000 - Train Loss: 0.6070 - Test Loss: 5.2537 - MSE: 5.2537 - MAE: 1.8636\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13066/20000 - Train Loss: 0.6070 - Test Loss: 5.2488 - MSE: 5.2488 - MAE: 1.8630\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13067/20000 - Train Loss: 0.6069 - Test Loss: 5.2511 - MSE: 5.2511 - MAE: 1.8633\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13068/20000 - Train Loss: 0.6069 - Test Loss: 5.2507 - MSE: 5.2507 - MAE: 1.8632\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13069/20000 - Train Loss: 0.6069 - Test Loss: 5.2485 - MSE: 5.2485 - MAE: 1.8629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13070/20000 - Train Loss: 0.6069 - Test Loss: 5.2519 - MSE: 5.2519 - MAE: 1.8633\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13071/20000 - Train Loss: 0.6068 - Test Loss: 5.2471 - MSE: 5.2471 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13072/20000 - Train Loss: 0.6068 - Test Loss: 5.2518 - MSE: 5.2518 - MAE: 1.8633\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13073/20000 - Train Loss: 0.6068 - Test Loss: 5.2470 - MSE: 5.2470 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13074/20000 - Train Loss: 0.6067 - Test Loss: 5.2505 - MSE: 5.2505 - MAE: 1.8631\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13075/20000 - Train Loss: 0.6067 - Test Loss: 5.2477 - MSE: 5.2477 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13076/20000 - Train Loss: 0.6067 - Test Loss: 5.2487 - MSE: 5.2487 - MAE: 1.8628\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13077/20000 - Train Loss: 0.6067 - Test Loss: 5.2487 - MSE: 5.2487 - MAE: 1.8628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13078/20000 - Train Loss: 0.6066 - Test Loss: 5.2470 - MSE: 5.2470 - MAE: 1.8626\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13079/20000 - Train Loss: 0.6066 - Test Loss: 5.2492 - MSE: 5.2492 - MAE: 1.8629\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13080/20000 - Train Loss: 0.6066 - Test Loss: 5.2460 - MSE: 5.2460 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13081/20000 - Train Loss: 0.6065 - Test Loss: 5.2489 - MSE: 5.2489 - MAE: 1.8628\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13082/20000 - Train Loss: 0.6065 - Test Loss: 5.2458 - MSE: 5.2458 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13083/20000 - Train Loss: 0.6065 - Test Loss: 5.2480 - MSE: 5.2480 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13084/20000 - Train Loss: 0.6064 - Test Loss: 5.2460 - MSE: 5.2460 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13085/20000 - Train Loss: 0.6064 - Test Loss: 5.2467 - MSE: 5.2467 - MAE: 1.8625\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13086/20000 - Train Loss: 0.6064 - Test Loss: 5.2464 - MSE: 5.2464 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13087/20000 - Train Loss: 0.6064 - Test Loss: 5.2455 - MSE: 5.2455 - MAE: 1.8623\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13088/20000 - Train Loss: 0.6063 - Test Loss: 5.2466 - MSE: 5.2466 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13089/20000 - Train Loss: 0.6063 - Test Loss: 5.2446 - MSE: 5.2446 - MAE: 1.8622\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13090/20000 - Train Loss: 0.6063 - Test Loss: 5.2465 - MSE: 5.2465 - MAE: 1.8624\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13091/20000 - Train Loss: 0.6062 - Test Loss: 5.2441 - MSE: 5.2441 - MAE: 1.8621\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13092/20000 - Train Loss: 0.6062 - Test Loss: 5.2459 - MSE: 5.2459 - MAE: 1.8623\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13093/20000 - Train Loss: 0.6062 - Test Loss: 5.2440 - MSE: 5.2440 - MAE: 1.8620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13094/20000 - Train Loss: 0.6061 - Test Loss: 5.2450 - MSE: 5.2450 - MAE: 1.8621\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13095/20000 - Train Loss: 0.6061 - Test Loss: 5.2441 - MSE: 5.2441 - MAE: 1.8620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13096/20000 - Train Loss: 0.6061 - Test Loss: 5.2441 - MSE: 5.2441 - MAE: 1.8620\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 13097/20000 - Train Loss: 0.6061 - Test Loss: 5.2441 - MSE: 5.2441 - MAE: 1.8620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13098/20000 - Train Loss: 0.6060 - Test Loss: 5.2432 - MSE: 5.2432 - MAE: 1.8619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13099/20000 - Train Loss: 0.6060 - Test Loss: 5.2440 - MSE: 5.2440 - MAE: 1.8620\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13100/20000 - Train Loss: 0.6060 - Test Loss: 5.2425 - MSE: 5.2425 - MAE: 1.8618\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13101/20000 - Train Loss: 0.6059 - Test Loss: 5.2437 - MSE: 5.2437 - MAE: 1.8619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13102/20000 - Train Loss: 0.6059 - Test Loss: 5.2421 - MSE: 5.2421 - MAE: 1.8617\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13103/20000 - Train Loss: 0.6059 - Test Loss: 5.2432 - MSE: 5.2432 - MAE: 1.8618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13104/20000 - Train Loss: 0.6059 - Test Loss: 5.2418 - MSE: 5.2418 - MAE: 1.8616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13105/20000 - Train Loss: 0.6058 - Test Loss: 5.2426 - MSE: 5.2426 - MAE: 1.8617\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13106/20000 - Train Loss: 0.6058 - Test Loss: 5.2416 - MSE: 5.2416 - MAE: 1.8616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13107/20000 - Train Loss: 0.6058 - Test Loss: 5.2419 - MSE: 5.2419 - MAE: 1.8616\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13108/20000 - Train Loss: 0.6057 - Test Loss: 5.2414 - MSE: 5.2414 - MAE: 1.8615\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13109/20000 - Train Loss: 0.6057 - Test Loss: 5.2412 - MSE: 5.2412 - MAE: 1.8615\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 13110/20000 - Train Loss: 0.6057 - Test Loss: 5.2412 - MSE: 5.2412 - MAE: 1.8615\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 13111/20000 - Train Loss: 0.6056 - Test Loss: 5.2405 - MSE: 5.2405 - MAE: 1.8614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13112/20000 - Train Loss: 0.6056 - Test Loss: 5.2409 - MSE: 5.2409 - MAE: 1.8614\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13113/20000 - Train Loss: 0.6056 - Test Loss: 5.2399 - MSE: 5.2399 - MAE: 1.8613\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 13114/20000 - Train Loss: 0.6056 - Test Loss: 5.2406 - MSE: 5.2406 - MAE: 1.8613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13115/20000 - Train Loss: 0.6055 - Test Loss: 5.2394 - MSE: 5.2394 - MAE: 1.8612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13116/20000 - Train Loss: 0.6055 - Test Loss: 5.2402 - MSE: 5.2402 - MAE: 1.8613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13117/20000 - Train Loss: 0.6055 - Test Loss: 5.2390 - MSE: 5.2390 - MAE: 1.8611\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13118/20000 - Train Loss: 0.6054 - Test Loss: 5.2397 - MSE: 5.2397 - MAE: 1.8612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13119/20000 - Train Loss: 0.6054 - Test Loss: 5.2386 - MSE: 5.2386 - MAE: 1.8610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13120/20000 - Train Loss: 0.6054 - Test Loss: 5.2393 - MSE: 5.2393 - MAE: 1.8611\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 13121/20000 - Train Loss: 0.6053 - Test Loss: 5.2382 - MSE: 5.2382 - MAE: 1.8609\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13122/20000 - Train Loss: 0.6053 - Test Loss: 5.2387 - MSE: 5.2387 - MAE: 1.8610\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13123/20000 - Train Loss: 0.6053 - Test Loss: 5.2379 - MSE: 5.2379 - MAE: 1.8609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13124/20000 - Train Loss: 0.6053 - Test Loss: 5.2381 - MSE: 5.2381 - MAE: 1.8609\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13125/20000 - Train Loss: 0.6052 - Test Loss: 5.2376 - MSE: 5.2376 - MAE: 1.8608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13126/20000 - Train Loss: 0.6052 - Test Loss: 5.2376 - MSE: 5.2376 - MAE: 1.8608\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13127/20000 - Train Loss: 0.6052 - Test Loss: 5.2372 - MSE: 5.2372 - MAE: 1.8607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13128/20000 - Train Loss: 0.6051 - Test Loss: 5.2371 - MSE: 5.2371 - MAE: 1.8607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13129/20000 - Train Loss: 0.6051 - Test Loss: 5.2369 - MSE: 5.2369 - MAE: 1.8607\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13130/20000 - Train Loss: 0.6051 - Test Loss: 5.2366 - MSE: 5.2366 - MAE: 1.8606\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13131/20000 - Train Loss: 0.6050 - Test Loss: 5.2365 - MSE: 5.2365 - MAE: 1.8606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13132/20000 - Train Loss: 0.6050 - Test Loss: 5.2361 - MSE: 5.2361 - MAE: 1.8605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13133/20000 - Train Loss: 0.6050 - Test Loss: 5.2360 - MSE: 5.2360 - MAE: 1.8605\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13134/20000 - Train Loss: 0.6050 - Test Loss: 5.2357 - MSE: 5.2357 - MAE: 1.8604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13135/20000 - Train Loss: 0.6049 - Test Loss: 5.2356 - MSE: 5.2356 - MAE: 1.8604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13136/20000 - Train Loss: 0.6049 - Test Loss: 5.2353 - MSE: 5.2353 - MAE: 1.8604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13137/20000 - Train Loss: 0.6049 - Test Loss: 5.2351 - MSE: 5.2351 - MAE: 1.8603\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13138/20000 - Train Loss: 0.6048 - Test Loss: 5.2349 - MSE: 5.2349 - MAE: 1.8603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13139/20000 - Train Loss: 0.6048 - Test Loss: 5.2346 - MSE: 5.2346 - MAE: 1.8602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13140/20000 - Train Loss: 0.6048 - Test Loss: 5.2345 - MSE: 5.2345 - MAE: 1.8602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13141/20000 - Train Loss: 0.6047 - Test Loss: 5.2341 - MSE: 5.2341 - MAE: 1.8602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13142/20000 - Train Loss: 0.6047 - Test Loss: 5.2341 - MSE: 5.2341 - MAE: 1.8601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13143/20000 - Train Loss: 0.6047 - Test Loss: 5.2337 - MSE: 5.2337 - MAE: 1.8601\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13144/20000 - Train Loss: 0.6047 - Test Loss: 5.2337 - MSE: 5.2337 - MAE: 1.8601\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13145/20000 - Train Loss: 0.6046 - Test Loss: 5.2332 - MSE: 5.2332 - MAE: 1.8600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13146/20000 - Train Loss: 0.6046 - Test Loss: 5.2332 - MSE: 5.2332 - MAE: 1.8600\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13147/20000 - Train Loss: 0.6046 - Test Loss: 5.2327 - MSE: 5.2327 - MAE: 1.8599\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13148/20000 - Train Loss: 0.6045 - Test Loss: 5.2328 - MSE: 5.2328 - MAE: 1.8599\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13149/20000 - Train Loss: 0.6045 - Test Loss: 5.2323 - MSE: 5.2323 - MAE: 1.8598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13150/20000 - Train Loss: 0.6045 - Test Loss: 5.2324 - MSE: 5.2324 - MAE: 1.8598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13151/20000 - Train Loss: 0.6045 - Test Loss: 5.2318 - MSE: 5.2318 - MAE: 1.8597\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13152/20000 - Train Loss: 0.6044 - Test Loss: 5.2320 - MSE: 5.2320 - MAE: 1.8597\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 13153/20000 - Train Loss: 0.6044 - Test Loss: 5.2313 - MSE: 5.2313 - MAE: 1.8596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13154/20000 - Train Loss: 0.6044 - Test Loss: 5.2317 - MSE: 5.2317 - MAE: 1.8597\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13155/20000 - Train Loss: 0.6043 - Test Loss: 5.2307 - MSE: 5.2307 - MAE: 1.8595\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13156/20000 - Train Loss: 0.6043 - Test Loss: 5.2313 - MSE: 5.2313 - MAE: 1.8596\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13157/20000 - Train Loss: 0.6043 - Test Loss: 5.2302 - MSE: 5.2302 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13158/20000 - Train Loss: 0.6042 - Test Loss: 5.2310 - MSE: 5.2310 - MAE: 1.8595\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13159/20000 - Train Loss: 0.6042 - Test Loss: 5.2296 - MSE: 5.2296 - MAE: 1.8593\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13160/20000 - Train Loss: 0.6042 - Test Loss: 5.2308 - MSE: 5.2308 - MAE: 1.8595\n",
      "2/2 [==============================] - 0s 994us/step\n",
      "Epoch 13161/20000 - Train Loss: 0.6042 - Test Loss: 5.2289 - MSE: 5.2289 - MAE: 1.8592\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13162/20000 - Train Loss: 0.6041 - Test Loss: 5.2306 - MSE: 5.2306 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13163/20000 - Train Loss: 0.6041 - Test Loss: 5.2282 - MSE: 5.2282 - MAE: 1.8591\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13164/20000 - Train Loss: 0.6041 - Test Loss: 5.2305 - MSE: 5.2305 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13165/20000 - Train Loss: 0.6040 - Test Loss: 5.2273 - MSE: 5.2273 - MAE: 1.8590\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13166/20000 - Train Loss: 0.6040 - Test Loss: 5.2305 - MSE: 5.2305 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13167/20000 - Train Loss: 0.6040 - Test Loss: 5.2263 - MSE: 5.2263 - MAE: 1.8588\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13168/20000 - Train Loss: 0.6039 - Test Loss: 5.2309 - MSE: 5.2309 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13169/20000 - Train Loss: 0.6039 - Test Loss: 5.2249 - MSE: 5.2249 - MAE: 1.8586\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13170/20000 - Train Loss: 0.6039 - Test Loss: 5.2316 - MSE: 5.2316 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13171/20000 - Train Loss: 0.6039 - Test Loss: 5.2230 - MSE: 5.2230 - MAE: 1.8583\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 13172/20000 - Train Loss: 0.6038 - Test Loss: 5.2330 - MSE: 5.2330 - MAE: 1.8596\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 13173/20000 - Train Loss: 0.6038 - Test Loss: 5.2202 - MSE: 5.2202 - MAE: 1.8579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13174/20000 - Train Loss: 0.6038 - Test Loss: 5.2355 - MSE: 5.2355 - MAE: 1.8599\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13175/20000 - Train Loss: 0.6038 - Test Loss: 5.2162 - MSE: 5.2162 - MAE: 1.8574\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13176/20000 - Train Loss: 0.6037 - Test Loss: 5.2396 - MSE: 5.2396 - MAE: 1.8604\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13177/20000 - Train Loss: 0.6037 - Test Loss: 5.2100 - MSE: 5.2100 - MAE: 1.8566\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13178/20000 - Train Loss: 0.6038 - Test Loss: 5.2467 - MSE: 5.2467 - MAE: 1.8612\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13179/20000 - Train Loss: 0.6038 - Test Loss: 5.2003 - MSE: 5.2003 - MAE: 1.8553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13180/20000 - Train Loss: 0.6039 - Test Loss: 5.2585 - MSE: 5.2585 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13181/20000 - Train Loss: 0.6040 - Test Loss: 5.1849 - MSE: 5.1849 - MAE: 1.8532\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13182/20000 - Train Loss: 0.6043 - Test Loss: 5.2786 - MSE: 5.2786 - MAE: 1.8651\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13183/20000 - Train Loss: 0.6047 - Test Loss: 5.1603 - MSE: 5.1603 - MAE: 1.8499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13184/20000 - Train Loss: 0.6055 - Test Loss: 5.3129 - MSE: 5.3129 - MAE: 1.8692\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13185/20000 - Train Loss: 0.6067 - Test Loss: 5.1212 - MSE: 5.1212 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13186/20000 - Train Loss: 0.6087 - Test Loss: 5.3710 - MSE: 5.3710 - MAE: 1.8760\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13187/20000 - Train Loss: 0.6119 - Test Loss: 5.0622 - MSE: 5.0622 - MAE: 1.8358\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13188/20000 - Train Loss: 0.6169 - Test Loss: 5.4665 - MSE: 5.4665 - MAE: 1.8865\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13189/20000 - Train Loss: 0.6242 - Test Loss: 4.9831 - MSE: 4.9831 - MAE: 1.8231\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13190/20000 - Train Loss: 0.6337 - Test Loss: 5.6023 - MSE: 5.6023 - MAE: 1.9034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13191/20000 - Train Loss: 0.6437 - Test Loss: 4.9065 - MSE: 4.9065 - MAE: 1.8103\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13192/20000 - Train Loss: 0.6502 - Test Loss: 5.7086 - MSE: 5.7086 - MAE: 1.9166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13193/20000 - Train Loss: 0.6474 - Test Loss: 4.8948 - MSE: 4.8948 - MAE: 1.8090\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13194/20000 - Train Loss: 0.6335 - Test Loss: 5.6013 - MSE: 5.6013 - MAE: 1.9033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13195/20000 - Train Loss: 0.6152 - Test Loss: 5.0332 - MSE: 5.0332 - MAE: 1.8312\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13196/20000 - Train Loss: 0.6040 - Test Loss: 5.2798 - MSE: 5.2798 - MAE: 1.8651\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13197/20000 - Train Loss: 0.6055 - Test Loss: 5.3184 - MSE: 5.3184 - MAE: 1.8697\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13198/20000 - Train Loss: 0.6150 - Test Loss: 5.0337 - MSE: 5.0337 - MAE: 1.8313\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13199/20000 - Train Loss: 0.6226 - Test Loss: 5.5174 - MSE: 5.5174 - MAE: 1.8923\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13200/20000 - Train Loss: 0.6211 - Test Loss: 4.9954 - MSE: 4.9954 - MAE: 1.8251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13201/20000 - Train Loss: 0.6122 - Test Loss: 5.4180 - MSE: 5.4180 - MAE: 1.8810\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13202/20000 - Train Loss: 0.6043 - Test Loss: 5.1540 - MSE: 5.1540 - MAE: 1.8488\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13203/20000 - Train Loss: 0.6037 - Test Loss: 5.1705 - MSE: 5.1705 - MAE: 1.8510\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 13204/20000 - Train Loss: 0.6088 - Test Loss: 5.3759 - MSE: 5.3759 - MAE: 1.8763\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 13205/20000 - Train Loss: 0.6131 - Test Loss: 5.0448 - MSE: 5.0448 - MAE: 1.8330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13206/20000 - Train Loss: 0.6119 - Test Loss: 5.4151 - MSE: 5.4151 - MAE: 1.8806\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13207/20000 - Train Loss: 0.6068 - Test Loss: 5.1069 - MSE: 5.1069 - MAE: 1.8422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13208/20000 - Train Loss: 0.6030 - Test Loss: 5.2500 - MSE: 5.2500 - MAE: 1.8613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13209/20000 - Train Loss: 0.6037 - Test Loss: 5.2802 - MSE: 5.2802 - MAE: 1.8650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13210/20000 - Train Loss: 0.6069 - Test Loss: 5.1036 - MSE: 5.1036 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13211/20000 - Train Loss: 0.6085 - Test Loss: 5.3724 - MSE: 5.3724 - MAE: 1.8757\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13212/20000 - Train Loss: 0.6068 - Test Loss: 5.1039 - MSE: 5.1039 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13213/20000 - Train Loss: 0.6038 - Test Loss: 5.2862 - MSE: 5.2862 - MAE: 1.8656\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13214/20000 - Train Loss: 0.6026 - Test Loss: 5.2227 - MSE: 5.2227 - MAE: 1.8577\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13215/20000 - Train Loss: 0.6038 - Test Loss: 5.1545 - MSE: 5.1545 - MAE: 1.8487\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13216/20000 - Train Loss: 0.6055 - Test Loss: 5.3246 - MSE: 5.3246 - MAE: 1.8702\n",
      "2/2 [==============================] - 0s 984us/step\n",
      "Epoch 13217/20000 - Train Loss: 0.6056 - Test Loss: 5.1182 - MSE: 5.1182 - MAE: 1.8437\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13218/20000 - Train Loss: 0.6041 - Test Loss: 5.2964 - MSE: 5.2964 - MAE: 1.8668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13219/20000 - Train Loss: 0.6027 - Test Loss: 5.1897 - MSE: 5.1897 - MAE: 1.8534\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13220/20000 - Train Loss: 0.6026 - Test Loss: 5.1941 - MSE: 5.1941 - MAE: 1.8540\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13221/20000 - Train Loss: 0.6035 - Test Loss: 5.2818 - MSE: 5.2818 - MAE: 1.8650\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13222/20000 - Train Loss: 0.6042 - Test Loss: 5.1396 - MSE: 5.1396 - MAE: 1.8466\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13223/20000 - Train Loss: 0.6038 - Test Loss: 5.2913 - MSE: 5.2913 - MAE: 1.8661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13224/20000 - Train Loss: 0.6029 - Test Loss: 5.1732 - MSE: 5.1732 - MAE: 1.8512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13225/20000 - Train Loss: 0.6023 - Test Loss: 5.2223 - MSE: 5.2223 - MAE: 1.8575\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13226/20000 - Train Loss: 0.6026 - Test Loss: 5.2466 - MSE: 5.2466 - MAE: 1.8606\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13227/20000 - Train Loss: 0.6031 - Test Loss: 5.1633 - MSE: 5.1633 - MAE: 1.8498\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13228/20000 - Train Loss: 0.6032 - Test Loss: 5.2772 - MSE: 5.2772 - MAE: 1.8643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13229/20000 - Train Loss: 0.6029 - Test Loss: 5.1683 - MSE: 5.1683 - MAE: 1.8504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13230/20000 - Train Loss: 0.6024 - Test Loss: 5.2396 - MSE: 5.2396 - MAE: 1.8597\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 13231/20000 - Train Loss: 0.6022 - Test Loss: 5.2198 - MSE: 5.2198 - MAE: 1.8571\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 13232/20000 - Train Loss: 0.6024 - Test Loss: 5.1862 - MSE: 5.1862 - MAE: 1.8528\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13233/20000 - Train Loss: 0.6026 - Test Loss: 5.2585 - MSE: 5.2585 - MAE: 1.8620\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13234/20000 - Train Loss: 0.6026 - Test Loss: 5.1719 - MSE: 5.1719 - MAE: 1.8509\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 13235/20000 - Train Loss: 0.6023 - Test Loss: 5.2467 - MSE: 5.2467 - MAE: 1.8605\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13236/20000 - Train Loss: 0.6021 - Test Loss: 5.2016 - MSE: 5.2016 - MAE: 1.8547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13237/20000 - Train Loss: 0.6020 - Test Loss: 5.2058 - MSE: 5.2058 - MAE: 1.8553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13238/20000 - Train Loss: 0.6021 - Test Loss: 5.2387 - MSE: 5.2387 - MAE: 1.8594\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13239/20000 - Train Loss: 0.6023 - Test Loss: 5.1812 - MSE: 5.1812 - MAE: 1.8520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13240/20000 - Train Loss: 0.6022 - Test Loss: 5.2451 - MSE: 5.2451 - MAE: 1.8602\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13241/20000 - Train Loss: 0.6020 - Test Loss: 5.1918 - MSE: 5.1918 - MAE: 1.8534\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13242/20000 - Train Loss: 0.6019 - Test Loss: 5.2200 - MSE: 5.2200 - MAE: 1.8570\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13243/20000 - Train Loss: 0.6019 - Test Loss: 5.2207 - MSE: 5.2207 - MAE: 1.8571\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13244/20000 - Train Loss: 0.6019 - Test Loss: 5.1934 - MSE: 5.1934 - MAE: 1.8536\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13245/20000 - Train Loss: 0.6020 - Test Loss: 5.2371 - MSE: 5.2371 - MAE: 1.8592\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 13246/20000 - Train Loss: 0.6019 - Test Loss: 5.1895 - MSE: 5.1895 - MAE: 1.8530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13247/20000 - Train Loss: 0.6018 - Test Loss: 5.2275 - MSE: 5.2275 - MAE: 1.8579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13248/20000 - Train Loss: 0.6017 - Test Loss: 5.2069 - MSE: 5.2069 - MAE: 1.8553\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13249/20000 - Train Loss: 0.6017 - Test Loss: 5.2056 - MSE: 5.2056 - MAE: 1.8551\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13250/20000 - Train Loss: 0.6017 - Test Loss: 5.2256 - MSE: 5.2256 - MAE: 1.8576\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 13251/20000 - Train Loss: 0.6017 - Test Loss: 5.1933 - MSE: 5.1933 - MAE: 1.8535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13252/20000 - Train Loss: 0.6017 - Test Loss: 5.2280 - MSE: 5.2280 - MAE: 1.8579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13253/20000 - Train Loss: 0.6016 - Test Loss: 5.1990 - MSE: 5.1990 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "Epoch 13254/20000 - Train Loss: 0.6016 - Test Loss: 5.2148 - MSE: 5.2148 - MAE: 1.8562\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13255/20000 - Train Loss: 0.6015 - Test Loss: 5.2139 - MSE: 5.2139 - MAE: 1.8561\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13256/20000 - Train Loss: 0.6015 - Test Loss: 5.2004 - MSE: 5.2004 - MAE: 1.8543\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13257/20000 - Train Loss: 0.6015 - Test Loss: 5.2230 - MSE: 5.2230 - MAE: 1.8572\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13258/20000 - Train Loss: 0.6015 - Test Loss: 5.1970 - MSE: 5.1970 - MAE: 1.8539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13259/20000 - Train Loss: 0.6014 - Test Loss: 5.2192 - MSE: 5.2192 - MAE: 1.8567\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13260/20000 - Train Loss: 0.6014 - Test Loss: 5.2049 - MSE: 5.2049 - MAE: 1.8549\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13261/20000 - Train Loss: 0.6014 - Test Loss: 5.2079 - MSE: 5.2079 - MAE: 1.8552\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13262/20000 - Train Loss: 0.6013 - Test Loss: 5.2150 - MSE: 5.2150 - MAE: 1.8561\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13263/20000 - Train Loss: 0.6013 - Test Loss: 5.1998 - MSE: 5.1998 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13264/20000 - Train Loss: 0.6013 - Test Loss: 5.2182 - MSE: 5.2182 - MAE: 1.8565\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13265/20000 - Train Loss: 0.6013 - Test Loss: 5.2004 - MSE: 5.2004 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13266/20000 - Train Loss: 0.6012 - Test Loss: 5.2129 - MSE: 5.2129 - MAE: 1.8558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13267/20000 - Train Loss: 0.6012 - Test Loss: 5.2073 - MSE: 5.2073 - MAE: 1.8551\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13268/20000 - Train Loss: 0.6012 - Test Loss: 5.2047 - MSE: 5.2047 - MAE: 1.8547\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13269/20000 - Train Loss: 0.6011 - Test Loss: 5.2133 - MSE: 5.2133 - MAE: 1.8558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13270/20000 - Train Loss: 0.6011 - Test Loss: 5.2004 - MSE: 5.2004 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 13271/20000 - Train Loss: 0.6011 - Test Loss: 5.2136 - MSE: 5.2136 - MAE: 1.8558\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13272/20000 - Train Loss: 0.6011 - Test Loss: 5.2023 - MSE: 5.2023 - MAE: 1.8544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13273/20000 - Train Loss: 0.6010 - Test Loss: 5.2088 - MSE: 5.2088 - MAE: 1.8552\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13274/20000 - Train Loss: 0.6010 - Test Loss: 5.2073 - MSE: 5.2073 - MAE: 1.8550\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13275/20000 - Train Loss: 0.6010 - Test Loss: 5.2032 - MSE: 5.2032 - MAE: 1.8545\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13276/20000 - Train Loss: 0.6010 - Test Loss: 5.2108 - MSE: 5.2108 - MAE: 1.8554\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13277/20000 - Train Loss: 0.6009 - Test Loss: 5.2009 - MSE: 5.2009 - MAE: 1.8541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13278/20000 - Train Loss: 0.6009 - Test Loss: 5.2102 - MSE: 5.2102 - MAE: 1.8553\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13279/20000 - Train Loss: 0.6009 - Test Loss: 5.2026 - MSE: 5.2026 - MAE: 1.8543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13280/20000 - Train Loss: 0.6008 - Test Loss: 5.2064 - MSE: 5.2064 - MAE: 1.8548\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13281/20000 - Train Loss: 0.6008 - Test Loss: 5.2060 - MSE: 5.2060 - MAE: 1.8547\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 13282/20000 - Train Loss: 0.6008 - Test Loss: 5.2026 - MSE: 5.2026 - MAE: 1.8543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13283/20000 - Train Loss: 0.6008 - Test Loss: 5.2080 - MSE: 5.2080 - MAE: 1.8550\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13284/20000 - Train Loss: 0.6007 - Test Loss: 5.2011 - MSE: 5.2011 - MAE: 1.8541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13285/20000 - Train Loss: 0.6007 - Test Loss: 5.2074 - MSE: 5.2074 - MAE: 1.8549\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13286/20000 - Train Loss: 0.6007 - Test Loss: 5.2021 - MSE: 5.2021 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13287/20000 - Train Loss: 0.6007 - Test Loss: 5.2046 - MSE: 5.2046 - MAE: 1.8545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13288/20000 - Train Loss: 0.6006 - Test Loss: 5.2044 - MSE: 5.2044 - MAE: 1.8544\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13289/20000 - Train Loss: 0.6006 - Test Loss: 5.2019 - MSE: 5.2019 - MAE: 1.8541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13290/20000 - Train Loss: 0.6006 - Test Loss: 5.2057 - MSE: 5.2057 - MAE: 1.8546\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13291/20000 - Train Loss: 0.6005 - Test Loss: 5.2006 - MSE: 5.2006 - MAE: 1.8539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13292/20000 - Train Loss: 0.6005 - Test Loss: 5.2051 - MSE: 5.2051 - MAE: 1.8545\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13293/20000 - Train Loss: 0.6005 - Test Loss: 5.2012 - MSE: 5.2012 - MAE: 1.8540\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13294/20000 - Train Loss: 0.6005 - Test Loss: 5.2032 - MSE: 5.2032 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13295/20000 - Train Loss: 0.6004 - Test Loss: 5.2025 - MSE: 5.2025 - MAE: 1.8541\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13296/20000 - Train Loss: 0.6004 - Test Loss: 5.2012 - MSE: 5.2012 - MAE: 1.8539\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13297/20000 - Train Loss: 0.6004 - Test Loss: 5.2034 - MSE: 5.2034 - MAE: 1.8542\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13298/20000 - Train Loss: 0.6004 - Test Loss: 5.2001 - MSE: 5.2001 - MAE: 1.8538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13299/20000 - Train Loss: 0.6003 - Test Loss: 5.2031 - MSE: 5.2031 - MAE: 1.8541\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13300/20000 - Train Loss: 0.6003 - Test Loss: 5.2001 - MSE: 5.2001 - MAE: 1.8537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13301/20000 - Train Loss: 0.6003 - Test Loss: 5.2019 - MSE: 5.2019 - MAE: 1.8539\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13302/20000 - Train Loss: 0.6002 - Test Loss: 5.2007 - MSE: 5.2007 - MAE: 1.8538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13303/20000 - Train Loss: 0.6002 - Test Loss: 5.2003 - MSE: 5.2003 - MAE: 1.8537\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13304/20000 - Train Loss: 0.6002 - Test Loss: 5.2013 - MSE: 5.2013 - MAE: 1.8538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13305/20000 - Train Loss: 0.6002 - Test Loss: 5.1993 - MSE: 5.1993 - MAE: 1.8536\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13306/20000 - Train Loss: 0.6001 - Test Loss: 5.2012 - MSE: 5.2012 - MAE: 1.8538\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13307/20000 - Train Loss: 0.6001 - Test Loss: 5.1990 - MSE: 5.1990 - MAE: 1.8535\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13308/20000 - Train Loss: 0.6001 - Test Loss: 5.2004 - MSE: 5.2004 - MAE: 1.8537\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13309/20000 - Train Loss: 0.6001 - Test Loss: 5.1992 - MSE: 5.1992 - MAE: 1.8535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13310/20000 - Train Loss: 0.6000 - Test Loss: 5.1993 - MSE: 5.1993 - MAE: 1.8535\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 13311/20000 - Train Loss: 0.6000 - Test Loss: 5.1995 - MSE: 5.1995 - MAE: 1.8535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13312/20000 - Train Loss: 0.6000 - Test Loss: 5.1983 - MSE: 5.1983 - MAE: 1.8533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13313/20000 - Train Loss: 0.5999 - Test Loss: 5.1995 - MSE: 5.1995 - MAE: 1.8535\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13314/20000 - Train Loss: 0.5999 - Test Loss: 5.1977 - MSE: 5.1977 - MAE: 1.8532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13315/20000 - Train Loss: 0.5999 - Test Loss: 5.1990 - MSE: 5.1990 - MAE: 1.8534\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 13316/20000 - Train Loss: 0.5999 - Test Loss: 5.1975 - MSE: 5.1975 - MAE: 1.8532\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 13317/20000 - Train Loss: 0.5998 - Test Loss: 5.1983 - MSE: 5.1983 - MAE: 1.8533\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13318/20000 - Train Loss: 0.5998 - Test Loss: 5.1976 - MSE: 5.1976 - MAE: 1.8532\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13319/20000 - Train Loss: 0.5998 - Test Loss: 5.1974 - MSE: 5.1974 - MAE: 1.8531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13320/20000 - Train Loss: 0.5998 - Test Loss: 5.1976 - MSE: 5.1976 - MAE: 1.8531\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13321/20000 - Train Loss: 0.5997 - Test Loss: 5.1966 - MSE: 5.1966 - MAE: 1.8530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13322/20000 - Train Loss: 0.5997 - Test Loss: 5.1975 - MSE: 5.1975 - MAE: 1.8531\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13323/20000 - Train Loss: 0.5997 - Test Loss: 5.1961 - MSE: 5.1961 - MAE: 1.8529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13324/20000 - Train Loss: 0.5996 - Test Loss: 5.1970 - MSE: 5.1970 - MAE: 1.8530\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13325/20000 - Train Loss: 0.5996 - Test Loss: 5.1959 - MSE: 5.1959 - MAE: 1.8529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13326/20000 - Train Loss: 0.5996 - Test Loss: 5.1963 - MSE: 5.1963 - MAE: 1.8529\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 13327/20000 - Train Loss: 0.5996 - Test Loss: 5.1957 - MSE: 5.1957 - MAE: 1.8528\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13328/20000 - Train Loss: 0.5995 - Test Loss: 5.1956 - MSE: 5.1956 - MAE: 1.8528\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13329/20000 - Train Loss: 0.5995 - Test Loss: 5.1956 - MSE: 5.1956 - MAE: 1.8528\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13330/20000 - Train Loss: 0.5995 - Test Loss: 5.1950 - MSE: 5.1950 - MAE: 1.8527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13331/20000 - Train Loss: 0.5995 - Test Loss: 5.1954 - MSE: 5.1954 - MAE: 1.8527\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13332/20000 - Train Loss: 0.5994 - Test Loss: 5.1945 - MSE: 5.1945 - MAE: 1.8526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13333/20000 - Train Loss: 0.5994 - Test Loss: 5.1950 - MSE: 5.1950 - MAE: 1.8526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13334/20000 - Train Loss: 0.5994 - Test Loss: 5.1942 - MSE: 5.1942 - MAE: 1.8525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13335/20000 - Train Loss: 0.5993 - Test Loss: 5.1945 - MSE: 5.1945 - MAE: 1.8525\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13336/20000 - Train Loss: 0.5993 - Test Loss: 5.1939 - MSE: 5.1939 - MAE: 1.8525\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 13337/20000 - Train Loss: 0.5993 - Test Loss: 5.1939 - MSE: 5.1939 - MAE: 1.8524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13338/20000 - Train Loss: 0.5993 - Test Loss: 5.1937 - MSE: 5.1937 - MAE: 1.8524\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13339/20000 - Train Loss: 0.5992 - Test Loss: 5.1933 - MSE: 5.1933 - MAE: 1.8523\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13340/20000 - Train Loss: 0.5992 - Test Loss: 5.1934 - MSE: 5.1934 - MAE: 1.8523\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13341/20000 - Train Loss: 0.5992 - Test Loss: 5.1928 - MSE: 5.1928 - MAE: 1.8522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13342/20000 - Train Loss: 0.5992 - Test Loss: 5.1930 - MSE: 5.1930 - MAE: 1.8523\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13343/20000 - Train Loss: 0.5991 - Test Loss: 5.1924 - MSE: 5.1924 - MAE: 1.8522\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13344/20000 - Train Loss: 0.5991 - Test Loss: 5.1926 - MSE: 5.1926 - MAE: 1.8522\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13345/20000 - Train Loss: 0.5991 - Test Loss: 5.1921 - MSE: 5.1921 - MAE: 1.8521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13346/20000 - Train Loss: 0.5990 - Test Loss: 5.1922 - MSE: 5.1922 - MAE: 1.8521\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13347/20000 - Train Loss: 0.5990 - Test Loss: 5.1917 - MSE: 5.1917 - MAE: 1.8520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13348/20000 - Train Loss: 0.5990 - Test Loss: 5.1917 - MSE: 5.1917 - MAE: 1.8520\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13349/20000 - Train Loss: 0.5990 - Test Loss: 5.1914 - MSE: 5.1914 - MAE: 1.8519\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13350/20000 - Train Loss: 0.5989 - Test Loss: 5.1912 - MSE: 5.1912 - MAE: 1.8519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13351/20000 - Train Loss: 0.5989 - Test Loss: 5.1910 - MSE: 5.1911 - MAE: 1.8519\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13352/20000 - Train Loss: 0.5989 - Test Loss: 5.1907 - MSE: 5.1907 - MAE: 1.8518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13353/20000 - Train Loss: 0.5989 - Test Loss: 5.1907 - MSE: 5.1906 - MAE: 1.8518\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13354/20000 - Train Loss: 0.5988 - Test Loss: 5.1903 - MSE: 5.1903 - MAE: 1.8517\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 13355/20000 - Train Loss: 0.5988 - Test Loss: 5.1902 - MSE: 5.1902 - MAE: 1.8517\n",
      "2/2 [==============================] - 0s 990us/step\n",
      "Epoch 13356/20000 - Train Loss: 0.5988 - Test Loss: 5.1900 - MSE: 5.1900 - MAE: 1.8517\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13357/20000 - Train Loss: 0.5987 - Test Loss: 5.1898 - MSE: 5.1898 - MAE: 1.8516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13358/20000 - Train Loss: 0.5987 - Test Loss: 5.1896 - MSE: 5.1896 - MAE: 1.8516\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13359/20000 - Train Loss: 0.5987 - Test Loss: 5.1893 - MSE: 5.1893 - MAE: 1.8515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13360/20000 - Train Loss: 0.5987 - Test Loss: 5.1892 - MSE: 5.1892 - MAE: 1.8515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13361/20000 - Train Loss: 0.5986 - Test Loss: 5.1889 - MSE: 5.1889 - MAE: 1.8515\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13362/20000 - Train Loss: 0.5986 - Test Loss: 5.1888 - MSE: 5.1888 - MAE: 1.8514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13363/20000 - Train Loss: 0.5986 - Test Loss: 5.1885 - MSE: 5.1885 - MAE: 1.8514\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13364/20000 - Train Loss: 0.5986 - Test Loss: 5.1884 - MSE: 5.1884 - MAE: 1.8514\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 13365/20000 - Train Loss: 0.5985 - Test Loss: 5.1881 - MSE: 5.1881 - MAE: 1.8513\n",
      "2/2 [==============================] - 0s 992us/step\n",
      "Epoch 13366/20000 - Train Loss: 0.5985 - Test Loss: 5.1880 - MSE: 5.1880 - MAE: 1.8513\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13367/20000 - Train Loss: 0.5985 - Test Loss: 5.1877 - MSE: 5.1877 - MAE: 1.8512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13368/20000 - Train Loss: 0.5984 - Test Loss: 5.1875 - MSE: 5.1875 - MAE: 1.8512\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13369/20000 - Train Loss: 0.5984 - Test Loss: 5.1873 - MSE: 5.1873 - MAE: 1.8512\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13370/20000 - Train Loss: 0.5984 - Test Loss: 5.1871 - MSE: 5.1871 - MAE: 1.8511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13371/20000 - Train Loss: 0.5984 - Test Loss: 5.1870 - MSE: 5.1870 - MAE: 1.8511\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13372/20000 - Train Loss: 0.5983 - Test Loss: 5.1867 - MSE: 5.1867 - MAE: 1.8510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13373/20000 - Train Loss: 0.5983 - Test Loss: 5.1866 - MSE: 5.1866 - MAE: 1.8510\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13374/20000 - Train Loss: 0.5983 - Test Loss: 5.1863 - MSE: 5.1863 - MAE: 1.8509\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13375/20000 - Train Loss: 0.5982 - Test Loss: 5.1861 - MSE: 5.1861 - MAE: 1.8509\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13376/20000 - Train Loss: 0.5982 - Test Loss: 5.1859 - MSE: 5.1859 - MAE: 1.8509\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13377/20000 - Train Loss: 0.5982 - Test Loss: 5.1857 - MSE: 5.1857 - MAE: 1.8508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13378/20000 - Train Loss: 0.5982 - Test Loss: 5.1854 - MSE: 5.1854 - MAE: 1.8508\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13379/20000 - Train Loss: 0.5981 - Test Loss: 5.1853 - MSE: 5.1853 - MAE: 1.8508\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 13380/20000 - Train Loss: 0.5981 - Test Loss: 5.1850 - MSE: 5.1850 - MAE: 1.8507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13381/20000 - Train Loss: 0.5981 - Test Loss: 5.1850 - MSE: 5.1850 - MAE: 1.8507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13382/20000 - Train Loss: 0.5981 - Test Loss: 5.1846 - MSE: 5.1846 - MAE: 1.8506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13383/20000 - Train Loss: 0.5980 - Test Loss: 5.1846 - MSE: 5.1846 - MAE: 1.8506\n",
      "2/2 [==============================] - 0s 974us/step\n",
      "Epoch 13384/20000 - Train Loss: 0.5980 - Test Loss: 5.1841 - MSE: 5.1841 - MAE: 1.8505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13385/20000 - Train Loss: 0.5980 - Test Loss: 5.1842 - MSE: 5.1842 - MAE: 1.8505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13386/20000 - Train Loss: 0.5979 - Test Loss: 5.1837 - MSE: 5.1837 - MAE: 1.8504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13387/20000 - Train Loss: 0.5979 - Test Loss: 5.1838 - MSE: 5.1838 - MAE: 1.8504\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 13388/20000 - Train Loss: 0.5979 - Test Loss: 5.1833 - MSE: 5.1833 - MAE: 1.8504\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "Epoch 13389/20000 - Train Loss: 0.5979 - Test Loss: 5.1833 - MSE: 5.1833 - MAE: 1.8503\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 13390/20000 - Train Loss: 0.5978 - Test Loss: 5.1829 - MSE: 5.1829 - MAE: 1.8503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13391/20000 - Train Loss: 0.5978 - Test Loss: 5.1829 - MSE: 5.1829 - MAE: 1.8503\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13392/20000 - Train Loss: 0.5978 - Test Loss: 5.1826 - MSE: 5.1826 - MAE: 1.8502\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13393/20000 - Train Loss: 0.5978 - Test Loss: 5.1825 - MSE: 5.1825 - MAE: 1.8502\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13394/20000 - Train Loss: 0.5977 - Test Loss: 5.1821 - MSE: 5.1821 - MAE: 1.8501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13395/20000 - Train Loss: 0.5977 - Test Loss: 5.1821 - MSE: 5.1821 - MAE: 1.8501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13396/20000 - Train Loss: 0.5977 - Test Loss: 5.1817 - MSE: 5.1817 - MAE: 1.8500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13397/20000 - Train Loss: 0.5976 - Test Loss: 5.1817 - MSE: 5.1817 - MAE: 1.8500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13398/20000 - Train Loss: 0.5976 - Test Loss: 5.1812 - MSE: 5.1812 - MAE: 1.8500\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 13399/20000 - Train Loss: 0.5976 - Test Loss: 5.1813 - MSE: 5.1813 - MAE: 1.8500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13400/20000 - Train Loss: 0.5976 - Test Loss: 5.1808 - MSE: 5.1808 - MAE: 1.8499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13401/20000 - Train Loss: 0.5975 - Test Loss: 5.1810 - MSE: 5.1810 - MAE: 1.8499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13402/20000 - Train Loss: 0.5975 - Test Loss: 5.1803 - MSE: 5.1803 - MAE: 1.8498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13403/20000 - Train Loss: 0.5975 - Test Loss: 5.1807 - MSE: 5.1807 - MAE: 1.8498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13404/20000 - Train Loss: 0.5974 - Test Loss: 5.1798 - MSE: 5.1798 - MAE: 1.8497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13405/20000 - Train Loss: 0.5974 - Test Loss: 5.1804 - MSE: 5.1804 - MAE: 1.8497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13406/20000 - Train Loss: 0.5974 - Test Loss: 5.1792 - MSE: 5.1792 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13407/20000 - Train Loss: 0.5974 - Test Loss: 5.1801 - MSE: 5.1801 - MAE: 1.8497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13408/20000 - Train Loss: 0.5973 - Test Loss: 5.1786 - MSE: 5.1786 - MAE: 1.8495\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13409/20000 - Train Loss: 0.5973 - Test Loss: 5.1800 - MSE: 5.1800 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13410/20000 - Train Loss: 0.5973 - Test Loss: 5.1779 - MSE: 5.1779 - MAE: 1.8494\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13411/20000 - Train Loss: 0.5973 - Test Loss: 5.1799 - MSE: 5.1799 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13412/20000 - Train Loss: 0.5972 - Test Loss: 5.1771 - MSE: 5.1771 - MAE: 1.8492\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13413/20000 - Train Loss: 0.5972 - Test Loss: 5.1800 - MSE: 5.1800 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13414/20000 - Train Loss: 0.5972 - Test Loss: 5.1761 - MSE: 5.1761 - MAE: 1.8491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13415/20000 - Train Loss: 0.5971 - Test Loss: 5.1803 - MSE: 5.1803 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 991us/step\n",
      "Epoch 13416/20000 - Train Loss: 0.5971 - Test Loss: 5.1747 - MSE: 5.1747 - MAE: 1.8488\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13417/20000 - Train Loss: 0.5971 - Test Loss: 5.1811 - MSE: 5.1811 - MAE: 1.8497\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13418/20000 - Train Loss: 0.5971 - Test Loss: 5.1729 - MSE: 5.1729 - MAE: 1.8486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13419/20000 - Train Loss: 0.5970 - Test Loss: 5.1824 - MSE: 5.1824 - MAE: 1.8498\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13420/20000 - Train Loss: 0.5970 - Test Loss: 5.1704 - MSE: 5.1704 - MAE: 1.8482\n",
      "2/2 [==============================] - 0s 989us/step\n",
      "Epoch 13421/20000 - Train Loss: 0.5970 - Test Loss: 5.1846 - MSE: 5.1846 - MAE: 1.8500\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13422/20000 - Train Loss: 0.5970 - Test Loss: 5.1667 - MSE: 5.1667 - MAE: 1.8477\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13423/20000 - Train Loss: 0.5970 - Test Loss: 5.1883 - MSE: 5.1883 - MAE: 1.8505\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13424/20000 - Train Loss: 0.5970 - Test Loss: 5.1612 - MSE: 5.1612 - MAE: 1.8470\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13425/20000 - Train Loss: 0.5970 - Test Loss: 5.1946 - MSE: 5.1946 - MAE: 1.8513\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13426/20000 - Train Loss: 0.5970 - Test Loss: 5.1526 - MSE: 5.1526 - MAE: 1.8458\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13427/20000 - Train Loss: 0.5971 - Test Loss: 5.2050 - MSE: 5.2050 - MAE: 1.8526\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13428/20000 - Train Loss: 0.5972 - Test Loss: 5.1390 - MSE: 5.1390 - MAE: 1.8440\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13429/20000 - Train Loss: 0.5974 - Test Loss: 5.2224 - MSE: 5.2224 - MAE: 1.8547\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13430/20000 - Train Loss: 0.5977 - Test Loss: 5.1176 - MSE: 5.1176 - MAE: 1.8411\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 13431/20000 - Train Loss: 0.5983 - Test Loss: 5.2517 - MSE: 5.2517 - MAE: 1.8583\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13432/20000 - Train Loss: 0.5992 - Test Loss: 5.0837 - MSE: 5.0837 - MAE: 1.8363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13433/20000 - Train Loss: 0.6008 - Test Loss: 5.3010 - MSE: 5.3010 - MAE: 1.8641\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13434/20000 - Train Loss: 0.6032 - Test Loss: 5.0321 - MSE: 5.0321 - MAE: 1.8288\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13435/20000 - Train Loss: 0.6071 - Test Loss: 5.3826 - MSE: 5.3826 - MAE: 1.8733\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13436/20000 - Train Loss: 0.6128 - Test Loss: 4.9604 - MSE: 4.9604 - MAE: 1.8175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13437/20000 - Train Loss: 0.6208 - Test Loss: 5.5041 - MSE: 5.5041 - MAE: 1.8882\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13438/20000 - Train Loss: 0.6303 - Test Loss: 4.8825 - MSE: 4.8825 - MAE: 1.8044\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13439/20000 - Train Loss: 0.6389 - Test Loss: 5.6265 - MSE: 5.6265 - MAE: 1.9038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13440/20000 - Train Loss: 0.6416 - Test Loss: 4.8467 - MSE: 4.8467 - MAE: 1.8009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13441/20000 - Train Loss: 0.6342 - Test Loss: 5.5971 - MSE: 5.5971 - MAE: 1.9001\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13442/20000 - Train Loss: 0.6181 - Test Loss: 4.9311 - MSE: 4.9311 - MAE: 1.8125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13443/20000 - Train Loss: 0.6023 - Test Loss: 5.3262 - MSE: 5.3262 - MAE: 1.8668\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13444/20000 - Train Loss: 0.5963 - Test Loss: 5.1751 - MSE: 5.1751 - MAE: 1.8485\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13445/20000 - Train Loss: 0.6015 - Test Loss: 5.0447 - MSE: 5.0447 - MAE: 1.8305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13446/20000 - Train Loss: 0.6109 - Test Loss: 5.4213 - MSE: 5.4213 - MAE: 1.8773\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13447/20000 - Train Loss: 0.6154 - Test Loss: 4.9428 - MSE: 4.9428 - MAE: 1.8144\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 13448/20000 - Train Loss: 0.6111 - Test Loss: 5.4235 - MSE: 5.4235 - MAE: 1.8775\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13449/20000 - Train Loss: 0.6022 - Test Loss: 5.0362 - MSE: 5.0362 - MAE: 1.8292\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13450/20000 - Train Loss: 0.5965 - Test Loss: 5.2029 - MSE: 5.2029 - MAE: 1.8520\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13451/20000 - Train Loss: 0.5979 - Test Loss: 5.2515 - MSE: 5.2515 - MAE: 1.8579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13452/20000 - Train Loss: 0.6031 - Test Loss: 5.0250 - MSE: 5.0250 - MAE: 1.8275\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13453/20000 - Train Loss: 0.6060 - Test Loss: 5.3724 - MSE: 5.3724 - MAE: 1.8719\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13454/20000 - Train Loss: 0.6037 - Test Loss: 5.0191 - MSE: 5.0191 - MAE: 1.8266\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13455/20000 - Train Loss: 0.5988 - Test Loss: 5.2716 - MSE: 5.2716 - MAE: 1.8603\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13456/20000 - Train Loss: 0.5961 - Test Loss: 5.1586 - MSE: 5.1586 - MAE: 1.8462\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13457/20000 - Train Loss: 0.5974 - Test Loss: 5.1021 - MSE: 5.1021 - MAE: 1.8386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13458/20000 - Train Loss: 0.6003 - Test Loss: 5.2993 - MSE: 5.2993 - MAE: 1.8635\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13459/20000 - Train Loss: 0.6013 - Test Loss: 5.0409 - MSE: 5.0409 - MAE: 1.8298\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13460/20000 - Train Loss: 0.5994 - Test Loss: 5.2852 - MSE: 5.2852 - MAE: 1.8618\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13461/20000 - Train Loss: 0.5968 - Test Loss: 5.1145 - MSE: 5.1145 - MAE: 1.8402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13462/20000 - Train Loss: 0.5959 - Test Loss: 5.1589 - MSE: 5.1589 - MAE: 1.8462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13463/20000 - Train Loss: 0.5971 - Test Loss: 5.2362 - MSE: 5.2362 - MAE: 1.8559\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13464/20000 - Train Loss: 0.5986 - Test Loss: 5.0748 - MSE: 5.0748 - MAE: 1.8347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13465/20000 - Train Loss: 0.5986 - Test Loss: 5.2713 - MSE: 5.2713 - MAE: 1.8601\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13466/20000 - Train Loss: 0.5973 - Test Loss: 5.0985 - MSE: 5.0985 - MAE: 1.8380\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13467/20000 - Train Loss: 0.5960 - Test Loss: 5.1950 - MSE: 5.1950 - MAE: 1.8507\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13468/20000 - Train Loss: 0.5959 - Test Loss: 5.1886 - MSE: 5.1886 - MAE: 1.8499\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13469/20000 - Train Loss: 0.5967 - Test Loss: 5.1106 - MSE: 5.1106 - MAE: 1.8396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13470/20000 - Train Loss: 0.5973 - Test Loss: 5.2451 - MSE: 5.2451 - MAE: 1.8569\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13471/20000 - Train Loss: 0.5971 - Test Loss: 5.0994 - MSE: 5.0994 - MAE: 1.8380\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13472/20000 - Train Loss: 0.5962 - Test Loss: 5.2128 - MSE: 5.2128 - MAE: 1.8529\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13473/20000 - Train Loss: 0.5956 - Test Loss: 5.1562 - MSE: 5.1562 - MAE: 1.8457\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13474/20000 - Train Loss: 0.5958 - Test Loss: 5.1428 - MSE: 5.1428 - MAE: 1.8439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13475/20000 - Train Loss: 0.5962 - Test Loss: 5.2152 - MSE: 5.2152 - MAE: 1.8531\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13476/20000 - Train Loss: 0.5965 - Test Loss: 5.1109 - MSE: 5.1109 - MAE: 1.8396\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13477/20000 - Train Loss: 0.5962 - Test Loss: 5.2157 - MSE: 5.2157 - MAE: 1.8532\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13478/20000 - Train Loss: 0.5957 - Test Loss: 5.1375 - MSE: 5.1375 - MAE: 1.8431\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13479/20000 - Train Loss: 0.5955 - Test Loss: 5.1679 - MSE: 5.1679 - MAE: 1.8471\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13480/20000 - Train Loss: 0.5956 - Test Loss: 5.1871 - MSE: 5.1871 - MAE: 1.8495\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13481/20000 - Train Loss: 0.5958 - Test Loss: 5.1282 - MSE: 5.1282 - MAE: 1.8418\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13482/20000 - Train Loss: 0.5959 - Test Loss: 5.2075 - MSE: 5.2075 - MAE: 1.8521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13483/20000 - Train Loss: 0.5957 - Test Loss: 5.1306 - MSE: 5.1306 - MAE: 1.8421\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13484/20000 - Train Loss: 0.5954 - Test Loss: 5.1836 - MSE: 5.1836 - MAE: 1.8490\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13485/20000 - Train Loss: 0.5953 - Test Loss: 5.1644 - MSE: 5.1644 - MAE: 1.8466\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13486/20000 - Train Loss: 0.5954 - Test Loss: 5.1470 - MSE: 5.1470 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13487/20000 - Train Loss: 0.5955 - Test Loss: 5.1925 - MSE: 5.1925 - MAE: 1.8501\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13488/20000 - Train Loss: 0.5955 - Test Loss: 5.1333 - MSE: 5.1333 - MAE: 1.8424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13489/20000 - Train Loss: 0.5954 - Test Loss: 5.1892 - MSE: 5.1892 - MAE: 1.8497\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 13490/20000 - Train Loss: 0.5952 - Test Loss: 5.1495 - MSE: 5.1495 - MAE: 1.8446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13491/20000 - Train Loss: 0.5952 - Test Loss: 5.1634 - MSE: 5.1634 - MAE: 1.8463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13492/20000 - Train Loss: 0.5952 - Test Loss: 5.1753 - MSE: 5.1753 - MAE: 1.8479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13493/20000 - Train Loss: 0.5952 - Test Loss: 5.1426 - MSE: 5.1426 - MAE: 1.8436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13494/20000 - Train Loss: 0.5952 - Test Loss: 5.1856 - MSE: 5.1856 - MAE: 1.8492\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13495/20000 - Train Loss: 0.5952 - Test Loss: 5.1434 - MSE: 5.1434 - MAE: 1.8437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13496/20000 - Train Loss: 0.5951 - Test Loss: 5.1737 - MSE: 5.1737 - MAE: 1.8476\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13497/20000 - Train Loss: 0.5950 - Test Loss: 5.1606 - MSE: 5.1606 - MAE: 1.8459\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13498/20000 - Train Loss: 0.5950 - Test Loss: 5.1542 - MSE: 5.1542 - MAE: 1.8451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13499/20000 - Train Loss: 0.5950 - Test Loss: 5.1759 - MSE: 5.1759 - MAE: 1.8479\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Epoch 13500/20000 - Train Loss: 0.5950 - Test Loss: 5.1451 - MSE: 5.1451 - MAE: 1.8438\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13501/20000 - Train Loss: 0.5950 - Test Loss: 5.1763 - MSE: 5.1763 - MAE: 1.8479\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13502/20000 - Train Loss: 0.5949 - Test Loss: 5.1513 - MSE: 5.1513 - MAE: 1.8446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13503/20000 - Train Loss: 0.5949 - Test Loss: 5.1641 - MSE: 5.1641 - MAE: 1.8463\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13504/20000 - Train Loss: 0.5948 - Test Loss: 5.1645 - MSE: 5.1645 - MAE: 1.8463\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13505/20000 - Train Loss: 0.5948 - Test Loss: 5.1516 - MSE: 5.1516 - MAE: 1.8446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13506/20000 - Train Loss: 0.5948 - Test Loss: 5.1722 - MSE: 5.1722 - MAE: 1.8473\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13507/20000 - Train Loss: 0.5948 - Test Loss: 5.1488 - MSE: 5.1488 - MAE: 1.8442\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13508/20000 - Train Loss: 0.5948 - Test Loss: 5.1688 - MSE: 5.1688 - MAE: 1.8468\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13509/20000 - Train Loss: 0.5947 - Test Loss: 5.1555 - MSE: 5.1555 - MAE: 1.8451\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13510/20000 - Train Loss: 0.5947 - Test Loss: 5.1590 - MSE: 5.1590 - MAE: 1.8455\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13511/20000 - Train Loss: 0.5947 - Test Loss: 5.1644 - MSE: 5.1644 - MAE: 1.8462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13512/20000 - Train Loss: 0.5947 - Test Loss: 5.1516 - MSE: 5.1516 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13513/20000 - Train Loss: 0.5946 - Test Loss: 5.1677 - MSE: 5.1677 - MAE: 1.8466\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13514/20000 - Train Loss: 0.5946 - Test Loss: 5.1514 - MSE: 5.1514 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13515/20000 - Train Loss: 0.5946 - Test Loss: 5.1637 - MSE: 5.1637 - MAE: 1.8461\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13516/20000 - Train Loss: 0.5945 - Test Loss: 5.1569 - MSE: 5.1569 - MAE: 1.8452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13517/20000 - Train Loss: 0.5945 - Test Loss: 5.1567 - MSE: 5.1567 - MAE: 1.8451\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13518/20000 - Train Loss: 0.5945 - Test Loss: 5.1625 - MSE: 5.1625 - MAE: 1.8459\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13519/20000 - Train Loss: 0.5945 - Test Loss: 5.1521 - MSE: 5.1521 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13520/20000 - Train Loss: 0.5945 - Test Loss: 5.1639 - MSE: 5.1639 - MAE: 1.8460\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13521/20000 - Train Loss: 0.5944 - Test Loss: 5.1526 - MSE: 5.1526 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13522/20000 - Train Loss: 0.5944 - Test Loss: 5.1605 - MSE: 5.1605 - MAE: 1.8456\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13523/20000 - Train Loss: 0.5944 - Test Loss: 5.1564 - MSE: 5.1564 - MAE: 1.8450\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13524/20000 - Train Loss: 0.5943 - Test Loss: 5.1556 - MSE: 5.1556 - MAE: 1.8449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13525/20000 - Train Loss: 0.5943 - Test Loss: 5.1601 - MSE: 5.1601 - MAE: 1.8454\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13526/20000 - Train Loss: 0.5943 - Test Loss: 5.1525 - MSE: 5.1525 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13527/20000 - Train Loss: 0.5943 - Test Loss: 5.1607 - MSE: 5.1607 - MAE: 1.8455\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13528/20000 - Train Loss: 0.5942 - Test Loss: 5.1528 - MSE: 5.1528 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13529/20000 - Train Loss: 0.5942 - Test Loss: 5.1583 - MSE: 5.1583 - MAE: 1.8452\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13530/20000 - Train Loss: 0.5942 - Test Loss: 5.1553 - MSE: 5.1553 - MAE: 1.8448\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13531/20000 - Train Loss: 0.5942 - Test Loss: 5.1548 - MSE: 5.1548 - MAE: 1.8447\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13532/20000 - Train Loss: 0.5941 - Test Loss: 5.1577 - MSE: 5.1577 - MAE: 1.8451\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13533/20000 - Train Loss: 0.5941 - Test Loss: 5.1524 - MSE: 5.1524 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13534/20000 - Train Loss: 0.5941 - Test Loss: 5.1582 - MSE: 5.1582 - MAE: 1.8451\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 13535/20000 - Train Loss: 0.5941 - Test Loss: 5.1523 - MSE: 5.1523 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13536/20000 - Train Loss: 0.5940 - Test Loss: 5.1566 - MSE: 5.1566 - MAE: 1.8449\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13537/20000 - Train Loss: 0.5940 - Test Loss: 5.1538 - MSE: 5.1538 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13538/20000 - Train Loss: 0.5940 - Test Loss: 5.1541 - MSE: 5.1541 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13539/20000 - Train Loss: 0.5940 - Test Loss: 5.1554 - MSE: 5.1554 - MAE: 1.8447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13540/20000 - Train Loss: 0.5939 - Test Loss: 5.1522 - MSE: 5.1522 - MAE: 1.8442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13541/20000 - Train Loss: 0.5939 - Test Loss: 5.1560 - MSE: 5.1560 - MAE: 1.8447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13542/20000 - Train Loss: 0.5939 - Test Loss: 5.1516 - MSE: 5.1516 - MAE: 1.8441\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13543/20000 - Train Loss: 0.5939 - Test Loss: 5.1551 - MSE: 5.1551 - MAE: 1.8446\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13544/20000 - Train Loss: 0.5938 - Test Loss: 5.1523 - MSE: 5.1523 - MAE: 1.8442\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13545/20000 - Train Loss: 0.5938 - Test Loss: 5.1534 - MSE: 5.1534 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13546/20000 - Train Loss: 0.5938 - Test Loss: 5.1533 - MSE: 5.1533 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13547/20000 - Train Loss: 0.5938 - Test Loss: 5.1518 - MSE: 5.1518 - MAE: 1.8441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13548/20000 - Train Loss: 0.5937 - Test Loss: 5.1538 - MSE: 5.1538 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13549/20000 - Train Loss: 0.5937 - Test Loss: 5.1509 - MSE: 5.1509 - MAE: 1.8439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13550/20000 - Train Loss: 0.5937 - Test Loss: 5.1535 - MSE: 5.1535 - MAE: 1.8442\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13551/20000 - Train Loss: 0.5937 - Test Loss: 5.1509 - MSE: 5.1509 - MAE: 1.8439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13552/20000 - Train Loss: 0.5936 - Test Loss: 5.1525 - MSE: 5.1525 - MAE: 1.8441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13553/20000 - Train Loss: 0.5936 - Test Loss: 5.1513 - MSE: 5.1513 - MAE: 1.8439\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13554/20000 - Train Loss: 0.5936 - Test Loss: 5.1512 - MSE: 5.1512 - MAE: 1.8439\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13555/20000 - Train Loss: 0.5936 - Test Loss: 5.1518 - MSE: 5.1518 - MAE: 1.8440\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13556/20000 - Train Loss: 0.5935 - Test Loss: 5.1502 - MSE: 5.1502 - MAE: 1.8437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13557/20000 - Train Loss: 0.5935 - Test Loss: 5.1517 - MSE: 5.1517 - MAE: 1.8439\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 13558/20000 - Train Loss: 0.5935 - Test Loss: 5.1498 - MSE: 5.1498 - MAE: 1.8436\n",
      "2/2 [==============================] - 0s 987us/step\n",
      "Epoch 13559/20000 - Train Loss: 0.5935 - Test Loss: 5.1512 - MSE: 5.1512 - MAE: 1.8438\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13560/20000 - Train Loss: 0.5934 - Test Loss: 5.1497 - MSE: 5.1497 - MAE: 1.8436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13561/20000 - Train Loss: 0.5934 - Test Loss: 5.1503 - MSE: 5.1503 - MAE: 1.8437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13562/20000 - Train Loss: 0.5934 - Test Loss: 5.1499 - MSE: 5.1499 - MAE: 1.8436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13563/20000 - Train Loss: 0.5934 - Test Loss: 5.1494 - MSE: 5.1494 - MAE: 1.8435\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13564/20000 - Train Loss: 0.5933 - Test Loss: 5.1500 - MSE: 5.1500 - MAE: 1.8436\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13565/20000 - Train Loss: 0.5933 - Test Loss: 5.1488 - MSE: 5.1488 - MAE: 1.8434\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13566/20000 - Train Loss: 0.5933 - Test Loss: 5.1497 - MSE: 5.1497 - MAE: 1.8435\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13567/20000 - Train Loss: 0.5933 - Test Loss: 5.1484 - MSE: 5.1484 - MAE: 1.8433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13568/20000 - Train Loss: 0.5932 - Test Loss: 5.1492 - MSE: 5.1492 - MAE: 1.8434\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13569/20000 - Train Loss: 0.5932 - Test Loss: 5.1483 - MSE: 5.1483 - MAE: 1.8433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13570/20000 - Train Loss: 0.5932 - Test Loss: 5.1484 - MSE: 5.1484 - MAE: 1.8433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13571/20000 - Train Loss: 0.5932 - Test Loss: 5.1482 - MSE: 5.1482 - MAE: 1.8433\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13572/20000 - Train Loss: 0.5931 - Test Loss: 5.1478 - MSE: 5.1478 - MAE: 1.8432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13573/20000 - Train Loss: 0.5931 - Test Loss: 5.1481 - MSE: 5.1481 - MAE: 1.8432\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13574/20000 - Train Loss: 0.5931 - Test Loss: 5.1472 - MSE: 5.1472 - MAE: 1.8431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13575/20000 - Train Loss: 0.5931 - Test Loss: 5.1478 - MSE: 5.1478 - MAE: 1.8431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13576/20000 - Train Loss: 0.5930 - Test Loss: 5.1469 - MSE: 5.1469 - MAE: 1.8430\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13577/20000 - Train Loss: 0.5930 - Test Loss: 5.1474 - MSE: 5.1474 - MAE: 1.8431\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13578/20000 - Train Loss: 0.5930 - Test Loss: 5.1466 - MSE: 5.1466 - MAE: 1.8429\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13579/20000 - Train Loss: 0.5930 - Test Loss: 5.1469 - MSE: 5.1469 - MAE: 1.8430\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13580/20000 - Train Loss: 0.5929 - Test Loss: 5.1463 - MSE: 5.1463 - MAE: 1.8429\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13581/20000 - Train Loss: 0.5929 - Test Loss: 5.1463 - MSE: 5.1463 - MAE: 1.8429\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 13582/20000 - Train Loss: 0.5929 - Test Loss: 5.1461 - MSE: 5.1461 - MAE: 1.8428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13583/20000 - Train Loss: 0.5928 - Test Loss: 5.1458 - MSE: 5.1458 - MAE: 1.8428\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13584/20000 - Train Loss: 0.5928 - Test Loss: 5.1459 - MSE: 5.1459 - MAE: 1.8428\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13585/20000 - Train Loss: 0.5928 - Test Loss: 5.1453 - MSE: 5.1453 - MAE: 1.8427\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13586/20000 - Train Loss: 0.5928 - Test Loss: 5.1455 - MSE: 5.1455 - MAE: 1.8427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13587/20000 - Train Loss: 0.5927 - Test Loss: 5.1450 - MSE: 5.1450 - MAE: 1.8426\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13588/20000 - Train Loss: 0.5927 - Test Loss: 5.1451 - MSE: 5.1451 - MAE: 1.8426\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13589/20000 - Train Loss: 0.5927 - Test Loss: 5.1446 - MSE: 5.1446 - MAE: 1.8425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13590/20000 - Train Loss: 0.5927 - Test Loss: 5.1447 - MSE: 5.1447 - MAE: 1.8425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13591/20000 - Train Loss: 0.5926 - Test Loss: 5.1443 - MSE: 5.1443 - MAE: 1.8425\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13592/20000 - Train Loss: 0.5926 - Test Loss: 5.1442 - MSE: 5.1442 - MAE: 1.8424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13593/20000 - Train Loss: 0.5926 - Test Loss: 5.1440 - MSE: 5.1440 - MAE: 1.8424\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13594/20000 - Train Loss: 0.5926 - Test Loss: 5.1437 - MSE: 5.1437 - MAE: 1.8423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13595/20000 - Train Loss: 0.5925 - Test Loss: 5.1437 - MSE: 5.1437 - MAE: 1.8423\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13596/20000 - Train Loss: 0.5925 - Test Loss: 5.1433 - MSE: 5.1433 - MAE: 1.8423\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13597/20000 - Train Loss: 0.5925 - Test Loss: 5.1433 - MSE: 5.1433 - MAE: 1.8423\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13598/20000 - Train Loss: 0.5925 - Test Loss: 5.1429 - MSE: 5.1429 - MAE: 1.8422\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13599/20000 - Train Loss: 0.5924 - Test Loss: 5.1429 - MSE: 5.1429 - MAE: 1.8422\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13600/20000 - Train Loss: 0.5924 - Test Loss: 5.1426 - MSE: 5.1426 - MAE: 1.8421\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13601/20000 - Train Loss: 0.5924 - Test Loss: 5.1425 - MSE: 5.1425 - MAE: 1.8421\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13602/20000 - Train Loss: 0.5924 - Test Loss: 5.1423 - MSE: 5.1423 - MAE: 1.8420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13603/20000 - Train Loss: 0.5923 - Test Loss: 5.1421 - MSE: 5.1421 - MAE: 1.8420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13604/20000 - Train Loss: 0.5923 - Test Loss: 5.1419 - MSE: 5.1419 - MAE: 1.8420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13605/20000 - Train Loss: 0.5923 - Test Loss: 5.1417 - MSE: 5.1417 - MAE: 1.8419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13606/20000 - Train Loss: 0.5923 - Test Loss: 5.1416 - MSE: 5.1416 - MAE: 1.8419\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13607/20000 - Train Loss: 0.5922 - Test Loss: 5.1412 - MSE: 5.1412 - MAE: 1.8418\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13608/20000 - Train Loss: 0.5922 - Test Loss: 5.1412 - MSE: 5.1412 - MAE: 1.8418\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13609/20000 - Train Loss: 0.5922 - Test Loss: 5.1408 - MSE: 5.1408 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13610/20000 - Train Loss: 0.5922 - Test Loss: 5.1409 - MSE: 5.1409 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13611/20000 - Train Loss: 0.5921 - Test Loss: 5.1404 - MSE: 5.1404 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13612/20000 - Train Loss: 0.5921 - Test Loss: 5.1405 - MSE: 5.1405 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13613/20000 - Train Loss: 0.5921 - Test Loss: 5.1400 - MSE: 5.1400 - MAE: 1.8416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13614/20000 - Train Loss: 0.5921 - Test Loss: 5.1401 - MSE: 5.1401 - MAE: 1.8416\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13615/20000 - Train Loss: 0.5920 - Test Loss: 5.1397 - MSE: 5.1397 - MAE: 1.8415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13616/20000 - Train Loss: 0.5920 - Test Loss: 5.1397 - MSE: 5.1397 - MAE: 1.8415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13617/20000 - Train Loss: 0.5920 - Test Loss: 5.1393 - MSE: 5.1393 - MAE: 1.8414\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13618/20000 - Train Loss: 0.5920 - Test Loss: 5.1393 - MSE: 5.1393 - MAE: 1.8414\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13619/20000 - Train Loss: 0.5919 - Test Loss: 5.1389 - MSE: 5.1389 - MAE: 1.8414\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13620/20000 - Train Loss: 0.5919 - Test Loss: 5.1389 - MSE: 5.1389 - MAE: 1.8413\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13621/20000 - Train Loss: 0.5919 - Test Loss: 5.1386 - MSE: 5.1386 - MAE: 1.8413\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13622/20000 - Train Loss: 0.5919 - Test Loss: 5.1385 - MSE: 5.1385 - MAE: 1.8412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13623/20000 - Train Loss: 0.5918 - Test Loss: 5.1382 - MSE: 5.1382 - MAE: 1.8412\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13624/20000 - Train Loss: 0.5918 - Test Loss: 5.1381 - MSE: 5.1381 - MAE: 1.8412\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13625/20000 - Train Loss: 0.5918 - Test Loss: 5.1379 - MSE: 5.1379 - MAE: 1.8411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13626/20000 - Train Loss: 0.5917 - Test Loss: 5.1376 - MSE: 5.1376 - MAE: 1.8411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13627/20000 - Train Loss: 0.5917 - Test Loss: 5.1375 - MSE: 5.1375 - MAE: 1.8411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13628/20000 - Train Loss: 0.5917 - Test Loss: 5.1372 - MSE: 5.1372 - MAE: 1.8410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13629/20000 - Train Loss: 0.5917 - Test Loss: 5.1371 - MSE: 5.1371 - MAE: 1.8410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13630/20000 - Train Loss: 0.5916 - Test Loss: 5.1368 - MSE: 5.1368 - MAE: 1.8409\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13631/20000 - Train Loss: 0.5916 - Test Loss: 5.1368 - MSE: 5.1368 - MAE: 1.8409\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13632/20000 - Train Loss: 0.5916 - Test Loss: 5.1364 - MSE: 5.1364 - MAE: 1.8408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13633/20000 - Train Loss: 0.5916 - Test Loss: 5.1364 - MSE: 5.1364 - MAE: 1.8408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13634/20000 - Train Loss: 0.5915 - Test Loss: 5.1360 - MSE: 5.1360 - MAE: 1.8408\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13635/20000 - Train Loss: 0.5915 - Test Loss: 5.1361 - MSE: 5.1361 - MAE: 1.8407\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13636/20000 - Train Loss: 0.5915 - Test Loss: 5.1356 - MSE: 5.1356 - MAE: 1.8407\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13637/20000 - Train Loss: 0.5915 - Test Loss: 5.1357 - MSE: 5.1357 - MAE: 1.8407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13638/20000 - Train Loss: 0.5914 - Test Loss: 5.1352 - MSE: 5.1352 - MAE: 1.8406\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13639/20000 - Train Loss: 0.5914 - Test Loss: 5.1354 - MSE: 5.1354 - MAE: 1.8406\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13640/20000 - Train Loss: 0.5914 - Test Loss: 5.1348 - MSE: 5.1348 - MAE: 1.8405\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13641/20000 - Train Loss: 0.5914 - Test Loss: 5.1350 - MSE: 5.1350 - MAE: 1.8405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13642/20000 - Train Loss: 0.5913 - Test Loss: 5.1343 - MSE: 5.1343 - MAE: 1.8404\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13643/20000 - Train Loss: 0.5913 - Test Loss: 5.1347 - MSE: 5.1347 - MAE: 1.8404\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13644/20000 - Train Loss: 0.5913 - Test Loss: 5.1338 - MSE: 5.1338 - MAE: 1.8403\n",
      "2/2 [==============================] - 0s 977us/step\n",
      "Epoch 13645/20000 - Train Loss: 0.5913 - Test Loss: 5.1344 - MSE: 5.1344 - MAE: 1.8404\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13646/20000 - Train Loss: 0.5912 - Test Loss: 5.1333 - MSE: 5.1333 - MAE: 1.8402\n",
      "2/2 [==============================] - 0s 979us/step\n",
      "Epoch 13647/20000 - Train Loss: 0.5912 - Test Loss: 5.1342 - MSE: 5.1342 - MAE: 1.8403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13648/20000 - Train Loss: 0.5912 - Test Loss: 5.1328 - MSE: 5.1328 - MAE: 1.8401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13649/20000 - Train Loss: 0.5912 - Test Loss: 5.1341 - MSE: 5.1341 - MAE: 1.8403\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13650/20000 - Train Loss: 0.5911 - Test Loss: 5.1321 - MSE: 5.1321 - MAE: 1.8400\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13651/20000 - Train Loss: 0.5911 - Test Loss: 5.1340 - MSE: 5.1340 - MAE: 1.8402\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13652/20000 - Train Loss: 0.5911 - Test Loss: 5.1313 - MSE: 5.1313 - MAE: 1.8399\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13653/20000 - Train Loss: 0.5911 - Test Loss: 5.1341 - MSE: 5.1341 - MAE: 1.8402\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13654/20000 - Train Loss: 0.5910 - Test Loss: 5.1304 - MSE: 5.1304 - MAE: 1.8397\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13655/20000 - Train Loss: 0.5910 - Test Loss: 5.1343 - MSE: 5.1343 - MAE: 1.8402\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13656/20000 - Train Loss: 0.5910 - Test Loss: 5.1292 - MSE: 5.1292 - MAE: 1.8395\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13657/20000 - Train Loss: 0.5910 - Test Loss: 5.1349 - MSE: 5.1349 - MAE: 1.8403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13658/20000 - Train Loss: 0.5909 - Test Loss: 5.1276 - MSE: 5.1276 - MAE: 1.8393\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 13659/20000 - Train Loss: 0.5909 - Test Loss: 5.1360 - MSE: 5.1360 - MAE: 1.8404\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13660/20000 - Train Loss: 0.5909 - Test Loss: 5.1254 - MSE: 5.1254 - MAE: 1.8390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13661/20000 - Train Loss: 0.5909 - Test Loss: 5.1379 - MSE: 5.1379 - MAE: 1.8406\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 13662/20000 - Train Loss: 0.5908 - Test Loss: 5.1222 - MSE: 5.1222 - MAE: 1.8385\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13663/20000 - Train Loss: 0.5908 - Test Loss: 5.1411 - MSE: 5.1411 - MAE: 1.8410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13664/20000 - Train Loss: 0.5908 - Test Loss: 5.1175 - MSE: 5.1175 - MAE: 1.8379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13665/20000 - Train Loss: 0.5908 - Test Loss: 5.1463 - MSE: 5.1463 - MAE: 1.8416\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13666/20000 - Train Loss: 0.5908 - Test Loss: 5.1102 - MSE: 5.1102 - MAE: 1.8369\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13667/20000 - Train Loss: 0.5909 - Test Loss: 5.1550 - MSE: 5.1550 - MAE: 1.8427\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13668/20000 - Train Loss: 0.5910 - Test Loss: 5.0988 - MSE: 5.0988 - MAE: 1.8353\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 13669/20000 - Train Loss: 0.5911 - Test Loss: 5.1694 - MSE: 5.1694 - MAE: 1.8445\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13670/20000 - Train Loss: 0.5913 - Test Loss: 5.0808 - MSE: 5.0808 - MAE: 1.8328\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13671/20000 - Train Loss: 0.5917 - Test Loss: 5.1934 - MSE: 5.1934 - MAE: 1.8475\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13672/20000 - Train Loss: 0.5924 - Test Loss: 5.0524 - MSE: 5.0524 - MAE: 1.8289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13673/20000 - Train Loss: 0.5935 - Test Loss: 5.2339 - MSE: 5.2339 - MAE: 1.8523\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13674/20000 - Train Loss: 0.5952 - Test Loss: 5.0085 - MSE: 5.0085 - MAE: 1.8225\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13675/20000 - Train Loss: 0.5980 - Test Loss: 5.3013 - MSE: 5.3013 - MAE: 1.8602\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13676/20000 - Train Loss: 0.6023 - Test Loss: 4.9450 - MSE: 4.9450 - MAE: 1.8127\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13677/20000 - Train Loss: 0.6086 - Test Loss: 5.4067 - MSE: 5.4067 - MAE: 1.8726\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13678/20000 - Train Loss: 0.6170 - Test Loss: 4.8679 - MSE: 4.8679 - MAE: 1.7996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13679/20000 - Train Loss: 0.6263 - Test Loss: 5.5366 - MSE: 5.5366 - MAE: 1.8897\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13680/20000 - Train Loss: 0.6336 - Test Loss: 4.8108 - MSE: 4.8108 - MAE: 1.7938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13681/20000 - Train Loss: 0.6338 - Test Loss: 5.5832 - MSE: 5.5832 - MAE: 1.8955\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13682/20000 - Train Loss: 0.6237 - Test Loss: 4.8413 - MSE: 4.8413 - MAE: 1.7964\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13683/20000 - Train Loss: 0.6070 - Test Loss: 5.3933 - MSE: 5.3933 - MAE: 1.8707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13684/20000 - Train Loss: 0.5934 - Test Loss: 5.0270 - MSE: 5.0270 - MAE: 1.8251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13685/20000 - Train Loss: 0.5907 - Test Loss: 5.0889 - MSE: 5.0889 - MAE: 1.8337\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13686/20000 - Train Loss: 0.5976 - Test Loss: 5.2969 - MSE: 5.2969 - MAE: 1.8595\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 13687/20000 - Train Loss: 0.6062 - Test Loss: 4.9168 - MSE: 4.9168 - MAE: 1.8079\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13688/20000 - Train Loss: 0.6087 - Test Loss: 5.4075 - MSE: 5.4075 - MAE: 1.8726\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 13689/20000 - Train Loss: 0.6028 - Test Loss: 4.9371 - MSE: 4.9371 - MAE: 1.8113\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13690/20000 - Train Loss: 0.5942 - Test Loss: 5.2502 - MSE: 5.2502 - MAE: 1.8540\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13691/20000 - Train Loss: 0.5901 - Test Loss: 5.1186 - MSE: 5.1186 - MAE: 1.8376\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13692/20000 - Train Loss: 0.5927 - Test Loss: 5.0339 - MSE: 5.0339 - MAE: 1.8260\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 13693/20000 - Train Loss: 0.5978 - Test Loss: 5.3003 - MSE: 5.3003 - MAE: 1.8597\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 13694/20000 - Train Loss: 0.5996 - Test Loss: 4.9585 - MSE: 4.9585 - MAE: 1.8146\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 13695/20000 - Train Loss: 0.5966 - Test Loss: 5.2850 - MSE: 5.2850 - MAE: 1.8580\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 13696/20000 - Train Loss: 0.5919 - Test Loss: 5.0467 - MSE: 5.0467 - MAE: 1.8277\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13697/20000 - Train Loss: 0.5900 - Test Loss: 5.1205 - MSE: 5.1205 - MAE: 1.8378\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13698/20000 - Train Loss: 0.5917 - Test Loss: 5.2057 - MSE: 5.2057 - MAE: 1.8485\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13699/20000 - Train Loss: 0.5944 - Test Loss: 5.0063 - MSE: 5.0063 - MAE: 1.8219\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13700/20000 - Train Loss: 0.5950 - Test Loss: 5.2637 - MSE: 5.2637 - MAE: 1.8554\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13701/20000 - Train Loss: 0.5929 - Test Loss: 5.0268 - MSE: 5.0268 - MAE: 1.8248\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13702/20000 - Train Loss: 0.5904 - Test Loss: 5.1702 - MSE: 5.1702 - MAE: 1.8441\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13703/20000 - Train Loss: 0.5899 - Test Loss: 5.1405 - MSE: 5.1405 - MAE: 1.8403\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13704/20000 - Train Loss: 0.5912 - Test Loss: 5.0561 - MSE: 5.0561 - MAE: 1.8290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13705/20000 - Train Loss: 0.5925 - Test Loss: 5.2238 - MSE: 5.2238 - MAE: 1.8506\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13706/20000 - Train Loss: 0.5923 - Test Loss: 5.0324 - MSE: 5.0324 - MAE: 1.8256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13707/20000 - Train Loss: 0.5910 - Test Loss: 5.1906 - MSE: 5.1906 - MAE: 1.8465\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13708/20000 - Train Loss: 0.5898 - Test Loss: 5.1005 - MSE: 5.1005 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13709/20000 - Train Loss: 0.5898 - Test Loss: 5.0987 - MSE: 5.0987 - MAE: 1.8347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13710/20000 - Train Loss: 0.5906 - Test Loss: 5.1819 - MSE: 5.1819 - MAE: 1.8454\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13711/20000 - Train Loss: 0.5912 - Test Loss: 5.0509 - MSE: 5.0509 - MAE: 1.8281\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13712/20000 - Train Loss: 0.5909 - Test Loss: 5.1904 - MSE: 5.1904 - MAE: 1.8465\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13713/20000 - Train Loss: 0.5901 - Test Loss: 5.0800 - MSE: 5.0800 - MAE: 1.8321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13714/20000 - Train Loss: 0.5896 - Test Loss: 5.1301 - MSE: 5.1301 - MAE: 1.8388\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13715/20000 - Train Loss: 0.5897 - Test Loss: 5.1452 - MSE: 5.1452 - MAE: 1.8407\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13716/20000 - Train Loss: 0.5901 - Test Loss: 5.0752 - MSE: 5.0752 - MAE: 1.8315\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13717/20000 - Train Loss: 0.5904 - Test Loss: 5.1769 - MSE: 5.1769 - MAE: 1.8447\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13718/20000 - Train Loss: 0.5901 - Test Loss: 5.0744 - MSE: 5.0744 - MAE: 1.8313\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13719/20000 - Train Loss: 0.5897 - Test Loss: 5.1486 - MSE: 5.1486 - MAE: 1.8411\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13720/20000 - Train Loss: 0.5894 - Test Loss: 5.1172 - MSE: 5.1172 - MAE: 1.8370\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13721/20000 - Train Loss: 0.5895 - Test Loss: 5.1000 - MSE: 5.1000 - MAE: 1.8347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13722/20000 - Train Loss: 0.5897 - Test Loss: 5.1563 - MSE: 5.1563 - MAE: 1.8420\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13723/20000 - Train Loss: 0.5898 - Test Loss: 5.0800 - MSE: 5.0800 - MAE: 1.8320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13724/20000 - Train Loss: 0.5897 - Test Loss: 5.1542 - MSE: 5.1542 - MAE: 1.8417\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13725/20000 - Train Loss: 0.5894 - Test Loss: 5.0999 - MSE: 5.0999 - MAE: 1.8347\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 13726/20000 - Train Loss: 0.5893 - Test Loss: 5.1206 - MSE: 5.1206 - MAE: 1.8374\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13727/20000 - Train Loss: 0.5893 - Test Loss: 5.1343 - MSE: 5.1343 - MAE: 1.8392\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13728/20000 - Train Loss: 0.5894 - Test Loss: 5.0928 - MSE: 5.0928 - MAE: 1.8337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13729/20000 - Train Loss: 0.5895 - Test Loss: 5.1488 - MSE: 5.1488 - MAE: 1.8410\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13730/20000 - Train Loss: 0.5894 - Test Loss: 5.0935 - MSE: 5.0935 - MAE: 1.8337\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13731/20000 - Train Loss: 0.5892 - Test Loss: 5.1334 - MSE: 5.1334 - MAE: 1.8390\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13732/20000 - Train Loss: 0.5891 - Test Loss: 5.1162 - MSE: 5.1162 - MAE: 1.8367\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13733/20000 - Train Loss: 0.5891 - Test Loss: 5.1078 - MSE: 5.1078 - MAE: 1.8356\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13734/20000 - Train Loss: 0.5892 - Test Loss: 5.1367 - MSE: 5.1367 - MAE: 1.8394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13735/20000 - Train Loss: 0.5892 - Test Loss: 5.0960 - MSE: 5.0960 - MAE: 1.8340\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13736/20000 - Train Loss: 0.5892 - Test Loss: 5.1370 - MSE: 5.1370 - MAE: 1.8394\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13737/20000 - Train Loss: 0.5891 - Test Loss: 5.1048 - MSE: 5.1048 - MAE: 1.8352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13738/20000 - Train Loss: 0.5890 - Test Loss: 5.1204 - MSE: 5.1204 - MAE: 1.8372\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13739/20000 - Train Loss: 0.5890 - Test Loss: 5.1226 - MSE: 5.1226 - MAE: 1.8375\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13740/20000 - Train Loss: 0.5890 - Test Loss: 5.1043 - MSE: 5.1043 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13741/20000 - Train Loss: 0.5890 - Test Loss: 5.1324 - MSE: 5.1324 - MAE: 1.8387\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13742/20000 - Train Loss: 0.5890 - Test Loss: 5.1015 - MSE: 5.1015 - MAE: 1.8346\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13743/20000 - Train Loss: 0.5889 - Test Loss: 5.1272 - MSE: 5.1272 - MAE: 1.8380\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13744/20000 - Train Loss: 0.5889 - Test Loss: 5.1113 - MSE: 5.1113 - MAE: 1.8359\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13745/20000 - Train Loss: 0.5888 - Test Loss: 5.1140 - MSE: 5.1140 - MAE: 1.8363\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13746/20000 - Train Loss: 0.5888 - Test Loss: 5.1231 - MSE: 5.1231 - MAE: 1.8374\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13747/20000 - Train Loss: 0.5888 - Test Loss: 5.1048 - MSE: 5.1048 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13748/20000 - Train Loss: 0.5888 - Test Loss: 5.1268 - MSE: 5.1268 - MAE: 1.8379\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13749/20000 - Train Loss: 0.5888 - Test Loss: 5.1056 - MSE: 5.1056 - MAE: 1.8351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13750/20000 - Train Loss: 0.5887 - Test Loss: 5.1208 - MSE: 5.1208 - MAE: 1.8371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13751/20000 - Train Loss: 0.5887 - Test Loss: 5.1137 - MSE: 5.1137 - MAE: 1.8361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13752/20000 - Train Loss: 0.5887 - Test Loss: 5.1113 - MSE: 5.1113 - MAE: 1.8358\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13753/20000 - Train Loss: 0.5887 - Test Loss: 5.1211 - MSE: 5.1211 - MAE: 1.8371\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13754/20000 - Train Loss: 0.5886 - Test Loss: 5.1061 - MSE: 5.1061 - MAE: 1.8351\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 13755/20000 - Train Loss: 0.5886 - Test Loss: 5.1220 - MSE: 5.1220 - MAE: 1.8372\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 13756/20000 - Train Loss: 0.5886 - Test Loss: 5.1079 - MSE: 5.1079 - MAE: 1.8353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13757/20000 - Train Loss: 0.5886 - Test Loss: 5.1168 - MSE: 5.1168 - MAE: 1.8364\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13758/20000 - Train Loss: 0.5885 - Test Loss: 5.1137 - MSE: 5.1137 - MAE: 1.8360\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13759/20000 - Train Loss: 0.5885 - Test Loss: 5.1103 - MSE: 5.1103 - MAE: 1.8356\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13760/20000 - Train Loss: 0.5885 - Test Loss: 5.1184 - MSE: 5.1184 - MAE: 1.8366\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13761/20000 - Train Loss: 0.5885 - Test Loss: 5.1071 - MSE: 5.1071 - MAE: 1.8351\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13762/20000 - Train Loss: 0.5884 - Test Loss: 5.1184 - MSE: 5.1184 - MAE: 1.8366\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13763/20000 - Train Loss: 0.5884 - Test Loss: 5.1086 - MSE: 5.1086 - MAE: 1.8353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13764/20000 - Train Loss: 0.5884 - Test Loss: 5.1146 - MSE: 5.1146 - MAE: 1.8361\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13765/20000 - Train Loss: 0.5884 - Test Loss: 5.1126 - MSE: 5.1126 - MAE: 1.8358\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13766/20000 - Train Loss: 0.5883 - Test Loss: 5.1099 - MSE: 5.1099 - MAE: 1.8354\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13767/20000 - Train Loss: 0.5883 - Test Loss: 5.1156 - MSE: 5.1156 - MAE: 1.8361\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13768/20000 - Train Loss: 0.5883 - Test Loss: 5.1076 - MSE: 5.1076 - MAE: 1.8351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13769/20000 - Train Loss: 0.5883 - Test Loss: 5.1156 - MSE: 5.1156 - MAE: 1.8361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13770/20000 - Train Loss: 0.5883 - Test Loss: 5.1084 - MSE: 5.1084 - MAE: 1.8352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13771/20000 - Train Loss: 0.5882 - Test Loss: 5.1129 - MSE: 5.1129 - MAE: 1.8357\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13772/20000 - Train Loss: 0.5882 - Test Loss: 5.1110 - MSE: 5.1110 - MAE: 1.8355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13773/20000 - Train Loss: 0.5882 - Test Loss: 5.1096 - MSE: 5.1096 - MAE: 1.8353\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13774/20000 - Train Loss: 0.5882 - Test Loss: 5.1131 - MSE: 5.1131 - MAE: 1.8357\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13775/20000 - Train Loss: 0.5881 - Test Loss: 5.1077 - MSE: 5.1077 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13776/20000 - Train Loss: 0.5881 - Test Loss: 5.1132 - MSE: 5.1132 - MAE: 1.8357\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13777/20000 - Train Loss: 0.5881 - Test Loss: 5.1079 - MSE: 5.1079 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13778/20000 - Train Loss: 0.5881 - Test Loss: 5.1116 - MSE: 5.1116 - MAE: 1.8355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13779/20000 - Train Loss: 0.5880 - Test Loss: 5.1093 - MSE: 5.1093 - MAE: 1.8351\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13780/20000 - Train Loss: 0.5880 - Test Loss: 5.1093 - MSE: 5.1093 - MAE: 1.8351\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13781/20000 - Train Loss: 0.5880 - Test Loss: 5.1108 - MSE: 5.1108 - MAE: 1.8353\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13782/20000 - Train Loss: 0.5880 - Test Loss: 5.1075 - MSE: 5.1075 - MAE: 1.8349\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13783/20000 - Train Loss: 0.5879 - Test Loss: 5.1112 - MSE: 5.1112 - MAE: 1.8353\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13784/20000 - Train Loss: 0.5879 - Test Loss: 5.1071 - MSE: 5.1071 - MAE: 1.8348\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13785/20000 - Train Loss: 0.5879 - Test Loss: 5.1103 - MSE: 5.1103 - MAE: 1.8352\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13786/20000 - Train Loss: 0.5879 - Test Loss: 5.1077 - MSE: 5.1077 - MAE: 1.8348\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13787/20000 - Train Loss: 0.5879 - Test Loss: 5.1087 - MSE: 5.1087 - MAE: 1.8349\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13788/20000 - Train Loss: 0.5878 - Test Loss: 5.1086 - MSE: 5.1086 - MAE: 1.8349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13789/20000 - Train Loss: 0.5878 - Test Loss: 5.1072 - MSE: 5.1072 - MAE: 1.8347\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13790/20000 - Train Loss: 0.5878 - Test Loss: 5.1091 - MSE: 5.1091 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13791/20000 - Train Loss: 0.5878 - Test Loss: 5.1064 - MSE: 5.1064 - MAE: 1.8346\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13792/20000 - Train Loss: 0.5877 - Test Loss: 5.1088 - MSE: 5.1088 - MAE: 1.8349\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13793/20000 - Train Loss: 0.5877 - Test Loss: 5.1063 - MSE: 5.1063 - MAE: 1.8345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13794/20000 - Train Loss: 0.5877 - Test Loss: 5.1079 - MSE: 5.1079 - MAE: 1.8347\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13795/20000 - Train Loss: 0.5877 - Test Loss: 5.1067 - MSE: 5.1067 - MAE: 1.8346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13796/20000 - Train Loss: 0.5876 - Test Loss: 5.1068 - MSE: 5.1068 - MAE: 1.8346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13797/20000 - Train Loss: 0.5876 - Test Loss: 5.1071 - MSE: 5.1071 - MAE: 1.8346\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13798/20000 - Train Loss: 0.5876 - Test Loss: 5.1058 - MSE: 5.1058 - MAE: 1.8344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13799/20000 - Train Loss: 0.5876 - Test Loss: 5.1072 - MSE: 5.1072 - MAE: 1.8346\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13800/20000 - Train Loss: 0.5875 - Test Loss: 5.1052 - MSE: 5.1052 - MAE: 1.8343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13801/20000 - Train Loss: 0.5875 - Test Loss: 5.1068 - MSE: 5.1068 - MAE: 1.8345\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13802/20000 - Train Loss: 0.5875 - Test Loss: 5.1052 - MSE: 5.1052 - MAE: 1.8343\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13803/20000 - Train Loss: 0.5875 - Test Loss: 5.1060 - MSE: 5.1060 - MAE: 1.8344\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13804/20000 - Train Loss: 0.5874 - Test Loss: 5.1053 - MSE: 5.1053 - MAE: 1.8342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13805/20000 - Train Loss: 0.5874 - Test Loss: 5.1051 - MSE: 5.1051 - MAE: 1.8342\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13806/20000 - Train Loss: 0.5874 - Test Loss: 5.1054 - MSE: 5.1054 - MAE: 1.8342\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 13807/20000 - Train Loss: 0.5874 - Test Loss: 5.1044 - MSE: 5.1044 - MAE: 1.8341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13808/20000 - Train Loss: 0.5874 - Test Loss: 5.1053 - MSE: 5.1053 - MAE: 1.8342\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13809/20000 - Train Loss: 0.5873 - Test Loss: 5.1039 - MSE: 5.1039 - MAE: 1.8340\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13810/20000 - Train Loss: 0.5873 - Test Loss: 5.1049 - MSE: 5.1049 - MAE: 1.8341\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13811/20000 - Train Loss: 0.5873 - Test Loss: 5.1037 - MSE: 5.1037 - MAE: 1.8339\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13812/20000 - Train Loss: 0.5873 - Test Loss: 5.1043 - MSE: 5.1043 - MAE: 1.8340\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13813/20000 - Train Loss: 0.5872 - Test Loss: 5.1037 - MSE: 5.1037 - MAE: 1.8339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13814/20000 - Train Loss: 0.5872 - Test Loss: 5.1036 - MSE: 5.1036 - MAE: 1.8339\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 13815/20000 - Train Loss: 0.5872 - Test Loss: 5.1036 - MSE: 5.1036 - MAE: 1.8339\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13816/20000 - Train Loss: 0.5872 - Test Loss: 5.1030 - MSE: 5.1030 - MAE: 1.8338\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 13817/20000 - Train Loss: 0.5871 - Test Loss: 5.1035 - MSE: 5.1035 - MAE: 1.8338\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13818/20000 - Train Loss: 0.5871 - Test Loss: 5.1025 - MSE: 5.1025 - MAE: 1.8337\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 13819/20000 - Train Loss: 0.5871 - Test Loss: 5.1032 - MSE: 5.1032 - MAE: 1.8338\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 13820/20000 - Train Loss: 0.5871 - Test Loss: 5.1022 - MSE: 5.1022 - MAE: 1.8336\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13821/20000 - Train Loss: 0.5870 - Test Loss: 5.1028 - MSE: 5.1028 - MAE: 1.8337\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13822/20000 - Train Loss: 0.5870 - Test Loss: 5.1019 - MSE: 5.1019 - MAE: 1.8335\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13823/20000 - Train Loss: 0.5870 - Test Loss: 5.1022 - MSE: 5.1022 - MAE: 1.8336\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13824/20000 - Train Loss: 0.5870 - Test Loss: 5.1018 - MSE: 5.1018 - MAE: 1.8335\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13825/20000 - Train Loss: 0.5869 - Test Loss: 5.1017 - MSE: 5.1017 - MAE: 1.8335\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13826/20000 - Train Loss: 0.5869 - Test Loss: 5.1016 - MSE: 5.1016 - MAE: 1.8334\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13827/20000 - Train Loss: 0.5869 - Test Loss: 5.1012 - MSE: 5.1012 - MAE: 1.8334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13828/20000 - Train Loss: 0.5869 - Test Loss: 5.1013 - MSE: 5.1013 - MAE: 1.8334\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13829/20000 - Train Loss: 0.5869 - Test Loss: 5.1008 - MSE: 5.1008 - MAE: 1.8333\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13830/20000 - Train Loss: 0.5868 - Test Loss: 5.1009 - MSE: 5.1009 - MAE: 1.8333\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13831/20000 - Train Loss: 0.5868 - Test Loss: 5.1004 - MSE: 5.1004 - MAE: 1.8332\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13832/20000 - Train Loss: 0.5868 - Test Loss: 5.1006 - MSE: 5.1006 - MAE: 1.8332\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13833/20000 - Train Loss: 0.5868 - Test Loss: 5.1001 - MSE: 5.1001 - MAE: 1.8331\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13834/20000 - Train Loss: 0.5867 - Test Loss: 5.1002 - MSE: 5.1002 - MAE: 1.8331\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13835/20000 - Train Loss: 0.5867 - Test Loss: 5.0998 - MSE: 5.0998 - MAE: 1.8331\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13836/20000 - Train Loss: 0.5867 - Test Loss: 5.0997 - MSE: 5.0997 - MAE: 1.8330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13837/20000 - Train Loss: 0.5867 - Test Loss: 5.0996 - MSE: 5.0996 - MAE: 1.8330\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13838/20000 - Train Loss: 0.5866 - Test Loss: 5.0993 - MSE: 5.0993 - MAE: 1.8329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13839/20000 - Train Loss: 0.5866 - Test Loss: 5.0993 - MSE: 5.0993 - MAE: 1.8329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13840/20000 - Train Loss: 0.5866 - Test Loss: 5.0989 - MSE: 5.0989 - MAE: 1.8329\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13841/20000 - Train Loss: 0.5866 - Test Loss: 5.0989 - MSE: 5.0989 - MAE: 1.8329\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13842/20000 - Train Loss: 0.5865 - Test Loss: 5.0986 - MSE: 5.0986 - MAE: 1.8328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13843/20000 - Train Loss: 0.5865 - Test Loss: 5.0985 - MSE: 5.0985 - MAE: 1.8328\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13844/20000 - Train Loss: 0.5865 - Test Loss: 5.0982 - MSE: 5.0982 - MAE: 1.8327\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13845/20000 - Train Loss: 0.5865 - Test Loss: 5.0981 - MSE: 5.0981 - MAE: 1.8327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13846/20000 - Train Loss: 0.5864 - Test Loss: 5.0979 - MSE: 5.0979 - MAE: 1.8326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13847/20000 - Train Loss: 0.5864 - Test Loss: 5.0977 - MSE: 5.0977 - MAE: 1.8326\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13848/20000 - Train Loss: 0.5864 - Test Loss: 5.0976 - MSE: 5.0976 - MAE: 1.8326\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13849/20000 - Train Loss: 0.5864 - Test Loss: 5.0974 - MSE: 5.0974 - MAE: 1.8325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13850/20000 - Train Loss: 0.5864 - Test Loss: 5.0972 - MSE: 5.0972 - MAE: 1.8325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13851/20000 - Train Loss: 0.5863 - Test Loss: 5.0970 - MSE: 5.0970 - MAE: 1.8325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13852/20000 - Train Loss: 0.5863 - Test Loss: 5.0968 - MSE: 5.0968 - MAE: 1.8324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13853/20000 - Train Loss: 0.5863 - Test Loss: 5.0967 - MSE: 5.0967 - MAE: 1.8324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13854/20000 - Train Loss: 0.5863 - Test Loss: 5.0965 - MSE: 5.0965 - MAE: 1.8323\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13855/20000 - Train Loss: 0.5862 - Test Loss: 5.0963 - MSE: 5.0963 - MAE: 1.8323\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13856/20000 - Train Loss: 0.5862 - Test Loss: 5.0961 - MSE: 5.0961 - MAE: 1.8323\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13857/20000 - Train Loss: 0.5862 - Test Loss: 5.0960 - MSE: 5.0960 - MAE: 1.8322\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13858/20000 - Train Loss: 0.5862 - Test Loss: 5.0957 - MSE: 5.0957 - MAE: 1.8322\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13859/20000 - Train Loss: 0.5861 - Test Loss: 5.0956 - MSE: 5.0956 - MAE: 1.8321\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13860/20000 - Train Loss: 0.5861 - Test Loss: 5.0953 - MSE: 5.0953 - MAE: 1.8321\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13861/20000 - Train Loss: 0.5861 - Test Loss: 5.0953 - MSE: 5.0953 - MAE: 1.8321\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13862/20000 - Train Loss: 0.5861 - Test Loss: 5.0949 - MSE: 5.0949 - MAE: 1.8320\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13863/20000 - Train Loss: 0.5860 - Test Loss: 5.0949 - MSE: 5.0949 - MAE: 1.8320\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13864/20000 - Train Loss: 0.5860 - Test Loss: 5.0946 - MSE: 5.0946 - MAE: 1.8319\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13865/20000 - Train Loss: 0.5860 - Test Loss: 5.0946 - MSE: 5.0946 - MAE: 1.8319\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13866/20000 - Train Loss: 0.5860 - Test Loss: 5.0942 - MSE: 5.0942 - MAE: 1.8318\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13867/20000 - Train Loss: 0.5859 - Test Loss: 5.0943 - MSE: 5.0943 - MAE: 1.8318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13868/20000 - Train Loss: 0.5859 - Test Loss: 5.0938 - MSE: 5.0938 - MAE: 1.8318\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Epoch 13869/20000 - Train Loss: 0.5859 - Test Loss: 5.0939 - MSE: 5.0939 - MAE: 1.8318\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13870/20000 - Train Loss: 0.5859 - Test Loss: 5.0934 - MSE: 5.0934 - MAE: 1.8317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13871/20000 - Train Loss: 0.5859 - Test Loss: 5.0936 - MSE: 5.0936 - MAE: 1.8317\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13872/20000 - Train Loss: 0.5858 - Test Loss: 5.0930 - MSE: 5.0930 - MAE: 1.8316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13873/20000 - Train Loss: 0.5858 - Test Loss: 5.0933 - MSE: 5.0933 - MAE: 1.8316\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13874/20000 - Train Loss: 0.5858 - Test Loss: 5.0926 - MSE: 5.0926 - MAE: 1.8315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13875/20000 - Train Loss: 0.5858 - Test Loss: 5.0929 - MSE: 5.0929 - MAE: 1.8315\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13876/20000 - Train Loss: 0.5857 - Test Loss: 5.0923 - MSE: 5.0923 - MAE: 1.8314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13877/20000 - Train Loss: 0.5857 - Test Loss: 5.0926 - MSE: 5.0926 - MAE: 1.8315\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13878/20000 - Train Loss: 0.5857 - Test Loss: 5.0919 - MSE: 5.0919 - MAE: 1.8314\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13879/20000 - Train Loss: 0.5857 - Test Loss: 5.0922 - MSE: 5.0922 - MAE: 1.8314\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13880/20000 - Train Loss: 0.5856 - Test Loss: 5.0915 - MSE: 5.0915 - MAE: 1.8313\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13881/20000 - Train Loss: 0.5856 - Test Loss: 5.0920 - MSE: 5.0920 - MAE: 1.8313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13882/20000 - Train Loss: 0.5856 - Test Loss: 5.0910 - MSE: 5.0910 - MAE: 1.8312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13883/20000 - Train Loss: 0.5856 - Test Loss: 5.0917 - MSE: 5.0917 - MAE: 1.8313\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13884/20000 - Train Loss: 0.5855 - Test Loss: 5.0905 - MSE: 5.0905 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13885/20000 - Train Loss: 0.5855 - Test Loss: 5.0915 - MSE: 5.0915 - MAE: 1.8312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13886/20000 - Train Loss: 0.5855 - Test Loss: 5.0900 - MSE: 5.0900 - MAE: 1.8310\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13887/20000 - Train Loss: 0.5855 - Test Loss: 5.0913 - MSE: 5.0913 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13888/20000 - Train Loss: 0.5854 - Test Loss: 5.0894 - MSE: 5.0894 - MAE: 1.8309\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13889/20000 - Train Loss: 0.5854 - Test Loss: 5.0912 - MSE: 5.0912 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13890/20000 - Train Loss: 0.5854 - Test Loss: 5.0887 - MSE: 5.0887 - MAE: 1.8307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13891/20000 - Train Loss: 0.5854 - Test Loss: 5.0913 - MSE: 5.0913 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13892/20000 - Train Loss: 0.5853 - Test Loss: 5.0879 - MSE: 5.0879 - MAE: 1.8306\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13893/20000 - Train Loss: 0.5853 - Test Loss: 5.0915 - MSE: 5.0915 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13894/20000 - Train Loss: 0.5853 - Test Loss: 5.0868 - MSE: 5.0868 - MAE: 1.8304\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13895/20000 - Train Loss: 0.5853 - Test Loss: 5.0920 - MSE: 5.0920 - MAE: 1.8311\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13896/20000 - Train Loss: 0.5853 - Test Loss: 5.0853 - MSE: 5.0853 - MAE: 1.8302\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13897/20000 - Train Loss: 0.5852 - Test Loss: 5.0930 - MSE: 5.0930 - MAE: 1.8312\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13898/20000 - Train Loss: 0.5852 - Test Loss: 5.0833 - MSE: 5.0833 - MAE: 1.8299\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13899/20000 - Train Loss: 0.5852 - Test Loss: 5.0947 - MSE: 5.0947 - MAE: 1.8314\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13900/20000 - Train Loss: 0.5852 - Test Loss: 5.0803 - MSE: 5.0803 - MAE: 1.8295\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13901/20000 - Train Loss: 0.5852 - Test Loss: 5.0977 - MSE: 5.0977 - MAE: 1.8318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13902/20000 - Train Loss: 0.5851 - Test Loss: 5.0759 - MSE: 5.0759 - MAE: 1.8289\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13903/20000 - Train Loss: 0.5851 - Test Loss: 5.1025 - MSE: 5.1025 - MAE: 1.8323\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13904/20000 - Train Loss: 0.5852 - Test Loss: 5.0692 - MSE: 5.0692 - MAE: 1.8279\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13905/20000 - Train Loss: 0.5852 - Test Loss: 5.1103 - MSE: 5.1103 - MAE: 1.8333\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13906/20000 - Train Loss: 0.5853 - Test Loss: 5.0588 - MSE: 5.0588 - MAE: 1.8265\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13907/20000 - Train Loss: 0.5854 - Test Loss: 5.1235 - MSE: 5.1235 - MAE: 1.8350\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13908/20000 - Train Loss: 0.5856 - Test Loss: 5.0422 - MSE: 5.0422 - MAE: 1.8242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13909/20000 - Train Loss: 0.5859 - Test Loss: 5.1455 - MSE: 5.1455 - MAE: 1.8377\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 13910/20000 - Train Loss: 0.5865 - Test Loss: 5.0161 - MSE: 5.0161 - MAE: 1.8205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13911/20000 - Train Loss: 0.5874 - Test Loss: 5.1825 - MSE: 5.1825 - MAE: 1.8423\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13912/20000 - Train Loss: 0.5889 - Test Loss: 4.9754 - MSE: 4.9754 - MAE: 1.8146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13913/20000 - Train Loss: 0.5914 - Test Loss: 5.2444 - MSE: 5.2444 - MAE: 1.8496\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13914/20000 - Train Loss: 0.5951 - Test Loss: 4.9155 - MSE: 4.9155 - MAE: 1.8053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13915/20000 - Train Loss: 0.6008 - Test Loss: 5.3431 - MSE: 5.3431 - MAE: 1.8613\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13916/20000 - Train Loss: 0.6086 - Test Loss: 4.8400 - MSE: 4.8400 - MAE: 1.7928\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13917/20000 - Train Loss: 0.6180 - Test Loss: 5.4727 - MSE: 5.4727 - MAE: 1.8786\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13918/20000 - Train Loss: 0.6265 - Test Loss: 4.7765 - MSE: 4.7765 - MAE: 1.7867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13919/20000 - Train Loss: 0.6294 - Test Loss: 5.5445 - MSE: 5.5445 - MAE: 1.8877\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13920/20000 - Train Loss: 0.6225 - Test Loss: 4.7879 - MSE: 4.7879 - MAE: 1.7876\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13921/20000 - Train Loss: 0.6069 - Test Loss: 5.3934 - MSE: 5.3934 - MAE: 1.8681\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 13922/20000 - Train Loss: 0.5911 - Test Loss: 4.9471 - MSE: 4.9471 - MAE: 1.8102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13923/20000 - Train Loss: 0.5846 - Test Loss: 5.0882 - MSE: 5.0882 - MAE: 1.8302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13924/20000 - Train Loss: 0.5893 - Test Loss: 5.2170 - MSE: 5.2170 - MAE: 1.8462\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13925/20000 - Train Loss: 0.5985 - Test Loss: 4.8893 - MSE: 4.8893 - MAE: 1.8009\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13926/20000 - Train Loss: 0.6034 - Test Loss: 5.3657 - MSE: 5.3657 - MAE: 1.8643\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13927/20000 - Train Loss: 0.5997 - Test Loss: 4.8815 - MSE: 4.8815 - MAE: 1.7996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13928/20000 - Train Loss: 0.5910 - Test Loss: 5.2409 - MSE: 5.2409 - MAE: 1.8489\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13929/20000 - Train Loss: 0.5849 - Test Loss: 5.0446 - MSE: 5.0446 - MAE: 1.8242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13930/20000 - Train Loss: 0.5858 - Test Loss: 5.0167 - MSE: 5.0167 - MAE: 1.8203\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13931/20000 - Train Loss: 0.5909 - Test Loss: 5.2407 - MSE: 5.2407 - MAE: 1.8488\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13932/20000 - Train Loss: 0.5941 - Test Loss: 4.9172 - MSE: 4.9172 - MAE: 1.8054\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13933/20000 - Train Loss: 0.5922 - Test Loss: 5.2576 - MSE: 5.2576 - MAE: 1.8507\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13934/20000 - Train Loss: 0.5875 - Test Loss: 4.9850 - MSE: 4.9850 - MAE: 1.8157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13935/20000 - Train Loss: 0.5845 - Test Loss: 5.1017 - MSE: 5.1017 - MAE: 1.8317\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 13936/20000 - Train Loss: 0.5854 - Test Loss: 5.1439 - MSE: 5.1439 - MAE: 1.8371\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13937/20000 - Train Loss: 0.5883 - Test Loss: 4.9725 - MSE: 4.9725 - MAE: 1.8138\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 13938/20000 - Train Loss: 0.5896 - Test Loss: 5.2234 - MSE: 5.2234 - MAE: 1.8467\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13939/20000 - Train Loss: 0.5880 - Test Loss: 4.9751 - MSE: 4.9751 - MAE: 1.8142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13940/20000 - Train Loss: 0.5854 - Test Loss: 5.1446 - MSE: 5.1446 - MAE: 1.8371\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13941/20000 - Train Loss: 0.5842 - Test Loss: 5.0824 - MSE: 5.0824 - MAE: 1.8291\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 13942/20000 - Train Loss: 0.5852 - Test Loss: 5.0248 - MSE: 5.0248 - MAE: 1.8213\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13943/20000 - Train Loss: 0.5867 - Test Loss: 5.1770 - MSE: 5.1770 - MAE: 1.8411\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13944/20000 - Train Loss: 0.5870 - Test Loss: 4.9876 - MSE: 4.9876 - MAE: 1.8160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13945/20000 - Train Loss: 0.5858 - Test Loss: 5.1578 - MSE: 5.1578 - MAE: 1.8387\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13946/20000 - Train Loss: 0.5844 - Test Loss: 5.0474 - MSE: 5.0474 - MAE: 1.8244\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13947/20000 - Train Loss: 0.5841 - Test Loss: 5.0668 - MSE: 5.0668 - MAE: 1.8270\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13948/20000 - Train Loss: 0.5849 - Test Loss: 5.1329 - MSE: 5.1329 - MAE: 1.8355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13949/20000 - Train Loss: 0.5856 - Test Loss: 5.0103 - MSE: 5.0103 - MAE: 1.8192\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13950/20000 - Train Loss: 0.5855 - Test Loss: 5.1519 - MSE: 5.1519 - MAE: 1.8379\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13951/20000 - Train Loss: 0.5847 - Test Loss: 5.0316 - MSE: 5.0316 - MAE: 1.8221\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 13952/20000 - Train Loss: 0.5841 - Test Loss: 5.0959 - MSE: 5.0959 - MAE: 1.8307\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13953/20000 - Train Loss: 0.5840 - Test Loss: 5.0965 - MSE: 5.0965 - MAE: 1.8308\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13954/20000 - Train Loss: 0.5845 - Test Loss: 5.0368 - MSE: 5.0368 - MAE: 1.8228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13955/20000 - Train Loss: 0.5848 - Test Loss: 5.1345 - MSE: 5.1345 - MAE: 1.8356\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13956/20000 - Train Loss: 0.5846 - Test Loss: 5.0299 - MSE: 5.0299 - MAE: 1.8218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13957/20000 - Train Loss: 0.5842 - Test Loss: 5.1113 - MSE: 5.1113 - MAE: 1.8327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13958/20000 - Train Loss: 0.5839 - Test Loss: 5.0703 - MSE: 5.0703 - MAE: 1.8273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13959/20000 - Train Loss: 0.5839 - Test Loss: 5.0620 - MSE: 5.0620 - MAE: 1.8262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13960/20000 - Train Loss: 0.5841 - Test Loss: 5.1121 - MSE: 5.1121 - MAE: 1.8327\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13961/20000 - Train Loss: 0.5843 - Test Loss: 5.0381 - MSE: 5.0381 - MAE: 1.8229\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13962/20000 - Train Loss: 0.5841 - Test Loss: 5.1142 - MSE: 5.1142 - MAE: 1.8330\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13963/20000 - Train Loss: 0.5839 - Test Loss: 5.0551 - MSE: 5.0551 - MAE: 1.8252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13964/20000 - Train Loss: 0.5837 - Test Loss: 5.0819 - MSE: 5.0819 - MAE: 1.8287\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13965/20000 - Train Loss: 0.5837 - Test Loss: 5.0900 - MSE: 5.0900 - MAE: 1.8298\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13966/20000 - Train Loss: 0.5839 - Test Loss: 5.0521 - MSE: 5.0521 - MAE: 1.8247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13967/20000 - Train Loss: 0.5839 - Test Loss: 5.1071 - MSE: 5.1071 - MAE: 1.8320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13968/20000 - Train Loss: 0.5838 - Test Loss: 5.0503 - MSE: 5.0503 - MAE: 1.8245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13969/20000 - Train Loss: 0.5837 - Test Loss: 5.0935 - MSE: 5.0935 - MAE: 1.8302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13970/20000 - Train Loss: 0.5836 - Test Loss: 5.0723 - MSE: 5.0723 - MAE: 1.8274\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13971/20000 - Train Loss: 0.5836 - Test Loss: 5.0675 - MSE: 5.0675 - MAE: 1.8267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13972/20000 - Train Loss: 0.5836 - Test Loss: 5.0940 - MSE: 5.0940 - MAE: 1.8302\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 13973/20000 - Train Loss: 0.5837 - Test Loss: 5.0542 - MSE: 5.0542 - MAE: 1.8249\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 13974/20000 - Train Loss: 0.5836 - Test Loss: 5.0959 - MSE: 5.0959 - MAE: 1.8304\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13975/20000 - Train Loss: 0.5835 - Test Loss: 5.0619 - MSE: 5.0619 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13976/20000 - Train Loss: 0.5835 - Test Loss: 5.0799 - MSE: 5.0799 - MAE: 1.8283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13977/20000 - Train Loss: 0.5834 - Test Loss: 5.0798 - MSE: 5.0798 - MAE: 1.8283\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13978/20000 - Train Loss: 0.5834 - Test Loss: 5.0631 - MSE: 5.0631 - MAE: 1.8260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13979/20000 - Train Loss: 0.5835 - Test Loss: 5.0906 - MSE: 5.0906 - MAE: 1.8297\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13980/20000 - Train Loss: 0.5834 - Test Loss: 5.0594 - MSE: 5.0594 - MAE: 1.8255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13981/20000 - Train Loss: 0.5834 - Test Loss: 5.0861 - MSE: 5.0861 - MAE: 1.8290\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13982/20000 - Train Loss: 0.5833 - Test Loss: 5.0689 - MSE: 5.0689 - MAE: 1.8267\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13983/20000 - Train Loss: 0.5833 - Test Loss: 5.0729 - MSE: 5.0729 - MAE: 1.8273\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13984/20000 - Train Loss: 0.5833 - Test Loss: 5.0810 - MSE: 5.0810 - MAE: 1.8283\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13985/20000 - Train Loss: 0.5833 - Test Loss: 5.0632 - MSE: 5.0632 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13986/20000 - Train Loss: 0.5833 - Test Loss: 5.0853 - MSE: 5.0853 - MAE: 1.8289\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13987/20000 - Train Loss: 0.5832 - Test Loss: 5.0637 - MSE: 5.0637 - MAE: 1.8260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13988/20000 - Train Loss: 0.5832 - Test Loss: 5.0794 - MSE: 5.0794 - MAE: 1.8281\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13989/20000 - Train Loss: 0.5832 - Test Loss: 5.0718 - MSE: 5.0718 - MAE: 1.8270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13990/20000 - Train Loss: 0.5831 - Test Loss: 5.0698 - MSE: 5.0698 - MAE: 1.8268\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13991/20000 - Train Loss: 0.5831 - Test Loss: 5.0794 - MSE: 5.0794 - MAE: 1.8280\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 13992/20000 - Train Loss: 0.5831 - Test Loss: 5.0644 - MSE: 5.0644 - MAE: 1.8260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13993/20000 - Train Loss: 0.5831 - Test Loss: 5.0806 - MSE: 5.0806 - MAE: 1.8281\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13994/20000 - Train Loss: 0.5831 - Test Loss: 5.0662 - MSE: 5.0662 - MAE: 1.8262\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 13995/20000 - Train Loss: 0.5830 - Test Loss: 5.0754 - MSE: 5.0754 - MAE: 1.8274\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 13996/20000 - Train Loss: 0.5830 - Test Loss: 5.0721 - MSE: 5.0721 - MAE: 1.8270\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13997/20000 - Train Loss: 0.5830 - Test Loss: 5.0687 - MSE: 5.0687 - MAE: 1.8265\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 13998/20000 - Train Loss: 0.5830 - Test Loss: 5.0769 - MSE: 5.0769 - MAE: 1.8276\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 13999/20000 - Train Loss: 0.5830 - Test Loss: 5.0655 - MSE: 5.0655 - MAE: 1.8261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14000/20000 - Train Loss: 0.5829 - Test Loss: 5.0769 - MSE: 5.0769 - MAE: 1.8276\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14001/20000 - Train Loss: 0.5829 - Test Loss: 5.0670 - MSE: 5.0670 - MAE: 1.8262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14002/20000 - Train Loss: 0.5829 - Test Loss: 5.0730 - MSE: 5.0730 - MAE: 1.8270\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14003/20000 - Train Loss: 0.5829 - Test Loss: 5.0711 - MSE: 5.0711 - MAE: 1.8267\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14004/20000 - Train Loss: 0.5828 - Test Loss: 5.0684 - MSE: 5.0684 - MAE: 1.8264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14005/20000 - Train Loss: 0.5828 - Test Loss: 5.0742 - MSE: 5.0742 - MAE: 1.8271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14006/20000 - Train Loss: 0.5828 - Test Loss: 5.0661 - MSE: 5.0661 - MAE: 1.8260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14007/20000 - Train Loss: 0.5828 - Test Loss: 5.0742 - MSE: 5.0742 - MAE: 1.8271\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14008/20000 - Train Loss: 0.5828 - Test Loss: 5.0669 - MSE: 5.0669 - MAE: 1.8261\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14009/20000 - Train Loss: 0.5827 - Test Loss: 5.0715 - MSE: 5.0715 - MAE: 1.8267\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14010/20000 - Train Loss: 0.5827 - Test Loss: 5.0696 - MSE: 5.0696 - MAE: 1.8264\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14011/20000 - Train Loss: 0.5827 - Test Loss: 5.0682 - MSE: 5.0682 - MAE: 1.8262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14012/20000 - Train Loss: 0.5827 - Test Loss: 5.0717 - MSE: 5.0717 - MAE: 1.8267\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14013/20000 - Train Loss: 0.5826 - Test Loss: 5.0662 - MSE: 5.0662 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14014/20000 - Train Loss: 0.5826 - Test Loss: 5.0719 - MSE: 5.0719 - MAE: 1.8267\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14015/20000 - Train Loss: 0.5826 - Test Loss: 5.0664 - MSE: 5.0664 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14016/20000 - Train Loss: 0.5826 - Test Loss: 5.0702 - MSE: 5.0702 - MAE: 1.8264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14017/20000 - Train Loss: 0.5826 - Test Loss: 5.0680 - MSE: 5.0680 - MAE: 1.8261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14018/20000 - Train Loss: 0.5825 - Test Loss: 5.0678 - MSE: 5.0678 - MAE: 1.8261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14019/20000 - Train Loss: 0.5825 - Test Loss: 5.0695 - MSE: 5.0695 - MAE: 1.8263\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14020/20000 - Train Loss: 0.5825 - Test Loss: 5.0661 - MSE: 5.0661 - MAE: 1.8258\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14021/20000 - Train Loss: 0.5825 - Test Loss: 5.0699 - MSE: 5.0699 - MAE: 1.8263\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14022/20000 - Train Loss: 0.5824 - Test Loss: 5.0658 - MSE: 5.0658 - MAE: 1.8258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14023/20000 - Train Loss: 0.5824 - Test Loss: 5.0689 - MSE: 5.0689 - MAE: 1.8261\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14024/20000 - Train Loss: 0.5824 - Test Loss: 5.0666 - MSE: 5.0666 - MAE: 1.8258\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14025/20000 - Train Loss: 0.5824 - Test Loss: 5.0673 - MSE: 5.0673 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14026/20000 - Train Loss: 0.5824 - Test Loss: 5.0675 - MSE: 5.0675 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14027/20000 - Train Loss: 0.5823 - Test Loss: 5.0659 - MSE: 5.0659 - MAE: 1.8257\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14028/20000 - Train Loss: 0.5823 - Test Loss: 5.0679 - MSE: 5.0679 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14029/20000 - Train Loss: 0.5823 - Test Loss: 5.0652 - MSE: 5.0652 - MAE: 1.8256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14030/20000 - Train Loss: 0.5823 - Test Loss: 5.0675 - MSE: 5.0675 - MAE: 1.8259\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14031/20000 - Train Loss: 0.5822 - Test Loss: 5.0653 - MSE: 5.0653 - MAE: 1.8255\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14032/20000 - Train Loss: 0.5822 - Test Loss: 5.0665 - MSE: 5.0665 - MAE: 1.8257\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14033/20000 - Train Loss: 0.5822 - Test Loss: 5.0657 - MSE: 5.0657 - MAE: 1.8256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14034/20000 - Train Loss: 0.5822 - Test Loss: 5.0654 - MSE: 5.0654 - MAE: 1.8255\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14035/20000 - Train Loss: 0.5822 - Test Loss: 5.0660 - MSE: 5.0660 - MAE: 1.8256\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14036/20000 - Train Loss: 0.5821 - Test Loss: 5.0646 - MSE: 5.0646 - MAE: 1.8254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14037/20000 - Train Loss: 0.5821 - Test Loss: 5.0660 - MSE: 5.0660 - MAE: 1.8255\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14038/20000 - Train Loss: 0.5821 - Test Loss: 5.0642 - MSE: 5.0642 - MAE: 1.8253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14039/20000 - Train Loss: 0.5821 - Test Loss: 5.0655 - MSE: 5.0655 - MAE: 1.8254\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14040/20000 - Train Loss: 0.5820 - Test Loss: 5.0642 - MSE: 5.0642 - MAE: 1.8253\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14041/20000 - Train Loss: 0.5820 - Test Loss: 5.0647 - MSE: 5.0647 - MAE: 1.8253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14042/20000 - Train Loss: 0.5820 - Test Loss: 5.0643 - MSE: 5.0643 - MAE: 1.8253\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14043/20000 - Train Loss: 0.5820 - Test Loss: 5.0639 - MSE: 5.0639 - MAE: 1.8252\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14044/20000 - Train Loss: 0.5820 - Test Loss: 5.0644 - MSE: 5.0644 - MAE: 1.8252\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14045/20000 - Train Loss: 0.5819 - Test Loss: 5.0634 - MSE: 5.0634 - MAE: 1.8251\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 14046/20000 - Train Loss: 0.5819 - Test Loss: 5.0641 - MSE: 5.0641 - MAE: 1.8252\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14047/20000 - Train Loss: 0.5819 - Test Loss: 5.0630 - MSE: 5.0630 - MAE: 1.8250\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14048/20000 - Train Loss: 0.5819 - Test Loss: 5.0637 - MSE: 5.0637 - MAE: 1.8251\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14049/20000 - Train Loss: 0.5818 - Test Loss: 5.0629 - MSE: 5.0629 - MAE: 1.8250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14050/20000 - Train Loss: 0.5818 - Test Loss: 5.0631 - MSE: 5.0631 - MAE: 1.8250\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14051/20000 - Train Loss: 0.5818 - Test Loss: 5.0628 - MSE: 5.0628 - MAE: 1.8249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14052/20000 - Train Loss: 0.5818 - Test Loss: 5.0625 - MSE: 5.0625 - MAE: 1.8249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14053/20000 - Train Loss: 0.5818 - Test Loss: 5.0627 - MSE: 5.0627 - MAE: 1.8249\n",
      "2/2 [==============================] - 0s 995us/step\n",
      "Epoch 14054/20000 - Train Loss: 0.5817 - Test Loss: 5.0620 - MSE: 5.0620 - MAE: 1.8248\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14055/20000 - Train Loss: 0.5817 - Test Loss: 5.0625 - MSE: 5.0625 - MAE: 1.8248\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14056/20000 - Train Loss: 0.5817 - Test Loss: 5.0616 - MSE: 5.0616 - MAE: 1.8247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14057/20000 - Train Loss: 0.5817 - Test Loss: 5.0621 - MSE: 5.0621 - MAE: 1.8247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14058/20000 - Train Loss: 0.5816 - Test Loss: 5.0615 - MSE: 5.0615 - MAE: 1.8246\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14059/20000 - Train Loss: 0.5816 - Test Loss: 5.0616 - MSE: 5.0616 - MAE: 1.8246\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14060/20000 - Train Loss: 0.5816 - Test Loss: 5.0613 - MSE: 5.0613 - MAE: 1.8246\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14061/20000 - Train Loss: 0.5816 - Test Loss: 5.0610 - MSE: 5.0610 - MAE: 1.8245\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14062/20000 - Train Loss: 0.5816 - Test Loss: 5.0611 - MSE: 5.0611 - MAE: 1.8245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14063/20000 - Train Loss: 0.5815 - Test Loss: 5.0606 - MSE: 5.0606 - MAE: 1.8244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14064/20000 - Train Loss: 0.5815 - Test Loss: 5.0609 - MSE: 5.0609 - MAE: 1.8245\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14065/20000 - Train Loss: 0.5815 - Test Loss: 5.0602 - MSE: 5.0602 - MAE: 1.8243\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14066/20000 - Train Loss: 0.5815 - Test Loss: 5.0606 - MSE: 5.0606 - MAE: 1.8244\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14067/20000 - Train Loss: 0.5814 - Test Loss: 5.0599 - MSE: 5.0599 - MAE: 1.8243\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14068/20000 - Train Loss: 0.5814 - Test Loss: 5.0602 - MSE: 5.0602 - MAE: 1.8243\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 14069/20000 - Train Loss: 0.5814 - Test Loss: 5.0596 - MSE: 5.0596 - MAE: 1.8242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14070/20000 - Train Loss: 0.5814 - Test Loss: 5.0597 - MSE: 5.0597 - MAE: 1.8242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14071/20000 - Train Loss: 0.5814 - Test Loss: 5.0594 - MSE: 5.0594 - MAE: 1.8241\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14072/20000 - Train Loss: 0.5813 - Test Loss: 5.0593 - MSE: 5.0593 - MAE: 1.8241\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14073/20000 - Train Loss: 0.5813 - Test Loss: 5.0592 - MSE: 5.0592 - MAE: 1.8241\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14074/20000 - Train Loss: 0.5813 - Test Loss: 5.0589 - MSE: 5.0589 - MAE: 1.8240\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14075/20000 - Train Loss: 0.5813 - Test Loss: 5.0589 - MSE: 5.0589 - MAE: 1.8240\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14076/20000 - Train Loss: 0.5812 - Test Loss: 5.0585 - MSE: 5.0585 - MAE: 1.8240\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14077/20000 - Train Loss: 0.5812 - Test Loss: 5.0585 - MSE: 5.0585 - MAE: 1.8239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14078/20000 - Train Loss: 0.5812 - Test Loss: 5.0582 - MSE: 5.0582 - MAE: 1.8239\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14079/20000 - Train Loss: 0.5812 - Test Loss: 5.0581 - MSE: 5.0581 - MAE: 1.8239\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14080/20000 - Train Loss: 0.5812 - Test Loss: 5.0580 - MSE: 5.0580 - MAE: 1.8238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14081/20000 - Train Loss: 0.5811 - Test Loss: 5.0577 - MSE: 5.0577 - MAE: 1.8238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14082/20000 - Train Loss: 0.5811 - Test Loss: 5.0577 - MSE: 5.0577 - MAE: 1.8237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14083/20000 - Train Loss: 0.5811 - Test Loss: 5.0573 - MSE: 5.0573 - MAE: 1.8237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14084/20000 - Train Loss: 0.5811 - Test Loss: 5.0573 - MSE: 5.0573 - MAE: 1.8237\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14085/20000 - Train Loss: 0.5810 - Test Loss: 5.0570 - MSE: 5.0570 - MAE: 1.8236\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14086/20000 - Train Loss: 0.5810 - Test Loss: 5.0570 - MSE: 5.0570 - MAE: 1.8236\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14087/20000 - Train Loss: 0.5810 - Test Loss: 5.0567 - MSE: 5.0567 - MAE: 1.8235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14088/20000 - Train Loss: 0.5810 - Test Loss: 5.0566 - MSE: 5.0566 - MAE: 1.8235\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14089/20000 - Train Loss: 0.5810 - Test Loss: 5.0564 - MSE: 5.0564 - MAE: 1.8235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14090/20000 - Train Loss: 0.5809 - Test Loss: 5.0562 - MSE: 5.0562 - MAE: 1.8234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14091/20000 - Train Loss: 0.5809 - Test Loss: 5.0561 - MSE: 5.0561 - MAE: 1.8234\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14092/20000 - Train Loss: 0.5809 - Test Loss: 5.0558 - MSE: 5.0558 - MAE: 1.8233\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14093/20000 - Train Loss: 0.5809 - Test Loss: 5.0558 - MSE: 5.0558 - MAE: 1.8233\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14094/20000 - Train Loss: 0.5808 - Test Loss: 5.0555 - MSE: 5.0555 - MAE: 1.8233\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14095/20000 - Train Loss: 0.5808 - Test Loss: 5.0555 - MSE: 5.0555 - MAE: 1.8232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14096/20000 - Train Loss: 0.5808 - Test Loss: 5.0552 - MSE: 5.0552 - MAE: 1.8232\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14097/20000 - Train Loss: 0.5808 - Test Loss: 5.0551 - MSE: 5.0551 - MAE: 1.8232\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14098/20000 - Train Loss: 0.5808 - Test Loss: 5.0548 - MSE: 5.0548 - MAE: 1.8231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14099/20000 - Train Loss: 0.5807 - Test Loss: 5.0548 - MSE: 5.0548 - MAE: 1.8231\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14100/20000 - Train Loss: 0.5807 - Test Loss: 5.0544 - MSE: 5.0544 - MAE: 1.8230\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14101/20000 - Train Loss: 0.5807 - Test Loss: 5.0545 - MSE: 5.0545 - MAE: 1.8230\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14102/20000 - Train Loss: 0.5807 - Test Loss: 5.0541 - MSE: 5.0541 - MAE: 1.8230\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14103/20000 - Train Loss: 0.5806 - Test Loss: 5.0541 - MSE: 5.0541 - MAE: 1.8229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14104/20000 - Train Loss: 0.5806 - Test Loss: 5.0538 - MSE: 5.0538 - MAE: 1.8229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14105/20000 - Train Loss: 0.5806 - Test Loss: 5.0538 - MSE: 5.0538 - MAE: 1.8229\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14106/20000 - Train Loss: 0.5806 - Test Loss: 5.0534 - MSE: 5.0534 - MAE: 1.8228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14107/20000 - Train Loss: 0.5806 - Test Loss: 5.0534 - MSE: 5.0534 - MAE: 1.8228\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14108/20000 - Train Loss: 0.5805 - Test Loss: 5.0531 - MSE: 5.0531 - MAE: 1.8227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14109/20000 - Train Loss: 0.5805 - Test Loss: 5.0530 - MSE: 5.0530 - MAE: 1.8227\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14110/20000 - Train Loss: 0.5805 - Test Loss: 5.0528 - MSE: 5.0528 - MAE: 1.8227\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14111/20000 - Train Loss: 0.5805 - Test Loss: 5.0526 - MSE: 5.0526 - MAE: 1.8226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14112/20000 - Train Loss: 0.5804 - Test Loss: 5.0525 - MSE: 5.0525 - MAE: 1.8226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14113/20000 - Train Loss: 0.5804 - Test Loss: 5.0523 - MSE: 5.0523 - MAE: 1.8225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14114/20000 - Train Loss: 0.5804 - Test Loss: 5.0522 - MSE: 5.0522 - MAE: 1.8225\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14115/20000 - Train Loss: 0.5804 - Test Loss: 5.0519 - MSE: 5.0519 - MAE: 1.8225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14116/20000 - Train Loss: 0.5803 - Test Loss: 5.0519 - MSE: 5.0519 - MAE: 1.8224\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14117/20000 - Train Loss: 0.5803 - Test Loss: 5.0516 - MSE: 5.0516 - MAE: 1.8224\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14118/20000 - Train Loss: 0.5803 - Test Loss: 5.0515 - MSE: 5.0515 - MAE: 1.8224\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14119/20000 - Train Loss: 0.5803 - Test Loss: 5.0513 - MSE: 5.0513 - MAE: 1.8223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14120/20000 - Train Loss: 0.5803 - Test Loss: 5.0512 - MSE: 5.0512 - MAE: 1.8223\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14121/20000 - Train Loss: 0.5802 - Test Loss: 5.0509 - MSE: 5.0509 - MAE: 1.8222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14122/20000 - Train Loss: 0.5802 - Test Loss: 5.0508 - MSE: 5.0508 - MAE: 1.8222\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14123/20000 - Train Loss: 0.5802 - Test Loss: 5.0506 - MSE: 5.0506 - MAE: 1.8222\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14124/20000 - Train Loss: 0.5802 - Test Loss: 5.0505 - MSE: 5.0505 - MAE: 1.8221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14125/20000 - Train Loss: 0.5801 - Test Loss: 5.0502 - MSE: 5.0502 - MAE: 1.8221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14126/20000 - Train Loss: 0.5801 - Test Loss: 5.0502 - MSE: 5.0502 - MAE: 1.8221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14127/20000 - Train Loss: 0.5801 - Test Loss: 5.0498 - MSE: 5.0498 - MAE: 1.8220\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14128/20000 - Train Loss: 0.5801 - Test Loss: 5.0499 - MSE: 5.0499 - MAE: 1.8220\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14129/20000 - Train Loss: 0.5801 - Test Loss: 5.0495 - MSE: 5.0495 - MAE: 1.8219\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14130/20000 - Train Loss: 0.5800 - Test Loss: 5.0496 - MSE: 5.0496 - MAE: 1.8219\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14131/20000 - Train Loss: 0.5800 - Test Loss: 5.0491 - MSE: 5.0491 - MAE: 1.8218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14132/20000 - Train Loss: 0.5800 - Test Loss: 5.0493 - MSE: 5.0493 - MAE: 1.8218\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14133/20000 - Train Loss: 0.5800 - Test Loss: 5.0486 - MSE: 5.0486 - MAE: 1.8217\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "Epoch 14134/20000 - Train Loss: 0.5799 - Test Loss: 5.0491 - MSE: 5.0491 - MAE: 1.8218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14135/20000 - Train Loss: 0.5799 - Test Loss: 5.0482 - MSE: 5.0482 - MAE: 1.8216\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14136/20000 - Train Loss: 0.5799 - Test Loss: 5.0489 - MSE: 5.0489 - MAE: 1.8217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14137/20000 - Train Loss: 0.5799 - Test Loss: 5.0476 - MSE: 5.0476 - MAE: 1.8215\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14138/20000 - Train Loss: 0.5799 - Test Loss: 5.0488 - MSE: 5.0488 - MAE: 1.8217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14139/20000 - Train Loss: 0.5798 - Test Loss: 5.0470 - MSE: 5.0470 - MAE: 1.8214\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14140/20000 - Train Loss: 0.5798 - Test Loss: 5.0488 - MSE: 5.0488 - MAE: 1.8217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14141/20000 - Train Loss: 0.5798 - Test Loss: 5.0461 - MSE: 5.0461 - MAE: 1.8213\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14142/20000 - Train Loss: 0.5798 - Test Loss: 5.0491 - MSE: 5.0491 - MAE: 1.8217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14143/20000 - Train Loss: 0.5797 - Test Loss: 5.0450 - MSE: 5.0450 - MAE: 1.8211\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14144/20000 - Train Loss: 0.5797 - Test Loss: 5.0498 - MSE: 5.0498 - MAE: 1.8217\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14145/20000 - Train Loss: 0.5797 - Test Loss: 5.0434 - MSE: 5.0434 - MAE: 1.8208\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14146/20000 - Train Loss: 0.5797 - Test Loss: 5.0510 - MSE: 5.0510 - MAE: 1.8218\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14147/20000 - Train Loss: 0.5797 - Test Loss: 5.0411 - MSE: 5.0411 - MAE: 1.8205\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14148/20000 - Train Loss: 0.5796 - Test Loss: 5.0532 - MSE: 5.0532 - MAE: 1.8221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14149/20000 - Train Loss: 0.5796 - Test Loss: 5.0375 - MSE: 5.0375 - MAE: 1.8200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14150/20000 - Train Loss: 0.5796 - Test Loss: 5.0572 - MSE: 5.0572 - MAE: 1.8226\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14151/20000 - Train Loss: 0.5796 - Test Loss: 5.0316 - MSE: 5.0316 - MAE: 1.8192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14152/20000 - Train Loss: 0.5796 - Test Loss: 5.0642 - MSE: 5.0642 - MAE: 1.8235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14153/20000 - Train Loss: 0.5797 - Test Loss: 5.0221 - MSE: 5.0221 - MAE: 1.8178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14154/20000 - Train Loss: 0.5798 - Test Loss: 5.0763 - MSE: 5.0763 - MAE: 1.8250\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14155/20000 - Train Loss: 0.5799 - Test Loss: 5.0063 - MSE: 5.0063 - MAE: 1.8156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14156/20000 - Train Loss: 0.5802 - Test Loss: 5.0977 - MSE: 5.0977 - MAE: 1.8277\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14157/20000 - Train Loss: 0.5808 - Test Loss: 4.9799 - MSE: 4.9799 - MAE: 1.8119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14158/20000 - Train Loss: 0.5817 - Test Loss: 5.1357 - MSE: 5.1357 - MAE: 1.8324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14159/20000 - Train Loss: 0.5833 - Test Loss: 4.9367 - MSE: 4.9367 - MAE: 1.8056\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14160/20000 - Train Loss: 0.5860 - Test Loss: 5.2032 - MSE: 5.2032 - MAE: 1.8405\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14161/20000 - Train Loss: 0.5905 - Test Loss: 4.8699 - MSE: 4.8699 - MAE: 1.7951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14162/20000 - Train Loss: 0.5976 - Test Loss: 5.3188 - MSE: 5.3188 - MAE: 1.8551\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 14163/20000 - Train Loss: 0.6079 - Test Loss: 4.7817 - MSE: 4.7817 - MAE: 1.7827\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14164/20000 - Train Loss: 0.6211 - Test Loss: 5.4821 - MSE: 5.4821 - MAE: 1.8767\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14165/20000 - Train Loss: 0.6332 - Test Loss: 4.7073 - MSE: 4.7073 - MAE: 1.7761\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14166/20000 - Train Loss: 0.6368 - Test Loss: 5.5712 - MSE: 5.5712 - MAE: 1.8887\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14167/20000 - Train Loss: 0.6247 - Test Loss: 4.7279 - MSE: 4.7279 - MAE: 1.7779\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14168/20000 - Train Loss: 0.6013 - Test Loss: 5.3483 - MSE: 5.3483 - MAE: 1.8591\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14169/20000 - Train Loss: 0.5824 - Test Loss: 4.9451 - MSE: 4.9451 - MAE: 1.8067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14170/20000 - Train Loss: 0.5807 - Test Loss: 4.9728 - MSE: 4.9728 - MAE: 1.8107\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14171/20000 - Train Loss: 0.5928 - Test Loss: 5.2769 - MSE: 5.2769 - MAE: 1.8491\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14172/20000 - Train Loss: 0.6038 - Test Loss: 4.7961 - MSE: 4.7961 - MAE: 1.7837\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14173/20000 - Train Loss: 0.6020 - Test Loss: 5.3538 - MSE: 5.3538 - MAE: 1.8598\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14174/20000 - Train Loss: 0.5896 - Test Loss: 4.8725 - MSE: 4.8725 - MAE: 1.7953\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14175/20000 - Train Loss: 0.5798 - Test Loss: 5.0930 - MSE: 5.0930 - MAE: 1.8268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14176/20000 - Train Loss: 0.5814 - Test Loss: 5.1336 - MSE: 5.1336 - MAE: 1.8319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14177/20000 - Train Loss: 0.5894 - Test Loss: 4.8729 - MSE: 4.8729 - MAE: 1.7954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14178/20000 - Train Loss: 0.5929 - Test Loss: 5.2783 - MSE: 5.2783 - MAE: 1.8492\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14179/20000 - Train Loss: 0.5879 - Test Loss: 4.8837 - MSE: 4.8837 - MAE: 1.7971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14180/20000 - Train Loss: 0.5807 - Test Loss: 5.1201 - MSE: 5.1201 - MAE: 1.8302\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14181/20000 - Train Loss: 0.5793 - Test Loss: 5.0769 - MSE: 5.0769 - MAE: 1.8247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14182/20000 - Train Loss: 0.5835 - Test Loss: 4.9242 - MSE: 4.9242 - MAE: 1.8034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14183/20000 - Train Loss: 0.5868 - Test Loss: 5.2154 - MSE: 5.2154 - MAE: 1.8415\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14184/20000 - Train Loss: 0.5849 - Test Loss: 4.9089 - MSE: 4.9089 - MAE: 1.8010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14185/20000 - Train Loss: 0.5805 - Test Loss: 5.1166 - MSE: 5.1166 - MAE: 1.8296\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14186/20000 - Train Loss: 0.5789 - Test Loss: 5.0529 - MSE: 5.0529 - MAE: 1.8215\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14187/20000 - Train Loss: 0.5810 - Test Loss: 4.9576 - MSE: 4.9576 - MAE: 1.8083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14188/20000 - Train Loss: 0.5833 - Test Loss: 5.1694 - MSE: 5.1694 - MAE: 1.8360\n",
      "2/2 [==============================] - 0s 978us/step\n",
      "Epoch 14189/20000 - Train Loss: 0.5826 - Test Loss: 4.9334 - MSE: 4.9334 - MAE: 1.8047\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14190/20000 - Train Loss: 0.5800 - Test Loss: 5.1059 - MSE: 5.1059 - MAE: 1.8282\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14191/20000 - Train Loss: 0.5787 - Test Loss: 5.0410 - MSE: 5.0410 - MAE: 1.8198\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 14192/20000 - Train Loss: 0.5798 - Test Loss: 4.9807 - MSE: 4.9807 - MAE: 1.8115\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14193/20000 - Train Loss: 0.5813 - Test Loss: 5.1355 - MSE: 5.1355 - MAE: 1.8318\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14194/20000 - Train Loss: 0.5810 - Test Loss: 4.9539 - MSE: 4.9539 - MAE: 1.8076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14195/20000 - Train Loss: 0.5795 - Test Loss: 5.0950 - MSE: 5.0950 - MAE: 1.8268\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14196/20000 - Train Loss: 0.5786 - Test Loss: 5.0336 - MSE: 5.0336 - MAE: 1.8188\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14197/20000 - Train Loss: 0.5791 - Test Loss: 4.9978 - MSE: 4.9978 - MAE: 1.8139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14198/20000 - Train Loss: 0.5800 - Test Loss: 5.1097 - MSE: 5.1097 - MAE: 1.8286\n",
      "2/2 [==============================] - 0s 968us/step\n",
      "Epoch 14199/20000 - Train Loss: 0.5800 - Test Loss: 4.9706 - MSE: 4.9706 - MAE: 1.8100\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14200/20000 - Train Loss: 0.5792 - Test Loss: 5.0859 - MSE: 5.0859 - MAE: 1.8255\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14201/20000 - Train Loss: 0.5785 - Test Loss: 5.0282 - MSE: 5.0282 - MAE: 1.8180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14202/20000 - Train Loss: 0.5787 - Test Loss: 5.0112 - MSE: 5.0112 - MAE: 1.8156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14203/20000 - Train Loss: 0.5793 - Test Loss: 5.0896 - MSE: 5.0896 - MAE: 1.8260\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14204/20000 - Train Loss: 0.5794 - Test Loss: 4.9840 - MSE: 4.9840 - MAE: 1.8118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14205/20000 - Train Loss: 0.5789 - Test Loss: 5.0781 - MSE: 5.0781 - MAE: 1.8245\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14206/20000 - Train Loss: 0.5785 - Test Loss: 5.0241 - MSE: 5.0241 - MAE: 1.8173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14207/20000 - Train Loss: 0.5785 - Test Loss: 5.0216 - MSE: 5.0216 - MAE: 1.8170\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14208/20000 - Train Loss: 0.5788 - Test Loss: 5.0736 - MSE: 5.0736 - MAE: 1.8238\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14209/20000 - Train Loss: 0.5789 - Test Loss: 4.9949 - MSE: 4.9949 - MAE: 1.8133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14210/20000 - Train Loss: 0.5787 - Test Loss: 5.0715 - MSE: 5.0715 - MAE: 1.8235\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14211/20000 - Train Loss: 0.5784 - Test Loss: 5.0210 - MSE: 5.0210 - MAE: 1.8168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14212/20000 - Train Loss: 0.5783 - Test Loss: 5.0297 - MSE: 5.0297 - MAE: 1.8180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14213/20000 - Train Loss: 0.5785 - Test Loss: 5.0606 - MSE: 5.0606 - MAE: 1.8221\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14214/20000 - Train Loss: 0.5786 - Test Loss: 5.0041 - MSE: 5.0041 - MAE: 1.8145\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14215/20000 - Train Loss: 0.5785 - Test Loss: 5.0653 - MSE: 5.0653 - MAE: 1.8227\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14216/20000 - Train Loss: 0.5783 - Test Loss: 5.0190 - MSE: 5.0190 - MAE: 1.8165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14217/20000 - Train Loss: 0.5782 - Test Loss: 5.0357 - MSE: 5.0357 - MAE: 1.8187\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14218/20000 - Train Loss: 0.5782 - Test Loss: 5.0501 - MSE: 5.0501 - MAE: 1.8206\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14219/20000 - Train Loss: 0.5783 - Test Loss: 5.0120 - MSE: 5.0120 - MAE: 1.8155\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14220/20000 - Train Loss: 0.5783 - Test Loss: 5.0592 - MSE: 5.0592 - MAE: 1.8218\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14221/20000 - Train Loss: 0.5782 - Test Loss: 5.0182 - MSE: 5.0182 - MAE: 1.8163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14222/20000 - Train Loss: 0.5781 - Test Loss: 5.0399 - MSE: 5.0399 - MAE: 1.8192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14223/20000 - Train Loss: 0.5781 - Test Loss: 5.0415 - MSE: 5.0415 - MAE: 1.8194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14224/20000 - Train Loss: 0.5781 - Test Loss: 5.0189 - MSE: 5.0189 - MAE: 1.8164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14225/20000 - Train Loss: 0.5781 - Test Loss: 5.0531 - MSE: 5.0531 - MAE: 1.8209\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14226/20000 - Train Loss: 0.5781 - Test Loss: 5.0185 - MSE: 5.0185 - MAE: 1.8163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14227/20000 - Train Loss: 0.5780 - Test Loss: 5.0422 - MSE: 5.0422 - MAE: 1.8194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14228/20000 - Train Loss: 0.5780 - Test Loss: 5.0348 - MSE: 5.0348 - MAE: 1.8184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14229/20000 - Train Loss: 0.5780 - Test Loss: 5.0247 - MSE: 5.0247 - MAE: 1.8171\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14230/20000 - Train Loss: 0.5780 - Test Loss: 5.0471 - MSE: 5.0471 - MAE: 1.8200\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14231/20000 - Train Loss: 0.5780 - Test Loss: 5.0199 - MSE: 5.0199 - MAE: 1.8164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14232/20000 - Train Loss: 0.5779 - Test Loss: 5.0428 - MSE: 5.0428 - MAE: 1.8195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14233/20000 - Train Loss: 0.5779 - Test Loss: 5.0298 - MSE: 5.0298 - MAE: 1.8177\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14234/20000 - Train Loss: 0.5779 - Test Loss: 5.0294 - MSE: 5.0294 - MAE: 1.8176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14235/20000 - Train Loss: 0.5779 - Test Loss: 5.0412 - MSE: 5.0412 - MAE: 1.8192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14236/20000 - Train Loss: 0.5779 - Test Loss: 5.0221 - MSE: 5.0221 - MAE: 1.8166\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14237/20000 - Train Loss: 0.5778 - Test Loss: 5.0418 - MSE: 5.0418 - MAE: 1.8192\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14238/20000 - Train Loss: 0.5778 - Test Loss: 5.0267 - MSE: 5.0267 - MAE: 1.8172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14239/20000 - Train Loss: 0.5778 - Test Loss: 5.0328 - MSE: 5.0328 - MAE: 1.8180\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14240/20000 - Train Loss: 0.5777 - Test Loss: 5.0360 - MSE: 5.0360 - MAE: 1.8184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14241/20000 - Train Loss: 0.5777 - Test Loss: 5.0247 - MSE: 5.0247 - MAE: 1.8169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14242/20000 - Train Loss: 0.5777 - Test Loss: 5.0396 - MSE: 5.0396 - MAE: 1.8189\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14243/20000 - Train Loss: 0.5777 - Test Loss: 5.0251 - MSE: 5.0251 - MAE: 1.8169\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14244/20000 - Train Loss: 0.5777 - Test Loss: 5.0347 - MSE: 5.0347 - MAE: 1.8182\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14245/20000 - Train Loss: 0.5776 - Test Loss: 5.0316 - MSE: 5.0316 - MAE: 1.8178\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14246/20000 - Train Loss: 0.5776 - Test Loss: 5.0274 - MSE: 5.0274 - MAE: 1.8172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14247/20000 - Train Loss: 0.5776 - Test Loss: 5.0365 - MSE: 5.0365 - MAE: 1.8184\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14248/20000 - Train Loss: 0.5776 - Test Loss: 5.0249 - MSE: 5.0249 - MAE: 1.8168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14249/20000 - Train Loss: 0.5776 - Test Loss: 5.0351 - MSE: 5.0351 - MAE: 1.8182\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14250/20000 - Train Loss: 0.5775 - Test Loss: 5.0283 - MSE: 5.0283 - MAE: 1.8173\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14251/20000 - Train Loss: 0.5775 - Test Loss: 5.0297 - MSE: 5.0297 - MAE: 1.8174\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14252/20000 - Train Loss: 0.5775 - Test Loss: 5.0330 - MSE: 5.0330 - MAE: 1.8179\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14253/20000 - Train Loss: 0.5775 - Test Loss: 5.0258 - MSE: 5.0258 - MAE: 1.8169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14254/20000 - Train Loss: 0.5775 - Test Loss: 5.0342 - MSE: 5.0342 - MAE: 1.8180\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14255/20000 - Train Loss: 0.5774 - Test Loss: 5.0263 - MSE: 5.0263 - MAE: 1.8169\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14256/20000 - Train Loss: 0.5774 - Test Loss: 5.0311 - MSE: 5.0311 - MAE: 1.8175\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14257/20000 - Train Loss: 0.5774 - Test Loss: 5.0298 - MSE: 5.0298 - MAE: 1.8173\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14258/20000 - Train Loss: 0.5774 - Test Loss: 5.0271 - MSE: 5.0271 - MAE: 1.8170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14259/20000 - Train Loss: 0.5774 - Test Loss: 5.0322 - MSE: 5.0322 - MAE: 1.8176\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14260/20000 - Train Loss: 0.5773 - Test Loss: 5.0256 - MSE: 5.0256 - MAE: 1.8167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14261/20000 - Train Loss: 0.5773 - Test Loss: 5.0314 - MSE: 5.0314 - MAE: 1.8175\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14262/20000 - Train Loss: 0.5773 - Test Loss: 5.0272 - MSE: 5.0272 - MAE: 1.8169\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14263/20000 - Train Loss: 0.5773 - Test Loss: 5.0284 - MSE: 5.0284 - MAE: 1.8171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14264/20000 - Train Loss: 0.5773 - Test Loss: 5.0296 - MSE: 5.0296 - MAE: 1.8172\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14265/20000 - Train Loss: 0.5772 - Test Loss: 5.0259 - MSE: 5.0259 - MAE: 1.8167\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14266/20000 - Train Loss: 0.5772 - Test Loss: 5.0304 - MSE: 5.0304 - MAE: 1.8173\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14267/20000 - Train Loss: 0.5772 - Test Loss: 5.0257 - MSE: 5.0257 - MAE: 1.8167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14268/20000 - Train Loss: 0.5772 - Test Loss: 5.0290 - MSE: 5.0290 - MAE: 1.8171\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14269/20000 - Train Loss: 0.5772 - Test Loss: 5.0272 - MSE: 5.0272 - MAE: 1.8168\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14270/20000 - Train Loss: 0.5771 - Test Loss: 5.0267 - MSE: 5.0267 - MAE: 1.8167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14271/20000 - Train Loss: 0.5771 - Test Loss: 5.0286 - MSE: 5.0286 - MAE: 1.8170\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14272/20000 - Train Loss: 0.5771 - Test Loss: 5.0253 - MSE: 5.0253 - MAE: 1.8165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14273/20000 - Train Loss: 0.5771 - Test Loss: 5.0286 - MSE: 5.0286 - MAE: 1.8169\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14274/20000 - Train Loss: 0.5771 - Test Loss: 5.0255 - MSE: 5.0255 - MAE: 1.8165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14275/20000 - Train Loss: 0.5770 - Test Loss: 5.0272 - MSE: 5.0272 - MAE: 1.8167\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14276/20000 - Train Loss: 0.5770 - Test Loss: 5.0266 - MSE: 5.0266 - MAE: 1.8166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14277/20000 - Train Loss: 0.5770 - Test Loss: 5.0255 - MSE: 5.0255 - MAE: 1.8165\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14278/20000 - Train Loss: 0.5770 - Test Loss: 5.0273 - MSE: 5.0273 - MAE: 1.8167\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14279/20000 - Train Loss: 0.5770 - Test Loss: 5.0247 - MSE: 5.0247 - MAE: 1.8163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14280/20000 - Train Loss: 0.5769 - Test Loss: 5.0270 - MSE: 5.0270 - MAE: 1.8166\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14281/20000 - Train Loss: 0.5769 - Test Loss: 5.0249 - MSE: 5.0249 - MAE: 1.8163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14282/20000 - Train Loss: 0.5769 - Test Loss: 5.0257 - MSE: 5.0257 - MAE: 1.8164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14283/20000 - Train Loss: 0.5769 - Test Loss: 5.0257 - MSE: 5.0257 - MAE: 1.8164\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14284/20000 - Train Loss: 0.5768 - Test Loss: 5.0245 - MSE: 5.0245 - MAE: 1.8162\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14285/20000 - Train Loss: 0.5768 - Test Loss: 5.0260 - MSE: 5.0260 - MAE: 1.8164\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14286/20000 - Train Loss: 0.5768 - Test Loss: 5.0240 - MSE: 5.0240 - MAE: 1.8161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14287/20000 - Train Loss: 0.5768 - Test Loss: 5.0254 - MSE: 5.0254 - MAE: 1.8163\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14288/20000 - Train Loss: 0.5768 - Test Loss: 5.0242 - MSE: 5.0242 - MAE: 1.8161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14289/20000 - Train Loss: 0.5767 - Test Loss: 5.0245 - MSE: 5.0245 - MAE: 1.8161\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 14290/20000 - Train Loss: 0.5767 - Test Loss: 5.0246 - MSE: 5.0246 - MAE: 1.8161\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14291/20000 - Train Loss: 0.5767 - Test Loss: 5.0236 - MSE: 5.0236 - MAE: 1.8160\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14292/20000 - Train Loss: 0.5767 - Test Loss: 5.0246 - MSE: 5.0246 - MAE: 1.8161\n",
      "2/2 [==============================] - 0s 967us/step\n",
      "Epoch 14293/20000 - Train Loss: 0.5767 - Test Loss: 5.0232 - MSE: 5.0232 - MAE: 1.8159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14294/20000 - Train Loss: 0.5766 - Test Loss: 5.0241 - MSE: 5.0241 - MAE: 1.8160\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14295/20000 - Train Loss: 0.5766 - Test Loss: 5.0232 - MSE: 5.0232 - MAE: 1.8159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14296/20000 - Train Loss: 0.5766 - Test Loss: 5.0234 - MSE: 5.0234 - MAE: 1.8159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14297/20000 - Train Loss: 0.5766 - Test Loss: 5.0234 - MSE: 5.0234 - MAE: 1.8159\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14298/20000 - Train Loss: 0.5766 - Test Loss: 5.0227 - MSE: 5.0227 - MAE: 1.8158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14299/20000 - Train Loss: 0.5765 - Test Loss: 5.0233 - MSE: 5.0233 - MAE: 1.8158\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14300/20000 - Train Loss: 0.5765 - Test Loss: 5.0223 - MSE: 5.0223 - MAE: 1.8157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14301/20000 - Train Loss: 0.5765 - Test Loss: 5.0229 - MSE: 5.0229 - MAE: 1.8158\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14302/20000 - Train Loss: 0.5765 - Test Loss: 5.0222 - MSE: 5.0222 - MAE: 1.8156\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14303/20000 - Train Loss: 0.5765 - Test Loss: 5.0223 - MSE: 5.0223 - MAE: 1.8156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14304/20000 - Train Loss: 0.5764 - Test Loss: 5.0222 - MSE: 5.0222 - MAE: 1.8156\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14305/20000 - Train Loss: 0.5764 - Test Loss: 5.0217 - MSE: 5.0217 - MAE: 1.8155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14306/20000 - Train Loss: 0.5764 - Test Loss: 5.0221 - MSE: 5.0221 - MAE: 1.8156\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14307/20000 - Train Loss: 0.5764 - Test Loss: 5.0213 - MSE: 5.0213 - MAE: 1.8155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14308/20000 - Train Loss: 0.5764 - Test Loss: 5.0217 - MSE: 5.0217 - MAE: 1.8155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14309/20000 - Train Loss: 0.5763 - Test Loss: 5.0212 - MSE: 5.0212 - MAE: 1.8154\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14310/20000 - Train Loss: 0.5763 - Test Loss: 5.0212 - MSE: 5.0212 - MAE: 1.8154\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14311/20000 - Train Loss: 0.5763 - Test Loss: 5.0211 - MSE: 5.0211 - MAE: 1.8154\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14312/20000 - Train Loss: 0.5763 - Test Loss: 5.0207 - MSE: 5.0207 - MAE: 1.8153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14313/20000 - Train Loss: 0.5763 - Test Loss: 5.0209 - MSE: 5.0209 - MAE: 1.8153\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14314/20000 - Train Loss: 0.5762 - Test Loss: 5.0203 - MSE: 5.0203 - MAE: 1.8152\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 14315/20000 - Train Loss: 0.5762 - Test Loss: 5.0206 - MSE: 5.0206 - MAE: 1.8152\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14316/20000 - Train Loss: 0.5762 - Test Loss: 5.0201 - MSE: 5.0201 - MAE: 1.8151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14317/20000 - Train Loss: 0.5762 - Test Loss: 5.0202 - MSE: 5.0202 - MAE: 1.8151\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14318/20000 - Train Loss: 0.5762 - Test Loss: 5.0199 - MSE: 5.0199 - MAE: 1.8151\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14319/20000 - Train Loss: 0.5761 - Test Loss: 5.0197 - MSE: 5.0197 - MAE: 1.8151\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14320/20000 - Train Loss: 0.5761 - Test Loss: 5.0197 - MSE: 5.0197 - MAE: 1.8150\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14321/20000 - Train Loss: 0.5761 - Test Loss: 5.0193 - MSE: 5.0193 - MAE: 1.8150\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14322/20000 - Train Loss: 0.5761 - Test Loss: 5.0194 - MSE: 5.0194 - MAE: 1.8150\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14323/20000 - Train Loss: 0.5761 - Test Loss: 5.0190 - MSE: 5.0190 - MAE: 1.8149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14324/20000 - Train Loss: 0.5760 - Test Loss: 5.0191 - MSE: 5.0191 - MAE: 1.8149\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14325/20000 - Train Loss: 0.5760 - Test Loss: 5.0188 - MSE: 5.0188 - MAE: 1.8148\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14326/20000 - Train Loss: 0.5760 - Test Loss: 5.0187 - MSE: 5.0187 - MAE: 1.8148\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14327/20000 - Train Loss: 0.5760 - Test Loss: 5.0185 - MSE: 5.0185 - MAE: 1.8148\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14328/20000 - Train Loss: 0.5760 - Test Loss: 5.0184 - MSE: 5.0184 - MAE: 1.8147\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14329/20000 - Train Loss: 0.5759 - Test Loss: 5.0182 - MSE: 5.0182 - MAE: 1.8147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14330/20000 - Train Loss: 0.5759 - Test Loss: 5.0181 - MSE: 5.0181 - MAE: 1.8147\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14331/20000 - Train Loss: 0.5759 - Test Loss: 5.0179 - MSE: 5.0179 - MAE: 1.8146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14332/20000 - Train Loss: 0.5759 - Test Loss: 5.0178 - MSE: 5.0178 - MAE: 1.8146\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14333/20000 - Train Loss: 0.5759 - Test Loss: 5.0176 - MSE: 5.0176 - MAE: 1.8145\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14334/20000 - Train Loss: 0.5758 - Test Loss: 5.0175 - MSE: 5.0175 - MAE: 1.8145\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14335/20000 - Train Loss: 0.5758 - Test Loss: 5.0172 - MSE: 5.0172 - MAE: 1.8145\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14336/20000 - Train Loss: 0.5758 - Test Loss: 5.0172 - MSE: 5.0172 - MAE: 1.8144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14337/20000 - Train Loss: 0.5758 - Test Loss: 5.0169 - MSE: 5.0169 - MAE: 1.8144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14338/20000 - Train Loss: 0.5757 - Test Loss: 5.0168 - MSE: 5.0168 - MAE: 1.8144\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14339/20000 - Train Loss: 0.5757 - Test Loss: 5.0166 - MSE: 5.0166 - MAE: 1.8143\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14340/20000 - Train Loss: 0.5757 - Test Loss: 5.0165 - MSE: 5.0165 - MAE: 1.8143\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 14341/20000 - Train Loss: 0.5757 - Test Loss: 5.0163 - MSE: 5.0163 - MAE: 1.8142\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14342/20000 - Train Loss: 0.5757 - Test Loss: 5.0162 - MSE: 5.0162 - MAE: 1.8142\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14343/20000 - Train Loss: 0.5756 - Test Loss: 5.0160 - MSE: 5.0160 - MAE: 1.8142\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14344/20000 - Train Loss: 0.5756 - Test Loss: 5.0159 - MSE: 5.0159 - MAE: 1.8141\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14345/20000 - Train Loss: 0.5756 - Test Loss: 5.0157 - MSE: 5.0157 - MAE: 1.8141\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14346/20000 - Train Loss: 0.5756 - Test Loss: 5.0156 - MSE: 5.0156 - MAE: 1.8141\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14347/20000 - Train Loss: 0.5756 - Test Loss: 5.0154 - MSE: 5.0154 - MAE: 1.8140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14348/20000 - Train Loss: 0.5755 - Test Loss: 5.0152 - MSE: 5.0152 - MAE: 1.8140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14349/20000 - Train Loss: 0.5755 - Test Loss: 5.0151 - MSE: 5.0151 - MAE: 1.8140\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14350/20000 - Train Loss: 0.5755 - Test Loss: 5.0149 - MSE: 5.0149 - MAE: 1.8139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14351/20000 - Train Loss: 0.5755 - Test Loss: 5.0148 - MSE: 5.0148 - MAE: 1.8139\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14352/20000 - Train Loss: 0.5755 - Test Loss: 5.0146 - MSE: 5.0146 - MAE: 1.8138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14353/20000 - Train Loss: 0.5754 - Test Loss: 5.0145 - MSE: 5.0145 - MAE: 1.8138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14354/20000 - Train Loss: 0.5754 - Test Loss: 5.0143 - MSE: 5.0143 - MAE: 1.8138\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14355/20000 - Train Loss: 0.5754 - Test Loss: 5.0141 - MSE: 5.0141 - MAE: 1.8137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14356/20000 - Train Loss: 0.5754 - Test Loss: 5.0140 - MSE: 5.0140 - MAE: 1.8137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14357/20000 - Train Loss: 0.5754 - Test Loss: 5.0138 - MSE: 5.0138 - MAE: 1.8137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14358/20000 - Train Loss: 0.5753 - Test Loss: 5.0136 - MSE: 5.0136 - MAE: 1.8136\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14359/20000 - Train Loss: 0.5753 - Test Loss: 5.0135 - MSE: 5.0135 - MAE: 1.8136\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14360/20000 - Train Loss: 0.5753 - Test Loss: 5.0133 - MSE: 5.0133 - MAE: 1.8135\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14361/20000 - Train Loss: 0.5753 - Test Loss: 5.0132 - MSE: 5.0132 - MAE: 1.8135\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14362/20000 - Train Loss: 0.5753 - Test Loss: 5.0130 - MSE: 5.0130 - MAE: 1.8135\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14363/20000 - Train Loss: 0.5752 - Test Loss: 5.0129 - MSE: 5.0129 - MAE: 1.8134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14364/20000 - Train Loss: 0.5752 - Test Loss: 5.0127 - MSE: 5.0127 - MAE: 1.8134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14365/20000 - Train Loss: 0.5752 - Test Loss: 5.0125 - MSE: 5.0125 - MAE: 1.8134\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14366/20000 - Train Loss: 0.5752 - Test Loss: 5.0124 - MSE: 5.0124 - MAE: 1.8133\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14367/20000 - Train Loss: 0.5751 - Test Loss: 5.0122 - MSE: 5.0122 - MAE: 1.8133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14368/20000 - Train Loss: 0.5751 - Test Loss: 5.0121 - MSE: 5.0121 - MAE: 1.8133\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14369/20000 - Train Loss: 0.5751 - Test Loss: 5.0119 - MSE: 5.0119 - MAE: 1.8132\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14370/20000 - Train Loss: 0.5751 - Test Loss: 5.0118 - MSE: 5.0118 - MAE: 1.8132\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14371/20000 - Train Loss: 0.5751 - Test Loss: 5.0116 - MSE: 5.0116 - MAE: 1.8131\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14372/20000 - Train Loss: 0.5750 - Test Loss: 5.0115 - MSE: 5.0115 - MAE: 1.8131\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14373/20000 - Train Loss: 0.5750 - Test Loss: 5.0113 - MSE: 5.0113 - MAE: 1.8131\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14374/20000 - Train Loss: 0.5750 - Test Loss: 5.0112 - MSE: 5.0112 - MAE: 1.8130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14375/20000 - Train Loss: 0.5750 - Test Loss: 5.0109 - MSE: 5.0109 - MAE: 1.8130\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14376/20000 - Train Loss: 0.5750 - Test Loss: 5.0109 - MSE: 5.0109 - MAE: 1.8130\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14377/20000 - Train Loss: 0.5749 - Test Loss: 5.0106 - MSE: 5.0106 - MAE: 1.8129\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14378/20000 - Train Loss: 0.5749 - Test Loss: 5.0106 - MSE: 5.0106 - MAE: 1.8129\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14379/20000 - Train Loss: 0.5749 - Test Loss: 5.0102 - MSE: 5.0102 - MAE: 1.8128\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14380/20000 - Train Loss: 0.5749 - Test Loss: 5.0103 - MSE: 5.0103 - MAE: 1.8128\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14381/20000 - Train Loss: 0.5749 - Test Loss: 5.0099 - MSE: 5.0099 - MAE: 1.8128\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14382/20000 - Train Loss: 0.5748 - Test Loss: 5.0100 - MSE: 5.0100 - MAE: 1.8127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14383/20000 - Train Loss: 0.5748 - Test Loss: 5.0096 - MSE: 5.0096 - MAE: 1.8127\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14384/20000 - Train Loss: 0.5748 - Test Loss: 5.0097 - MSE: 5.0097 - MAE: 1.8127\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 14385/20000 - Train Loss: 0.5748 - Test Loss: 5.0093 - MSE: 5.0093 - MAE: 1.8126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14386/20000 - Train Loss: 0.5748 - Test Loss: 5.0093 - MSE: 5.0093 - MAE: 1.8126\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14387/20000 - Train Loss: 0.5747 - Test Loss: 5.0090 - MSE: 5.0090 - MAE: 1.8125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14388/20000 - Train Loss: 0.5747 - Test Loss: 5.0090 - MSE: 5.0090 - MAE: 1.8125\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 14389/20000 - Train Loss: 0.5747 - Test Loss: 5.0087 - MSE: 5.0087 - MAE: 1.8125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14390/20000 - Train Loss: 0.5747 - Test Loss: 5.0086 - MSE: 5.0086 - MAE: 1.8124\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14391/20000 - Train Loss: 0.5747 - Test Loss: 5.0084 - MSE: 5.0084 - MAE: 1.8124\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14392/20000 - Train Loss: 0.5746 - Test Loss: 5.0083 - MSE: 5.0083 - MAE: 1.8124\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14393/20000 - Train Loss: 0.5746 - Test Loss: 5.0081 - MSE: 5.0081 - MAE: 1.8123\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14394/20000 - Train Loss: 0.5746 - Test Loss: 5.0079 - MSE: 5.0079 - MAE: 1.8123\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14395/20000 - Train Loss: 0.5746 - Test Loss: 5.0078 - MSE: 5.0078 - MAE: 1.8122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14396/20000 - Train Loss: 0.5745 - Test Loss: 5.0076 - MSE: 5.0076 - MAE: 1.8122\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14397/20000 - Train Loss: 0.5745 - Test Loss: 5.0075 - MSE: 5.0075 - MAE: 1.8122\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14398/20000 - Train Loss: 0.5745 - Test Loss: 5.0073 - MSE: 5.0073 - MAE: 1.8121\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14399/20000 - Train Loss: 0.5745 - Test Loss: 5.0073 - MSE: 5.0073 - MAE: 1.8121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14400/20000 - Train Loss: 0.5745 - Test Loss: 5.0069 - MSE: 5.0069 - MAE: 1.8120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14401/20000 - Train Loss: 0.5744 - Test Loss: 5.0070 - MSE: 5.0070 - MAE: 1.8120\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14402/20000 - Train Loss: 0.5744 - Test Loss: 5.0065 - MSE: 5.0065 - MAE: 1.8120\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14403/20000 - Train Loss: 0.5744 - Test Loss: 5.0067 - MSE: 5.0067 - MAE: 1.8120\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14404/20000 - Train Loss: 0.5744 - Test Loss: 5.0061 - MSE: 5.0061 - MAE: 1.8119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14405/20000 - Train Loss: 0.5744 - Test Loss: 5.0065 - MSE: 5.0065 - MAE: 1.8119\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14406/20000 - Train Loss: 0.5743 - Test Loss: 5.0057 - MSE: 5.0057 - MAE: 1.8118\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14407/20000 - Train Loss: 0.5743 - Test Loss: 5.0063 - MSE: 5.0063 - MAE: 1.8118\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14408/20000 - Train Loss: 0.5743 - Test Loss: 5.0053 - MSE: 5.0053 - MAE: 1.8117\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14409/20000 - Train Loss: 0.5743 - Test Loss: 5.0061 - MSE: 5.0061 - MAE: 1.8118\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14410/20000 - Train Loss: 0.5743 - Test Loss: 5.0048 - MSE: 5.0048 - MAE: 1.8116\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14411/20000 - Train Loss: 0.5742 - Test Loss: 5.0059 - MSE: 5.0059 - MAE: 1.8117\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14412/20000 - Train Loss: 0.5742 - Test Loss: 5.0043 - MSE: 5.0043 - MAE: 1.8115\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14413/20000 - Train Loss: 0.5742 - Test Loss: 5.0059 - MSE: 5.0059 - MAE: 1.8117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14414/20000 - Train Loss: 0.5742 - Test Loss: 5.0036 - MSE: 5.0036 - MAE: 1.8114\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14415/20000 - Train Loss: 0.5742 - Test Loss: 5.0059 - MSE: 5.0059 - MAE: 1.8117\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14416/20000 - Train Loss: 0.5741 - Test Loss: 5.0029 - MSE: 5.0029 - MAE: 1.8112\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14417/20000 - Train Loss: 0.5741 - Test Loss: 5.0061 - MSE: 5.0061 - MAE: 1.8117\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14418/20000 - Train Loss: 0.5741 - Test Loss: 5.0019 - MSE: 5.0019 - MAE: 1.8111\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14419/20000 - Train Loss: 0.5741 - Test Loss: 5.0066 - MSE: 5.0066 - MAE: 1.8117\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14420/20000 - Train Loss: 0.5741 - Test Loss: 5.0007 - MSE: 5.0007 - MAE: 1.8109\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14421/20000 - Train Loss: 0.5740 - Test Loss: 5.0074 - MSE: 5.0074 - MAE: 1.8118\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14422/20000 - Train Loss: 0.5740 - Test Loss: 4.9991 - MSE: 4.9991 - MAE: 1.8106\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14423/20000 - Train Loss: 0.5740 - Test Loss: 5.0086 - MSE: 5.0086 - MAE: 1.8119\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14424/20000 - Train Loss: 0.5740 - Test Loss: 4.9968 - MSE: 4.9968 - MAE: 1.8103\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14425/20000 - Train Loss: 0.5740 - Test Loss: 5.0108 - MSE: 5.0108 - MAE: 1.8122\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 14426/20000 - Train Loss: 0.5739 - Test Loss: 4.9935 - MSE: 4.9935 - MAE: 1.8098\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14427/20000 - Train Loss: 0.5739 - Test Loss: 5.0142 - MSE: 5.0142 - MAE: 1.8126\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14428/20000 - Train Loss: 0.5739 - Test Loss: 4.9886 - MSE: 4.9886 - MAE: 1.8091\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14429/20000 - Train Loss: 0.5740 - Test Loss: 5.0198 - MSE: 5.0198 - MAE: 1.8133\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14430/20000 - Train Loss: 0.5740 - Test Loss: 4.9811 - MSE: 4.9811 - MAE: 1.8080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14431/20000 - Train Loss: 0.5740 - Test Loss: 5.0289 - MSE: 5.0289 - MAE: 1.8145\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14432/20000 - Train Loss: 0.5741 - Test Loss: 4.9693 - MSE: 4.9693 - MAE: 1.8064\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14433/20000 - Train Loss: 0.5743 - Test Loss: 5.0440 - MSE: 5.0440 - MAE: 1.8164\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14434/20000 - Train Loss: 0.5746 - Test Loss: 4.9509 - MSE: 4.9509 - MAE: 1.8038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14435/20000 - Train Loss: 0.5751 - Test Loss: 5.0690 - MSE: 5.0690 - MAE: 1.8195\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14436/20000 - Train Loss: 0.5758 - Test Loss: 4.9220 - MSE: 4.9220 - MAE: 1.7996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14437/20000 - Train Loss: 0.5770 - Test Loss: 5.1106 - MSE: 5.1106 - MAE: 1.8247\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14438/20000 - Train Loss: 0.5790 - Test Loss: 4.8782 - MSE: 4.8782 - MAE: 1.7929\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14439/20000 - Train Loss: 0.5820 - Test Loss: 5.1787 - MSE: 5.1787 - MAE: 1.8328\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14440/20000 - Train Loss: 0.5866 - Test Loss: 4.8165 - MSE: 4.8165 - MAE: 1.7829\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14441/20000 - Train Loss: 0.5931 - Test Loss: 5.2824 - MSE: 5.2824 - MAE: 1.8468\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14442/20000 - Train Loss: 0.6013 - Test Loss: 4.7450 - MSE: 4.7450 - MAE: 1.7744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14443/20000 - Train Loss: 0.6099 - Test Loss: 5.4011 - MSE: 5.4011 - MAE: 1.8627\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14444/20000 - Train Loss: 0.6155 - Test Loss: 4.6986 - MSE: 4.6986 - MAE: 1.7703\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14445/20000 - Train Loss: 0.6135 - Test Loss: 5.4234 - MSE: 5.4234 - MAE: 1.8655\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14446/20000 - Train Loss: 0.6022 - Test Loss: 4.7407 - MSE: 4.7407 - MAE: 1.7740\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14447/20000 - Train Loss: 0.5864 - Test Loss: 5.2247 - MSE: 5.2247 - MAE: 1.8386\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14448/20000 - Train Loss: 0.5752 - Test Loss: 4.9264 - MSE: 4.9264 - MAE: 1.8000\n",
      "2/2 [==============================] - 0s 973us/step\n",
      "Epoch 14449/20000 - Train Loss: 0.5744 - Test Loss: 4.9458 - MSE: 4.9458 - MAE: 1.8028\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14450/20000 - Train Loss: 0.5815 - Test Loss: 5.1738 - MSE: 5.1738 - MAE: 1.8320\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14451/20000 - Train Loss: 0.5891 - Test Loss: 4.7984 - MSE: 4.7984 - MAE: 1.7797\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14452/20000 - Train Loss: 0.5905 - Test Loss: 5.2616 - MSE: 5.2616 - MAE: 1.8438\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14453/20000 - Train Loss: 0.5846 - Test Loss: 4.8257 - MSE: 4.8257 - MAE: 1.7843\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14454/20000 - Train Loss: 0.5768 - Test Loss: 5.1093 - MSE: 5.1093 - MAE: 1.8242\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14455/20000 - Train Loss: 0.5733 - Test Loss: 4.9959 - MSE: 4.9959 - MAE: 1.8097\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14456/20000 - Train Loss: 0.5759 - Test Loss: 4.9114 - MSE: 4.9114 - MAE: 1.7977\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14457/20000 - Train Loss: 0.5805 - Test Loss: 5.1620 - MSE: 5.1620 - MAE: 1.8305\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14458/20000 - Train Loss: 0.5822 - Test Loss: 4.8422 - MSE: 4.8422 - MAE: 1.7870\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14459/20000 - Train Loss: 0.5795 - Test Loss: 5.1500 - MSE: 5.1500 - MAE: 1.8290\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14460/20000 - Train Loss: 0.5752 - Test Loss: 4.9206 - MSE: 4.9206 - MAE: 1.7990\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14461/20000 - Train Loss: 0.5732 - Test Loss: 5.0006 - MSE: 5.0006 - MAE: 1.8102\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14462/20000 - Train Loss: 0.5746 - Test Loss: 5.0665 - MSE: 5.0665 - MAE: 1.8188\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14463/20000 - Train Loss: 0.5771 - Test Loss: 4.8909 - MSE: 4.8909 - MAE: 1.7946\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14464/20000 - Train Loss: 0.5779 - Test Loss: 5.1285 - MSE: 5.1285 - MAE: 1.8264\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14465/20000 - Train Loss: 0.5763 - Test Loss: 4.9008 - MSE: 4.9008 - MAE: 1.7960\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14466/20000 - Train Loss: 0.5740 - Test Loss: 5.0517 - MSE: 5.0517 - MAE: 1.8168\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14467/20000 - Train Loss: 0.5731 - Test Loss: 5.0002 - MSE: 5.0002 - MAE: 1.8101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14468/20000 - Train Loss: 0.5740 - Test Loss: 4.9437 - MSE: 4.9437 - MAE: 1.8022\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14469/20000 - Train Loss: 0.5753 - Test Loss: 5.0852 - MSE: 5.0852 - MAE: 1.8210\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14470/20000 - Train Loss: 0.5756 - Test Loss: 4.9096 - MSE: 4.9096 - MAE: 1.7973\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14471/20000 - Train Loss: 0.5746 - Test Loss: 5.0697 - MSE: 5.0697 - MAE: 1.8191\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14472/20000 - Train Loss: 0.5734 - Test Loss: 4.9616 - MSE: 4.9616 - MAE: 1.8047\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14473/20000 - Train Loss: 0.5730 - Test Loss: 4.9885 - MSE: 4.9885 - MAE: 1.8084\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14474/20000 - Train Loss: 0.5735 - Test Loss: 5.0397 - MSE: 5.0397 - MAE: 1.8152\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 14475/20000 - Train Loss: 0.5742 - Test Loss: 4.9333 - MSE: 4.9333 - MAE: 1.8006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14476/20000 - Train Loss: 0.5743 - Test Loss: 5.0637 - MSE: 5.0637 - MAE: 1.8182\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14477/20000 - Train Loss: 0.5737 - Test Loss: 4.9457 - MSE: 4.9457 - MAE: 1.8024\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14478/20000 - Train Loss: 0.5731 - Test Loss: 5.0188 - MSE: 5.0188 - MAE: 1.8124\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14479/20000 - Train Loss: 0.5729 - Test Loss: 5.0020 - MSE: 5.0020 - MAE: 1.8101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14480/20000 - Train Loss: 0.5732 - Test Loss: 4.9624 - MSE: 4.9624 - MAE: 1.8047\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14481/20000 - Train Loss: 0.5735 - Test Loss: 5.0432 - MSE: 5.0432 - MAE: 1.8155\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14482/20000 - Train Loss: 0.5736 - Test Loss: 4.9470 - MSE: 4.9470 - MAE: 1.8025\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14483/20000 - Train Loss: 0.5732 - Test Loss: 5.0321 - MSE: 5.0321 - MAE: 1.8140\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14484/20000 - Train Loss: 0.5729 - Test Loss: 4.9767 - MSE: 4.9767 - MAE: 1.8066\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14485/20000 - Train Loss: 0.5728 - Test Loss: 4.9893 - MSE: 4.9893 - MAE: 1.8083\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14486/20000 - Train Loss: 0.5729 - Test Loss: 5.0175 - MSE: 5.0175 - MAE: 1.8121\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14487/20000 - Train Loss: 0.5731 - Test Loss: 4.9598 - MSE: 4.9598 - MAE: 1.8042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14488/20000 - Train Loss: 0.5731 - Test Loss: 5.0301 - MSE: 5.0301 - MAE: 1.8137\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14489/20000 - Train Loss: 0.5729 - Test Loss: 4.9653 - MSE: 4.9653 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14490/20000 - Train Loss: 0.5727 - Test Loss: 5.0081 - MSE: 5.0081 - MAE: 1.8108\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14491/20000 - Train Loss: 0.5726 - Test Loss: 4.9943 - MSE: 4.9943 - MAE: 1.8089\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14492/20000 - Train Loss: 0.5727 - Test Loss: 4.9778 - MSE: 4.9778 - MAE: 1.8067\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 14493/20000 - Train Loss: 0.5728 - Test Loss: 5.0174 - MSE: 5.0174 - MAE: 1.8120\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14494/20000 - Train Loss: 0.5728 - Test Loss: 4.9664 - MSE: 4.9664 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14495/20000 - Train Loss: 0.5727 - Test Loss: 5.0153 - MSE: 5.0153 - MAE: 1.8116\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14496/20000 - Train Loss: 0.5726 - Test Loss: 4.9790 - MSE: 4.9790 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14497/20000 - Train Loss: 0.5725 - Test Loss: 4.9945 - MSE: 4.9945 - MAE: 1.8088\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14498/20000 - Train Loss: 0.5725 - Test Loss: 5.0005 - MSE: 5.0005 - MAE: 1.8096\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14499/20000 - Train Loss: 0.5726 - Test Loss: 4.9760 - MSE: 4.9760 - MAE: 1.8063\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14500/20000 - Train Loss: 0.5726 - Test Loss: 5.0113 - MSE: 5.0113 - MAE: 1.8110\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14501/20000 - Train Loss: 0.5726 - Test Loss: 4.9739 - MSE: 4.9739 - MAE: 1.8060\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14502/20000 - Train Loss: 0.5725 - Test Loss: 5.0041 - MSE: 5.0041 - MAE: 1.8101\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14503/20000 - Train Loss: 0.5724 - Test Loss: 4.9864 - MSE: 4.9864 - MAE: 1.8077\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14504/20000 - Train Loss: 0.5724 - Test Loss: 4.9882 - MSE: 4.9882 - MAE: 1.8079\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14505/20000 - Train Loss: 0.5724 - Test Loss: 5.0005 - MSE: 5.0005 - MAE: 1.8095\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14506/20000 - Train Loss: 0.5724 - Test Loss: 4.9777 - MSE: 4.9777 - MAE: 1.8064\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14507/20000 - Train Loss: 0.5724 - Test Loss: 5.0047 - MSE: 5.0047 - MAE: 1.8101\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14508/20000 - Train Loss: 0.5724 - Test Loss: 4.9793 - MSE: 4.9793 - MAE: 1.8066\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14509/20000 - Train Loss: 0.5723 - Test Loss: 4.9972 - MSE: 4.9972 - MAE: 1.8090\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14510/20000 - Train Loss: 0.5723 - Test Loss: 4.9892 - MSE: 4.9892 - MAE: 1.8079\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14511/20000 - Train Loss: 0.5723 - Test Loss: 4.9861 - MSE: 4.9861 - MAE: 1.8075\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14512/20000 - Train Loss: 0.5723 - Test Loss: 4.9980 - MSE: 4.9980 - MAE: 1.8091\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14513/20000 - Train Loss: 0.5723 - Test Loss: 4.9801 - MSE: 4.9801 - MAE: 1.8066\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14514/20000 - Train Loss: 0.5722 - Test Loss: 4.9993 - MSE: 4.9993 - MAE: 1.8092\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14515/20000 - Train Loss: 0.5722 - Test Loss: 4.9823 - MSE: 4.9823 - MAE: 1.8069\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14516/20000 - Train Loss: 0.5722 - Test Loss: 4.9932 - MSE: 4.9932 - MAE: 1.8084\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14517/20000 - Train Loss: 0.5722 - Test Loss: 4.9893 - MSE: 4.9893 - MAE: 1.8078\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14518/20000 - Train Loss: 0.5721 - Test Loss: 4.9856 - MSE: 4.9856 - MAE: 1.8073\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14519/20000 - Train Loss: 0.5721 - Test Loss: 4.9949 - MSE: 4.9949 - MAE: 1.8086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14520/20000 - Train Loss: 0.5721 - Test Loss: 4.9819 - MSE: 4.9819 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14521/20000 - Train Loss: 0.5721 - Test Loss: 4.9953 - MSE: 4.9953 - MAE: 1.8086\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14522/20000 - Train Loss: 0.5721 - Test Loss: 4.9836 - MSE: 4.9836 - MAE: 1.8070\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14523/20000 - Train Loss: 0.5720 - Test Loss: 4.9910 - MSE: 4.9910 - MAE: 1.8080\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14524/20000 - Train Loss: 0.5720 - Test Loss: 4.9883 - MSE: 4.9883 - MAE: 1.8076\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14525/20000 - Train Loss: 0.5720 - Test Loss: 4.9858 - MSE: 4.9858 - MAE: 1.8072\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14526/20000 - Train Loss: 0.5720 - Test Loss: 4.9920 - MSE: 4.9920 - MAE: 1.8081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14527/20000 - Train Loss: 0.5720 - Test Loss: 4.9830 - MSE: 4.9830 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14528/20000 - Train Loss: 0.5720 - Test Loss: 4.9923 - MSE: 4.9923 - MAE: 1.8081\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14529/20000 - Train Loss: 0.5719 - Test Loss: 4.9838 - MSE: 4.9838 - MAE: 1.8069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14530/20000 - Train Loss: 0.5719 - Test Loss: 4.9896 - MSE: 4.9896 - MAE: 1.8077\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14531/20000 - Train Loss: 0.5719 - Test Loss: 4.9867 - MSE: 4.9867 - MAE: 1.8073\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14532/20000 - Train Loss: 0.5719 - Test Loss: 4.9860 - MSE: 4.9860 - MAE: 1.8072\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14533/20000 - Train Loss: 0.5718 - Test Loss: 4.9893 - MSE: 4.9893 - MAE: 1.8076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14534/20000 - Train Loss: 0.5718 - Test Loss: 4.9837 - MSE: 4.9837 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14535/20000 - Train Loss: 0.5718 - Test Loss: 4.9899 - MSE: 4.9899 - MAE: 1.8076\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14536/20000 - Train Loss: 0.5718 - Test Loss: 4.9836 - MSE: 4.9836 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14537/20000 - Train Loss: 0.5718 - Test Loss: 4.9884 - MSE: 4.9884 - MAE: 1.8074\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14538/20000 - Train Loss: 0.5718 - Test Loss: 4.9852 - MSE: 4.9852 - MAE: 1.8070\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14539/20000 - Train Loss: 0.5717 - Test Loss: 4.9860 - MSE: 4.9860 - MAE: 1.8071\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14540/20000 - Train Loss: 0.5717 - Test Loss: 4.9869 - MSE: 4.9869 - MAE: 1.8072\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14541/20000 - Train Loss: 0.5717 - Test Loss: 4.9840 - MSE: 4.9840 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14542/20000 - Train Loss: 0.5717 - Test Loss: 4.9877 - MSE: 4.9877 - MAE: 1.8072\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14543/20000 - Train Loss: 0.5717 - Test Loss: 4.9833 - MSE: 4.9833 - MAE: 1.8066\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14544/20000 - Train Loss: 0.5716 - Test Loss: 4.9872 - MSE: 4.9872 - MAE: 1.8071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14545/20000 - Train Loss: 0.5716 - Test Loss: 4.9838 - MSE: 4.9838 - MAE: 1.8067\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14546/20000 - Train Loss: 0.5716 - Test Loss: 4.9857 - MSE: 4.9857 - MAE: 1.8069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14547/20000 - Train Loss: 0.5716 - Test Loss: 4.9849 - MSE: 4.9849 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14548/20000 - Train Loss: 0.5716 - Test Loss: 4.9840 - MSE: 4.9840 - MAE: 1.8066\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14549/20000 - Train Loss: 0.5715 - Test Loss: 4.9858 - MSE: 4.9858 - MAE: 1.8069\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14550/20000 - Train Loss: 0.5715 - Test Loss: 4.9829 - MSE: 4.9829 - MAE: 1.8065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14551/20000 - Train Loss: 0.5715 - Test Loss: 4.9858 - MSE: 4.9858 - MAE: 1.8068\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14552/20000 - Train Loss: 0.5715 - Test Loss: 4.9828 - MSE: 4.9828 - MAE: 1.8064\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14553/20000 - Train Loss: 0.5715 - Test Loss: 4.9850 - MSE: 4.9850 - MAE: 1.8067\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14554/20000 - Train Loss: 0.5714 - Test Loss: 4.9832 - MSE: 4.9832 - MAE: 1.8064\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14555/20000 - Train Loss: 0.5714 - Test Loss: 4.9839 - MSE: 4.9839 - MAE: 1.8065\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14556/20000 - Train Loss: 0.5714 - Test Loss: 4.9838 - MSE: 4.9838 - MAE: 1.8065\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14557/20000 - Train Loss: 0.5714 - Test Loss: 4.9828 - MSE: 4.9828 - MAE: 1.8063\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14558/20000 - Train Loss: 0.5714 - Test Loss: 4.9840 - MSE: 4.9840 - MAE: 1.8065\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14559/20000 - Train Loss: 0.5713 - Test Loss: 4.9822 - MSE: 4.9822 - MAE: 1.8062\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14560/20000 - Train Loss: 0.5713 - Test Loss: 4.9839 - MSE: 4.9839 - MAE: 1.8064\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14561/20000 - Train Loss: 0.5713 - Test Loss: 4.9820 - MSE: 4.9820 - MAE: 1.8062\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14562/20000 - Train Loss: 0.5713 - Test Loss: 4.9833 - MSE: 4.9833 - MAE: 1.8063\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14563/20000 - Train Loss: 0.5713 - Test Loss: 4.9821 - MSE: 4.9821 - MAE: 1.8061\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14564/20000 - Train Loss: 0.5713 - Test Loss: 4.9825 - MSE: 4.9825 - MAE: 1.8062\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14565/20000 - Train Loss: 0.5712 - Test Loss: 4.9823 - MSE: 4.9823 - MAE: 1.8061\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14566/20000 - Train Loss: 0.5712 - Test Loss: 4.9817 - MSE: 4.9817 - MAE: 1.8060\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14567/20000 - Train Loss: 0.5712 - Test Loss: 4.9824 - MSE: 4.9824 - MAE: 1.8061\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14568/20000 - Train Loss: 0.5712 - Test Loss: 4.9812 - MSE: 4.9812 - MAE: 1.8059\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14569/20000 - Train Loss: 0.5712 - Test Loss: 4.9822 - MSE: 4.9822 - MAE: 1.8061\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14570/20000 - Train Loss: 0.5711 - Test Loss: 4.9809 - MSE: 4.9809 - MAE: 1.8059\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14571/20000 - Train Loss: 0.5711 - Test Loss: 4.9817 - MSE: 4.9817 - MAE: 1.8060\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14572/20000 - Train Loss: 0.5711 - Test Loss: 4.9809 - MSE: 4.9809 - MAE: 1.8058\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14573/20000 - Train Loss: 0.5711 - Test Loss: 4.9811 - MSE: 4.9811 - MAE: 1.8059\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14574/20000 - Train Loss: 0.5711 - Test Loss: 4.9809 - MSE: 4.9809 - MAE: 1.8058\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14575/20000 - Train Loss: 0.5710 - Test Loss: 4.9806 - MSE: 4.9806 - MAE: 1.8057\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14576/20000 - Train Loss: 0.5710 - Test Loss: 4.9808 - MSE: 4.9808 - MAE: 1.8058\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14577/20000 - Train Loss: 0.5710 - Test Loss: 4.9801 - MSE: 4.9801 - MAE: 1.8057\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14578/20000 - Train Loss: 0.5710 - Test Loss: 4.9806 - MSE: 4.9806 - MAE: 1.8057\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14579/20000 - Train Loss: 0.5710 - Test Loss: 4.9797 - MSE: 4.9797 - MAE: 1.8056\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14580/20000 - Train Loss: 0.5709 - Test Loss: 4.9803 - MSE: 4.9803 - MAE: 1.8056\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14581/20000 - Train Loss: 0.5709 - Test Loss: 4.9795 - MSE: 4.9795 - MAE: 1.8055\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14582/20000 - Train Loss: 0.5709 - Test Loss: 4.9799 - MSE: 4.9799 - MAE: 1.8056\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14583/20000 - Train Loss: 0.5709 - Test Loss: 4.9793 - MSE: 4.9793 - MAE: 1.8055\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14584/20000 - Train Loss: 0.5709 - Test Loss: 4.9795 - MSE: 4.9795 - MAE: 1.8055\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14585/20000 - Train Loss: 0.5708 - Test Loss: 4.9792 - MSE: 4.9792 - MAE: 1.8054\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14586/20000 - Train Loss: 0.5708 - Test Loss: 4.9790 - MSE: 4.9790 - MAE: 1.8054\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 14587/20000 - Train Loss: 0.5708 - Test Loss: 4.9790 - MSE: 4.9790 - MAE: 1.8053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14588/20000 - Train Loss: 0.5708 - Test Loss: 4.9786 - MSE: 4.9786 - MAE: 1.8053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14589/20000 - Train Loss: 0.5708 - Test Loss: 4.9788 - MSE: 4.9788 - MAE: 1.8053\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14590/20000 - Train Loss: 0.5707 - Test Loss: 4.9783 - MSE: 4.9783 - MAE: 1.8052\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14591/20000 - Train Loss: 0.5707 - Test Loss: 4.9785 - MSE: 4.9785 - MAE: 1.8052\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14592/20000 - Train Loss: 0.5707 - Test Loss: 4.9780 - MSE: 4.9780 - MAE: 1.8051\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14593/20000 - Train Loss: 0.5707 - Test Loss: 4.9782 - MSE: 4.9782 - MAE: 1.8051\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14594/20000 - Train Loss: 0.5707 - Test Loss: 4.9778 - MSE: 4.9778 - MAE: 1.8051\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14595/20000 - Train Loss: 0.5706 - Test Loss: 4.9778 - MSE: 4.9778 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14596/20000 - Train Loss: 0.5706 - Test Loss: 4.9776 - MSE: 4.9776 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14597/20000 - Train Loss: 0.5706 - Test Loss: 4.9774 - MSE: 4.9774 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14598/20000 - Train Loss: 0.5706 - Test Loss: 4.9774 - MSE: 4.9774 - MAE: 1.8049\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14599/20000 - Train Loss: 0.5706 - Test Loss: 4.9770 - MSE: 4.9770 - MAE: 1.8049\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14600/20000 - Train Loss: 0.5706 - Test Loss: 4.9771 - MSE: 4.9771 - MAE: 1.8049\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14601/20000 - Train Loss: 0.5705 - Test Loss: 4.9767 - MSE: 4.9767 - MAE: 1.8048\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14602/20000 - Train Loss: 0.5705 - Test Loss: 4.9768 - MSE: 4.9768 - MAE: 1.8048\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14603/20000 - Train Loss: 0.5705 - Test Loss: 4.9765 - MSE: 4.9765 - MAE: 1.8047\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14604/20000 - Train Loss: 0.5705 - Test Loss: 4.9764 - MSE: 4.9764 - MAE: 1.8047\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14605/20000 - Train Loss: 0.5705 - Test Loss: 4.9762 - MSE: 4.9762 - MAE: 1.8047\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14606/20000 - Train Loss: 0.5704 - Test Loss: 4.9761 - MSE: 4.9761 - MAE: 1.8046\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14607/20000 - Train Loss: 0.5704 - Test Loss: 4.9760 - MSE: 4.9760 - MAE: 1.8046\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14608/20000 - Train Loss: 0.5704 - Test Loss: 4.9757 - MSE: 4.9757 - MAE: 1.8046\n",
      "2/2 [==============================] - 0s 54ms/step\n",
      "Epoch 14609/20000 - Train Loss: 0.5704 - Test Loss: 4.9757 - MSE: 4.9757 - MAE: 1.8045\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14610/20000 - Train Loss: 0.5704 - Test Loss: 4.9754 - MSE: 4.9754 - MAE: 1.8045\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14611/20000 - Train Loss: 0.5703 - Test Loss: 4.9754 - MSE: 4.9754 - MAE: 1.8045\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14612/20000 - Train Loss: 0.5703 - Test Loss: 4.9751 - MSE: 4.9751 - MAE: 1.8044\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14613/20000 - Train Loss: 0.5703 - Test Loss: 4.9751 - MSE: 4.9751 - MAE: 1.8044\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14614/20000 - Train Loss: 0.5703 - Test Loss: 4.9748 - MSE: 4.9748 - MAE: 1.8043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14615/20000 - Train Loss: 0.5703 - Test Loss: 4.9748 - MSE: 4.9748 - MAE: 1.8043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14616/20000 - Train Loss: 0.5702 - Test Loss: 4.9745 - MSE: 4.9745 - MAE: 1.8043\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14617/20000 - Train Loss: 0.5702 - Test Loss: 4.9745 - MSE: 4.9745 - MAE: 1.8042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14618/20000 - Train Loss: 0.5702 - Test Loss: 4.9742 - MSE: 4.9742 - MAE: 1.8042\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14619/20000 - Train Loss: 0.5702 - Test Loss: 4.9741 - MSE: 4.9741 - MAE: 1.8042\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14620/20000 - Train Loss: 0.5702 - Test Loss: 4.9739 - MSE: 4.9739 - MAE: 1.8041\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14621/20000 - Train Loss: 0.5701 - Test Loss: 4.9739 - MSE: 4.9739 - MAE: 1.8041\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14622/20000 - Train Loss: 0.5701 - Test Loss: 4.9736 - MSE: 4.9736 - MAE: 1.8040\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14623/20000 - Train Loss: 0.5701 - Test Loss: 4.9736 - MSE: 4.9736 - MAE: 1.8040\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14624/20000 - Train Loss: 0.5701 - Test Loss: 4.9733 - MSE: 4.9733 - MAE: 1.8040\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14625/20000 - Train Loss: 0.5701 - Test Loss: 4.9733 - MSE: 4.9733 - MAE: 1.8040\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14626/20000 - Train Loss: 0.5700 - Test Loss: 4.9730 - MSE: 4.9730 - MAE: 1.8039\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14627/20000 - Train Loss: 0.5700 - Test Loss: 4.9730 - MSE: 4.9730 - MAE: 1.8039\n",
      "2/2 [==============================] - 0s 971us/step\n",
      "Epoch 14628/20000 - Train Loss: 0.5700 - Test Loss: 4.9726 - MSE: 4.9726 - MAE: 1.8038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14629/20000 - Train Loss: 0.5700 - Test Loss: 4.9728 - MSE: 4.9728 - MAE: 1.8038\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14630/20000 - Train Loss: 0.5700 - Test Loss: 4.9723 - MSE: 4.9723 - MAE: 1.8037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14631/20000 - Train Loss: 0.5699 - Test Loss: 4.9725 - MSE: 4.9725 - MAE: 1.8038\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14632/20000 - Train Loss: 0.5699 - Test Loss: 4.9719 - MSE: 4.9719 - MAE: 1.8037\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Epoch 14633/20000 - Train Loss: 0.5699 - Test Loss: 4.9723 - MSE: 4.9723 - MAE: 1.8037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14634/20000 - Train Loss: 0.5699 - Test Loss: 4.9715 - MSE: 4.9715 - MAE: 1.8036\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14635/20000 - Train Loss: 0.5699 - Test Loss: 4.9721 - MSE: 4.9721 - MAE: 1.8036\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14636/20000 - Train Loss: 0.5698 - Test Loss: 4.9711 - MSE: 4.9711 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14637/20000 - Train Loss: 0.5698 - Test Loss: 4.9720 - MSE: 4.9720 - MAE: 1.8036\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14638/20000 - Train Loss: 0.5698 - Test Loss: 4.9706 - MSE: 4.9706 - MAE: 1.8034\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14639/20000 - Train Loss: 0.5698 - Test Loss: 4.9719 - MSE: 4.9719 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14640/20000 - Train Loss: 0.5698 - Test Loss: 4.9701 - MSE: 4.9701 - MAE: 1.8033\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14641/20000 - Train Loss: 0.5697 - Test Loss: 4.9718 - MSE: 4.9718 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14642/20000 - Train Loss: 0.5697 - Test Loss: 4.9695 - MSE: 4.9695 - MAE: 1.8032\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14643/20000 - Train Loss: 0.5697 - Test Loss: 4.9718 - MSE: 4.9718 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14644/20000 - Train Loss: 0.5697 - Test Loss: 4.9688 - MSE: 4.9688 - MAE: 1.8030\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14645/20000 - Train Loss: 0.5697 - Test Loss: 4.9720 - MSE: 4.9720 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14646/20000 - Train Loss: 0.5697 - Test Loss: 4.9679 - MSE: 4.9679 - MAE: 1.8029\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14647/20000 - Train Loss: 0.5696 - Test Loss: 4.9724 - MSE: 4.9724 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14648/20000 - Train Loss: 0.5696 - Test Loss: 4.9668 - MSE: 4.9668 - MAE: 1.8027\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14649/20000 - Train Loss: 0.5696 - Test Loss: 4.9730 - MSE: 4.9730 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14650/20000 - Train Loss: 0.5696 - Test Loss: 4.9653 - MSE: 4.9653 - MAE: 1.8025\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14651/20000 - Train Loss: 0.5696 - Test Loss: 4.9742 - MSE: 4.9742 - MAE: 1.8037\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14652/20000 - Train Loss: 0.5695 - Test Loss: 4.9632 - MSE: 4.9632 - MAE: 1.8021\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14653/20000 - Train Loss: 0.5695 - Test Loss: 4.9762 - MSE: 4.9762 - MAE: 1.8039\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14654/20000 - Train Loss: 0.5695 - Test Loss: 4.9602 - MSE: 4.9602 - MAE: 1.8017\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14655/20000 - Train Loss: 0.5695 - Test Loss: 4.9793 - MSE: 4.9793 - MAE: 1.8043\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14656/20000 - Train Loss: 0.5695 - Test Loss: 4.9557 - MSE: 4.9557 - MAE: 1.8010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14657/20000 - Train Loss: 0.5695 - Test Loss: 4.9844 - MSE: 4.9844 - MAE: 1.8049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14658/20000 - Train Loss: 0.5695 - Test Loss: 4.9489 - MSE: 4.9489 - MAE: 1.8001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14659/20000 - Train Loss: 0.5696 - Test Loss: 4.9925 - MSE: 4.9925 - MAE: 1.8060\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14660/20000 - Train Loss: 0.5697 - Test Loss: 4.9384 - MSE: 4.9384 - MAE: 1.7986\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14661/20000 - Train Loss: 0.5698 - Test Loss: 5.0057 - MSE: 5.0057 - MAE: 1.8077\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14662/20000 - Train Loss: 0.5700 - Test Loss: 4.9222 - MSE: 4.9222 - MAE: 1.7963\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14663/20000 - Train Loss: 0.5704 - Test Loss: 5.0274 - MSE: 5.0274 - MAE: 1.8104\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14664/20000 - Train Loss: 0.5710 - Test Loss: 4.8969 - MSE: 4.8969 - MAE: 1.7926\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14665/20000 - Train Loss: 0.5719 - Test Loss: 5.0632 - MSE: 5.0632 - MAE: 1.8149\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14666/20000 - Train Loss: 0.5734 - Test Loss: 4.8582 - MSE: 4.8582 - MAE: 1.7867\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14667/20000 - Train Loss: 0.5758 - Test Loss: 5.1220 - MSE: 5.1220 - MAE: 1.8220\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14668/20000 - Train Loss: 0.5794 - Test Loss: 4.8027 - MSE: 4.8027 - MAE: 1.7779\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14669/20000 - Train Loss: 0.5847 - Test Loss: 5.2134 - MSE: 5.2134 - MAE: 1.8344\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14670/20000 - Train Loss: 0.5918 - Test Loss: 4.7342 - MSE: 4.7342 - MAE: 1.7691\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14671/20000 - Train Loss: 0.6001 - Test Loss: 5.3296 - MSE: 5.3296 - MAE: 1.8503\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14672/20000 - Train Loss: 0.6074 - Test Loss: 4.6780 - MSE: 4.6780 - MAE: 1.7643\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14673/20000 - Train Loss: 0.6099 - Test Loss: 5.3913 - MSE: 5.3913 - MAE: 1.8584\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14674/20000 - Train Loss: 0.6038 - Test Loss: 4.6888 - MSE: 4.6888 - MAE: 1.7652\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14675/20000 - Train Loss: 0.5902 - Test Loss: 5.2586 - MSE: 5.2586 - MAE: 1.8406\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14676/20000 - Train Loss: 0.5759 - Test Loss: 4.8285 - MSE: 4.8285 - MAE: 1.7819\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14677/20000 - Train Loss: 0.5692 - Test Loss: 4.9857 - MSE: 4.9857 - MAE: 1.8048\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14678/20000 - Train Loss: 0.5721 - Test Loss: 5.0690 - MSE: 5.0690 - MAE: 1.8154\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14679/20000 - Train Loss: 0.5800 - Test Loss: 4.7956 - MSE: 4.7956 - MAE: 1.7765\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14680/20000 - Train Loss: 0.5855 - Test Loss: 5.2204 - MSE: 5.2204 - MAE: 1.8352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14681/20000 - Train Loss: 0.5840 - Test Loss: 4.7702 - MSE: 4.7702 - MAE: 1.7726\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14682/20000 - Train Loss: 0.5770 - Test Loss: 5.1372 - MSE: 5.1372 - MAE: 1.8236\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14683/20000 - Train Loss: 0.5704 - Test Loss: 4.8979 - MSE: 4.8979 - MAE: 1.7924\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14684/20000 - Train Loss: 0.5692 - Test Loss: 4.9357 - MSE: 4.9357 - MAE: 1.7978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14685/20000 - Train Loss: 0.5727 - Test Loss: 5.0809 - MSE: 5.0809 - MAE: 1.8168\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14686/20000 - Train Loss: 0.5767 - Test Loss: 4.8193 - MSE: 4.8193 - MAE: 1.7803\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14687/20000 - Train Loss: 0.5770 - Test Loss: 5.1379 - MSE: 5.1379 - MAE: 1.8235\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14688/20000 - Train Loss: 0.5737 - Test Loss: 4.8476 - MSE: 4.8476 - MAE: 1.7848\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14689/20000 - Train Loss: 0.5699 - Test Loss: 5.0244 - MSE: 5.0244 - MAE: 1.8096\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14690/20000 - Train Loss: 0.5689 - Test Loss: 4.9783 - MSE: 4.9783 - MAE: 1.8036\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14691/20000 - Train Loss: 0.5707 - Test Loss: 4.8893 - MSE: 4.8893 - MAE: 1.7911\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14692/20000 - Train Loss: 0.5728 - Test Loss: 5.0835 - MSE: 5.0835 - MAE: 1.8170\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14693/20000 - Train Loss: 0.5731 - Test Loss: 4.8526 - MSE: 4.8526 - MAE: 1.7855\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14694/20000 - Train Loss: 0.5713 - Test Loss: 5.0576 - MSE: 5.0576 - MAE: 1.8137\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14695/20000 - Train Loss: 0.5693 - Test Loss: 4.9212 - MSE: 4.9212 - MAE: 1.7956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14696/20000 - Train Loss: 0.5687 - Test Loss: 4.9512 - MSE: 4.9512 - MAE: 1.7998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14697/20000 - Train Loss: 0.5697 - Test Loss: 5.0216 - MSE: 5.0216 - MAE: 1.8091\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14698/20000 - Train Loss: 0.5709 - Test Loss: 4.8822 - MSE: 4.8822 - MAE: 1.7899\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14699/20000 - Train Loss: 0.5710 - Test Loss: 5.0520 - MSE: 5.0520 - MAE: 1.8130\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14700/20000 - Train Loss: 0.5700 - Test Loss: 4.8986 - MSE: 4.8986 - MAE: 1.7923\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14701/20000 - Train Loss: 0.5689 - Test Loss: 4.9930 - MSE: 4.9930 - MAE: 1.8053\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14702/20000 - Train Loss: 0.5686 - Test Loss: 4.9710 - MSE: 4.9710 - MAE: 1.8024\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14703/20000 - Train Loss: 0.5691 - Test Loss: 4.9203 - MSE: 4.9203 - MAE: 1.7954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14704/20000 - Train Loss: 0.5698 - Test Loss: 5.0251 - MSE: 5.0251 - MAE: 1.8095\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14705/20000 - Train Loss: 0.5698 - Test Loss: 4.9003 - MSE: 4.9003 - MAE: 1.7925\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14706/20000 - Train Loss: 0.5693 - Test Loss: 5.0113 - MSE: 5.0113 - MAE: 1.8077\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14707/20000 - Train Loss: 0.5687 - Test Loss: 4.9381 - MSE: 4.9381 - MAE: 1.7978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14708/20000 - Train Loss: 0.5685 - Test Loss: 4.9557 - MSE: 4.9557 - MAE: 1.8002\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14709/20000 - Train Loss: 0.5688 - Test Loss: 4.9913 - MSE: 4.9913 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14710/20000 - Train Loss: 0.5691 - Test Loss: 4.9172 - MSE: 4.9172 - MAE: 1.7948\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14711/20000 - Train Loss: 0.5691 - Test Loss: 5.0085 - MSE: 5.0085 - MAE: 1.8072\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14712/20000 - Train Loss: 0.5689 - Test Loss: 4.9239 - MSE: 4.9239 - MAE: 1.7958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14713/20000 - Train Loss: 0.5685 - Test Loss: 4.9802 - MSE: 4.9802 - MAE: 1.8035\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14714/20000 - Train Loss: 0.5684 - Test Loss: 4.9613 - MSE: 4.9613 - MAE: 1.8009\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14715/20000 - Train Loss: 0.5685 - Test Loss: 4.9409 - MSE: 4.9409 - MAE: 1.7981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14716/20000 - Train Loss: 0.5687 - Test Loss: 4.9918 - MSE: 4.9918 - MAE: 1.8050\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14717/20000 - Train Loss: 0.5687 - Test Loss: 4.9259 - MSE: 4.9259 - MAE: 1.7960\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14718/20000 - Train Loss: 0.5686 - Test Loss: 4.9895 - MSE: 4.9895 - MAE: 1.8046\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14719/20000 - Train Loss: 0.5684 - Test Loss: 4.9420 - MSE: 4.9420 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14720/20000 - Train Loss: 0.5683 - Test Loss: 4.9626 - MSE: 4.9626 - MAE: 1.8010\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14721/20000 - Train Loss: 0.5683 - Test Loss: 4.9700 - MSE: 4.9700 - MAE: 1.8020\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14722/20000 - Train Loss: 0.5684 - Test Loss: 4.9386 - MSE: 4.9386 - MAE: 1.7977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14723/20000 - Train Loss: 0.5684 - Test Loss: 4.9843 - MSE: 4.9843 - MAE: 1.8039\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14724/20000 - Train Loss: 0.5684 - Test Loss: 4.9359 - MSE: 4.9359 - MAE: 1.7973\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14725/20000 - Train Loss: 0.5683 - Test Loss: 4.9752 - MSE: 4.9752 - MAE: 1.8026\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14726/20000 - Train Loss: 0.5682 - Test Loss: 4.9521 - MSE: 4.9521 - MAE: 1.7995\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14727/20000 - Train Loss: 0.5682 - Test Loss: 4.9547 - MSE: 4.9547 - MAE: 1.7998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14728/20000 - Train Loss: 0.5682 - Test Loss: 4.9706 - MSE: 4.9706 - MAE: 1.8019\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14729/20000 - Train Loss: 0.5682 - Test Loss: 4.9412 - MSE: 4.9412 - MAE: 1.7979\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14730/20000 - Train Loss: 0.5682 - Test Loss: 4.9760 - MSE: 4.9760 - MAE: 1.8026\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14731/20000 - Train Loss: 0.5681 - Test Loss: 4.9433 - MSE: 4.9433 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14732/20000 - Train Loss: 0.5681 - Test Loss: 4.9664 - MSE: 4.9664 - MAE: 1.8013\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14733/20000 - Train Loss: 0.5680 - Test Loss: 4.9562 - MSE: 4.9562 - MAE: 1.7999\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14734/20000 - Train Loss: 0.5680 - Test Loss: 4.9521 - MSE: 4.9521 - MAE: 1.7993\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14735/20000 - Train Loss: 0.5680 - Test Loss: 4.9678 - MSE: 4.9678 - MAE: 1.8015\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14736/20000 - Train Loss: 0.5680 - Test Loss: 4.9444 - MSE: 4.9444 - MAE: 1.7983\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14737/20000 - Train Loss: 0.5680 - Test Loss: 4.9695 - MSE: 4.9695 - MAE: 1.8017\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14738/20000 - Train Loss: 0.5680 - Test Loss: 4.9475 - MSE: 4.9475 - MAE: 1.7986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14739/20000 - Train Loss: 0.5679 - Test Loss: 4.9617 - MSE: 4.9617 - MAE: 1.8006\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14740/20000 - Train Loss: 0.5679 - Test Loss: 4.9567 - MSE: 4.9567 - MAE: 1.7999\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14741/20000 - Train Loss: 0.5679 - Test Loss: 4.9519 - MSE: 4.9519 - MAE: 1.7992\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14742/20000 - Train Loss: 0.5679 - Test Loss: 4.9641 - MSE: 4.9641 - MAE: 1.8009\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 14743/20000 - Train Loss: 0.5679 - Test Loss: 4.9472 - MSE: 4.9472 - MAE: 1.7985\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14744/20000 - Train Loss: 0.5679 - Test Loss: 4.9647 - MSE: 4.9647 - MAE: 1.8009\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14745/20000 - Train Loss: 0.5678 - Test Loss: 4.9495 - MSE: 4.9495 - MAE: 1.7988\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14746/20000 - Train Loss: 0.5678 - Test Loss: 4.9592 - MSE: 4.9592 - MAE: 1.8001\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14747/20000 - Train Loss: 0.5678 - Test Loss: 4.9557 - MSE: 4.9557 - MAE: 1.7996\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14748/20000 - Train Loss: 0.5678 - Test Loss: 4.9524 - MSE: 4.9524 - MAE: 1.7992\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14749/20000 - Train Loss: 0.5678 - Test Loss: 4.9606 - MSE: 4.9606 - MAE: 1.8003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14750/20000 - Train Loss: 0.5677 - Test Loss: 4.9490 - MSE: 4.9490 - MAE: 1.7987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14751/20000 - Train Loss: 0.5677 - Test Loss: 4.9612 - MSE: 4.9612 - MAE: 1.8003\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14752/20000 - Train Loss: 0.5677 - Test Loss: 4.9502 - MSE: 4.9502 - MAE: 1.7988\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14753/20000 - Train Loss: 0.5677 - Test Loss: 4.9576 - MSE: 4.9576 - MAE: 1.7998\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Epoch 14754/20000 - Train Loss: 0.5677 - Test Loss: 4.9542 - MSE: 4.9542 - MAE: 1.7993\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14755/20000 - Train Loss: 0.5676 - Test Loss: 4.9528 - MSE: 4.9528 - MAE: 1.7991\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14756/20000 - Train Loss: 0.5676 - Test Loss: 4.9578 - MSE: 4.9578 - MAE: 1.7998\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14757/20000 - Train Loss: 0.5676 - Test Loss: 4.9499 - MSE: 4.9499 - MAE: 1.7987\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14758/20000 - Train Loss: 0.5676 - Test Loss: 4.9586 - MSE: 4.9586 - MAE: 1.7999\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14759/20000 - Train Loss: 0.5676 - Test Loss: 4.9501 - MSE: 4.9501 - MAE: 1.7987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14760/20000 - Train Loss: 0.5676 - Test Loss: 4.9565 - MSE: 4.9565 - MAE: 1.7995\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14761/20000 - Train Loss: 0.5675 - Test Loss: 4.9525 - MSE: 4.9525 - MAE: 1.7990\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14762/20000 - Train Loss: 0.5675 - Test Loss: 4.9532 - MSE: 4.9532 - MAE: 1.7991\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Epoch 14763/20000 - Train Loss: 0.5675 - Test Loss: 4.9550 - MSE: 4.9550 - MAE: 1.7993\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14764/20000 - Train Loss: 0.5675 - Test Loss: 4.9507 - MSE: 4.9507 - MAE: 1.7987\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14765/20000 - Train Loss: 0.5675 - Test Loss: 4.9561 - MSE: 4.9561 - MAE: 1.7994\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14766/20000 - Train Loss: 0.5674 - Test Loss: 4.9501 - MSE: 4.9501 - MAE: 1.7986\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14767/20000 - Train Loss: 0.5674 - Test Loss: 4.9552 - MSE: 4.9552 - MAE: 1.7992\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14768/20000 - Train Loss: 0.5674 - Test Loss: 4.9512 - MSE: 4.9512 - MAE: 1.7987\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14769/20000 - Train Loss: 0.5674 - Test Loss: 4.9531 - MSE: 4.9531 - MAE: 1.7989\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14770/20000 - Train Loss: 0.5674 - Test Loss: 4.9529 - MSE: 4.9529 - MAE: 1.7989\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14771/20000 - Train Loss: 0.5674 - Test Loss: 4.9510 - MSE: 4.9510 - MAE: 1.7986\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14772/20000 - Train Loss: 0.5673 - Test Loss: 4.9540 - MSE: 4.9540 - MAE: 1.7990\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14773/20000 - Train Loss: 0.5673 - Test Loss: 4.9499 - MSE: 4.9499 - MAE: 1.7984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14774/20000 - Train Loss: 0.5673 - Test Loss: 4.9539 - MSE: 4.9539 - MAE: 1.7990\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14775/20000 - Train Loss: 0.5673 - Test Loss: 4.9500 - MSE: 4.9500 - MAE: 1.7984\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14776/20000 - Train Loss: 0.5673 - Test Loss: 4.9528 - MSE: 4.9528 - MAE: 1.7988\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14777/20000 - Train Loss: 0.5672 - Test Loss: 4.9508 - MSE: 4.9508 - MAE: 1.7985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14778/20000 - Train Loss: 0.5672 - Test Loss: 4.9513 - MSE: 4.9513 - MAE: 1.7985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14779/20000 - Train Loss: 0.5672 - Test Loss: 4.9517 - MSE: 4.9517 - MAE: 1.7986\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14780/20000 - Train Loss: 0.5672 - Test Loss: 4.9500 - MSE: 4.9500 - MAE: 1.7983\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14781/20000 - Train Loss: 0.5672 - Test Loss: 4.9521 - MSE: 4.9521 - MAE: 1.7986\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14782/20000 - Train Loss: 0.5672 - Test Loss: 4.9495 - MSE: 4.9495 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14783/20000 - Train Loss: 0.5671 - Test Loss: 4.9518 - MSE: 4.9518 - MAE: 1.7985\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14784/20000 - Train Loss: 0.5671 - Test Loss: 4.9495 - MSE: 4.9495 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14785/20000 - Train Loss: 0.5671 - Test Loss: 4.9510 - MSE: 4.9510 - MAE: 1.7984\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14786/20000 - Train Loss: 0.5671 - Test Loss: 4.9499 - MSE: 4.9499 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14787/20000 - Train Loss: 0.5671 - Test Loss: 4.9500 - MSE: 4.9500 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14788/20000 - Train Loss: 0.5670 - Test Loss: 4.9502 - MSE: 4.9502 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14789/20000 - Train Loss: 0.5670 - Test Loss: 4.9493 - MSE: 4.9493 - MAE: 1.7981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14790/20000 - Train Loss: 0.5670 - Test Loss: 4.9502 - MSE: 4.9502 - MAE: 1.7982\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14791/20000 - Train Loss: 0.5670 - Test Loss: 4.9488 - MSE: 4.9488 - MAE: 1.7980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14792/20000 - Train Loss: 0.5670 - Test Loss: 4.9499 - MSE: 4.9499 - MAE: 1.7981\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14793/20000 - Train Loss: 0.5670 - Test Loss: 4.9487 - MSE: 4.9487 - MAE: 1.7980\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14794/20000 - Train Loss: 0.5669 - Test Loss: 4.9494 - MSE: 4.9494 - MAE: 1.7980\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14795/20000 - Train Loss: 0.5669 - Test Loss: 4.9488 - MSE: 4.9488 - MAE: 1.7979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14796/20000 - Train Loss: 0.5669 - Test Loss: 4.9487 - MSE: 4.9487 - MAE: 1.7979\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14797/20000 - Train Loss: 0.5669 - Test Loss: 4.9488 - MSE: 4.9488 - MAE: 1.7979\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14798/20000 - Train Loss: 0.5669 - Test Loss: 4.9482 - MSE: 4.9482 - MAE: 1.7978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14799/20000 - Train Loss: 0.5668 - Test Loss: 4.9486 - MSE: 4.9486 - MAE: 1.7978\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14800/20000 - Train Loss: 0.5668 - Test Loss: 4.9479 - MSE: 4.9479 - MAE: 1.7977\n",
      "2/2 [==============================] - 0s 969us/step\n",
      "Epoch 14801/20000 - Train Loss: 0.5668 - Test Loss: 4.9483 - MSE: 4.9483 - MAE: 1.7978\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14802/20000 - Train Loss: 0.5668 - Test Loss: 4.9477 - MSE: 4.9477 - MAE: 1.7977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14803/20000 - Train Loss: 0.5668 - Test Loss: 4.9480 - MSE: 4.9480 - MAE: 1.7977\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14804/20000 - Train Loss: 0.5667 - Test Loss: 4.9475 - MSE: 4.9475 - MAE: 1.7976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14805/20000 - Train Loss: 0.5667 - Test Loss: 4.9476 - MSE: 4.9476 - MAE: 1.7976\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14806/20000 - Train Loss: 0.5667 - Test Loss: 4.9473 - MSE: 4.9473 - MAE: 1.7975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14807/20000 - Train Loss: 0.5667 - Test Loss: 4.9472 - MSE: 4.9472 - MAE: 1.7975\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14808/20000 - Train Loss: 0.5667 - Test Loss: 4.9471 - MSE: 4.9471 - MAE: 1.7975\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14809/20000 - Train Loss: 0.5667 - Test Loss: 4.9469 - MSE: 4.9469 - MAE: 1.7974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14810/20000 - Train Loss: 0.5666 - Test Loss: 4.9469 - MSE: 4.9469 - MAE: 1.7974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14811/20000 - Train Loss: 0.5666 - Test Loss: 4.9465 - MSE: 4.9465 - MAE: 1.7974\n",
      "2/2 [==============================] - 0s 25ms/step\n",
      "Epoch 14812/20000 - Train Loss: 0.5666 - Test Loss: 4.9467 - MSE: 4.9467 - MAE: 1.7974\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14813/20000 - Train Loss: 0.5666 - Test Loss: 4.9461 - MSE: 4.9462 - MAE: 1.7973\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14814/20000 - Train Loss: 0.5666 - Test Loss: 4.9464 - MSE: 4.9464 - MAE: 1.7973\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Epoch 14815/20000 - Train Loss: 0.5665 - Test Loss: 4.9459 - MSE: 4.9459 - MAE: 1.7972\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14816/20000 - Train Loss: 0.5665 - Test Loss: 4.9461 - MSE: 4.9461 - MAE: 1.7972\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14817/20000 - Train Loss: 0.5665 - Test Loss: 4.9457 - MSE: 4.9457 - MAE: 1.7972\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14818/20000 - Train Loss: 0.5665 - Test Loss: 4.9457 - MSE: 4.9457 - MAE: 1.7971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14819/20000 - Train Loss: 0.5665 - Test Loss: 4.9454 - MSE: 4.9454 - MAE: 1.7971\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14820/20000 - Train Loss: 0.5665 - Test Loss: 4.9454 - MSE: 4.9454 - MAE: 1.7971\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14821/20000 - Train Loss: 0.5664 - Test Loss: 4.9451 - MSE: 4.9451 - MAE: 1.7970\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14822/20000 - Train Loss: 0.5664 - Test Loss: 4.9451 - MSE: 4.9451 - MAE: 1.7970\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14823/20000 - Train Loss: 0.5664 - Test Loss: 4.9449 - MSE: 4.9449 - MAE: 1.7970\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14824/20000 - Train Loss: 0.5664 - Test Loss: 4.9447 - MSE: 4.9447 - MAE: 1.7969\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14825/20000 - Train Loss: 0.5664 - Test Loss: 4.9448 - MSE: 4.9448 - MAE: 1.7969\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14826/20000 - Train Loss: 0.5663 - Test Loss: 4.9443 - MSE: 4.9443 - MAE: 1.7968\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14827/20000 - Train Loss: 0.5663 - Test Loss: 4.9446 - MSE: 4.9446 - MAE: 1.7968\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14828/20000 - Train Loss: 0.5663 - Test Loss: 4.9440 - MSE: 4.9440 - MAE: 1.7967\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14829/20000 - Train Loss: 0.5663 - Test Loss: 4.9443 - MSE: 4.9443 - MAE: 1.7968\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Epoch 14830/20000 - Train Loss: 0.5663 - Test Loss: 4.9437 - MSE: 4.9437 - MAE: 1.7967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14831/20000 - Train Loss: 0.5663 - Test Loss: 4.9440 - MSE: 4.9440 - MAE: 1.7967\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14832/20000 - Train Loss: 0.5662 - Test Loss: 4.9434 - MSE: 4.9434 - MAE: 1.7966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14833/20000 - Train Loss: 0.5662 - Test Loss: 4.9437 - MSE: 4.9437 - MAE: 1.7966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14834/20000 - Train Loss: 0.5662 - Test Loss: 4.9432 - MSE: 4.9432 - MAE: 1.7965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14835/20000 - Train Loss: 0.5662 - Test Loss: 4.9433 - MSE: 4.9433 - MAE: 1.7965\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14836/20000 - Train Loss: 0.5662 - Test Loss: 4.9430 - MSE: 4.9430 - MAE: 1.7965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14837/20000 - Train Loss: 0.5661 - Test Loss: 4.9430 - MSE: 4.9430 - MAE: 1.7965\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14838/20000 - Train Loss: 0.5661 - Test Loss: 4.9427 - MSE: 4.9427 - MAE: 1.7964\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Epoch 14839/20000 - Train Loss: 0.5661 - Test Loss: 4.9427 - MSE: 4.9427 - MAE: 1.7964\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14840/20000 - Train Loss: 0.5661 - Test Loss: 4.9425 - MSE: 4.9425 - MAE: 1.7963\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Epoch 14841/20000 - Train Loss: 0.5661 - Test Loss: 4.9423 - MSE: 4.9423 - MAE: 1.7963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14842/20000 - Train Loss: 0.5660 - Test Loss: 4.9423 - MSE: 4.9423 - MAE: 1.7963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14843/20000 - Train Loss: 0.5660 - Test Loss: 4.9420 - MSE: 4.9420 - MAE: 1.7962\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14844/20000 - Train Loss: 0.5660 - Test Loss: 4.9421 - MSE: 4.9421 - MAE: 1.7962\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14845/20000 - Train Loss: 0.5660 - Test Loss: 4.9416 - MSE: 4.9416 - MAE: 1.7961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14846/20000 - Train Loss: 0.5660 - Test Loss: 4.9418 - MSE: 4.9418 - MAE: 1.7962\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14847/20000 - Train Loss: 0.5660 - Test Loss: 4.9413 - MSE: 4.9413 - MAE: 1.7961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14848/20000 - Train Loss: 0.5659 - Test Loss: 4.9416 - MSE: 4.9416 - MAE: 1.7961\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14849/20000 - Train Loss: 0.5659 - Test Loss: 4.9410 - MSE: 4.9410 - MAE: 1.7960\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14850/20000 - Train Loss: 0.5659 - Test Loss: 4.9413 - MSE: 4.9413 - MAE: 1.7960\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14851/20000 - Train Loss: 0.5659 - Test Loss: 4.9407 - MSE: 4.9407 - MAE: 1.7959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14852/20000 - Train Loss: 0.5659 - Test Loss: 4.9410 - MSE: 4.9410 - MAE: 1.7959\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14853/20000 - Train Loss: 0.5658 - Test Loss: 4.9404 - MSE: 4.9404 - MAE: 1.7958\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14854/20000 - Train Loss: 0.5658 - Test Loss: 4.9407 - MSE: 4.9407 - MAE: 1.7959\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14855/20000 - Train Loss: 0.5658 - Test Loss: 4.9401 - MSE: 4.9401 - MAE: 1.7958\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14856/20000 - Train Loss: 0.5658 - Test Loss: 4.9405 - MSE: 4.9405 - MAE: 1.7958\n",
      "2/2 [==============================] - 0s 972us/step\n",
      "Epoch 14857/20000 - Train Loss: 0.5658 - Test Loss: 4.9398 - MSE: 4.9398 - MAE: 1.7957\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14858/20000 - Train Loss: 0.5658 - Test Loss: 4.9402 - MSE: 4.9402 - MAE: 1.7957\n",
      "2/2 [==============================] - 0s 970us/step\n",
      "Epoch 14859/20000 - Train Loss: 0.5657 - Test Loss: 4.9395 - MSE: 4.9395 - MAE: 1.7956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14860/20000 - Train Loss: 0.5657 - Test Loss: 4.9400 - MSE: 4.9400 - MAE: 1.7957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14861/20000 - Train Loss: 0.5657 - Test Loss: 4.9391 - MSE: 4.9391 - MAE: 1.7955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14862/20000 - Train Loss: 0.5657 - Test Loss: 4.9398 - MSE: 4.9398 - MAE: 1.7956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14863/20000 - Train Loss: 0.5657 - Test Loss: 4.9387 - MSE: 4.9387 - MAE: 1.7954\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14864/20000 - Train Loss: 0.5656 - Test Loss: 4.9396 - MSE: 4.9396 - MAE: 1.7956\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14865/20000 - Train Loss: 0.5656 - Test Loss: 4.9382 - MSE: 4.9382 - MAE: 1.7954\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14866/20000 - Train Loss: 0.5656 - Test Loss: 4.9395 - MSE: 4.9395 - MAE: 1.7955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14867/20000 - Train Loss: 0.5656 - Test Loss: 4.9377 - MSE: 4.9377 - MAE: 1.7952\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14868/20000 - Train Loss: 0.5656 - Test Loss: 4.9396 - MSE: 4.9396 - MAE: 1.7955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14869/20000 - Train Loss: 0.5655 - Test Loss: 4.9370 - MSE: 4.9370 - MAE: 1.7951\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14870/20000 - Train Loss: 0.5655 - Test Loss: 4.9397 - MSE: 4.9397 - MAE: 1.7955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14871/20000 - Train Loss: 0.5655 - Test Loss: 4.9362 - MSE: 4.9362 - MAE: 1.7950\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14872/20000 - Train Loss: 0.5655 - Test Loss: 4.9401 - MSE: 4.9401 - MAE: 1.7955\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14873/20000 - Train Loss: 0.5655 - Test Loss: 4.9352 - MSE: 4.9352 - MAE: 1.7948\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14874/20000 - Train Loss: 0.5655 - Test Loss: 4.9407 - MSE: 4.9407 - MAE: 1.7955\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14875/20000 - Train Loss: 0.5654 - Test Loss: 4.9337 - MSE: 4.9337 - MAE: 1.7946\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14876/20000 - Train Loss: 0.5654 - Test Loss: 4.9418 - MSE: 4.9418 - MAE: 1.7957\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14877/20000 - Train Loss: 0.5654 - Test Loss: 4.9317 - MSE: 4.9317 - MAE: 1.7943\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14878/20000 - Train Loss: 0.5654 - Test Loss: 4.9437 - MSE: 4.9437 - MAE: 1.7959\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14879/20000 - Train Loss: 0.5654 - Test Loss: 4.9288 - MSE: 4.9288 - MAE: 1.7938\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14880/20000 - Train Loss: 0.5654 - Test Loss: 4.9468 - MSE: 4.9468 - MAE: 1.7963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14881/20000 - Train Loss: 0.5654 - Test Loss: 4.9244 - MSE: 4.9244 - MAE: 1.7932\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14882/20000 - Train Loss: 0.5654 - Test Loss: 4.9517 - MSE: 4.9517 - MAE: 1.7969\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14883/20000 - Train Loss: 0.5654 - Test Loss: 4.9177 - MSE: 4.9177 - MAE: 1.7922\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Epoch 14884/20000 - Train Loss: 0.5654 - Test Loss: 4.9598 - MSE: 4.9598 - MAE: 1.7979\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14885/20000 - Train Loss: 0.5655 - Test Loss: 4.9073 - MSE: 4.9073 - MAE: 1.7907\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14886/20000 - Train Loss: 0.5657 - Test Loss: 4.9730 - MSE: 4.9730 - MAE: 1.7997\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14887/20000 - Train Loss: 0.5659 - Test Loss: 4.8911 - MSE: 4.8911 - MAE: 1.7884\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14888/20000 - Train Loss: 0.5662 - Test Loss: 4.9948 - MSE: 4.9948 - MAE: 1.8025\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Epoch 14889/20000 - Train Loss: 0.5669 - Test Loss: 4.8656 - MSE: 4.8656 - MAE: 1.7846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14890/20000 - Train Loss: 0.5678 - Test Loss: 5.0311 - MSE: 5.0311 - MAE: 1.8071\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14891/20000 - Train Loss: 0.5694 - Test Loss: 4.8263 - MSE: 4.8263 - MAE: 1.7787\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14892/20000 - Train Loss: 0.5719 - Test Loss: 5.0913 - MSE: 5.0913 - MAE: 1.8144\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14893/20000 - Train Loss: 0.5757 - Test Loss: 4.7696 - MSE: 4.7696 - MAE: 1.7695\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14894/20000 - Train Loss: 0.5813 - Test Loss: 5.1859 - MSE: 5.1859 - MAE: 1.8277\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "Epoch 14895/20000 - Train Loss: 0.5888 - Test Loss: 4.6995 - MSE: 4.6995 - MAE: 1.7619\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14896/20000 - Train Loss: 0.5977 - Test Loss: 5.3065 - MSE: 5.3065 - MAE: 1.8443\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14897/20000 - Train Loss: 0.6054 - Test Loss: 4.6431 - MSE: 4.6431 - MAE: 1.7570\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14898/20000 - Train Loss: 0.6075 - Test Loss: 5.3672 - MSE: 5.3672 - MAE: 1.8525\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14899/20000 - Train Loss: 0.6004 - Test Loss: 4.6574 - MSE: 4.6574 - MAE: 1.7583\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14900/20000 - Train Loss: 0.5855 - Test Loss: 5.2202 - MSE: 5.2202 - MAE: 1.8325\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Epoch 14901/20000 - Train Loss: 0.5708 - Test Loss: 4.8073 - MSE: 4.8073 - MAE: 1.7755\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Epoch 14902/20000 - Train Loss: 0.5649 - Test Loss: 4.9370 - MSE: 4.9370 - MAE: 1.7946\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Epoch 14903/20000 - Train Loss: 0.5692 - Test Loss: 5.0568 - MSE: 5.0568 - MAE: 1.8100\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14904/20000 - Train Loss: 0.5778 - Test Loss: 4.7528 - MSE: 4.7528 - MAE: 1.7669\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "Epoch 14905/20000 - Train Loss: 0.5826 - Test Loss: 5.1974 - MSE: 5.1974 - MAE: 1.8292\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Epoch 14906/20000 - Train Loss: 0.5796 - Test Loss: 4.7418 - MSE: 4.7418 - MAE: 1.7655\n",
      "1/2 [==============>...............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from evaluate_ts import evaluate_ts\n",
    "from tools import fetch_cosine_values, format_dataset, fetch_stock_price\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.random.set_seed(101)\n",
    "\n",
    "symbol = \"MSFT\"\n",
    "feat_dimension = 20\n",
    "train_size = 252\n",
    "test_size = 252 - feat_dimension\n",
    "\n",
    "# 텐서플로우 매개변수 정의\n",
    "learning_rate = 0.5\n",
    "optimizer = tf.keras.optimizers.Adam\n",
    "n_epochs = 20000\n",
    "\n",
    "# 주가를 가져와 훈련 데이터와 테스트 데이터를 분할\n",
    "stock_values = fetch_stock_price(symbol, datetime.date(2017, 1, 1), datetime.date(2018, 12, 31))\n",
    "minibatch_cos_X, minibatch_cos_y = format_dataset(stock_values, feat_dimension)\n",
    "train_X = minibatch_cos_X[:train_size, :].astype(np.float32)\n",
    "train_y = minibatch_cos_y[:train_size].reshape((-1, 1)).astype(np.float32)\n",
    "test_X = minibatch_cos_X[train_size:, :].astype(np.float32)\n",
    "test_y = minibatch_cos_y[train_size:].reshape((-1, 1)).astype(np.float32)\n",
    "\n",
    "# Define the regression model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1, input_shape=(feat_dimension,)))\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = optimizer(learning_rate)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn)\n",
    "\n",
    "# Perform training\n",
    "mse_values = []\n",
    "mae_values = []\n",
    "for epoch in range(n_epochs):\n",
    "    model.fit(train_X, train_y, batch_size=train_size, verbose=0)\n",
    "    train_loss = model.evaluate(train_X, train_y, verbose=0)\n",
    "    test_loss = model.evaluate(test_X, test_y, verbose=0)\n",
    "    y_pred = model.predict(test_X)\n",
    "    mse = np.mean((y_pred - test_y) ** 2)\n",
    "    mae = np.mean(np.abs(y_pred - test_y))\n",
    "    mse_values.append(mse)\n",
    "    mae_values.append(mae)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f} - MSE: {mse:.4f} - MAE: {mae:.4f}\")\n",
    "\n",
    "# Evaluate on test dataset\n",
    "test_loss = model.evaluate(test_X, test_y)\n",
    "y_pred = model.predict(test_X)\n",
    "\n",
    "# Evaluate the results\n",
    "evaluate_ts(test_X, test_y, y_pred)\n",
    "\n",
    "# Plot the predicted and true values\n",
    "plt.plot(range(len(cos_values)), cos_values, 'b')\n",
    "plt.plot(range(len(cos_values) - test_size, len(cos_values)), y_pred, 'r--')\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Predicted and true values\")\n",
    "plt.title(\"Predicted (Red) VS Real (Blue)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 위와 동일한 모델을 적용하여 주가에 적용해본다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
