{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Project Comprehensive\n",
    "\n",
    "> - 본 문서는 UpbitAnalyzer 프로젝트의 데이터 분석 종합본입니다.\n",
    "> - 본 프로젝트에 활용한 데이터 분석에 관한 개괄적인 내용과 분석 기법, 유용한 링크 등을 포함합니다.\n",
    "> - 프로젝트는 데이터 분석에 대한 별도의 [`README.md`](../README.md)를 포함하고 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분석 노트\n",
    "\n",
    "> 아래의 내용은 본 프로젝트에 활용하는 데이터분석 기법에 대한 내용을 서술하고 있습니다. `.ipynb`를 포함하는 실제 데이터분석은 별도의 파일에서 실행됩니다.\n",
    "\n",
    "1. 상관관계 분석 for Conv2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful Links and References\n",
    "\n",
    "- [Convolutional Neural Networks, Explained](https://towardsdatascience.com/convolutional-neural-networks-explained-9cc5188c4939)\n",
    "- [Tistory: CNN 설명](https://rubber-tree.tistory.com/entry/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-CNN-Convolutional-Neural-Network-%EC%84%A4%EB%AA%85)\n",
    "- [Tistory: Pdding은 무엇인가?](https://supermemi.tistory.com/entry/CNN-Padding-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80)\n",
    "- [Deep Learing Fundarmentals: Zero Padding In Convolutional Neural Networks Explained](https://deeplizard.com/learn/video/qSTv_m-KFk0)\n",
    "\n",
    "---\n",
    "\n",
    "- [Github: Deep Learning for Cryptocurrency Price Prediction](https://github.com/khuangaf/CryptocurrencyPrediction/tree/master)\n",
    "- [Medium: Predicting Cryptocurrency Price With Tensorflow and Keras](https://medium.com/@huangkh19951228/predicting-cryptocurrency-price-with-tensorflow-and-keras-e1674b0dc58a)\n",
    "- [MRC-LSTM: A Hybrid Approach of Multi-scale Residual CNN and LSTM to Predict Bitcoin Price](../docs/MRC-LSTM_A_Hybrid_Approach_of_Multi-scale_Residual_CNN%20and_LSTM_to_Predict_Bitcoin_Price.pdf)\n",
    "- [A Comparative Study of Bitcoin Price Prediction Using Deep Learning](../docs/A_Comparative_Study_of_Bitcoin_Price_Prediction_Us.pdf)\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Layer Structure\n",
    "\n",
    "![cnn's structure](../assets/cnn_layer_structure.png)\n",
    "\n",
    "<!--\n",
    "//FIXME: CNN의 전체 과정을 레이어, 학습, 역전파, loss, 모델, 예측 등을 주요 키워드를 포함하여 간략히 입력. 개요처럼, 본 문서에서 cnn 과정에 대한 이해를 도울 수 있도록.\n",
    "-->\n",
    "\n",
    "## CNN Processing\n",
    "\n",
    "1. Input Data\n",
    "  - prepocessing\n",
    "  - normalization\n",
    "2. Convolution Layer\n",
    "  - filters\n",
    "3. Activation Layer\n",
    "  - ReLU(Rectified Linear Unit): 대표적인 활성화 함수\n",
    "4. Pooliong Layer\n",
    "  - max pooling\n",
    "5. Fully Connected Layer\n",
    "  - flatten\n",
    "6. 출력값 연산: fc의 출력값을 softmax함수에 넘겨 각 클래스에 대한 확률 값 계산\n",
    "7. Learning\n",
    "  - Backpropagation Algoritm\n",
    "8. Prediction\n",
    "9. Fine-tuning: 미리 학습된 모델의 일부 레이어 동결, 나머지 층의 가중치 조정\n",
    "  - 적은 양의 데이터에도 학습 가능\n",
    "10. Adjustment Hyperparameter\n",
    "11. Model 평가, 저장 배포"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fc vs cnn](../assets/cnn_layer_structure_vs_fully.png \"완전연결계층(Full Connected Layer)과 합성곱계층\")\n",
    "\n",
    "<!-- //FIXME: 아래 목록으로 단순하게 위 이미지를 설명할 수 없음  -->\n",
    "- INPUT: 하나의 컬러 이미지는 3차원 데이터이다.\n",
    "- Feature Learning: batch mode에서 사용되는 여러 장의 사진은 4차원 데이터이다(정육면체).\n",
    "- 이미지를 fully-connected 신경망 학습에 활용할 경우, 3차원 데이터를 1차원으로 평면화 시켜야 한다.\n",
    "- 일반적으로 위 과정에서 공간정보가 손실되나, CNN은 공간정보를 유지한 상태로 학습이 가능하다.\n",
    "\n",
    "### 1. Convolution Layer\n",
    "\n",
    "![cnn input data shape](../assets/conv_layer_input_data.png \"Conv Layer의 입출력 데이터 형상\")\n",
    "\n",
    "Input(이미지) 데이터는 (height x width x channel)의 3차원 tensor로 표현될 수 있습니다. 이미지의 색상이 rgb 코드로 표현되어 있다면 채널의 크기는 3, 각 채널에는 r, g, b 값이 저장됩니다.\n",
    "convolution layer는 입력 이미지에 filter를 적용해 특징을 추출합니다. filter를 이용해 입력 이미지를 sliding window 형태로 훑어가면서 feature map이라는 특징 추출 결과를 반환합니다. 경우에 따라 여러 filter를 사용해 다양한 특징을 추출하기도 합니다.\n",
    "\n",
    "> CNN 이전의 FC(완전연결계층)은 모두 연산에 대한 입력으로서 평탄화된 1차원 데이터로 변환되었으나, CNN은 feature map을 활용해 연산에 대한 입력과 출력 모두 형상을 유지한다. 이것이 cnn이 이미지 데이터에 대한 처리에 효과적인 이유이며, \n",
    "\n",
    "### 2. filter\n",
    "\n",
    "![cnn's filter](../assets/cnn_filter.png)\n",
    "\n",
    "cnn의 filter는 cnn이 입력 데이터의 지역정보를 고려해 특징을 추출하기 위해 사용되는 중요한 요소입니다. 일반적으로 작은 직사각형 형태로 이루어져 있고, sliding window 형태로 활용됩니다.\n",
    "cnn에서 filter는 자동으로 학습됩니다. 즉, 초기에는 무작위로 초기화된 filter를 사용하지만, 역적파 알고리즘(backpropagation)을 이용해 filter의 가중치(weight)를 학습하면서 최적의 filter를 자동으로 찾아냅니다.\n",
    "\n",
    "예를 들어, 이미지 분류 문제에서 convolution layer에서 여러 개의 filter를 사용해 입력 이미지의 다양한 특징을 추출하려고 할 때, 각 filter는 입력 이미지의 특정 부분에서만 반응하고, 이러한 반응 패턴은 filter의 가중치를 조정하면서 자동으로 학습 됩니다. 이러한 filter는 이미지에서 특정 패턴을 인식하는데 사용됩니다.\n",
    "\n",
    "또한, filter의 크기, stride, padding 등의 하이퍼파라미터를 조정해 filter의 특성을 변경할 수도 있습니다. 이때, filter의 크기는 입력 이미지에서 추출하려는 특징의 크기와 관련 있으며, stride는 필터를 적용하는 간격을, padding은 입력 이미지의 가장자리 부분에서 필터를 적용할 때 생기는 정보 손실을 방지하는 데 사용됩니다.\n",
    "\n",
    "### 3. padding\n",
    "\n",
    "padding은 conv 연산을 수행하기 전, 입력 데이터 주변을 특정 값으로 채워 늘리는 것을 의미합니다. padding은 주로 출력 데이터의 공간적 크기(spatial)를 조절하기 위해 사용됩니다. 하이퍼파라미터로 어떤 값을 채울지도 정할 수 있습니다(주로 zero-padding 사용).\n",
    "\n",
    "> 즉, 입력데이터의 크기(spatial)가 conv layer를 지날 때 마다 가장자리의 정보들이 손실되는 것을 방지하기 위해 사용됩니다.\n",
    "\n",
    "### 4. stride\n",
    "\n",
    "앞서 언급했듯이, stride는 입력 데이터에 필터를 적용할 때 이동할 간격을 조절해야 합니다. 이 간격을 stride라고 하며, 이 stride는 출력 데이터의 크기를 조절하는데 사용됩니다.\n",
    "\n",
    "일반적으로 stride는 1과 같이 작은 값일 수록 더 잘 작동됩니다. 다만, 1일 경우 입력 데이터의 크기는 pooling layer에서만 조절하게 할 수 있습니다.\n",
    "\n",
    "![cnn's stride and 0 padding](../assets/cnn_stride.gif \"CNN의 zero-padding, stride=1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. pooling layer\n",
    "\n",
    "이미지의 크기를 유지한 채, fully connected layer로 가게 된다면 연산량이 기하급수적으로 증가할텐데, 이때, 적당히 크기도 줄이고, 특정 feature를 강조하기 위해 pooling layer를 사용합니다.\n",
    "\n",
    "#### Max Pooling\n",
    "\n",
    "cnn에서는 주로 뉴런이 가장 큰 신호에 반응하는 것과 유사한 max pooling을 사용합니다. 이는 노이즈 감소, 연산 속도 증가, 분별력 향상을 위한 좋은 전략입니다.\n",
    "\n",
    "![cnn pooling layer: max pooling](../assets/cnn_max_pooling.png)\n",
    "\n",
    "이미지의 특징은, 인접 픽셀 간 유사도가 매우 높다는 것 입니다. 때무에 이미지는 픽셀 수준이 아니라, 특정 속성을 갖는 \"선택 영역\" 수준으로 표현될 수 있습니다. pooling layer는 이미지의 이러하 특징을 바탕으로 설계되었습니다. 그리고 max-pooing은 선택 영역에서 가장 큰 값을 해당 영역의 대표 값으로 설정하는 것과 같은 것입니다.\n",
    "\n",
    "- 선택 영역 내부에서 데이터(이미지의 경우 픽셀)들이 이동, 회전 등 변경: pooling layer는 이러한 데이터의 변경으로 cnn의 출력이 영향을 받는 문제를 완화시킵니다.\n",
    "- 속도 향상, overfitting 완화: pooling layer는 cnn이 처리한 데이터의 크기가 크게 줄어들어 model parameter 또한 크게 감소하게 합니다. 따라서 cnn의 학습 시간을 절약시키고, overfitting 문제 또한 어느정도 완화시킬 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Layer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "** \n",
    "-->\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMpNobSqGMsm6+kO4LODD7F",
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "17ZE5htR9MNkKX3xQPjtiC2_LsvHfGVW5",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
